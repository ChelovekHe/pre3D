{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set config\n",
      "load symbol\n",
      "num_images 3424\n",
      "kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import logging\n",
    "import os\n",
    "import pprint\n",
    "import mxnet as mx\n",
    "import numpy as np\n",
    "\n",
    "from rcnn.dataset import *\n",
    "from rcnn.core import callback, metric\n",
    "from rcnn.core.loader import AnchorLoader\n",
    "from rcnn.core.module import MutableModule\n",
    "from rcnn.utils.load_model import load_param\n",
    "from rcnn.symbol.symbol_vgg import *\n",
    "from rcnn.config import config\n",
    "# set up logger\n",
    "logging.basicConfig()\n",
    "logger = logging.getLogger()\n",
    "logger.setLevel(logging.INFO)\n",
    "\n",
    "print 'set config'\n",
    "# setup config\n",
    "config.TRAIN.BATCH_IMAGES = 1\n",
    "config.TRAIN.BATCH_ROIS = 128\n",
    "config.TRAIN.END2END = True\n",
    "config.TRAIN.BBOX_3D = True\n",
    "config.TRAIN.BBOX_NORMALIZATION_PRECOMPUTED = True\n",
    "config.TRAIN.BG_THRESH_LO = 0.0\n",
    "\n",
    "print 'load symbol'\n",
    "# load symbol\n",
    "sym = eval('get_vgg_train')()\n",
    "feat_sym = sym.get_internals()['rpn_cls_score_output']\n",
    "\n",
    "ctx=[mx.gpu(4)]\n",
    "batch_size = len(ctx)\n",
    "input_batch_size = config.TRAIN.BATCH_IMAGES * batch_size\n",
    "# pprint.pprint(config)\n",
    "imdb = eval('Kitti')('val', 'data', 'data/kitti')\n",
    "roidb=imdb.gt_roidb()\n",
    "\n",
    "train_data = AnchorLoader(feat_sym, roidb, batch_size=input_batch_size, shuffle=True,\n",
    "                              ctx=ctx, work_load_list=None)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]\n"
     ]
    }
   ],
   "source": [
    "# infer max shape\n",
    "max_data_shape = [('data', (input_batch_size, 3, 1000, 1000))]\n",
    "max_data_shape, max_label_shape = train_data.infer_shape(max_data_shape)\n",
    "max_data_shape.append(('gt_boxes', (input_batch_size, 100, 5)))\n",
    "max_data_shape.append(('gt_boxes', (input_batch_size, 100, 5)))\n",
    "print 'providing maximum shape', max_data_shape, max_label_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# infer max shape\n",
    "max_data_shape = [('data', (input_batch_size, 3, 1000, 1000))]\n",
    "max_data_shape, max_label_shape = train_data.infer_shape(max_data_shape)\n",
    "max_data_shape.append(('gt_boxes', (input_batch_size, 100, 5)))\n",
    "print 'providing maximum shape', max_data_shape, max_label_shape\n",
    "arg_params, aux_params = load_param('/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg', 20, convert=True)\n",
    "# infer shape\n",
    "data_shape_dict = dict(train_data.provide_data + train_data.provide_label)\n",
    "sym.list_outputs()\n",
    "arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)\n",
    "arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)\n",
    "arg_shape_dict = dict(zip(sym.list_arguments(), arg_shape))\n",
    "out_shape_dict = dict(zip(sym.list_outputs(), out_shape))\n",
    "aux_shape_dict = dict(zip(sym.list_auxiliary_states(), aux_shape))\n",
    "print 'output shape'\n",
    "pprint.pprint(out_shape_dict)\n",
    "# print 'arg shape'\n",
    "# pprint.pprint(arg_shape_dict)\n",
    "# print 'aux shape'\n",
    "# pprint.pprint(aux_shape_dict)\n",
    "# initialize params\n",
    "arg_params['fc6_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_weight'])\n",
    "arg_params['fc6_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc6_bias'])\n",
    "arg_params['fc7_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc7_weight'])\n",
    "arg_params['fc7_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc7_bias'])\n",
    "\n",
    "# initial 3D BBOX estimation\n",
    "if config.TRAIN.BBOX_3D: \n",
    "    arg_params['fc6_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_dim_weight'])\n",
    "    arg_params['fc6_dim_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc6_dim_bias'])\n",
    "    arg_params['fc6_angle_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_angle_weight'])\n",
    "    arg_params['fc6_angle_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc6_angle_bias'])\n",
    "    arg_params['fc6_conf_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_conf_weight'])\n",
    "    arg_params['fc6_conf_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc6_conf_bias'])\n",
    "\n",
    "    arg_params['fc7_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc7_dim_weight'])\n",
    "    arg_params['fc7_dim_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc7_dim_bias'])\n",
    "    arg_params['fc7_angle_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc7_angle_weight'])\n",
    "    arg_params['fc7_angle_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc7_angle_bias'])\n",
    "    arg_params['fc7_conf_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc7_conf_weight'])\n",
    "    arg_params['fc7_conf_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc7_conf_bias'])\n",
    "\n",
    "    arg_params['fc8_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_dim_weight'])\n",
    "    arg_params['fc8_dim_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc8_dim_bias'])\n",
    "    arg_params['fc8_angle_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_angle_weight'])\n",
    "    arg_params['fc8_angle_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc8_angle_bias'])\n",
    "    arg_params['fc8_conf_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_conf_weight'])\n",
    "    arg_params['fc8_conf_bias'] = mx.nd.zeros(shape=arg_shape_dict['fc8_conf_bias'])\n",
    "\n",
    "arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])\n",
    "arg_params['rpn_conv_3x3_bias'] = mx.nd.zeros(shape=arg_shape_dict['rpn_conv_3x3_bias'])\n",
    "arg_params['rpn_cls_score_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_cls_score_weight'])\n",
    "arg_params['rpn_cls_score_bias'] = mx.nd.zeros(shape=arg_shape_dict['rpn_cls_score_bias'])\n",
    "arg_params['rpn_bbox_pred_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_bbox_pred_weight'])\n",
    "arg_params['rpn_bbox_pred_bias'] = mx.nd.zeros(shape=arg_shape_dict['rpn_bbox_pred_bias'])\n",
    "arg_params['cls_score_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['cls_score_weight'])\n",
    "arg_params['cls_score_bias'] = mx.nd.zeros(shape=arg_shape_dict['cls_score_bias'])\n",
    "arg_params['bbox_pred_weight'] = mx.random.normal(0, 0.001, shape=arg_shape_dict['bbox_pred_weight'])\n",
    "arg_params['bbox_pred_bias'] = mx.nd.zeros(shape=arg_shape_dict['bbox_pred_bias'])\n",
    "\n",
    "# check parameter shapes\n",
    "for k in sym.list_arguments():\n",
    "    if k in data_shape_dict:\n",
    "        continue\n",
    "    assert k in arg_params, k + ' not initialized'\n",
    "    assert arg_params[k].shape == arg_shape_dict[k], \\\n",
    "        'shape inconsistent for ' + k + ' inferred ' + str(arg_shape_dict[k]) + ' provided ' + str(arg_params[k].shape)\n",
    "for k in sym.list_auxiliary_states():\n",
    "    assert k in aux_params, k + ' not initialized'\n",
    "    assert aux_params[k].shape == aux_shape_dict[k], \\\n",
    "        'shape inconsistent for ' + k + ' inferred ' + str(aux_shape_dict[k]) + ' provided ' + str(aux_params[k].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create solver\n",
    "fixed_param_prefix = ['conv1', 'conv2']\n",
    "data_names = [k[0] for k in train_data.provide_data]\n",
    "label_names = [k[0] for k in train_data.provide_label]\n",
    "mod = MutableModule(sym, data_names=data_names, label_names=label_names,\n",
    "                    logger=logger, context=ctx, work_load_list=None,\n",
    "                    max_data_shapes=max_data_shape, max_label_shapes=max_label_shape,\n",
    "                    fixed_param_prefix=fixed_param_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# decide training params\n",
    "# metric\n",
    "rpn_eval_metric = metric.RPNAccMetric()\n",
    "rpn_cls_metric = metric.RPNLogLossMetric()\n",
    "rpn_bbox_metric = metric.RPNL1LossMetric()\n",
    "\n",
    "eval_metric = metric.RCNNAccMetric()\n",
    "cls_metric = metric.RCNNLogLossMetric()\n",
    "bbox_metric = metric.RCNNL1LossMetric()\n",
    "eval_metrics = mx.metric.CompositeEvalMetric()\n",
    "\n",
    "if config.TRAIN.BBOX_3D: \n",
    "    conf_metric = metric.RCNNConfLossMetric()\n",
    "    dim_metric = metric.RCNNDimLossMetric()\n",
    "    angle_metric = metric.RCNNAngleLossMetric()\n",
    "\n",
    "    for child_metric in [rpn_eval_metric, rpn_cls_metric, rpn_bbox_metric, eval_metric, cls_metric, bbox_metric, conf_metric, dim_metric, angle_metric]:\n",
    "        eval_metrics.add(child_metric)\n",
    "else:\n",
    "    for child_metric in [rpn_eval_metric, rpn_cls_metric, rpn_bbox_metric, eval_metric, cls_metric, bbox_metric]:\n",
    "        eval_metrics.add(child_metric)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# callback\n",
    "batch_end_callback = callback.Speedometer(train_data.batch_size, frequent=20)\n",
    "means = np.tile(np.array(config.TRAIN.BBOX_MEANS), imdb.num_classes)\n",
    "stds = np.tile(np.array(config.TRAIN.BBOX_STDS), imdb.num_classes)\n",
    "epoch_end_callback = callback.do_checkpoint('model/basic', means, stds)\n",
    "# optimizer\n",
    "optimizer_params = {'momentum': 0.9,\n",
    "                    'wd': 0.0005,\n",
    "                    'learning_rate': 0.00001,\n",
    "                    'lr_scheduler': mx.lr_scheduler.FactorScheduler(30000, 0.1),\n",
    "                    'rescale_grad': (1.0 / batch_size)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "752\n"
     ]
    }
   ],
   "source": [
    "mod.fit(train_data, eval_metric=eval_metrics, epoch_end_callback=epoch_end_callback,\n",
    "        batch_end_callback=batch_end_callback, kvstore='device',\n",
    "        optimizer='sgd', optimizer_params=optimizer_params,\n",
    "        arg_params=arg_params, aux_params=aux_params, begin_epoch=1, num_epoch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
