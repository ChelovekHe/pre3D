{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:44:00] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
python: can't open file 'example/env/train_3dbox.py': [Errno 2] No such file or directory
  File "example/env/train_3dbox.py", line 91
    '''
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 187, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 32, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 142
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss])
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 144
    return rcnn
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                           ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    im_info = mx.symbol.Variable(name="im_info")
                                               ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 246
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 245
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 10, in <module>
    from rcnn.processing.generate_anchor import generator_anchors
ImportError: cannot import name generator_anchors
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189, in <module>
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS):
AttributeError: 'EasyDict' object has no attribute 'NUM_CLASSES'
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 83, in get_vgg_rpn_roi
    rpn_cls_prob = mx.symbol.SoftmaxOutput(data=rpn_cls_score_reshape, label=rpn_label, multi_output=True,
NameError: global name 'rpn_label' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 95, in get_vgg_rpn_roi
    cls_prob=rpn_cls_act_reshape, bbox_pred=rpn_bbox_pred, im_info=im_info, name='rois',
NameError: global name 'im_info' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 141, in get_3dbox_loss
    loss_dim = mx.symbol.square(data=(target_dim-dim_pred), name="loss_dim")
NameError: global name 'target_dim' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 199, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 153, in get_3dbox_loss
    rot_loss = RotLoss()
NameError: global name 'RotLoss' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 166
    loss_total = loss_dim * alpha / 64 + loss_conf
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 207, in get_vgg_3dbox_train
    cls_prob = mx.symbol.SoftmaxOutput(name='cls_prob', data=cls_score, label=label, normalization='batch')
UnboundLocalError: local variable 'label' referenced before assignment
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 212, in get_vgg_3dbox_train
    bbox_loss_ = bbox_outside_weight * \
NameError: global name 'bbox_outside_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 214, in get_vgg_3dbox_train
    data=rpn_bbox_inside_weight * (bbox_pred - bbox_target))
NameError: global name 'bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 194, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(im_info, relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 124, in get_vgg_rpn_roi
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss, label, bbox_targt, bbox_weight])
NameError: global name 'bbox_targt' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 51, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 346, in get_batch
    self.anchor_ratios, self.allowed_border)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 417, in assign_anchor
    bbox_weights[labels == 1, :] = np.array(config.TRAIN.RPN_BBOX_WEIGHTS)
AttributeError: 'EasyDict' object has no attribute 'RPN_BBOX_WEIGHTS'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 2L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 8L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 200, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 49, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
NameError: global name 'data_shape_dict' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2488L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 191, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 61, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2488L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
  File "example/env/train_3dbox.py", line 114
    print 'ok'
    ^
IndentationError: unexpected indent
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2489L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
ok
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:13:52] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Error in CustomOp.forward: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 724, in forward_entry
    aux=tensors[4])
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 42, in forward
    sample_rois(all_rois, fg_rois_per_image, rois_per_image, self._num_classes, gt_boxes=gt_boxes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 283, in sample_rois
    expand_bbox_regression_targets(bbox_target_data, num_classes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/processing/bbox_regression.py", line 139, in expand_bbox_regression_targets
    bbox_weights[index, start:end] = config.TRAIN.BBOX_WEIGHTS
AttributeError: 'EasyDict' object has no attribute 'BBOX_WEIGHTS'

[11:14:08] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:16:51] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.49 samples/sec	Train-RPNAcc=0.580171,	RPNLogLoss=0.689842,	RPNL1Loss=0.111169,	RCNNAcc=0.207961,	RCNNLogLoss=2.817367,	RCNNL1Loss=0.212329,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.55 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.689458,	RPNL1Loss=0.126438,	RCNNAcc=0.487614,	RCNNLogLoss=2.268237,	RCNNL1Loss=0.265416,	
