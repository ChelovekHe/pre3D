{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:44:00] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
python: can't open file 'example/env/train_3dbox.py': [Errno 2] No such file or directory
  File "example/env/train_3dbox.py", line 91
    '''
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 187, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 32, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 142
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss])
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 144
    return rcnn
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                           ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    im_info = mx.symbol.Variable(name="im_info")
                                               ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 246
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 245
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 10, in <module>
    from rcnn.processing.generate_anchor import generator_anchors
ImportError: cannot import name generator_anchors
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189, in <module>
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS):
AttributeError: 'EasyDict' object has no attribute 'NUM_CLASSES'
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 83, in get_vgg_rpn_roi
    rpn_cls_prob = mx.symbol.SoftmaxOutput(data=rpn_cls_score_reshape, label=rpn_label, multi_output=True,
NameError: global name 'rpn_label' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 95, in get_vgg_rpn_roi
    cls_prob=rpn_cls_act_reshape, bbox_pred=rpn_bbox_pred, im_info=im_info, name='rois',
NameError: global name 'im_info' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 141, in get_3dbox_loss
    loss_dim = mx.symbol.square(data=(target_dim-dim_pred), name="loss_dim")
NameError: global name 'target_dim' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 199, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 153, in get_3dbox_loss
    rot_loss = RotLoss()
NameError: global name 'RotLoss' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 166
    loss_total = loss_dim * alpha / 64 + loss_conf
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 207, in get_vgg_3dbox_train
    cls_prob = mx.symbol.SoftmaxOutput(name='cls_prob', data=cls_score, label=label, normalization='batch')
UnboundLocalError: local variable 'label' referenced before assignment
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 212, in get_vgg_3dbox_train
    bbox_loss_ = bbox_outside_weight * \
NameError: global name 'bbox_outside_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 214, in get_vgg_3dbox_train
    data=rpn_bbox_inside_weight * (bbox_pred - bbox_target))
NameError: global name 'bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 194, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(im_info, relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 124, in get_vgg_rpn_roi
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss, label, bbox_targt, bbox_weight])
NameError: global name 'bbox_targt' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 51, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 346, in get_batch
    self.anchor_ratios, self.allowed_border)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 417, in assign_anchor
    bbox_weights[labels == 1, :] = np.array(config.TRAIN.RPN_BBOX_WEIGHTS)
AttributeError: 'EasyDict' object has no attribute 'RPN_BBOX_WEIGHTS'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 2L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 8L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 200, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 49, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
NameError: global name 'data_shape_dict' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2488L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 191, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 61, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2488L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
  File "example/env/train_3dbox.py", line 114
    print 'ok'
    ^
IndentationError: unexpected indent
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2489L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
ok
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:13:52] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Error in CustomOp.forward: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 724, in forward_entry
    aux=tensors[4])
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 42, in forward
    sample_rois(all_rois, fg_rois_per_image, rois_per_image, self._num_classes, gt_boxes=gt_boxes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 283, in sample_rois
    expand_bbox_regression_targets(bbox_target_data, num_classes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/processing/bbox_regression.py", line 139, in expand_bbox_regression_targets
    bbox_weights[index, start:end] = config.TRAIN.BBOX_WEIGHTS
AttributeError: 'EasyDict' object has no attribute 'BBOX_WEIGHTS'

[11:14:08] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:16:51] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.49 samples/sec	Train-RPNAcc=0.580171,	RPNLogLoss=0.689842,	RPNL1Loss=0.111169,	RCNNAcc=0.207961,	RCNNLogLoss=2.817367,	RCNNL1Loss=0.212329,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.55 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.689458,	RPNL1Loss=0.126438,	RCNNAcc=0.487614,	RCNNLogLoss=2.268237,	RCNNL1Loss=0.265416,	
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 8, in <module>
    from rcnn.config import config
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/config.py", line 78
    config.TRAIN.RPN_NMS_THRESH = 0.7ls
                                      ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 97, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc8_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:38:10] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
[11:38:26] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:38:26] src/executor/graph_executor.cc:44: Check failed: i < head_grads.size() && !head_grads[i].is_none() Because the last operator is not Loss function, head_gradient is required in calling backward.

Stack trace returned 27 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f4db7a3271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor8BackwardERKSt6vectorINS_7NDArrayESaIS3_EE+0x15d) [0x7f4db8275add]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXExecutorBackward+0xb8) [0x7f4db8219778]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f4e60f61adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f4e60f6140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f4e611785fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f4e61179f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (17) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (18) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (19) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (20) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (21) python() [0x4a1634]
[bt] (22) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (23) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (24) python(Py_Main+0xb5e) [0x44f904]
[bt] (25) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f4e624eff45]
[bt] (26) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 196, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 410, in fit
    self.forward_backward(data_batch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 144, in forward_backward
    self.backward()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 179, in backward
    self._curr_module.backward(out_grads=out_grads)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 465, in backward
    self._exec_group.backward(out_grads=out_grads)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 411, in backward
    exec_.backward(out_grads=out_grads_slice)
  File "/home/hustxly/mxnet/python/mxnet/executor.py", line 147, in backward
    ndarray))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [11:38:26] src/executor/graph_executor.cc:44: Check failed: i < head_grads.size() && !head_grads[i].is_none() Because the last operator is not Loss function, head_gradient is required in calling backward.

Stack trace returned 27 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f4db7a3271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor8BackwardERKSt6vectorINS_7NDArrayESaIS3_EE+0x15d) [0x7f4db8275add]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXExecutorBackward+0xb8) [0x7f4db8219778]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f4e60f61adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f4e60f6140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f4e611785fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f4e61179f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (17) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (18) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (19) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (20) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (21) python() [0x4a1634]
[bt] (22) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (23) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (24) python(Py_Main+0xb5e) [0x44f904]
[bt] (25) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f4e624eff45]
[bt] (26) python() [0x578c4e]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:59:24] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 196, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[12:43:49] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 203, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[12:45:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.54 samples/sec	Train-RPNAcc=0.588356,	RPNLogLoss=0.688438,	RPNL1Loss=0.115115,	RCNNAcc=0.194940,	RCNNLogLoss=2.837928,	RCNNL1Loss=0.272949,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.50 samples/sec	Train-RPNAcc=0.592702,	RPNLogLoss=0.687396,	RPNL1Loss=0.132219,	RCNNAcc=0.472370,	RCNNLogLoss=2.298971,	RCNNL1Loss=0.329313,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.69 samples/sec	Train-RPNAcc=0.600218,	RPNLogLoss=0.686898,	RPNL1Loss=0.136774,	RCNNAcc=0.594647,	RCNNLogLoss=1.909852,	RCNNL1Loss=0.335864,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[20:28:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.61 samples/sec	Train-RPNAcc=0.563616,	RPNLogLoss=0.691758,	RPNL1Loss=0.118104,	RCNNAcc=0.191592,	RCNNLogLoss=2.841586,	RCNNL1Loss=0.258174,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[20:54:15] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 105, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc8_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 12L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 105, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc9_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 12L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[21:00:17] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:43:21] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.60 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.688932,	RPNL1Loss=0.162465,	RCNNAcc=0.177455,	RCNNLogLoss=2.885032,	RCNNL1Loss=0.336327,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.86 samples/sec	Train-RPNAcc=0.593274,	RPNLogLoss=0.688133,	RPNL1Loss=0.129164,	RCNNAcc=0.470655,	RCNNLogLoss=2.306914,	RCNNL1Loss=0.329383,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.82 samples/sec	Train-RPNAcc=0.601178,	RPNLogLoss=0.687275,	RPNL1Loss=0.120215,	RCNNAcc=0.608222,	RCNNLogLoss=1.880212,	RCNNL1Loss=0.306126,	
INFO:root:Epoch[1] Batch [80]	Speed: 0.97 samples/sec	Train-RPNAcc=0.608314,	RPNLogLoss=0.686595,	RPNL1Loss=0.119597,	RCNNAcc=0.675540,	RCNNLogLoss=1.607514,	RCNNL1Loss=0.297878,	
INFO:root:Epoch[1] Batch [100]	Speed: 0.79 samples/sec	Train-RPNAcc=0.616607,	RPNLogLoss=0.685581,	RPNL1Loss=0.130103,	RCNNAcc=0.703899,	RCNNLogLoss=1.459083,	RCNNL1Loss=0.321868,	
INFO:root:Epoch[1] Batch [120]	Speed: 0.87 samples/sec	Train-RPNAcc=0.625678,	RPNLogLoss=0.684273,	RPNL1Loss=0.127825,	RCNNAcc=0.728177,	RCNNLogLoss=1.320564,	RCNNL1Loss=0.324794,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.95 samples/sec	Train-RPNAcc=0.633283,	RPNLogLoss=0.682898,	RPNL1Loss=0.132785,	RCNNAcc=0.748781,	RCNNLogLoss=1.202359,	RCNNL1Loss=0.323892,	
INFO:root:Epoch[1] Batch [160]	Speed: 0.83 samples/sec	Train-RPNAcc=0.640115,	RPNLogLoss=0.681510,	RPNL1Loss=0.134434,	RCNNAcc=0.762277,	RCNNLogLoss=1.113592,	RCNNL1Loss=0.326054,	
INFO:root:Epoch[1] Batch [180]	Speed: 0.79 samples/sec	Train-RPNAcc=0.647402,	RPNLogLoss=0.680011,	RPNL1Loss=0.135963,	RCNNAcc=0.776934,	RCNNLogLoss=1.031368,	RCNNL1Loss=0.319910,	
INFO:root:Epoch[1] Batch [200]	Speed: 0.98 samples/sec	Train-RPNAcc=0.653898,	RPNLogLoss=0.678374,	RPNL1Loss=0.137699,	RCNNAcc=0.786303,	RCNNLogLoss=0.968132,	RCNNL1Loss=0.321844,	
INFO:root:Epoch[1] Batch [220]	Speed: 0.88 samples/sec	Train-RPNAcc=0.661093,	RPNLogLoss=0.676715,	RPNL1Loss=0.134511,	RCNNAcc=0.796663,	RCNNLogLoss=0.910511,	RCNNL1Loss=0.315775,	
INFO:root:Epoch[1] Batch [240]	Speed: 1.05 samples/sec	Train-RPNAcc=0.667012,	RPNLogLoss=0.674963,	RPNL1Loss=0.133910,	RCNNAcc=0.804785,	RCNNLogLoss=0.859739,	RCNNL1Loss=0.314300,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.95 samples/sec	Train-RPNAcc=0.673746,	RPNLogLoss=0.673179,	RPNL1Loss=0.133964,	RCNNAcc=0.810973,	RCNNLogLoss=0.818879,	RCNNL1Loss=0.315344,	
INFO:root:Epoch[1] Batch [280]	Speed: 0.94 samples/sec	Train-RPNAcc=0.681425,	RPNLogLoss=0.671202,	RPNL1Loss=0.133793,	RCNNAcc=0.817977,	RCNNLogLoss=0.779751,	RCNNL1Loss=0.311582,	
INFO:root:Epoch[1] Batch [300]	Speed: 1.08 samples/sec	Train-RPNAcc=0.689083,	RPNLogLoss=0.669286,	RPNL1Loss=0.132383,	RCNNAcc=0.821455,	RCNNLogLoss=0.750870,	RCNNL1Loss=0.314483,	
INFO:root:Epoch[1] Batch [320]	Speed: 0.96 samples/sec	Train-RPNAcc=0.695848,	RPNLogLoss=0.667271,	RPNL1Loss=0.133914,	RCNNAcc=0.825131,	RCNNLogLoss=0.724867,	RCNNL1Loss=0.316649,	
INFO:root:Epoch[1] Batch [340]	Speed: 1.08 samples/sec	Train-RPNAcc=0.703996,	RPNLogLoss=0.664977,	RPNL1Loss=0.133020,	RCNNAcc=0.828789,	RCNNLogLoss=0.700400,	RCNNL1Loss=0.318892,	
INFO:root:Epoch[1] Batch [360]	Speed: 0.92 samples/sec	Train-RPNAcc=0.710981,	RPNLogLoss=0.662672,	RPNL1Loss=0.133019,	RCNNAcc=0.829856,	RCNNLogLoss=0.681870,	RCNNL1Loss=0.329944,	
INFO:root:Epoch[1] Batch [380]	Speed: 1.13 samples/sec	Train-RPNAcc=0.718688,	RPNLogLoss=0.660018,	RPNL1Loss=0.132743,	RCNNAcc=0.833661,	RCNNLogLoss=0.659349,	RCNNL1Loss=0.328331,	
INFO:root:Epoch[1] Batch [400]	Speed: 1.02 samples/sec	Train-RPNAcc=0.724614,	RPNLogLoss=0.657702,	RPNL1Loss=0.133130,	RCNNAcc=0.835178,	RCNNLogLoss=0.643083,	RCNNL1Loss=0.330612,	
INFO:root:Epoch[1] Batch [420]	Speed: 1.01 samples/sec	Train-RPNAcc=0.730942,	RPNLogLoss=0.655227,	RPNL1Loss=0.133190,	RCNNAcc=0.837162,	RCNNLogLoss=0.627163,	RCNNL1Loss=0.332483,	
INFO:root:Epoch[1] Batch [440]	Speed: 1.17 samples/sec	Train-RPNAcc=0.736899,	RPNLogLoss=0.652507,	RPNL1Loss=0.133504,	RCNNAcc=0.839675,	RCNNLogLoss=0.611529,	RCNNL1Loss=0.333065,	
INFO:root:Epoch[1] Batch [460]	Speed: 1.04 samples/sec	Train-RPNAcc=0.742365,	RPNLogLoss=0.649930,	RPNL1Loss=0.132935,	RCNNAcc=0.840530,	RCNNLogLoss=0.599674,	RCNNL1Loss=0.336655,	
INFO:root:Epoch[1] Batch [480]	Speed: 1.08 samples/sec	Train-RPNAcc=0.747466,	RPNLogLoss=0.647449,	RPNL1Loss=0.134214,	RCNNAcc=0.841768,	RCNNLogLoss=0.587771,	RCNNL1Loss=0.337567,	
INFO:root:Epoch[1] Batch [500]	Speed: 1.02 samples/sec	Train-RPNAcc=0.751770,	RPNLogLoss=0.644765,	RPNL1Loss=0.134417,	RCNNAcc=0.842970,	RCNNLogLoss=0.576698,	RCNNL1Loss=0.340340,	
INFO:root:Epoch[1] Batch [520]	Speed: 0.99 samples/sec	Train-RPNAcc=0.756425,	RPNLogLoss=0.642058,	RPNL1Loss=0.134187,	RCNNAcc=0.844200,	RCNNLogLoss=0.566322,	RCNNL1Loss=0.340579,	
INFO:root:Epoch[1] Batch [540]	Speed: 1.03 samples/sec	Train-RPNAcc=0.760116,	RPNLogLoss=0.639343,	RPNL1Loss=0.134406,	RCNNAcc=0.844154,	RCNNLogLoss=0.558783,	RCNNL1Loss=0.345100,	
INFO:root:Epoch[1] Batch [560]	Speed: 1.06 samples/sec	Train-RPNAcc=0.764706,	RPNLogLoss=0.636167,	RPNL1Loss=0.133693,	RCNNAcc=0.844962,	RCNNLogLoss=0.550100,	RCNNL1Loss=0.347409,	
INFO:root:Epoch[1] Batch [580]	Speed: 1.20 samples/sec	Train-RPNAcc=0.768684,	RPNLogLoss=0.632904,	RPNL1Loss=0.133879,	RCNNAcc=0.846130,	RCNNLogLoss=0.540802,	RCNNL1Loss=0.347832,	
INFO:root:Epoch[1] Batch [600]	Speed: 1.06 samples/sec	Train-RPNAcc=0.772697,	RPNLogLoss=0.629603,	RPNL1Loss=0.133035,	RCNNAcc=0.847364,	RCNNLogLoss=0.532077,	RCNNL1Loss=0.348467,	
INFO:root:Epoch[1] Batch [620]	Speed: 1.05 samples/sec	Train-RPNAcc=0.775042,	RPNLogLoss=0.626668,	RPNL1Loss=0.133769,	RCNNAcc=0.847675,	RCNNLogLoss=0.526164,	RCNNL1Loss=0.350132,	
INFO:root:Epoch[1] Batch [640]	Speed: 1.11 samples/sec	Train-RPNAcc=0.778014,	RPNLogLoss=0.623491,	RPNL1Loss=0.132403,	RCNNAcc=0.848162,	RCNNLogLoss=0.520149,	RCNNL1Loss=0.352079,	
INFO:root:Epoch[1] Batch [660]	Speed: 1.24 samples/sec	Train-RPNAcc=0.781746,	RPNLogLoss=0.619570,	RPNL1Loss=0.131171,	RCNNAcc=0.848986,	RCNNLogLoss=0.513084,	RCNNL1Loss=0.351516,	
INFO:root:Epoch[1] Batch [680]	Speed: 0.96 samples/sec	Train-RPNAcc=0.783688,	RPNLogLoss=0.616576,	RPNL1Loss=0.132369,	RCNNAcc=0.849062,	RCNNLogLoss=0.507960,	RCNNL1Loss=0.353803,	
INFO:root:Epoch[1] Batch [700]	Speed: 1.07 samples/sec	Train-RPNAcc=0.786482,	RPNLogLoss=0.613146,	RPNL1Loss=0.131892,	RCNNAcc=0.849601,	RCNNLogLoss=0.502239,	RCNNL1Loss=0.355016,	
INFO:root:Epoch[1] Batch [720]	Speed: 1.18 samples/sec	Train-RPNAcc=0.788900,	RPNLogLoss=0.609293,	RPNL1Loss=0.132436,	RCNNAcc=0.850046,	RCNNLogLoss=0.497134,	RCNNL1Loss=0.353960,	
INFO:root:Epoch[1] Batch [740]	Speed: 0.99 samples/sec	Train-RPNAcc=0.790776,	RPNLogLoss=0.606082,	RPNL1Loss=0.132961,	RCNNAcc=0.849749,	RCNNLogLoss=0.493672,	RCNNL1Loss=0.355475,	
INFO:root:Epoch[1] Batch [760]	Speed: 1.27 samples/sec	Train-RPNAcc=0.793497,	RPNLogLoss=0.602047,	RPNL1Loss=0.132501,	RCNNAcc=0.850741,	RCNNLogLoss=0.488898,	RCNNL1Loss=0.352915,	
INFO:root:Epoch[1] Batch [780]	Speed: 1.07 samples/sec	Train-RPNAcc=0.795304,	RPNLogLoss=0.598195,	RPNL1Loss=0.132957,	RCNNAcc=0.851132,	RCNNLogLoss=0.484880,	RCNNL1Loss=0.352076,	
INFO:root:Epoch[1] Batch [800]	Speed: 1.17 samples/sec	Train-RPNAcc=0.797509,	RPNLogLoss=0.594006,	RPNL1Loss=0.132641,	RCNNAcc=0.851562,	RCNNLogLoss=0.480475,	RCNNL1Loss=0.351652,	
INFO:root:Epoch[1] Batch [820]	Speed: 0.99 samples/sec	Train-RPNAcc=0.799259,	RPNLogLoss=0.589931,	RPNL1Loss=0.132236,	RCNNAcc=0.851667,	RCNNLogLoss=0.477351,	RCNNL1Loss=0.351855,	
INFO:root:Epoch[1] Batch [840]	Speed: 1.16 samples/sec	Train-RPNAcc=0.801515,	RPNLogLoss=0.585073,	RPNL1Loss=0.131305,	RCNNAcc=0.852046,	RCNNLogLoss=0.473784,	RCNNL1Loss=0.351850,	
INFO:root:Epoch[1] Batch [860]	Speed: 1.09 samples/sec	Train-RPNAcc=0.803136,	RPNLogLoss=0.580394,	RPNL1Loss=0.131323,	RCNNAcc=0.853323,	RCNNLogLoss=0.468089,	RCNNL1Loss=0.349920,	
INFO:root:Epoch[1] Batch [880]	Speed: 1.14 samples/sec	Train-RPNAcc=0.804976,	RPNLogLoss=0.575774,	RPNL1Loss=0.130716,	RCNNAcc=0.853212,	RCNNLogLoss=0.465926,	RCNNL1Loss=0.350124,	
INFO:root:Epoch[1] Batch [900]	Speed: 1.08 samples/sec	Train-RPNAcc=0.806638,	RPNLogLoss=0.571388,	RPNL1Loss=0.130127,	RCNNAcc=0.853331,	RCNNLogLoss=0.462832,	RCNNL1Loss=0.349852,	
INFO:root:Epoch[1] Batch [920]	Speed: 1.09 samples/sec	Train-RPNAcc=0.807818,	RPNLogLoss=0.567060,	RPNL1Loss=0.129675,	RCNNAcc=0.852589,	RCNNLogLoss=0.461446,	RCNNL1Loss=0.351843,	
INFO:root:Epoch[1] Batch [940]	Speed: 1.18 samples/sec	Train-RPNAcc=0.809810,	RPNLogLoss=0.562262,	RPNL1Loss=0.128891,	RCNNAcc=0.852658,	RCNNLogLoss=0.459461,	RCNNL1Loss=0.353024,	
INFO:root:Epoch[1] Batch [960]	Speed: 1.05 samples/sec	Train-RPNAcc=0.811459,	RPNLogLoss=0.557935,	RPNL1Loss=0.128235,	RCNNAcc=0.851725,	RCNNLogLoss=0.459469,	RCNNL1Loss=0.356156,	
INFO:root:Epoch[1] Batch [980]	Speed: 1.15 samples/sec	Train-RPNAcc=0.813026,	RPNLogLoss=0.553008,	RPNL1Loss=0.127361,	RCNNAcc=0.852024,	RCNNLogLoss=0.456953,	RCNNL1Loss=0.355789,	
INFO:root:Epoch[1] Batch [1000]	Speed: 1.00 samples/sec	Train-RPNAcc=0.814397,	RPNLogLoss=0.548546,	RPNL1Loss=0.126685,	RCNNAcc=0.851890,	RCNNLogLoss=0.455288,	RCNNL1Loss=0.355424,	
INFO:root:Epoch[1] Batch [1020]	Speed: 1.02 samples/sec	Train-RPNAcc=0.814937,	RPNLogLoss=0.544657,	RPNL1Loss=0.126519,	RCNNAcc=0.851892,	RCNNLogLoss=0.453571,	RCNNL1Loss=0.355157,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [1040]	Speed: 1.07 samples/sec	Train-RPNAcc=0.816875,	RPNLogLoss=0.539735,	RPNL1Loss=0.125172,	RCNNAcc=0.852178,	RCNNLogLoss=0.451253,	RCNNL1Loss=0.354670,	
INFO:root:Epoch[1] Batch [1060]	Speed: 1.12 samples/sec	Train-RPNAcc=0.818619,	RPNLogLoss=0.535017,	RPNL1Loss=0.124124,	RCNNAcc=0.852233,	RCNNLogLoss=0.449141,	RCNNL1Loss=0.354627,	
INFO:root:Epoch[1] Batch [1080]	Speed: 1.11 samples/sec	Train-RPNAcc=0.820247,	RPNLogLoss=0.530131,	RPNL1Loss=0.123006,	RCNNAcc=0.852336,	RCNNLogLoss=0.447343,	RCNNL1Loss=0.354002,	
INFO:root:Epoch[1] Batch [1100]	Speed: 1.05 samples/sec	Train-RPNAcc=0.821249,	RPNLogLoss=0.526050,	RPNL1Loss=0.122464,	RCNNAcc=0.852194,	RCNNLogLoss=0.446310,	RCNNL1Loss=0.354471,	
INFO:root:Epoch[1] Batch [1120]	Speed: 1.08 samples/sec	Train-RPNAcc=0.822187,	RPNLogLoss=0.521730,	RPNL1Loss=0.121908,	RCNNAcc=0.852622,	RCNNLogLoss=0.444003,	RCNNL1Loss=0.354099,	
INFO:root:Epoch[1] Batch [1140]	Speed: 1.04 samples/sec	Train-RPNAcc=0.822740,	RPNLogLoss=0.518268,	RPNL1Loss=0.121691,	RCNNAcc=0.852637,	RCNNLogLoss=0.442641,	RCNNL1Loss=0.354184,	
INFO:root:Epoch[1] Batch [1160]	Speed: 1.05 samples/sec	Train-RPNAcc=0.824027,	RPNLogLoss=0.513836,	RPNL1Loss=0.121004,	RCNNAcc=0.853090,	RCNNLogLoss=0.440523,	RCNNL1Loss=0.353089,	
INFO:root:Epoch[1] Batch [1180]	Speed: 0.99 samples/sec	Train-RPNAcc=0.824837,	RPNLogLoss=0.510054,	RPNL1Loss=0.120765,	RCNNAcc=0.853296,	RCNNLogLoss=0.439043,	RCNNL1Loss=0.352558,	
INFO:root:Epoch[1] Batch [1200]	Speed: 1.16 samples/sec	Train-RPNAcc=0.826359,	RPNLogLoss=0.505413,	RPNL1Loss=0.119724,	RCNNAcc=0.854119,	RCNNLogLoss=0.436003,	RCNNL1Loss=0.350563,	
INFO:root:Epoch[1] Batch [1220]	Speed: 1.04 samples/sec	Train-RPNAcc=0.827450,	RPNLogLoss=0.501343,	RPNL1Loss=0.119174,	RCNNAcc=0.854666,	RCNNLogLoss=0.433401,	RCNNL1Loss=0.349877,	
INFO:root:Epoch[1] Batch [1240]	Speed: 1.06 samples/sec	Train-RPNAcc=0.828468,	RPNLogLoss=0.497260,	RPNL1Loss=0.118499,	RCNNAcc=0.854861,	RCNNLogLoss=0.431979,	RCNNL1Loss=0.349589,	
INFO:root:Epoch[1] Batch [1260]	Speed: 1.06 samples/sec	Train-RPNAcc=0.829534,	RPNLogLoss=0.493290,	RPNL1Loss=0.117782,	RCNNAcc=0.855032,	RCNNLogLoss=0.430573,	RCNNL1Loss=0.350005,	
INFO:root:Epoch[1] Batch [1280]	Speed: 1.07 samples/sec	Train-RPNAcc=0.830839,	RPNLogLoss=0.488974,	RPNL1Loss=0.116837,	RCNNAcc=0.855856,	RCNNLogLoss=0.427962,	RCNNL1Loss=0.348670,	
INFO:root:Epoch[1] Batch [1300]	Speed: 0.98 samples/sec	Train-RPNAcc=0.831392,	RPNLogLoss=0.485824,	RPNL1Loss=0.116581,	RCNNAcc=0.856132,	RCNNLogLoss=0.426386,	RCNNL1Loss=0.348556,	
INFO:root:Epoch[1] Batch [1320]	Speed: 0.88 samples/sec	Train-RPNAcc=0.832339,	RPNLogLoss=0.482435,	RPNL1Loss=0.115929,	RCNNAcc=0.856495,	RCNNLogLoss=0.424572,	RCNNL1Loss=0.347671,	
INFO:root:Epoch[1] Batch [1340]	Speed: 0.92 samples/sec	Train-RPNAcc=0.832867,	RPNLogLoss=0.479282,	RPNL1Loss=0.115635,	RCNNAcc=0.856503,	RCNNLogLoss=0.423538,	RCNNL1Loss=0.348206,	
INFO:root:Epoch[1] Batch [1360]	Speed: 1.05 samples/sec	Train-RPNAcc=0.833486,	RPNLogLoss=0.476126,	RPNL1Loss=0.115235,	RCNNAcc=0.856953,	RCNNLogLoss=0.421439,	RCNNL1Loss=0.347231,	
INFO:root:Epoch[1] Batch [1380]	Speed: 0.93 samples/sec	Train-RPNAcc=0.834320,	RPNLogLoss=0.472979,	RPNL1Loss=0.114770,	RCNNAcc=0.857078,	RCNNLogLoss=0.420568,	RCNNL1Loss=0.347059,	
INFO:root:Epoch[1] Batch [1400]	Speed: 0.95 samples/sec	Train-RPNAcc=0.834630,	RPNLogLoss=0.470317,	RPNL1Loss=0.114736,	RCNNAcc=0.857373,	RCNNLogLoss=0.418936,	RCNNL1Loss=0.346159,	
INFO:root:Epoch[1] Batch [1420]	Speed: 1.00 samples/sec	Train-RPNAcc=0.835432,	RPNLogLoss=0.466944,	RPNL1Loss=0.114319,	RCNNAcc=0.857902,	RCNNLogLoss=0.417026,	RCNNL1Loss=0.345495,	
INFO:root:Epoch[1] Batch [1440]	Speed: 0.96 samples/sec	Train-RPNAcc=0.836314,	RPNLogLoss=0.463818,	RPNL1Loss=0.113788,	RCNNAcc=0.858063,	RCNNLogLoss=0.415863,	RCNNL1Loss=0.345305,	
INFO:root:Epoch[1] Batch [1460]	Speed: 0.99 samples/sec	Train-RPNAcc=0.837191,	RPNLogLoss=0.460567,	RPNL1Loss=0.113247,	RCNNAcc=0.858498,	RCNNLogLoss=0.414457,	RCNNL1Loss=0.344589,	
INFO:root:Epoch[1] Batch [1480]	Speed: 1.01 samples/sec	Train-RPNAcc=0.838158,	RPNLogLoss=0.457168,	RPNL1Loss=0.112627,	RCNNAcc=0.859349,	RCNNLogLoss=0.411654,	RCNNL1Loss=0.343083,	
INFO:root:Epoch[1] Batch [1500]	Speed: 0.96 samples/sec	Train-RPNAcc=0.838761,	RPNLogLoss=0.454152,	RPNL1Loss=0.112245,	RCNNAcc=0.859932,	RCNNLogLoss=0.409602,	RCNNL1Loss=0.342678,	
INFO:root:Epoch[1] Batch [1520]	Speed: 0.95 samples/sec	Train-RPNAcc=0.839199,	RPNLogLoss=0.451570,	RPNL1Loss=0.112015,	RCNNAcc=0.860305,	RCNNLogLoss=0.407903,	RCNNL1Loss=0.342089,	
INFO:root:Epoch[1] Batch [1540]	Speed: 0.99 samples/sec	Train-RPNAcc=0.840135,	RPNLogLoss=0.448353,	RPNL1Loss=0.111471,	RCNNAcc=0.861149,	RCNNLogLoss=0.405247,	RCNNL1Loss=0.340469,	
INFO:root:Epoch[1] Batch [1560]	Speed: 0.92 samples/sec	Train-RPNAcc=0.840980,	RPNLogLoss=0.445351,	RPNL1Loss=0.110940,	RCNNAcc=0.861757,	RCNNLogLoss=0.403333,	RCNNL1Loss=0.339179,	
INFO:root:Epoch[1] Batch [1580]	Speed: 0.95 samples/sec	Train-RPNAcc=0.841198,	RPNLogLoss=0.442907,	RPNL1Loss=0.110687,	RCNNAcc=0.862221,	RCNNLogLoss=0.401616,	RCNNL1Loss=0.338461,	
INFO:root:Epoch[1] Batch [1600]	Speed: 0.91 samples/sec	Train-RPNAcc=0.841932,	RPNLogLoss=0.440233,	RPNL1Loss=0.110348,	RCNNAcc=0.862552,	RCNNLogLoss=0.400357,	RCNNL1Loss=0.337958,	
INFO:root:Epoch[1] Batch [1620]	Speed: 1.01 samples/sec	Train-RPNAcc=0.842605,	RPNLogLoss=0.437301,	RPNL1Loss=0.109857,	RCNNAcc=0.863279,	RCNNLogLoss=0.397903,	RCNNL1Loss=0.336401,	
INFO:root:Epoch[1] Batch [1640]	Speed: 0.96 samples/sec	Train-RPNAcc=0.843476,	RPNLogLoss=0.434480,	RPNL1Loss=0.109200,	RCNNAcc=0.863750,	RCNNLogLoss=0.396246,	RCNNL1Loss=0.335754,	
INFO:root:Epoch[1] Batch [1660]	Speed: 0.98 samples/sec	Train-RPNAcc=0.843825,	RPNLogLoss=0.432425,	RPNL1Loss=0.108899,	RCNNAcc=0.864314,	RCNNLogLoss=0.394565,	RCNNL1Loss=0.334447,	
INFO:root:Epoch[1] Batch [1680]	Speed: 0.93 samples/sec	Train-RPNAcc=0.844459,	RPNLogLoss=0.430120,	RPNL1Loss=0.108693,	RCNNAcc=0.864552,	RCNNLogLoss=0.393331,	RCNNL1Loss=0.334202,	
INFO:root:Epoch[1] Batch [1700]	Speed: 0.89 samples/sec	Train-RPNAcc=0.845029,	RPNLogLoss=0.427665,	RPNL1Loss=0.108301,	RCNNAcc=0.864813,	RCNNLogLoss=0.392536,	RCNNL1Loss=0.333634,	
INFO:root:Epoch[1] Batch [1720]	Speed: 0.88 samples/sec	Train-RPNAcc=0.845625,	RPNLogLoss=0.425311,	RPNL1Loss=0.107978,	RCNNAcc=0.865322,	RCNNLogLoss=0.390896,	RCNNL1Loss=0.332790,	
INFO:root:Epoch[1] Batch [1740]	Speed: 1.01 samples/sec	Train-RPNAcc=0.846478,	RPNLogLoss=0.422680,	RPNL1Loss=0.107412,	RCNNAcc=0.865971,	RCNNLogLoss=0.388914,	RCNNL1Loss=0.332261,	
INFO:root:Epoch[1] Batch [1760]	Speed: 0.93 samples/sec	Train-RPNAcc=0.847199,	RPNLogLoss=0.420201,	RPNL1Loss=0.106928,	RCNNAcc=0.866708,	RCNNLogLoss=0.386591,	RCNNL1Loss=0.331131,	
INFO:root:Epoch[1] Batch [1780]	Speed: 0.83 samples/sec	Train-RPNAcc=0.847917,	RPNLogLoss=0.417796,	RPNL1Loss=0.106519,	RCNNAcc=0.867038,	RCNNLogLoss=0.385380,	RCNNL1Loss=0.330498,	
INFO:root:Epoch[1] Batch [1800]	Speed: 0.92 samples/sec	Train-RPNAcc=0.848513,	RPNLogLoss=0.415443,	RPNL1Loss=0.106213,	RCNNAcc=0.867600,	RCNNLogLoss=0.383498,	RCNNL1Loss=0.329358,	
INFO:root:Epoch[1] Batch [1820]	Speed: 0.93 samples/sec	Train-RPNAcc=0.849111,	RPNLogLoss=0.413136,	RPNL1Loss=0.105776,	RCNNAcc=0.868131,	RCNNLogLoss=0.381828,	RCNNL1Loss=0.328459,	
INFO:root:Epoch[1] Batch [1840]	Speed: 0.80 samples/sec	Train-RPNAcc=0.849430,	RPNLogLoss=0.411209,	RPNL1Loss=0.105585,	RCNNAcc=0.868401,	RCNNLogLoss=0.380722,	RCNNL1Loss=0.328127,	
INFO:root:Epoch[1] Batch [1860]	Speed: 0.87 samples/sec	Train-RPNAcc=0.849890,	RPNLogLoss=0.409092,	RPNL1Loss=0.105389,	RCNNAcc=0.868716,	RCNNLogLoss=0.379563,	RCNNL1Loss=0.327404,	
INFO:root:Epoch[1] Batch [1880]	Speed: 0.83 samples/sec	Train-RPNAcc=0.850262,	RPNLogLoss=0.407280,	RPNL1Loss=0.105237,	RCNNAcc=0.869052,	RCNNLogLoss=0.378324,	RCNNL1Loss=0.326779,	
INFO:root:Epoch[1] Batch [1900]	Speed: 0.83 samples/sec	Train-RPNAcc=0.850849,	RPNLogLoss=0.405081,	RPNL1Loss=0.104827,	RCNNAcc=0.869616,	RCNNLogLoss=0.376586,	RCNNL1Loss=0.326059,	
INFO:root:Epoch[1] Batch [1920]	Speed: 0.95 samples/sec	Train-RPNAcc=0.851532,	RPNLogLoss=0.402839,	RPNL1Loss=0.104314,	RCNNAcc=0.870238,	RCNNLogLoss=0.374799,	RCNNL1Loss=0.324857,	
INFO:root:Epoch[1] Batch [1940]	Speed: 0.84 samples/sec	Train-RPNAcc=0.851657,	RPNLogLoss=0.401223,	RPNL1Loss=0.104239,	RCNNAcc=0.870766,	RCNNLogLoss=0.373113,	RCNNL1Loss=0.323880,	
INFO:root:Epoch[1] Batch [1960]	Speed: 0.90 samples/sec	Train-RPNAcc=0.852351,	RPNLogLoss=0.399245,	RPNL1Loss=0.103919,	RCNNAcc=0.870976,	RCNNLogLoss=0.372378,	RCNNL1Loss=0.323489,	
INFO:root:Epoch[1] Batch [1980]	Speed: 0.90 samples/sec	Train-RPNAcc=0.852970,	RPNLogLoss=0.397362,	RPNL1Loss=0.103675,	RCNNAcc=0.871344,	RCNNLogLoss=0.371173,	RCNNL1Loss=0.323022,	
INFO:root:Epoch[1] Batch [2000]	Speed: 0.85 samples/sec	Train-RPNAcc=0.853530,	RPNLogLoss=0.395380,	RPNL1Loss=0.103362,	RCNNAcc=0.871744,	RCNNLogLoss=0.369963,	RCNNL1Loss=0.322354,	
INFO:root:Epoch[1] Batch [2020]	Speed: 0.85 samples/sec	Train-RPNAcc=0.854075,	RPNLogLoss=0.393485,	RPNL1Loss=0.103038,	RCNNAcc=0.872035,	RCNNLogLoss=0.368766,	RCNNL1Loss=0.322073,	
INFO:root:Epoch[1] Batch [2040]	Speed: 0.92 samples/sec	Train-RPNAcc=0.854529,	RPNLogLoss=0.391560,	RPNL1Loss=0.102764,	RCNNAcc=0.872588,	RCNNLogLoss=0.366963,	RCNNL1Loss=0.321183,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [2060]	Speed: 0.90 samples/sec	Train-RPNAcc=0.855219,	RPNLogLoss=0.389481,	RPNL1Loss=0.102409,	RCNNAcc=0.873230,	RCNNLogLoss=0.365144,	RCNNL1Loss=0.319860,	
INFO:root:Epoch[1] Batch [2080]	Speed: 0.88 samples/sec	Train-RPNAcc=0.856030,	RPNLogLoss=0.387163,	RPNL1Loss=0.101906,	RCNNAcc=0.873787,	RCNNLogLoss=0.363700,	RCNNL1Loss=0.318832,	
INFO:root:Epoch[1] Batch [2100]	Speed: 0.80 samples/sec	Train-RPNAcc=0.856502,	RPNLogLoss=0.385392,	RPNL1Loss=0.101687,	RCNNAcc=0.874018,	RCNNLogLoss=0.362625,	RCNNL1Loss=0.318381,	
INFO:root:Epoch[1] Batch [2120]	Speed: 0.89 samples/sec	Train-RPNAcc=0.857252,	RPNLogLoss=0.383350,	RPNL1Loss=0.101195,	RCNNAcc=0.874599,	RCNNLogLoss=0.360952,	RCNNL1Loss=0.317366,	
INFO:root:Epoch[1] Batch [2140]	Speed: 0.83 samples/sec	Train-RPNAcc=0.857658,	RPNLogLoss=0.381711,	RPNL1Loss=0.101094,	RCNNAcc=0.875113,	RCNNLogLoss=0.359405,	RCNNL1Loss=0.316549,	
INFO:root:Epoch[1] Batch [2160]	Speed: 0.90 samples/sec	Train-RPNAcc=0.858370,	RPNLogLoss=0.379575,	RPNL1Loss=0.100591,	RCNNAcc=0.875622,	RCNNLogLoss=0.357947,	RCNNL1Loss=0.315718,	
INFO:root:Epoch[1] Batch [2180]	Speed: 0.81 samples/sec	Train-RPNAcc=0.858976,	RPNLogLoss=0.377806,	RPNL1Loss=0.100302,	RCNNAcc=0.876003,	RCNNLogLoss=0.356597,	RCNNL1Loss=0.314991,	
INFO:root:Epoch[1] Batch [2200]	Speed: 0.86 samples/sec	Train-RPNAcc=0.859687,	RPNLogLoss=0.375743,	RPNL1Loss=0.099743,	RCNNAcc=0.876548,	RCNNLogLoss=0.354912,	RCNNL1Loss=0.313974,	
INFO:root:Epoch[1] Batch [2220]	Speed: 0.82 samples/sec	Train-RPNAcc=0.860165,	RPNLogLoss=0.374027,	RPNL1Loss=0.099471,	RCNNAcc=0.876833,	RCNNLogLoss=0.354012,	RCNNL1Loss=0.313638,	
INFO:root:Epoch[1] Batch [2240]	Speed: 0.85 samples/sec	Train-RPNAcc=0.860475,	RPNLogLoss=0.372665,	RPNL1Loss=0.099325,	RCNNAcc=0.877221,	RCNNLogLoss=0.352803,	RCNNL1Loss=0.313252,	
INFO:root:Epoch[1] Batch [2260]	Speed: 0.81 samples/sec	Train-RPNAcc=0.860971,	RPNLogLoss=0.371062,	RPNL1Loss=0.099041,	RCNNAcc=0.877505,	RCNNLogLoss=0.351964,	RCNNL1Loss=0.312908,	
INFO:root:Epoch[1] Batch [2280]	Speed: 0.85 samples/sec	Train-RPNAcc=0.861350,	RPNLogLoss=0.369532,	RPNL1Loss=0.098839,	RCNNAcc=0.877891,	RCNNLogLoss=0.350823,	RCNNL1Loss=0.312481,	
INFO:root:Epoch[1] Batch [2300]	Speed: 0.85 samples/sec	Train-RPNAcc=0.861983,	RPNLogLoss=0.367731,	RPNL1Loss=0.098447,	RCNNAcc=0.878283,	RCNNLogLoss=0.349503,	RCNNL1Loss=0.311819,	
INFO:root:Epoch[1] Batch [2320]	Speed: 0.80 samples/sec	Train-RPNAcc=0.862500,	RPNLogLoss=0.366047,	RPNL1Loss=0.098150,	RCNNAcc=0.878514,	RCNNLogLoss=0.348630,	RCNNL1Loss=0.311647,	
INFO:root:Epoch[1] Batch [2340]	Speed: 0.82 samples/sec	Train-RPNAcc=0.862757,	RPNLogLoss=0.364759,	RPNL1Loss=0.098071,	RCNNAcc=0.878674,	RCNNLogLoss=0.348093,	RCNNL1Loss=0.311368,	
INFO:root:Epoch[1] Batch [2360]	Speed: 0.80 samples/sec	Train-RPNAcc=0.863233,	RPNLogLoss=0.363512,	RPNL1Loss=0.097934,	RCNNAcc=0.878941,	RCNNLogLoss=0.347285,	RCNNL1Loss=0.310773,	
INFO:root:Epoch[1] Batch [2380]	Speed: 0.81 samples/sec	Train-RPNAcc=0.863578,	RPNLogLoss=0.362260,	RPNL1Loss=0.097664,	RCNNAcc=0.879187,	RCNNLogLoss=0.346573,	RCNNL1Loss=0.310616,	
INFO:root:Epoch[1] Batch [2400]	Speed: 0.86 samples/sec	Train-RPNAcc=0.864077,	RPNLogLoss=0.360688,	RPNL1Loss=0.097365,	RCNNAcc=0.879721,	RCNNLogLoss=0.345060,	RCNNL1Loss=0.309721,	
INFO:root:Epoch[1] Batch [2420]	Speed: 0.81 samples/sec	Train-RPNAcc=0.864507,	RPNLogLoss=0.359195,	RPNL1Loss=0.097014,	RCNNAcc=0.879924,	RCNNLogLoss=0.344369,	RCNNL1Loss=0.309600,	
INFO:root:Epoch[1] Batch [2440]	Speed: 0.85 samples/sec	Train-RPNAcc=0.865043,	RPNLogLoss=0.357729,	RPNL1Loss=0.096715,	RCNNAcc=0.880188,	RCNNLogLoss=0.343552,	RCNNL1Loss=0.309412,	
INFO:root:Epoch[1] Batch [2460]	Speed: 0.86 samples/sec	Train-RPNAcc=0.865592,	RPNLogLoss=0.356121,	RPNL1Loss=0.096385,	RCNNAcc=0.880600,	RCNNLogLoss=0.342278,	RCNNL1Loss=0.308501,	
INFO:root:Epoch[1] Batch [2480]	Speed: 0.84 samples/sec	Train-RPNAcc=0.865915,	RPNLogLoss=0.354900,	RPNL1Loss=0.096300,	RCNNAcc=0.880885,	RCNNLogLoss=0.341440,	RCNNL1Loss=0.308160,	
INFO:root:Epoch[1] Batch [2500]	Speed: 0.77 samples/sec	Train-RPNAcc=0.866503,	RPNLogLoss=0.353377,	RPNL1Loss=0.096017,	RCNNAcc=0.881198,	RCNNLogLoss=0.340451,	RCNNL1Loss=0.307925,	
INFO:root:Epoch[1] Batch [2520]	Speed: 0.85 samples/sec	Train-RPNAcc=0.866978,	RPNLogLoss=0.352023,	RPNL1Loss=0.095836,	RCNNAcc=0.881468,	RCNNLogLoss=0.339454,	RCNNL1Loss=0.307576,	
INFO:root:Epoch[1] Batch [2540]	Speed: 0.78 samples/sec	Train-RPNAcc=0.867393,	RPNLogLoss=0.350769,	RPNL1Loss=0.095712,	RCNNAcc=0.881773,	RCNNLogLoss=0.338405,	RCNNL1Loss=0.307129,	
INFO:root:Epoch[1] Batch [2560]	Speed: 0.88 samples/sec	Train-RPNAcc=0.867976,	RPNLogLoss=0.349246,	RPNL1Loss=0.095394,	RCNNAcc=0.882154,	RCNNLogLoss=0.337287,	RCNNL1Loss=0.306302,	
INFO:root:Epoch[1] Batch [2580]	Speed: 0.76 samples/sec	Train-RPNAcc=0.868224,	RPNLogLoss=0.348230,	RPNL1Loss=0.095425,	RCNNAcc=0.882228,	RCNNLogLoss=0.336893,	RCNNL1Loss=0.306407,	
INFO:root:Epoch[1] Batch [2600]	Speed: 0.77 samples/sec	Train-RPNAcc=0.868763,	RPNLogLoss=0.346880,	RPNL1Loss=0.095226,	RCNNAcc=0.882539,	RCNNLogLoss=0.336105,	RCNNL1Loss=0.306320,	
INFO:root:Epoch[1] Batch [2620]	Speed: 0.78 samples/sec	Train-RPNAcc=0.869076,	RPNLogLoss=0.345934,	RPNL1Loss=0.095203,	RCNNAcc=0.882672,	RCNNLogLoss=0.335624,	RCNNL1Loss=0.306459,	
INFO:root:Epoch[1] Batch [2640]	Speed: 0.79 samples/sec	Train-RPNAcc=0.869564,	RPNLogLoss=0.344696,	RPNL1Loss=0.094978,	RCNNAcc=0.882966,	RCNNLogLoss=0.334689,	RCNNL1Loss=0.306015,	
INFO:root:Epoch[1] Batch [2660]	Speed: 0.80 samples/sec	Train-RPNAcc=0.869997,	RPNLogLoss=0.343478,	RPNL1Loss=0.094815,	RCNNAcc=0.883182,	RCNNLogLoss=0.333949,	RCNNL1Loss=0.305626,	
INFO:root:Epoch[1] Batch [2680]	Speed: 0.75 samples/sec	Train-RPNAcc=0.870244,	RPNLogLoss=0.342589,	RPNL1Loss=0.094792,	RCNNAcc=0.883145,	RCNNLogLoss=0.333905,	RCNNL1Loss=0.305916,	
INFO:root:Epoch[1] Batch [2700]	Speed: 0.83 samples/sec	Train-RPNAcc=0.870861,	RPNLogLoss=0.341033,	RPNL1Loss=0.094362,	RCNNAcc=0.883550,	RCNNLogLoss=0.332634,	RCNNL1Loss=0.305160,	
INFO:root:Epoch[1] Batch [2720]	Speed: 0.78 samples/sec	Train-RPNAcc=0.871280,	RPNLogLoss=0.339874,	RPNL1Loss=0.094282,	RCNNAcc=0.883869,	RCNNLogLoss=0.331607,	RCNNL1Loss=0.304597,	
INFO:root:Epoch[1] Batch [2740]	Speed: 0.79 samples/sec	Train-RPNAcc=0.871836,	RPNLogLoss=0.338558,	RPNL1Loss=0.094042,	RCNNAcc=0.884135,	RCNNLogLoss=0.330815,	RCNNL1Loss=0.304116,	
INFO:root:Epoch[1] Batch [2760]	Speed: 0.75 samples/sec	Train-RPNAcc=0.872173,	RPNLogLoss=0.337499,	RPNL1Loss=0.093953,	RCNNAcc=0.884369,	RCNNLogLoss=0.330101,	RCNNL1Loss=0.303963,	
INFO:root:Epoch[1] Batch [2780]	Speed: 0.89 samples/sec	Train-RPNAcc=0.872786,	RPNLogLoss=0.336105,	RPNL1Loss=0.093614,	RCNNAcc=0.884745,	RCNNLogLoss=0.328845,	RCNNL1Loss=0.303127,	
INFO:root:Epoch[1] Batch [2800]	Speed: 0.83 samples/sec	Train-RPNAcc=0.873272,	RPNLogLoss=0.334800,	RPNL1Loss=0.093364,	RCNNAcc=0.885005,	RCNNLogLoss=0.327897,	RCNNL1Loss=0.302808,	
INFO:root:Epoch[1] Batch [2820]	Speed: 0.84 samples/sec	Train-RPNAcc=0.873694,	RPNLogLoss=0.333542,	RPNL1Loss=0.093155,	RCNNAcc=0.885302,	RCNNLogLoss=0.326976,	RCNNL1Loss=0.302299,	
INFO:root:Epoch[1] Batch [2840]	Speed: 0.82 samples/sec	Train-RPNAcc=0.874215,	RPNLogLoss=0.332263,	RPNL1Loss=0.092859,	RCNNAcc=0.885667,	RCNNLogLoss=0.326070,	RCNNL1Loss=0.301765,	
INFO:root:Epoch[1] Batch [2860]	Speed: 0.76 samples/sec	Train-RPNAcc=0.874590,	RPNLogLoss=0.331169,	RPNL1Loss=0.092796,	RCNNAcc=0.885964,	RCNNLogLoss=0.325104,	RCNNL1Loss=0.301385,	
INFO:root:Epoch[1] Batch [2880]	Speed: 0.81 samples/sec	Train-RPNAcc=0.875062,	RPNLogLoss=0.329917,	RPNL1Loss=0.092560,	RCNNAcc=0.886243,	RCNNLogLoss=0.324285,	RCNNL1Loss=0.300833,	
INFO:root:Epoch[1] Batch [2900]	Speed: 0.78 samples/sec	Train-RPNAcc=0.875470,	RPNLogLoss=0.328748,	RPNL1Loss=0.092372,	RCNNAcc=0.886470,	RCNNLogLoss=0.323418,	RCNNL1Loss=0.300475,	
INFO:root:Epoch[1] Batch [2920]	Speed: 0.75 samples/sec	Train-RPNAcc=0.875895,	RPNLogLoss=0.327618,	RPNL1Loss=0.092282,	RCNNAcc=0.886669,	RCNNLogLoss=0.322733,	RCNNL1Loss=0.300041,	
INFO:root:Epoch[1] Batch [2940]	Speed: 0.75 samples/sec	Train-RPNAcc=0.876250,	RPNLogLoss=0.326665,	RPNL1Loss=0.092158,	RCNNAcc=0.886725,	RCNNLogLoss=0.322477,	RCNNL1Loss=0.300266,	
INFO:root:Epoch[1] Batch [2960]	Speed: 0.76 samples/sec	Train-RPNAcc=0.876689,	RPNLogLoss=0.325513,	RPNL1Loss=0.091947,	RCNNAcc=0.887016,	RCNNLogLoss=0.321724,	RCNNL1Loss=0.300075,	
INFO:root:Epoch[1] Batch [2980]	Speed: 0.78 samples/sec	Train-RPNAcc=0.877068,	RPNLogLoss=0.324529,	RPNL1Loss=0.091807,	RCNNAcc=0.887121,	RCNNLogLoss=0.321303,	RCNNL1Loss=0.300163,	
INFO:root:Epoch[1] Batch [3000]	Speed: 0.68 samples/sec	Train-RPNAcc=0.877355,	RPNLogLoss=0.323731,	RPNL1Loss=0.091801,	RCNNAcc=0.887186,	RCNNLogLoss=0.320999,	RCNNL1Loss=0.300308,	
INFO:root:Epoch[1] Batch [3020]	Speed: 0.74 samples/sec	Train-RPNAcc=0.877728,	RPNLogLoss=0.322710,	RPNL1Loss=0.091593,	RCNNAcc=0.887317,	RCNNLogLoss=0.320447,	RCNNL1Loss=0.300151,	
INFO:root:Epoch[1] Batch [3040]	Speed: 0.78 samples/sec	Train-RPNAcc=0.878118,	RPNLogLoss=0.321665,	RPNL1Loss=0.091380,	RCNNAcc=0.887506,	RCNNLogLoss=0.319877,	RCNNL1Loss=0.299999,	
INFO:root:Epoch[1] Batch [3060]	Speed: 0.80 samples/sec	Train-RPNAcc=0.878530,	RPNLogLoss=0.320569,	RPNL1Loss=0.091227,	RCNNAcc=0.887879,	RCNNLogLoss=0.318745,	RCNNL1Loss=0.299309,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [3080]	Speed: 0.85 samples/sec	Train-RPNAcc=0.878962,	RPNLogLoss=0.319501,	RPNL1Loss=0.090994,	RCNNAcc=0.888221,	RCNNLogLoss=0.317726,	RCNNL1Loss=0.298720,	
INFO:root:Epoch[1] Batch [3100]	Speed: 0.73 samples/sec	Train-RPNAcc=0.879255,	RPNLogLoss=0.318536,	RPNL1Loss=0.090907,	RCNNAcc=0.888479,	RCNNLogLoss=0.316958,	RCNNL1Loss=0.298433,	
INFO:root:Epoch[1] Batch [3120]	Speed: 0.77 samples/sec	Train-RPNAcc=0.879737,	RPNLogLoss=0.317332,	RPNL1Loss=0.090663,	RCNNAcc=0.888710,	RCNNLogLoss=0.316287,	RCNNL1Loss=0.298104,	
INFO:root:Epoch[1] Batch [3140]	Speed: 0.82 samples/sec	Train-RPNAcc=0.880104,	RPNLogLoss=0.316404,	RPNL1Loss=0.090415,	RCNNAcc=0.888906,	RCNNLogLoss=0.315656,	RCNNL1Loss=0.297855,	
INFO:root:Epoch[1] Batch [3160]	Speed: 0.74 samples/sec	Train-RPNAcc=0.880350,	RPNLogLoss=0.315526,	RPNL1Loss=0.090253,	RCNNAcc=0.889172,	RCNNLogLoss=0.314879,	RCNNL1Loss=0.297455,	
INFO:root:Epoch[1] Batch [3180]	Speed: 0.81 samples/sec	Train-RPNAcc=0.880799,	RPNLogLoss=0.314427,	RPNL1Loss=0.090053,	RCNNAcc=0.889444,	RCNNLogLoss=0.314085,	RCNNL1Loss=0.297004,	
INFO:root:Epoch[1] Batch [3200]	Speed: 0.73 samples/sec	Train-RPNAcc=0.881271,	RPNLogLoss=0.313309,	RPNL1Loss=0.089866,	RCNNAcc=0.889685,	RCNNLogLoss=0.313411,	RCNNL1Loss=0.296764,	
INFO:root:Epoch[1] Batch [3220]	Speed: 0.75 samples/sec	Train-RPNAcc=0.881772,	RPNLogLoss=0.312162,	RPNL1Loss=0.089596,	RCNNAcc=0.889859,	RCNNLogLoss=0.312799,	RCNNL1Loss=0.296392,	
INFO:root:Epoch[1] Batch [3240]	Speed: 0.76 samples/sec	Train-RPNAcc=0.882195,	RPNLogLoss=0.311205,	RPNL1Loss=0.089553,	RCNNAcc=0.890027,	RCNNLogLoss=0.312225,	RCNNL1Loss=0.296088,	
INFO:root:Epoch[1] Batch [3260]	Speed: 0.82 samples/sec	Train-RPNAcc=0.882612,	RPNLogLoss=0.310177,	RPNL1Loss=0.089306,	RCNNAcc=0.890335,	RCNNLogLoss=0.311239,	RCNNL1Loss=0.295620,	
INFO:root:Epoch[1] Batch [3280]	Speed: 0.78 samples/sec	Train-RPNAcc=0.882961,	RPNLogLoss=0.309295,	RPNL1Loss=0.089213,	RCNNAcc=0.890508,	RCNNLogLoss=0.310685,	RCNNL1Loss=0.295442,	
INFO:root:Epoch[1] Batch [3300]	Speed: 0.73 samples/sec	Train-RPNAcc=0.883343,	RPNLogLoss=0.308459,	RPNL1Loss=0.089042,	RCNNAcc=0.890606,	RCNNLogLoss=0.310287,	RCNNL1Loss=0.295175,	
INFO:root:Epoch[1] Batch [3320]	Speed: 0.76 samples/sec	Train-RPNAcc=0.883836,	RPNLogLoss=0.307340,	RPNL1Loss=0.088750,	RCNNAcc=0.890903,	RCNNLogLoss=0.309439,	RCNNL1Loss=0.294700,	
INFO:root:Epoch[1] Batch [3340]	Speed: 0.77 samples/sec	Train-RPNAcc=0.884183,	RPNLogLoss=0.306505,	RPNL1Loss=0.088563,	RCNNAcc=0.891027,	RCNNLogLoss=0.309030,	RCNNL1Loss=0.294633,	
INFO:root:Epoch[1] Batch [3360]	Speed: 0.73 samples/sec	Train-RPNAcc=0.884549,	RPNLogLoss=0.305537,	RPNL1Loss=0.088361,	RCNNAcc=0.891190,	RCNNLogLoss=0.308435,	RCNNL1Loss=0.294278,	
INFO:root:Epoch[1] Batch [3380]	Speed: 0.73 samples/sec	Train-RPNAcc=0.884922,	RPNLogLoss=0.304614,	RPNL1Loss=0.088266,	RCNNAcc=0.891390,	RCNNLogLoss=0.307786,	RCNNL1Loss=0.294002,	
INFO:root:Epoch[1] Batch [3400]	Speed: 0.77 samples/sec	Train-RPNAcc=0.885211,	RPNLogLoss=0.303823,	RPNL1Loss=0.088167,	RCNNAcc=0.891463,	RCNNLogLoss=0.307527,	RCNNL1Loss=0.294042,	
INFO:root:Epoch[1] Batch [3420]	Speed: 0.75 samples/sec	Train-RPNAcc=0.885608,	RPNLogLoss=0.302873,	RPNL1Loss=0.087930,	RCNNAcc=0.891744,	RCNNLogLoss=0.306744,	RCNNL1Loss=0.293725,	
INFO:root:Epoch[1] Batch [3440]	Speed: 0.79 samples/sec	Train-RPNAcc=0.885994,	RPNLogLoss=0.301923,	RPNL1Loss=0.087752,	RCNNAcc=0.891955,	RCNNLogLoss=0.306182,	RCNNL1Loss=0.293499,	
INFO:root:Epoch[1] Batch [3460]	Speed: 0.76 samples/sec	Train-RPNAcc=0.886320,	RPNLogLoss=0.301185,	RPNL1Loss=0.087696,	RCNNAcc=0.892131,	RCNNLogLoss=0.305670,	RCNNL1Loss=0.293321,	
INFO:root:Epoch[1] Batch [3480]	Speed: 0.79 samples/sec	Train-RPNAcc=0.886690,	RPNLogLoss=0.300291,	RPNL1Loss=0.087597,	RCNNAcc=0.892429,	RCNNLogLoss=0.304746,	RCNNL1Loss=0.292909,	
INFO:root:Epoch[1] Batch [3500]	Speed: 0.80 samples/sec	Train-RPNAcc=0.887093,	RPNLogLoss=0.299409,	RPNL1Loss=0.087419,	RCNNAcc=0.892694,	RCNNLogLoss=0.303968,	RCNNL1Loss=0.292452,	
INFO:root:Epoch[1] Batch [3520]	Speed: 0.72 samples/sec	Train-RPNAcc=0.887481,	RPNLogLoss=0.298568,	RPNL1Loss=0.087351,	RCNNAcc=0.892722,	RCNNLogLoss=0.303750,	RCNNL1Loss=0.292397,	
INFO:root:Epoch[1] Batch [3540]	Speed: 0.70 samples/sec	Train-RPNAcc=0.887812,	RPNLogLoss=0.297797,	RPNL1Loss=0.087285,	RCNNAcc=0.892798,	RCNNLogLoss=0.303351,	RCNNL1Loss=0.292350,	
INFO:root:Epoch[1] Batch [3560]	Speed: 0.80 samples/sec	Train-RPNAcc=0.888141,	RPNLogLoss=0.296934,	RPNL1Loss=0.087136,	RCNNAcc=0.893005,	RCNNLogLoss=0.302687,	RCNNL1Loss=0.292005,	
INFO:root:Epoch[1] Batch [3580]	Speed: 0.79 samples/sec	Train-RPNAcc=0.888484,	RPNLogLoss=0.296042,	RPNL1Loss=0.086949,	RCNNAcc=0.893204,	RCNNLogLoss=0.302060,	RCNNL1Loss=0.291705,	
INFO:root:Epoch[1] Batch [3600]	Speed: 0.79 samples/sec	Train-RPNAcc=0.888887,	RPNLogLoss=0.295138,	RPNL1Loss=0.086757,	RCNNAcc=0.893389,	RCNNLogLoss=0.301446,	RCNNL1Loss=0.291451,	
INFO:root:Epoch[1] Batch [3620]	Speed: 0.80 samples/sec	Train-RPNAcc=0.889241,	RPNLogLoss=0.294307,	RPNL1Loss=0.086597,	RCNNAcc=0.893553,	RCNNLogLoss=0.300891,	RCNNL1Loss=0.291383,	
INFO:root:Epoch[1] Batch [3640]	Speed: 0.72 samples/sec	Train-RPNAcc=0.889564,	RPNLogLoss=0.293580,	RPNL1Loss=0.086513,	RCNNAcc=0.893642,	RCNNLogLoss=0.300624,	RCNNL1Loss=0.291307,	
INFO:root:Epoch[1] Batch [3660]	Speed: 0.78 samples/sec	Train-RPNAcc=0.889923,	RPNLogLoss=0.292662,	RPNL1Loss=0.086292,	RCNNAcc=0.893839,	RCNNLogLoss=0.300041,	RCNNL1Loss=0.291076,	
INFO:root:Epoch[1] Batch [3680]	Speed: 0.75 samples/sec	Train-RPNAcc=0.890303,	RPNLogLoss=0.291776,	RPNL1Loss=0.086176,	RCNNAcc=0.893944,	RCNNLogLoss=0.299564,	RCNNL1Loss=0.291087,	
INFO:root:Epoch[1] Batch [3700]	Speed: 0.75 samples/sec	Train-RPNAcc=0.890678,	RPNLogLoss=0.290852,	RPNL1Loss=0.086016,	RCNNAcc=0.894125,	RCNNLogLoss=0.298946,	RCNNL1Loss=0.290833,	
INFO:root:Epoch[1] Batch [3720]	Speed: 0.81 samples/sec	Train-RPNAcc=0.891035,	RPNLogLoss=0.289928,	RPNL1Loss=0.085789,	RCNNAcc=0.894310,	RCNNLogLoss=0.298283,	RCNNL1Loss=0.290378,	
INFO:root:Epoch[1] Batch [3740]	Speed: 0.72 samples/sec	Train-RPNAcc=0.891315,	RPNLogLoss=0.289160,	RPNL1Loss=0.085662,	RCNNAcc=0.894522,	RCNNLogLoss=0.297681,	RCNNL1Loss=0.290024,	
INFO:root:Epoch[1] Batch [3760]	Speed: 0.74 samples/sec	Train-RPNAcc=0.891652,	RPNLogLoss=0.288380,	RPNL1Loss=0.085599,	RCNNAcc=0.894626,	RCNNLogLoss=0.297383,	RCNNL1Loss=0.289930,	
INFO:root:Epoch[1] Batch [3780]	Speed: 0.77 samples/sec	Train-RPNAcc=0.892011,	RPNLogLoss=0.287519,	RPNL1Loss=0.085421,	RCNNAcc=0.894859,	RCNNLogLoss=0.296681,	RCNNL1Loss=0.289586,	
INFO:root:Epoch[1] Batch [3800]	Speed: 0.73 samples/sec	Train-RPNAcc=0.892275,	RPNLogLoss=0.286899,	RPNL1Loss=0.085363,	RCNNAcc=0.895015,	RCNNLogLoss=0.296178,	RCNNL1Loss=0.289428,	
INFO:root:Epoch[1] Batch [3820]	Speed: 0.79 samples/sec	Train-RPNAcc=0.892568,	RPNLogLoss=0.286173,	RPNL1Loss=0.085222,	RCNNAcc=0.895164,	RCNNLogLoss=0.295763,	RCNNL1Loss=0.289301,	
INFO:root:Epoch[1] Batch [3840]	Speed: 0.72 samples/sec	Train-RPNAcc=0.892874,	RPNLogLoss=0.285401,	RPNL1Loss=0.085071,	RCNNAcc=0.895313,	RCNNLogLoss=0.295307,	RCNNL1Loss=0.289266,	
INFO:root:Epoch[1] Batch [3860]	Speed: 0.75 samples/sec	Train-RPNAcc=0.893122,	RPNLogLoss=0.284730,	RPNL1Loss=0.084993,	RCNNAcc=0.895354,	RCNNLogLoss=0.295009,	RCNNL1Loss=0.289338,	
INFO:root:Epoch[1] Batch [3880]	Speed: 0.73 samples/sec	Train-RPNAcc=0.893479,	RPNLogLoss=0.283902,	RPNL1Loss=0.084802,	RCNNAcc=0.895515,	RCNNLogLoss=0.294501,	RCNNL1Loss=0.289172,	
INFO:root:Epoch[1] Batch [3900]	Speed: 0.74 samples/sec	Train-RPNAcc=0.893734,	RPNLogLoss=0.283224,	RPNL1Loss=0.084746,	RCNNAcc=0.895692,	RCNNLogLoss=0.293985,	RCNNL1Loss=0.289008,	
INFO:root:Epoch[1] Batch [3920]	Speed: 0.77 samples/sec	Train-RPNAcc=0.894068,	RPNLogLoss=0.282454,	RPNL1Loss=0.084545,	RCNNAcc=0.895778,	RCNNLogLoss=0.293700,	RCNNL1Loss=0.288941,	
INFO:root:Epoch[1] Batch [3940]	Speed: 0.80 samples/sec	Train-RPNAcc=0.894430,	RPNLogLoss=0.281573,	RPNL1Loss=0.084358,	RCNNAcc=0.896013,	RCNNLogLoss=0.292983,	RCNNL1Loss=0.288560,	
INFO:root:Epoch[1] Batch [3960]	Speed: 0.73 samples/sec	Train-RPNAcc=0.894672,	RPNLogLoss=0.280852,	RPNL1Loss=0.084197,	RCNNAcc=0.896201,	RCNNLogLoss=0.292472,	RCNNL1Loss=0.288173,	
INFO:root:Epoch[1] Batch [3980]	Speed: 0.74 samples/sec	Train-RPNAcc=0.894941,	RPNLogLoss=0.280201,	RPNL1Loss=0.084106,	RCNNAcc=0.896300,	RCNNLogLoss=0.292150,	RCNNL1Loss=0.288053,	
INFO:root:Epoch[1] Batch [4000]	Speed: 0.79 samples/sec	Train-RPNAcc=0.895286,	RPNLogLoss=0.279377,	RPNL1Loss=0.083921,	RCNNAcc=0.896522,	RCNNLogLoss=0.291513,	RCNNL1Loss=0.287612,	
INFO:root:Epoch[1] Batch [4020]	Speed: 0.70 samples/sec	Train-RPNAcc=0.895602,	RPNLogLoss=0.278600,	RPNL1Loss=0.083741,	RCNNAcc=0.896681,	RCNNLogLoss=0.290987,	RCNNL1Loss=0.287542,	
INFO:root:Epoch[1] Batch [4040]	Speed: 0.78 samples/sec	Train-RPNAcc=0.895944,	RPNLogLoss=0.277805,	RPNL1Loss=0.083567,	RCNNAcc=0.896821,	RCNNLogLoss=0.290634,	RCNNL1Loss=0.287396,	
INFO:root:Epoch[1] Batch [4060]	Speed: 0.77 samples/sec	Train-RPNAcc=0.896282,	RPNLogLoss=0.276975,	RPNL1Loss=0.083359,	RCNNAcc=0.897025,	RCNNLogLoss=0.290139,	RCNNL1Loss=0.287045,	
INFO:root:Epoch[1] Batch [4080]	Speed: 0.74 samples/sec	Train-RPNAcc=0.896521,	RPNLogLoss=0.276407,	RPNL1Loss=0.083295,	RCNNAcc=0.897065,	RCNNLogLoss=0.290016,	RCNNL1Loss=0.287057,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [4100]	Speed: 0.75 samples/sec	Train-RPNAcc=0.896871,	RPNLogLoss=0.275656,	RPNL1Loss=0.083153,	RCNNAcc=0.897268,	RCNNLogLoss=0.289440,	RCNNL1Loss=0.286815,	
INFO:root:Epoch[1] Batch [4120]	Speed: 0.69 samples/sec	Train-RPNAcc=0.897061,	RPNLogLoss=0.275153,	RPNL1Loss=0.083099,	RCNNAcc=0.897321,	RCNNLogLoss=0.289194,	RCNNL1Loss=0.286739,	
INFO:root:Epoch[1] Batch [4140]	Speed: 0.71 samples/sec	Train-RPNAcc=0.897314,	RPNLogLoss=0.274557,	RPNL1Loss=0.083002,	RCNNAcc=0.897455,	RCNNLogLoss=0.288763,	RCNNL1Loss=0.286609,	
INFO:root:Epoch[1] Batch [4160]	Speed: 0.73 samples/sec	Train-RPNAcc=0.897598,	RPNLogLoss=0.273902,	RPNL1Loss=0.082931,	RCNNAcc=0.897583,	RCNNLogLoss=0.288372,	RCNNL1Loss=0.286402,	
INFO:root:Epoch[1] Batch [4180]	Speed: 0.78 samples/sec	Train-RPNAcc=0.897907,	RPNLogLoss=0.273249,	RPNL1Loss=0.082765,	RCNNAcc=0.897684,	RCNNLogLoss=0.288060,	RCNNL1Loss=0.286367,	
INFO:root:Epoch[1] Batch [4200]	Speed: 0.77 samples/sec	Train-RPNAcc=0.898248,	RPNLogLoss=0.272505,	RPNL1Loss=0.082614,	RCNNAcc=0.897835,	RCNNLogLoss=0.287686,	RCNNL1Loss=0.286128,	
INFO:root:Epoch[1] Batch [4220]	Speed: 0.73 samples/sec	Train-RPNAcc=0.898549,	RPNLogLoss=0.271786,	RPNL1Loss=0.082484,	RCNNAcc=0.897990,	RCNNLogLoss=0.287123,	RCNNL1Loss=0.285880,	
INFO:root:Epoch[1] Batch [4240]	Speed: 0.71 samples/sec	Train-RPNAcc=0.898770,	RPNLogLoss=0.271244,	RPNL1Loss=0.082399,	RCNNAcc=0.898062,	RCNNLogLoss=0.286885,	RCNNL1Loss=0.285890,	
INFO:root:Epoch[1] Batch [4260]	Speed: 0.79 samples/sec	Train-RPNAcc=0.899113,	RPNLogLoss=0.270510,	RPNL1Loss=0.082218,	RCNNAcc=0.898142,	RCNNLogLoss=0.286614,	RCNNL1Loss=0.285887,	
INFO:root:Epoch[1] Batch [4280]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899429,	RPNLogLoss=0.269785,	RPNL1Loss=0.082040,	RCNNAcc=0.898312,	RCNNLogLoss=0.286102,	RCNNL1Loss=0.285601,	
INFO:root:Epoch[1] Batch [4300]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899713,	RPNLogLoss=0.269159,	RPNL1Loss=0.081905,	RCNNAcc=0.898438,	RCNNLogLoss=0.285752,	RCNNL1Loss=0.285412,	
INFO:root:Epoch[1] Batch [4320]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899994,	RPNLogLoss=0.268486,	RPNL1Loss=0.081750,	RCNNAcc=0.898606,	RCNNLogLoss=0.285243,	RCNNL1Loss=0.285165,	
INFO:root:Epoch[1] Batch [4340]	Speed: 0.73 samples/sec	Train-RPNAcc=0.900334,	RPNLogLoss=0.267694,	RPNL1Loss=0.081541,	RCNNAcc=0.898740,	RCNNLogLoss=0.284824,	RCNNL1Loss=0.284869,	
INFO:root:Epoch[1] Batch [4360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.900544,	RPNLogLoss=0.267180,	RPNL1Loss=0.081472,	RCNNAcc=0.898824,	RCNNLogLoss=0.284539,	RCNNL1Loss=0.284874,	
INFO:root:Epoch[1] Batch [4380]	Speed: 0.79 samples/sec	Train-RPNAcc=0.900877,	RPNLogLoss=0.266395,	RPNL1Loss=0.081273,	RCNNAcc=0.899013,	RCNNLogLoss=0.283994,	RCNNL1Loss=0.284553,	
INFO:root:Epoch[1] Batch [4400]	Speed: 0.78 samples/sec	Train-RPNAcc=0.901175,	RPNLogLoss=0.265675,	RPNL1Loss=0.081113,	RCNNAcc=0.899162,	RCNNLogLoss=0.283540,	RCNNL1Loss=0.284336,	
INFO:root:Epoch[1] Batch [4420]	Speed: 0.72 samples/sec	Train-RPNAcc=0.901360,	RPNLogLoss=0.265206,	RPNL1Loss=0.081075,	RCNNAcc=0.899238,	RCNNLogLoss=0.283356,	RCNNL1Loss=0.284324,	
INFO:root:Epoch[1] Batch [4440]	Speed: 0.70 samples/sec	Train-RPNAcc=0.901578,	RPNLogLoss=0.264669,	RPNL1Loss=0.080992,	RCNNAcc=0.899375,	RCNNLogLoss=0.282898,	RCNNL1Loss=0.284250,	
INFO:root:Epoch[1] Batch [4460]	Speed: 0.71 samples/sec	Train-RPNAcc=0.901822,	RPNLogLoss=0.264137,	RPNL1Loss=0.080950,	RCNNAcc=0.899434,	RCNNLogLoss=0.282657,	RCNNL1Loss=0.284284,	
INFO:root:Epoch[1] Batch [4480]	Speed: 0.77 samples/sec	Train-RPNAcc=0.902077,	RPNLogLoss=0.263537,	RPNL1Loss=0.080781,	RCNNAcc=0.899546,	RCNNLogLoss=0.282264,	RCNNL1Loss=0.284127,	
INFO:root:Epoch[1] Batch [4500]	Speed: 0.74 samples/sec	Train-RPNAcc=0.902329,	RPNLogLoss=0.262906,	RPNL1Loss=0.080689,	RCNNAcc=0.899734,	RCNNLogLoss=0.281757,	RCNNL1Loss=0.283886,	
INFO:root:Epoch[1] Batch [4520]	Speed: 0.74 samples/sec	Train-RPNAcc=0.902549,	RPNLogLoss=0.262388,	RPNL1Loss=0.080676,	RCNNAcc=0.899865,	RCNNLogLoss=0.281387,	RCNNL1Loss=0.283761,	
INFO:root:Epoch[1] Batch [4540]	Speed: 0.73 samples/sec	Train-RPNAcc=0.902834,	RPNLogLoss=0.261710,	RPNL1Loss=0.080554,	RCNNAcc=0.900053,	RCNNLogLoss=0.280903,	RCNNL1Loss=0.283533,	
INFO:root:Epoch[1] Batch [4560]	Speed: 0.69 samples/sec	Train-RPNAcc=0.903026,	RPNLogLoss=0.261240,	RPNL1Loss=0.080481,	RCNNAcc=0.900116,	RCNNLogLoss=0.280688,	RCNNL1Loss=0.283652,	
INFO:root:Epoch[1] Batch [4580]	Speed: 0.66 samples/sec	Train-RPNAcc=0.903251,	RPNLogLoss=0.260753,	RPNL1Loss=0.080409,	RCNNAcc=0.900174,	RCNNLogLoss=0.280480,	RCNNL1Loss=0.283566,	
INFO:root:Epoch[1] Batch [4600]	Speed: 0.74 samples/sec	Train-RPNAcc=0.903517,	RPNLogLoss=0.260240,	RPNL1Loss=0.080371,	RCNNAcc=0.900271,	RCNNLogLoss=0.280162,	RCNNL1Loss=0.283449,	
INFO:root:Epoch[1] Batch [4620]	Speed: 0.78 samples/sec	Train-RPNAcc=0.903788,	RPNLogLoss=0.259644,	RPNL1Loss=0.080241,	RCNNAcc=0.900426,	RCNNLogLoss=0.279678,	RCNNL1Loss=0.283259,	
INFO:root:Epoch[1] Batch [4640]	Speed: 0.73 samples/sec	Train-RPNAcc=0.904017,	RPNLogLoss=0.259068,	RPNL1Loss=0.080089,	RCNNAcc=0.900540,	RCNNLogLoss=0.279335,	RCNNL1Loss=0.282956,	
INFO:root:Epoch[1] Batch [4660]	Speed: 0.78 samples/sec	Train-RPNAcc=0.904263,	RPNLogLoss=0.258475,	RPNL1Loss=0.079964,	RCNNAcc=0.900665,	RCNNLogLoss=0.278925,	RCNNL1Loss=0.282718,	
INFO:root:Epoch[1] Batch [4680]	Speed: 0.74 samples/sec	Train-RPNAcc=0.904521,	RPNLogLoss=0.257890,	RPNL1Loss=0.079857,	RCNNAcc=0.900751,	RCNNLogLoss=0.278668,	RCNNL1Loss=0.282745,	
INFO:root:Epoch[1] Batch [4700]	Speed: 0.80 samples/sec	Train-RPNAcc=0.904804,	RPNLogLoss=0.257231,	RPNL1Loss=0.079689,	RCNNAcc=0.900875,	RCNNLogLoss=0.278281,	RCNNL1Loss=0.282483,	
INFO:root:Epoch[1] Batch [4720]	Speed: 0.71 samples/sec	Train-RPNAcc=0.905028,	RPNLogLoss=0.256661,	RPNL1Loss=0.079593,	RCNNAcc=0.900946,	RCNNLogLoss=0.277976,	RCNNL1Loss=0.282334,	
INFO:root:Epoch[1] Batch [4740]	Speed: 0.77 samples/sec	Train-RPNAcc=0.905306,	RPNLogLoss=0.256017,	RPNL1Loss=0.079454,	RCNNAcc=0.901087,	RCNNLogLoss=0.277564,	RCNNL1Loss=0.282172,	
INFO:root:Epoch[1] Batch [4760]	Speed: 0.73 samples/sec	Train-RPNAcc=0.905526,	RPNLogLoss=0.255477,	RPNL1Loss=0.079378,	RCNNAcc=0.901170,	RCNNLogLoss=0.277305,	RCNNL1Loss=0.282113,	
INFO:root:Epoch[1] Batch [4780]	Speed: 0.71 samples/sec	Train-RPNAcc=0.905726,	RPNLogLoss=0.255010,	RPNL1Loss=0.079347,	RCNNAcc=0.901184,	RCNNLogLoss=0.277140,	RCNNL1Loss=0.282194,	
INFO:root:Epoch[1] Batch [4800]	Speed: 0.80 samples/sec	Train-RPNAcc=0.906025,	RPNLogLoss=0.254307,	RPNL1Loss=0.079162,	RCNNAcc=0.901425,	RCNNLogLoss=0.276460,	RCNNL1Loss=0.281712,	
INFO:root:Epoch[1] Batch [4820]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906253,	RPNLogLoss=0.253766,	RPNL1Loss=0.079084,	RCNNAcc=0.901518,	RCNNLogLoss=0.276129,	RCNNL1Loss=0.281576,	
INFO:root:Epoch[1] Batch [4840]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906539,	RPNLogLoss=0.253150,	RPNL1Loss=0.078924,	RCNNAcc=0.901715,	RCNNLogLoss=0.275593,	RCNNL1Loss=0.281237,	
INFO:root:Epoch[1] Batch [4860]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906838,	RPNLogLoss=0.252472,	RPNL1Loss=0.078776,	RCNNAcc=0.901816,	RCNNLogLoss=0.275262,	RCNNL1Loss=0.281074,	
INFO:root:Epoch[1] Batch [4880]	Speed: 0.73 samples/sec	Train-RPNAcc=0.907020,	RPNLogLoss=0.252081,	RPNL1Loss=0.078806,	RCNNAcc=0.901876,	RCNNLogLoss=0.275095,	RCNNL1Loss=0.280980,	
INFO:root:Epoch[1] Batch [4900]	Speed: 0.80 samples/sec	Train-RPNAcc=0.907308,	RPNLogLoss=0.251394,	RPNL1Loss=0.078645,	RCNNAcc=0.902067,	RCNNLogLoss=0.274503,	RCNNL1Loss=0.280646,	
INFO:root:Epoch[1] Batch [4920]	Speed: 0.72 samples/sec	Train-RPNAcc=0.907545,	RPNLogLoss=0.250798,	RPNL1Loss=0.078515,	RCNNAcc=0.902162,	RCNNLogLoss=0.274184,	RCNNL1Loss=0.280613,	
INFO:root:Epoch[1] Batch [4940]	Speed: 0.75 samples/sec	Train-RPNAcc=0.907778,	RPNLogLoss=0.250253,	RPNL1Loss=0.078414,	RCNNAcc=0.902324,	RCNNLogLoss=0.273814,	RCNNL1Loss=0.280308,	
INFO:root:Epoch[1] Batch [4960]	Speed: 0.73 samples/sec	Train-RPNAcc=0.908055,	RPNLogLoss=0.249642,	RPNL1Loss=0.078238,	RCNNAcc=0.902434,	RCNNLogLoss=0.273491,	RCNNL1Loss=0.280126,	
INFO:root:Epoch[1] Batch [4980]	Speed: 0.71 samples/sec	Train-RPNAcc=0.908252,	RPNLogLoss=0.249143,	RPNL1Loss=0.078156,	RCNNAcc=0.902445,	RCNNLogLoss=0.273346,	RCNNL1Loss=0.280018,	
INFO:root:Epoch[1] Batch [5000]	Speed: 0.77 samples/sec	Train-RPNAcc=0.908489,	RPNLogLoss=0.248578,	RPNL1Loss=0.078025,	RCNNAcc=0.902573,	RCNNLogLoss=0.272951,	RCNNL1Loss=0.279818,	
INFO:root:Epoch[1] Batch [5020]	Speed: 0.75 samples/sec	Train-RPNAcc=0.908760,	RPNLogLoss=0.247965,	RPNL1Loss=0.077843,	RCNNAcc=0.902737,	RCNNLogLoss=0.272524,	RCNNL1Loss=0.279552,	
INFO:root:Epoch[1] Batch [5040]	Speed: 0.74 samples/sec	Train-RPNAcc=0.908936,	RPNLogLoss=0.247545,	RPNL1Loss=0.077784,	RCNNAcc=0.902858,	RCNNLogLoss=0.272181,	RCNNL1Loss=0.279498,	
INFO:root:Epoch[1] Batch [5060]	Speed: 0.72 samples/sec	Train-RPNAcc=0.909163,	RPNLogLoss=0.247003,	RPNL1Loss=0.077716,	RCNNAcc=0.902996,	RCNNLogLoss=0.271752,	RCNNL1Loss=0.279341,	
INFO:root:Epoch[1] Batch [5080]	Speed: 0.78 samples/sec	Train-RPNAcc=0.909435,	RPNLogLoss=0.246408,	RPNL1Loss=0.077546,	RCNNAcc=0.903124,	RCNNLogLoss=0.271336,	RCNNL1Loss=0.279091,	
INFO:root:Epoch[1] Batch [5100]	Speed: 0.70 samples/sec	Train-RPNAcc=0.909692,	RPNLogLoss=0.245802,	RPNL1Loss=0.077445,	RCNNAcc=0.903208,	RCNNLogLoss=0.271054,	RCNNL1Loss=0.278974,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [5120]	Speed: 0.70 samples/sec	Train-RPNAcc=0.909963,	RPNLogLoss=0.245170,	RPNL1Loss=0.077298,	RCNNAcc=0.903351,	RCNNLogLoss=0.270594,	RCNNL1Loss=0.278668,	
INFO:root:Epoch[1] Batch [5140]	Speed: 0.75 samples/sec	Train-RPNAcc=0.910224,	RPNLogLoss=0.244568,	RPNL1Loss=0.077164,	RCNNAcc=0.903474,	RCNNLogLoss=0.270211,	RCNNL1Loss=0.278516,	
INFO:root:Epoch[1] Batch [5160]	Speed: 0.74 samples/sec	Train-RPNAcc=0.910466,	RPNLogLoss=0.243956,	RPNL1Loss=0.077031,	RCNNAcc=0.903613,	RCNNLogLoss=0.269810,	RCNNL1Loss=0.278249,	
INFO:root:Epoch[1] Batch [5180]	Speed: 0.77 samples/sec	Train-RPNAcc=0.910690,	RPNLogLoss=0.243444,	RPNL1Loss=0.076918,	RCNNAcc=0.903803,	RCNNLogLoss=0.269320,	RCNNL1Loss=0.277901,	
INFO:root:Epoch[1] Batch [5200]	Speed: 0.71 samples/sec	Train-RPNAcc=0.910879,	RPNLogLoss=0.243013,	RPNL1Loss=0.076818,	RCNNAcc=0.903937,	RCNNLogLoss=0.268872,	RCNNL1Loss=0.277825,	
INFO:root:Epoch[1] Batch [5220]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911058,	RPNLogLoss=0.242564,	RPNL1Loss=0.076743,	RCNNAcc=0.904028,	RCNNLogLoss=0.268582,	RCNNL1Loss=0.277632,	
INFO:root:Epoch[1] Batch [5240]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911271,	RPNLogLoss=0.242094,	RPNL1Loss=0.076677,	RCNNAcc=0.904160,	RCNNLogLoss=0.268168,	RCNNL1Loss=0.277501,	
INFO:root:Epoch[1] Batch [5260]	Speed: 0.76 samples/sec	Train-RPNAcc=0.911492,	RPNLogLoss=0.241602,	RPNL1Loss=0.076578,	RCNNAcc=0.904259,	RCNNLogLoss=0.267887,	RCNNL1Loss=0.277402,	
INFO:root:Epoch[1] Batch [5280]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911745,	RPNLogLoss=0.241048,	RPNL1Loss=0.076472,	RCNNAcc=0.904358,	RCNNLogLoss=0.267521,	RCNNL1Loss=0.277258,	
INFO:root:Epoch[1] Batch [5300]	Speed: 0.70 samples/sec	Train-RPNAcc=0.911932,	RPNLogLoss=0.240665,	RPNL1Loss=0.076497,	RCNNAcc=0.904405,	RCNNLogLoss=0.267390,	RCNNL1Loss=0.277314,	
INFO:root:Epoch[1] Batch [5320]	Speed: 0.75 samples/sec	Train-RPNAcc=0.912115,	RPNLogLoss=0.240178,	RPNL1Loss=0.076399,	RCNNAcc=0.904534,	RCNNLogLoss=0.267043,	RCNNL1Loss=0.277159,	
INFO:root:Epoch[1] Batch [5340]	Speed: 0.75 samples/sec	Train-RPNAcc=0.912335,	RPNLogLoss=0.239681,	RPNL1Loss=0.076302,	RCNNAcc=0.904632,	RCNNLogLoss=0.266712,	RCNNL1Loss=0.277067,	
INFO:root:Epoch[1] Batch [5360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.912546,	RPNLogLoss=0.239202,	RPNL1Loss=0.076228,	RCNNAcc=0.904707,	RCNNLogLoss=0.266483,	RCNNL1Loss=0.276950,	
INFO:root:Epoch[1] Batch [5380]	Speed: 0.73 samples/sec	Train-RPNAcc=0.912774,	RPNLogLoss=0.238676,	RPNL1Loss=0.076123,	RCNNAcc=0.904893,	RCNNLogLoss=0.265949,	RCNNL1Loss=0.276662,	
INFO:root:Epoch[1] Batch [5400]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913004,	RPNLogLoss=0.238117,	RPNL1Loss=0.075997,	RCNNAcc=0.904990,	RCNNLogLoss=0.265616,	RCNNL1Loss=0.276434,	
INFO:root:Epoch[1] Batch [5420]	Speed: 0.69 samples/sec	Train-RPNAcc=0.913177,	RPNLogLoss=0.237754,	RPNL1Loss=0.075970,	RCNNAcc=0.905035,	RCNNLogLoss=0.265429,	RCNNL1Loss=0.276429,	
INFO:root:Epoch[1] Batch [5440]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913411,	RPNLogLoss=0.237215,	RPNL1Loss=0.075830,	RCNNAcc=0.905153,	RCNNLogLoss=0.265066,	RCNNL1Loss=0.276254,	
INFO:root:Epoch[1] Batch [5460]	Speed: 0.72 samples/sec	Train-RPNAcc=0.913592,	RPNLogLoss=0.236801,	RPNL1Loss=0.075742,	RCNNAcc=0.905177,	RCNNLogLoss=0.264962,	RCNNL1Loss=0.276302,	
INFO:root:Epoch[1] Batch [5480]	Speed: 0.70 samples/sec	Train-RPNAcc=0.913738,	RPNLogLoss=0.236452,	RPNL1Loss=0.075719,	RCNNAcc=0.905229,	RCNNLogLoss=0.264747,	RCNNL1Loss=0.276287,	
INFO:root:Epoch[1] Batch [5500]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913955,	RPNLogLoss=0.235980,	RPNL1Loss=0.075598,	RCNNAcc=0.905313,	RCNNLogLoss=0.264466,	RCNNL1Loss=0.276218,	
INFO:root:Epoch[1] Batch [5520]	Speed: 0.74 samples/sec	Train-RPNAcc=0.914161,	RPNLogLoss=0.235513,	RPNL1Loss=0.075502,	RCNNAcc=0.905414,	RCNNLogLoss=0.264185,	RCNNL1Loss=0.276074,	
INFO:root:Epoch[1] Batch [5540]	Speed: 0.69 samples/sec	Train-RPNAcc=0.914352,	RPNLogLoss=0.235120,	RPNL1Loss=0.075437,	RCNNAcc=0.905459,	RCNNLogLoss=0.264035,	RCNNL1Loss=0.276114,	
INFO:root:Epoch[1] Batch [5560]	Speed: 0.74 samples/sec	Train-RPNAcc=0.914546,	RPNLogLoss=0.234689,	RPNL1Loss=0.075365,	RCNNAcc=0.905543,	RCNNLogLoss=0.263714,	RCNNL1Loss=0.276001,	
INFO:root:Epoch[1] Batch [5580]	Speed: 0.72 samples/sec	Train-RPNAcc=0.914749,	RPNLogLoss=0.234252,	RPNL1Loss=0.075319,	RCNNAcc=0.905593,	RCNNLogLoss=0.263549,	RCNNL1Loss=0.275978,	
INFO:root:Epoch[1] Batch [5600]	Speed: 0.75 samples/sec	Train-RPNAcc=0.914948,	RPNLogLoss=0.233796,	RPNL1Loss=0.075211,	RCNNAcc=0.905666,	RCNNLogLoss=0.263305,	RCNNL1Loss=0.275851,	
INFO:root:Epoch[1] Batch [5620]	Speed: 0.71 samples/sec	Train-RPNAcc=0.915075,	RPNLogLoss=0.233499,	RPNL1Loss=0.075147,	RCNNAcc=0.905708,	RCNNLogLoss=0.263132,	RCNNL1Loss=0.275739,	
INFO:root:Epoch[1] Batch [5640]	Speed: 0.74 samples/sec	Train-RPNAcc=0.915270,	RPNLogLoss=0.233055,	RPNL1Loss=0.075075,	RCNNAcc=0.905781,	RCNNLogLoss=0.262898,	RCNNL1Loss=0.275707,	
INFO:root:Epoch[1] Batch [5660]	Speed: 0.75 samples/sec	Train-RPNAcc=0.915443,	RPNLogLoss=0.232677,	RPNL1Loss=0.075037,	RCNNAcc=0.905865,	RCNNLogLoss=0.262610,	RCNNL1Loss=0.275551,	
INFO:root:Epoch[1] Batch [5680]	Speed: 0.76 samples/sec	Train-RPNAcc=0.915650,	RPNLogLoss=0.232207,	RPNL1Loss=0.074952,	RCNNAcc=0.905953,	RCNNLogLoss=0.262314,	RCNNL1Loss=0.275368,	
INFO:root:Epoch[1] Batch [5700]	Speed: 0.74 samples/sec	Train-RPNAcc=0.915873,	RPNLogLoss=0.231669,	RPNL1Loss=0.074855,	RCNNAcc=0.906128,	RCNNLogLoss=0.261821,	RCNNL1Loss=0.274966,	
INFO:root:Epoch[1] Batch [5720]	Speed: 0.77 samples/sec	Train-RPNAcc=0.916065,	RPNLogLoss=0.231197,	RPNL1Loss=0.074731,	RCNNAcc=0.906224,	RCNNLogLoss=0.261472,	RCNNL1Loss=0.274897,	
INFO:root:Epoch[1] Batch [5740]	Speed: 0.70 samples/sec	Train-RPNAcc=0.916239,	RPNLogLoss=0.230762,	RPNL1Loss=0.074640,	RCNNAcc=0.906264,	RCNNLogLoss=0.261274,	RCNNL1Loss=0.274790,	
INFO:root:Epoch[1] Batch [5760]	Speed: 0.71 samples/sec	Train-RPNAcc=0.916416,	RPNLogLoss=0.230374,	RPNL1Loss=0.074609,	RCNNAcc=0.906321,	RCNNLogLoss=0.261136,	RCNNL1Loss=0.274685,	
INFO:root:Epoch[1] Batch [5780]	Speed: 0.75 samples/sec	Train-RPNAcc=0.916576,	RPNLogLoss=0.230022,	RPNL1Loss=0.074523,	RCNNAcc=0.906385,	RCNNLogLoss=0.260929,	RCNNL1Loss=0.274483,	
INFO:root:Epoch[1] Batch [5800]	Speed: 0.76 samples/sec	Train-RPNAcc=0.916786,	RPNLogLoss=0.229533,	RPNL1Loss=0.074439,	RCNNAcc=0.906522,	RCNNLogLoss=0.260504,	RCNNL1Loss=0.274300,	
INFO:root:Epoch[1] Batch [5820]	Speed: 0.68 samples/sec	Train-RPNAcc=0.916913,	RPNLogLoss=0.229241,	RPNL1Loss=0.074432,	RCNNAcc=0.906524,	RCNNLogLoss=0.260447,	RCNNL1Loss=0.274352,	
INFO:root:Epoch[1] Batch [5840]	Speed: 0.75 samples/sec	Train-RPNAcc=0.917094,	RPNLogLoss=0.228819,	RPNL1Loss=0.074358,	RCNNAcc=0.906622,	RCNNLogLoss=0.260130,	RCNNL1Loss=0.274158,	
INFO:root:Epoch[1] Batch [5860]	Speed: 0.76 samples/sec	Train-RPNAcc=0.917269,	RPNLogLoss=0.228397,	RPNL1Loss=0.074241,	RCNNAcc=0.906741,	RCNNLogLoss=0.259755,	RCNNL1Loss=0.273905,	
INFO:root:Epoch[1] Batch [5880]	Speed: 0.74 samples/sec	Train-RPNAcc=0.917462,	RPNLogLoss=0.227935,	RPNL1Loss=0.074188,	RCNNAcc=0.906811,	RCNNLogLoss=0.259518,	RCNNL1Loss=0.273790,	
INFO:root:Epoch[1] Batch [5900]	Speed: 0.72 samples/sec	Train-RPNAcc=0.917636,	RPNLogLoss=0.227541,	RPNL1Loss=0.074108,	RCNNAcc=0.906876,	RCNNLogLoss=0.259261,	RCNNL1Loss=0.273655,	
INFO:root:Epoch[1] Batch [5920]	Speed: 0.72 samples/sec	Train-RPNAcc=0.917810,	RPNLogLoss=0.227157,	RPNL1Loss=0.074032,	RCNNAcc=0.906963,	RCNNLogLoss=0.258973,	RCNNL1Loss=0.273480,	
INFO:root:Epoch[1] Batch [5940]	Speed: 0.68 samples/sec	Train-RPNAcc=0.918016,	RPNLogLoss=0.226708,	RPNL1Loss=0.073941,	RCNNAcc=0.907050,	RCNNLogLoss=0.258704,	RCNNL1Loss=0.273414,	
INFO:root:Epoch[1] Batch [5960]	Speed: 0.71 samples/sec	Train-RPNAcc=0.918188,	RPNLogLoss=0.226282,	RPNL1Loss=0.073829,	RCNNAcc=0.907116,	RCNNLogLoss=0.258518,	RCNNL1Loss=0.273364,	
INFO:root:Epoch[1] Batch [5980]	Speed: 0.76 samples/sec	Train-RPNAcc=0.918367,	RPNLogLoss=0.225872,	RPNL1Loss=0.073724,	RCNNAcc=0.907201,	RCNNLogLoss=0.258268,	RCNNL1Loss=0.273211,	
INFO:root:Epoch[1] Batch [6000]	Speed: 0.72 samples/sec	Train-RPNAcc=0.918533,	RPNLogLoss=0.225446,	RPNL1Loss=0.073605,	RCNNAcc=0.907267,	RCNNLogLoss=0.258066,	RCNNL1Loss=0.273150,	
INFO:root:Epoch[1] Batch [6020]	Speed: 0.74 samples/sec	Train-RPNAcc=0.918716,	RPNLogLoss=0.225025,	RPNL1Loss=0.073491,	RCNNAcc=0.907324,	RCNNLogLoss=0.257840,	RCNNL1Loss=0.272991,	
INFO:root:Epoch[1] Batch [6040]	Speed: 0.73 samples/sec	Train-RPNAcc=0.918891,	RPNLogLoss=0.224585,	RPNL1Loss=0.073414,	RCNNAcc=0.907415,	RCNNLogLoss=0.257573,	RCNNL1Loss=0.272863,	
INFO:root:Epoch[1] Batch [6060]	Speed: 0.71 samples/sec	Train-RPNAcc=0.919074,	RPNLogLoss=0.224132,	RPNL1Loss=0.073337,	RCNNAcc=0.907513,	RCNNLogLoss=0.257244,	RCNNL1Loss=0.272696,	
INFO:root:Epoch[1] Batch [6080]	Speed: 0.73 samples/sec	Train-RPNAcc=0.919239,	RPNLogLoss=0.223751,	RPNL1Loss=0.073258,	RCNNAcc=0.907604,	RCNNLogLoss=0.256945,	RCNNL1Loss=0.272629,	
INFO:root:Epoch[1] Batch [6100]	Speed: 0.71 samples/sec	Train-RPNAcc=0.919393,	RPNLogLoss=0.223468,	RPNL1Loss=0.073195,	RCNNAcc=0.907670,	RCNNLogLoss=0.256713,	RCNNL1Loss=0.272679,	
INFO:root:Epoch[1] Batch [6120]	Speed: 0.72 samples/sec	Train-RPNAcc=0.919560,	RPNLogLoss=0.223062,	RPNL1Loss=0.073111,	RCNNAcc=0.907777,	RCNNLogLoss=0.256368,	RCNNL1Loss=0.272506,	
INFO:root:Epoch[1] Batch [6140]	Speed: 0.69 samples/sec	Train-RPNAcc=0.919707,	RPNLogLoss=0.222685,	RPNL1Loss=0.073026,	RCNNAcc=0.907824,	RCNNLogLoss=0.256183,	RCNNL1Loss=0.272461,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [6160]	Speed: 0.73 samples/sec	Train-RPNAcc=0.919890,	RPNLogLoss=0.222243,	RPNL1Loss=0.072896,	RCNNAcc=0.907886,	RCNNLogLoss=0.255935,	RCNNL1Loss=0.272342,	
INFO:root:Epoch[1] Batch [6180]	Speed: 0.78 samples/sec	Train-RPNAcc=0.920087,	RPNLogLoss=0.221745,	RPNL1Loss=0.072751,	RCNNAcc=0.908035,	RCNNLogLoss=0.255503,	RCNNL1Loss=0.272036,	
INFO:root:Epoch[1] Batch [6200]	Speed: 0.71 samples/sec	Train-RPNAcc=0.920246,	RPNLogLoss=0.221390,	RPNL1Loss=0.072714,	RCNNAcc=0.908067,	RCNNLogLoss=0.255362,	RCNNL1Loss=0.272016,	
INFO:root:Epoch[1] Batch [6220]	Speed: 0.74 samples/sec	Train-RPNAcc=0.920407,	RPNLogLoss=0.221017,	RPNL1Loss=0.072605,	RCNNAcc=0.908151,	RCNNLogLoss=0.255081,	RCNNL1Loss=0.271831,	
INFO:root:Epoch[1] Batch [6240]	Speed: 0.70 samples/sec	Train-RPNAcc=0.920575,	RPNLogLoss=0.220620,	RPNL1Loss=0.072575,	RCNNAcc=0.908213,	RCNNLogLoss=0.254873,	RCNNL1Loss=0.271763,	
INFO:root:Epoch[1] Batch [6260]	Speed: 0.72 samples/sec	Train-RPNAcc=0.920707,	RPNLogLoss=0.220303,	RPNL1Loss=0.072522,	RCNNAcc=0.908234,	RCNNLogLoss=0.254789,	RCNNL1Loss=0.271840,	
INFO:root:Epoch[1] Batch [6280]	Speed: 0.74 samples/sec	Train-RPNAcc=0.920877,	RPNLogLoss=0.219907,	RPNL1Loss=0.072442,	RCNNAcc=0.908335,	RCNNLogLoss=0.254518,	RCNNL1Loss=0.271698,	
INFO:root:Epoch[1] Batch [6300]	Speed: 0.70 samples/sec	Train-RPNAcc=0.921063,	RPNLogLoss=0.219472,	RPNL1Loss=0.072360,	RCNNAcc=0.908428,	RCNNLogLoss=0.254286,	RCNNL1Loss=0.271578,	
INFO:root:Epoch[1] Batch [6320]	Speed: 0.73 samples/sec	Train-RPNAcc=0.921225,	RPNLogLoss=0.219083,	RPNL1Loss=0.072266,	RCNNAcc=0.908538,	RCNNLogLoss=0.253996,	RCNNL1Loss=0.271370,	
INFO:root:Epoch[1] Batch [6340]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921383,	RPNLogLoss=0.218714,	RPNL1Loss=0.072193,	RCNNAcc=0.908613,	RCNNLogLoss=0.253787,	RCNNL1Loss=0.271310,	
INFO:root:Epoch[1] Batch [6360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921558,	RPNLogLoss=0.218363,	RPNL1Loss=0.072154,	RCNNAcc=0.908671,	RCNNLogLoss=0.253604,	RCNNL1Loss=0.271341,	
INFO:root:Epoch[1] Batch [6380]	Speed: 0.75 samples/sec	Train-RPNAcc=0.921720,	RPNLogLoss=0.217990,	RPNL1Loss=0.072061,	RCNNAcc=0.908757,	RCNNLogLoss=0.253311,	RCNNL1Loss=0.271175,	
INFO:root:Epoch[1] Batch [6400]	Speed: 0.72 samples/sec	Train-RPNAcc=0.921866,	RPNLogLoss=0.217653,	RPNL1Loss=0.071990,	RCNNAcc=0.908778,	RCNNLogLoss=0.253197,	RCNNL1Loss=0.271105,	
INFO:root:Epoch[1] Batch [6420]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921986,	RPNLogLoss=0.217403,	RPNL1Loss=0.071991,	RCNNAcc=0.908775,	RCNNLogLoss=0.253155,	RCNNL1Loss=0.271151,	
INFO:root:Epoch[1] Batch [6440]	Speed: 0.70 samples/sec	Train-RPNAcc=0.922125,	RPNLogLoss=0.217050,	RPNL1Loss=0.071926,	RCNNAcc=0.908817,	RCNNLogLoss=0.252955,	RCNNL1Loss=0.271171,	
INFO:root:Epoch[1] Batch [6460]	Speed: 0.73 samples/sec	Train-RPNAcc=0.922285,	RPNLogLoss=0.216678,	RPNL1Loss=0.071838,	RCNNAcc=0.908850,	RCNNLogLoss=0.252828,	RCNNL1Loss=0.271139,	
INFO:root:Epoch[1] Batch [6480]	Speed: 0.74 samples/sec	Train-RPNAcc=0.922449,	RPNLogLoss=0.216274,	RPNL1Loss=0.071729,	RCNNAcc=0.908936,	RCNNLogLoss=0.252551,	RCNNL1Loss=0.270984,	
INFO:root:Epoch[1] Batch [6500]	Speed: 0.69 samples/sec	Train-RPNAcc=0.922580,	RPNLogLoss=0.215951,	RPNL1Loss=0.071688,	RCNNAcc=0.908967,	RCNNLogLoss=0.252402,	RCNNL1Loss=0.271004,	
INFO:root:Epoch[1] Batch [6520]	Speed: 0.75 samples/sec	Train-RPNAcc=0.922739,	RPNLogLoss=0.215572,	RPNL1Loss=0.071603,	RCNNAcc=0.909047,	RCNNLogLoss=0.252140,	RCNNL1Loss=0.270894,	
INFO:root:Epoch[1] Batch [6540]	Speed: 0.72 samples/sec	Train-RPNAcc=0.922905,	RPNLogLoss=0.215178,	RPNL1Loss=0.071499,	RCNNAcc=0.909120,	RCNNLogLoss=0.251894,	RCNNL1Loss=0.270804,	
INFO:root:Epoch[1] Batch [6560]	Speed: 0.75 samples/sec	Train-RPNAcc=0.923050,	RPNLogLoss=0.214833,	RPNL1Loss=0.071420,	RCNNAcc=0.909174,	RCNNLogLoss=0.251704,	RCNNL1Loss=0.270731,	
INFO:root:Epoch[1] Batch [6580]	Speed: 0.74 samples/sec	Train-RPNAcc=0.923169,	RPNLogLoss=0.214526,	RPNL1Loss=0.071377,	RCNNAcc=0.909232,	RCNNLogLoss=0.251507,	RCNNL1Loss=0.270643,	
INFO:root:Epoch[1] Batch [6600]	Speed: 0.73 samples/sec	Train-RPNAcc=0.923320,	RPNLogLoss=0.214177,	RPNL1Loss=0.071335,	RCNNAcc=0.909318,	RCNNLogLoss=0.251246,	RCNNL1Loss=0.270514,	
INFO:root:Epoch[1] Batch [6620]	Speed: 0.71 samples/sec	Train-RPNAcc=0.923453,	RPNLogLoss=0.213872,	RPNL1Loss=0.071273,	RCNNAcc=0.909360,	RCNNLogLoss=0.251106,	RCNNL1Loss=0.270503,	
INFO:root:Epoch[1] Batch [6640]	Speed: 0.67 samples/sec	Train-RPNAcc=0.923560,	RPNLogLoss=0.213606,	RPNL1Loss=0.071256,	RCNNAcc=0.909413,	RCNNLogLoss=0.250900,	RCNNL1Loss=0.270498,	
INFO:root:Epoch[1] Batch [6660]	Speed: 0.74 samples/sec	Train-RPNAcc=0.923694,	RPNLogLoss=0.213276,	RPNL1Loss=0.071197,	RCNNAcc=0.909516,	RCNNLogLoss=0.250608,	RCNNL1Loss=0.270439,	
INFO:root:Epoch[1] Batch [6680]	Speed: 0.72 samples/sec	Train-RPNAcc=0.923813,	RPNLogLoss=0.212986,	RPNL1Loss=0.071154,	RCNNAcc=0.909600,	RCNNLogLoss=0.250380,	RCNNL1Loss=0.270286,	
INFO:root:Epoch[1] Batch [6700]	Speed: 0.72 samples/sec	Train-RPNAcc=0.923990,	RPNLogLoss=0.212577,	RPNL1Loss=0.071047,	RCNNAcc=0.909714,	RCNNLogLoss=0.250062,	RCNNL1Loss=0.270077,	
INFO:root:Epoch[1] Batch [6720]	Speed: 0.74 samples/sec	Train-RPNAcc=0.924134,	RPNLogLoss=0.212233,	RPNL1Loss=0.071016,	RCNNAcc=0.909795,	RCNNLogLoss=0.249844,	RCNNL1Loss=0.270049,	
INFO:root:Epoch[1] Batch [6740]	Speed: 0.69 samples/sec	Train-RPNAcc=0.924264,	RPNLogLoss=0.211950,	RPNL1Loss=0.070987,	RCNNAcc=0.909844,	RCNNLogLoss=0.249689,	RCNNL1Loss=0.270040,	
INFO:root:Epoch[1] Batch [6760]	Speed: 0.74 samples/sec	Train-RPNAcc=0.924400,	RPNLogLoss=0.211590,	RPNL1Loss=0.070882,	RCNNAcc=0.909927,	RCNNLogLoss=0.249435,	RCNNL1Loss=0.269953,	
INFO:root:Epoch[1] Batch [6780]	Speed: 0.71 samples/sec	Train-RPNAcc=0.924562,	RPNLogLoss=0.211205,	RPNL1Loss=0.070804,	RCNNAcc=0.909996,	RCNNLogLoss=0.249206,	RCNNL1Loss=0.269791,	
INFO:root:Epoch[1] Batch [6800]	Speed: 0.70 samples/sec	Train-RPNAcc=0.924675,	RPNLogLoss=0.210946,	RPNL1Loss=0.070781,	RCNNAcc=0.909991,	RCNNLogLoss=0.249189,	RCNNL1Loss=0.269869,	
INFO:root:Epoch[1] Batch [6820]	Speed: 0.70 samples/sec	Train-RPNAcc=0.924771,	RPNLogLoss=0.210679,	RPNL1Loss=0.070780,	RCNNAcc=0.910039,	RCNNLogLoss=0.249048,	RCNNL1Loss=0.269827,	
INFO:root:Epoch[1] Batch [6840]	Speed: 0.72 samples/sec	Train-RPNAcc=0.924908,	RPNLogLoss=0.210382,	RPNL1Loss=0.070718,	RCNNAcc=0.910064,	RCNNLogLoss=0.248947,	RCNNL1Loss=0.269828,	
INFO:root:Epoch[1] Train-RPNAcc=0.924962
INFO:root:Epoch[1] Train-RPNLogLoss=0.210268
INFO:root:Epoch[1] Train-RPNL1Loss=0.070704
INFO:root:Epoch[1] Train-RCNNAcc=0.910088
INFO:root:Epoch[1] Train-RCNNLogLoss=0.248865
INFO:root:Epoch[1] Train-RCNNL1Loss=0.269769
INFO:root:Epoch[1] Time cost=8478.565
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
[12:04:44] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [12:04:44] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f471823771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f4718352ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f4718a263da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f47c1766adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f47c176640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f47c197d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f47c197ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47c2cf4f45]
[bt] (32) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 139, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 436, in fit
    callback(epoch, self.symbol, arg_params, aux_params)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/callback.py", line 41, in _callback
    arg['bbox_pred_weight_test'] = (arg['bbox_pred_weight'].T * mx.nd.array(stds)).T
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 141, in __mul__
    return multiply(self, other)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 763, in multiply
    None)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 683, in _ufunc_helper
    return fn_array(lhs, rhs)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/ndarray.py", line 131, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [12:04:44] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f471823771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f4718352ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f4718a263da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f47c1766adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f47c176640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f47c197d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f47c197ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47c2cf4f45]
[bt] (32) python() [0x578c4e]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[15:31:36] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.32 samples/sec	Train-RPNAcc=0.568266,	RPNLogLoss=0.690575,	RPNL1Loss=0.205601,	RCNNAcc=0.167039,	RCNNLogLoss=2.897209,	RCNNL1Loss=0.392915,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.35 samples/sec	Train-RPNAcc=0.574028,	RPNLogLoss=0.690181,	RPNL1Loss=0.176274,	RCNNAcc=0.455602,	RCNNLogLoss=2.330655,	RCNNL1Loss=0.368696,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.35 samples/sec	Train-RPNAcc=0.590100,	RPNLogLoss=0.688450,	RPNL1Loss=0.173849,	RCNNAcc=0.580943,	RCNNLogLoss=1.935022,	RCNNL1Loss=0.367200,	
INFO:root:Epoch[1] Batch [80]	Speed: 0.39 samples/sec	Train-RPNAcc=0.598139,	RPNLogLoss=0.687671,	RPNL1Loss=0.181154,	RCNNAcc=0.653646,	RCNNLogLoss=1.654464,	RCNNL1Loss=0.346961,	
INFO:root:Epoch[1] Batch [100]	Speed: 0.37 samples/sec	Train-RPNAcc=0.608640,	RPNLogLoss=0.686473,	RPNL1Loss=0.170385,	RCNNAcc=0.696782,	RCNNLogLoss=1.454009,	RCNNL1Loss=0.333254,	
INFO:root:Epoch[1] Batch [120]	Speed: 0.35 samples/sec	Train-RPNAcc=0.615928,	RPNLogLoss=0.685261,	RPNL1Loss=0.160919,	RCNNAcc=0.728435,	RCNNLogLoss=1.300138,	RCNNL1Loss=0.320475,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.31 samples/sec	Train-RPNAcc=0.624197,	RPNLogLoss=0.683894,	RPNL1Loss=0.158642,	RCNNAcc=0.747396,	RCNNLogLoss=1.190032,	RCNNL1Loss=0.320617,	
INFO:root:Epoch[1] Batch [160]	Speed: 0.34 samples/sec	Train-RPNAcc=0.632570,	RPNLogLoss=0.682278,	RPNL1Loss=0.155862,	RCNNAcc=0.760530,	RCNNLogLoss=1.101494,	RCNNL1Loss=0.323855,	
INFO:root:Epoch[1] Batch [180]	Speed: 0.39 samples/sec	Train-RPNAcc=0.638014,	RPNLogLoss=0.680976,	RPNL1Loss=0.157402,	RCNNAcc=0.771193,	RCNNLogLoss=1.028079,	RCNNL1Loss=0.327429,	
INFO:root:Epoch[1] Batch [200]	Speed: 0.36 samples/sec	Train-RPNAcc=0.647699,	RPNLogLoss=0.679157,	RPNL1Loss=0.151758,	RCNNAcc=0.783582,	RCNNLogLoss=0.958333,	RCNNL1Loss=0.322216,	
INFO:root:Epoch[1] Batch [220]	Speed: 0.31 samples/sec	Train-RPNAcc=0.655419,	RPNLogLoss=0.677278,	RPNL1Loss=0.147366,	RCNNAcc=0.791077,	RCNNLogLoss=0.905604,	RCNNL1Loss=0.326945,	
INFO:root:Epoch[1] Batch [240]	Speed: 0.40 samples/sec	Train-RPNAcc=0.663236,	RPNLogLoss=0.675329,	RPNL1Loss=0.144618,	RCNNAcc=0.799630,	RCNNLogLoss=0.857097,	RCNNL1Loss=0.326116,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.39 samples/sec	Train-RPNAcc=0.669630,	RPNLogLoss=0.673505,	RPNL1Loss=0.146396,	RCNNAcc=0.808459,	RCNNLogLoss=0.811099,	RCNNL1Loss=0.318188,	
INFO:root:Epoch[1] Batch [280]	Speed: 0.34 samples/sec	Train-RPNAcc=0.677352,	RPNLogLoss=0.671438,	RPNL1Loss=0.145468,	RCNNAcc=0.812111,	RCNNLogLoss=0.778790,	RCNNL1Loss=0.323562,	
INFO:root:Epoch[1] Batch [300]	Speed: 0.34 samples/sec	Train-RPNAcc=0.683360,	RPNLogLoss=0.669611,	RPNL1Loss=0.145939,	RCNNAcc=0.815070,	RCNNLogLoss=0.749703,	RCNNL1Loss=0.325645,	
INFO:root:Epoch[1] Batch [320]	Speed: 0.37 samples/sec	Train-RPNAcc=0.690664,	RPNLogLoss=0.667664,	RPNL1Loss=0.145182,	RCNNAcc=0.818146,	RCNNLogLoss=0.723253,	RCNNL1Loss=0.328968,	
INFO:root:Epoch[1] Batch [340]	Speed: 0.36 samples/sec	Train-RPNAcc=0.697684,	RPNLogLoss=0.665629,	RPNL1Loss=0.145408,	RCNNAcc=0.821687,	RCNNLogLoss=0.699003,	RCNNL1Loss=0.329717,	
INFO:root:Epoch[1] Batch [360]	Speed: 0.62 samples/sec	Train-RPNAcc=0.705094,	RPNLogLoss=0.663366,	RPNL1Loss=0.144495,	RCNNAcc=0.826091,	RCNNLogLoss=0.674604,	RCNNL1Loss=0.328032,	
INFO:root:Epoch[1] Batch [380]	Speed: 0.54 samples/sec	Train-RPNAcc=0.712475,	RPNLogLoss=0.661046,	RPNL1Loss=0.145015,	RCNNAcc=0.830832,	RCNNLogLoss=0.651164,	RCNNL1Loss=0.324276,	
INFO:root:Epoch[1] Batch [400]	Speed: 0.45 samples/sec	Train-RPNAcc=0.720591,	RPNLogLoss=0.658437,	RPNL1Loss=0.142943,	RCNNAcc=0.833502,	RCNNLogLoss=0.633454,	RCNNL1Loss=0.326085,	
INFO:root:Epoch[1] Batch [420]	Speed: 0.37 samples/sec	Train-RPNAcc=0.726674,	RPNLogLoss=0.656164,	RPNL1Loss=0.142754,	RCNNAcc=0.834806,	RCNNLogLoss=0.619199,	RCNNL1Loss=0.329407,	
INFO:root:Epoch[1] Batch [440]	Speed: 0.39 samples/sec	Train-RPNAcc=0.732276,	RPNLogLoss=0.653843,	RPNL1Loss=0.142357,	RCNNAcc=0.834485,	RCNNLogLoss=0.609091,	RCNNL1Loss=0.338099,	
INFO:root:Epoch[1] Batch [460]	Speed: 0.35 samples/sec	Train-RPNAcc=0.737925,	RPNLogLoss=0.651189,	RPNL1Loss=0.142825,	RCNNAcc=0.837497,	RCNNLogLoss=0.593639,	RCNNL1Loss=0.335519,	
INFO:root:Epoch[1] Batch [480]	Speed: 0.26 samples/sec	Train-RPNAcc=0.742821,	RPNLogLoss=0.648629,	RPNL1Loss=0.142762,	RCNNAcc=0.836977,	RCNNLogLoss=0.585568,	RCNNL1Loss=0.341680,	
INFO:root:Epoch[1] Batch [500]	Speed: 0.38 samples/sec	Train-RPNAcc=0.748503,	RPNLogLoss=0.645714,	RPNL1Loss=0.141457,	RCNNAcc=0.838994,	RCNNLogLoss=0.573152,	RCNNL1Loss=0.341064,	
INFO:root:Epoch[1] Batch [520]	Speed: 0.33 samples/sec	Train-RPNAcc=0.752849,	RPNLogLoss=0.642961,	RPNL1Loss=0.140702,	RCNNAcc=0.840481,	RCNNLogLoss=0.561523,	RCNNL1Loss=0.342540,	
INFO:root:Epoch[1] Batch [540]	Speed: 0.27 samples/sec	Train-RPNAcc=0.757690,	RPNLogLoss=0.639817,	RPNL1Loss=0.139826,	RCNNAcc=0.842291,	RCNNLogLoss=0.551162,	RCNNL1Loss=0.341942,	
INFO:root:Epoch[1] Batch [560]	Speed: 0.34 samples/sec	Train-RPNAcc=0.762248,	RPNLogLoss=0.636640,	RPNL1Loss=0.140053,	RCNNAcc=0.844056,	RCNNLogLoss=0.541311,	RCNNL1Loss=0.341765,	
INFO:root:Epoch[1] Batch [580]	Speed: 0.36 samples/sec	Train-RPNAcc=0.764704,	RPNLogLoss=0.634265,	RPNL1Loss=0.141005,	RCNNAcc=0.844449,	RCNNLogLoss=0.534302,	RCNNL1Loss=0.345216,	
INFO:root:Epoch[1] Batch [600]	Speed: 0.37 samples/sec	Train-RPNAcc=0.768680,	RPNLogLoss=0.630831,	RPNL1Loss=0.140021,	RCNNAcc=0.845700,	RCNNLogLoss=0.525432,	RCNNL1Loss=0.344658,	
INFO:root:Epoch[1] Batch [620]	Speed: 0.40 samples/sec	Train-RPNAcc=0.771412,	RPNLogLoss=0.627968,	RPNL1Loss=0.139923,	RCNNAcc=0.846681,	RCNNLogLoss=0.518945,	RCNNL1Loss=0.345208,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2482L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 9L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[04:47:16] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2482L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 752L, 2482L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.57 samples/sec	Train-RPNAcc=0.584077,	RPNLogLoss=0.690725,	RPNL1Loss=0.163435,	RCNNAcc=0.160714,	RCNNLogLoss=2.895509,	RCNNL1Loss=0.342722,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:02:39] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
  File "example/env/train_end2end.py", line 153
    else
       ^
SyntaxError: invalid syntax
  File "example/env/train_end2end.py", line 153
    else
       ^
SyntaxError: invalid syntax
Error in proposal_target.list_arguments: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 656, in list_arguments_entry
    ret = op_prop.list_arguments()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 88, in list_arguments
    if config.TRAIN.BBOX_3D:
NameError: global name 'config' is not defined

[15:29:38] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:29:38] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe87bb3771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7fe87c4ec13a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7fe87c4ecd49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7fe87c457893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7fe87c44d9ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7fe87d11a558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7fe87c33bfe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe925066adc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe92506640c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe92527d5fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe92527ef9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe9265f4f45]
[bt] (23) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 184, in get_vgg_train
    batch_rois=config.TRAIN.BATCH_ROIS, fg_fraction=config.TRAIN.FG_FRACTION)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/symbol.py", line 181, in creator
    ctypes.byref(sym_handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:29:38] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe87bb3771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7fe87c4ec13a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7fe87c4ecd49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7fe87c457893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7fe87c44d9ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7fe87d11a558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7fe87c33bfe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe925066adc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe92506640c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe92527d5fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe92527ef9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe9265f4f45]
[bt] (23) python() [0x578c4e]

Error in proposal_target.list_arguments: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 656, in list_arguments_entry
    ret = op_prop.list_arguments()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 88, in list_arguments
    if config.TRAIN.BBOX_3D:
NameError: global name 'config' is not defined

[15:29:47] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:29:47] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f008fd7c71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7f009073113a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7f0090731d49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7f009069c893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7f00906929ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7f009135f558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7f0090580fe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f01312abadc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f01312ab40c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f01314c25fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f01314c3f9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0132839f45]
[bt] (23) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 184, in get_vgg_train
    batch_rois=config.TRAIN.BATCH_ROIS, fg_fraction=config.TRAIN.FG_FRACTION)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/symbol.py", line 181, in creator
    ctypes.byref(sym_handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:29:47] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f008fd7c71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7f009073113a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7f0090731d49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7f009069c893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7f00906929ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7f009135f558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7f0090580fe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f01312abadc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f01312ab40c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f01314c25fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f01314c3f9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0132839f45]
[bt] (23) python() [0x578c4e]

[15:31:30] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:31:30] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1800ed271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f18024b4204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f180249361b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f18aa401adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f18aa40140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f18aa6185fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f18aa619f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f18ab98ff45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:31:30] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1800ed271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f18024b4204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f180249361b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f18aa401adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f18aa40140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f18aa6185fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f18aa619f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f18ab98ff45]
[bt] (22) python() [0x578c4e]

[15:35:46] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:35:46] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0d9374471c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f0d94d26204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f0d94d0561b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0e3cc73adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0e3cc7340c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f0e3ce8a5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f0e3ce8bf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0e3e201f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:35:46] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0d9374471c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f0d94d26204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f0d94d0561b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0e3cc73adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0e3cc7340c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f0e3ce8a5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f0e3ce8bf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0e3e201f45]
[bt] (22) python() [0x578c4e]

[15:37:09] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:37:09] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fc2a55e571c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7fc2a6bc7204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7fc2a6ba661b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc34eb14adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fc34eb1440c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fc34ed2b5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fc34ed2cf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fc3500a2f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:37:09] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fc2a55e571c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7fc2a6bc7204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7fc2a6ba661b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc34eb14adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fc34eb1440c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fc34ed2b5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fc34ed2cf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fc3500a2f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 47, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/train_ry_alpha_car_only.lst
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 128, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
{'width': 1242, 'boxes': array([[ 647.61999512,  184.41999817,  695.29998779,  222.78999329],
       [ 711.75      ,  180.25      ,  748.84997559,  208.71000671],
       [ 417.28997803,  183.52999878,  478.65002441,  208.33000183],
       [ 301.90997314,  185.50999451,  370.02001953,  212.36999512]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/004104.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1], dtype=int32), 'height': 375}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 73, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'width': 1242, 'boxes': array([[ 1038.27001953,   202.75      ,  1231.06005859,   316.29000854],
       [  718.04998779,   183.69999695,   774.14001465,   222.69999695],
       [  494.96002197,   165.41999817,   598.23999023,   210.11999512],
       [  917.42004395,   184.63999939,   960.25      ,   214.88999939],
       [  781.7199707 ,   176.52000427,   806.10998535,   198.50999451],
       [  527.70001221,   190.5       ,   679.46002197,   278.92999268]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/001718.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1, 1, 1], dtype=int32), 'height': 375}
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 73, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'width': 1242, 'boxes': array([[ 640.20001221,  172.3999939 ,  661.9699707 ,  193.36000061],
       [ 783.07000732,  178.52999878,  806.04998779,  193.02999878]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1]), 'max_overlaps': array([ 1.,  1.], dtype=float32), 'image': 'data/kitti/images/005653.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1], dtype=int32), 'height': 375}
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'gt_classes': array([1, 1, 1, 1], dtype=int32), 'gt_angles': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'gt_dims': array([[ 1.52999997,  1.62      ,  3.76999998],
       [ 1.75999999,  1.76999998,  4.40999985],
       [ 1.48000002,  1.64999998,  4.4000001 ],
       [ 1.41999996,  1.65999997,  3.6400001 ]], dtype=float32), 'max_classes': array([1, 1, 1, 1]), 'image': 'data/kitti/images/002586.png', 'height': 375, 'orientation_ry': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'width': 1242, 'boxes': array([[ 1086.52001953,   198.00999451,  1241.        ,   374.        ],
       [  459.17999268,   170.33000183,   548.57000732,   230.77000427],
       [  530.86999512,   176.91000366,   593.33001709,   214.44000244],
       [  619.23999023,   175.27999878,   652.78997803,   198.19999695]], dtype=float32), 'gt_position': array([[  3.00999999,   1.62      ,   1.40999997],
       [ -3.33999991,   1.71000004,  23.29000092],
       [ -1.99000001,   1.65999997,  30.73999977],
       [  1.70000005,   1.59000003,  46.84000015]], dtype=float32), 'gt_confs': array([[1],
       [1],
       [1],
       [1]], dtype=int32), 'max_overlaps': array([ 1.,  1.,  1.,  1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 0.47      ,  1.83000004,  1.80999994,  1.72000003], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32)}
{'gt_classes': array([1, 1, 1, 1], dtype=int32), 'gt_angles': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'gt_dims': array([[ 1.52999997,  1.62      ,  3.76999998],
       [ 1.75999999,  1.76999998,  4.40999985],
       [ 1.48000002,  1.64999998,  4.4000001 ],
       [ 1.41999996,  1.65999997,  3.6400001 ]], dtype=float32), 'max_classes': array([1, 1, 1, 1]), 'image': 'data/kitti/images/002586.png', 'height': 375, 'orientation_ry': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'width': 1242, 'boxes': array([[ 1086.52001953,   198.00999451,  1241.        ,   374.        ],
       [  459.17999268,   170.33000183,   548.57000732,   230.77000427],
       [  530.86999512,   176.91000366,   593.33001709,   214.44000244],
       [  619.23999023,   175.27999878,   652.78997803,   198.19999695]], dtype=float32), 'gt_position': array([[  3.00999999,   1.62      ,   1.40999997],
       [ -3.33999991,   1.71000004,  23.29000092],
       [ -1.99000001,   1.65999997,  30.73999977],
       [  1.70000005,   1.59000003,  46.84000015]], dtype=float32), 'gt_confs': array([[1],
       [1],
       [1],
       [1]], dtype=int32), 'max_overlaps': array([ 1.,  1.,  1.,  1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 0.47      ,  1.83000004,  1.80999994,  1.72000003], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32)}
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 4L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 4L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 4L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 4L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'width': 1242, 'boxes': array([[  32.26000977,  180.38000488,  441.7199707 ,  374.        ],
       [ 720.72998047,  183.41000366,  874.77001953,  281.22000122],
       [ 390.79998779,  188.1499939 ,  529.86999512,  283.91000366],
       [ 706.21002197,  179.6000061 ,  796.59997559,  244.71000671],
       [ 469.36999512,  184.30000305,  559.76000977,  249.19000244],
       [ 680.88000488,  179.27999878,  727.59002686,  219.72999573],
       [ 530.44000244,  180.6000061 ,  573.83001709,  213.25      ],
       [ 563.88000488,  176.19000244,  587.91998291,  197.77000427]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1, 1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/003755.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), 'height': 375}
{'width': 1242, 'boxes': array([[  32.26000977,  180.38000488,  441.7199707 ,  374.        ],
       [ 720.72998047,  183.41000366,  874.77001953,  281.22000122],
       [ 390.79998779,  188.1499939 ,  529.86999512,  283.91000366],
       [ 706.21002197,  179.6000061 ,  796.59997559,  244.71000671],
       [ 469.36999512,  184.30000305,  559.76000977,  249.19000244],
       [ 680.88000488,  179.27999878,  727.59002686,  219.72999573],
       [ 530.44000244,  180.6000061 ,  573.83001709,  213.25      ],
       [ 563.88000488,  176.19000244,  587.91998291,  197.77000427]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1, 1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/003755.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), 'height': 375}
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 327, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([-1.57000005], dtype=float32), 'gt_dims': array([[ 1.65999997,  1.73000002,  3.04999995]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/001854.png', 'height': 375, 'orientation_ry': array([-1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 541.0300293 ,  174.86000061,  562.78997803,  193.61999512]], dtype=float32), 'gt_position': array([[ -5.30999994,   1.87      ,  66.15000153]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([-1.49000001], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 1L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 1L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 3L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 3L, 1L)
  data: (1L, 3L, 752L, 2482L)
  gt_angles: (1L, 3L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1, 1, 1], dtype=int32), 'gt_angles': array([-1.59000003,  1.52999997,  1.54999995], dtype=float32), 'gt_dims': array([[ 1.64999998,  1.66999996,  3.6400001 ],
       [ 1.42999995,  1.63      ,  4.30999994],
       [ 1.44000006,  1.62      ,  4.01999998]], dtype=float32), 'max_classes': array([1, 1, 1]), 'image': 'data/kitti/images/000939.png', 'height': 375, 'orientation_ry': array([-1.59000003,  1.52999997,  1.54999995], dtype=float32), 'width': 1242, 'boxes': array([[ 588.47998047,  175.30999756,  615.2199707 ,  201.75      ],
       [ 172.50999451,  194.49000549,  317.16000366,  263.48001099],
       [ 414.16000366,  184.28999329,  460.20999146,  212.97000122]], dtype=float32), 'gt_position': array([[ -0.57999998,   1.83000004,  47.31999969],
       [ -9.06000042,   2.02999997,  18.23999977],
       [ -9.38000011,   2.08999991,  39.31000137]], dtype=float32), 'gt_confs': array([[1],
       [1],
       [1]], dtype=int32), 'max_overlaps': array([ 1.,  1.,  1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([-1.58000004,  1.98000002,  1.77999997], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 3L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 3L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 3L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'width': 1242, 'boxes': array([[   0.        ,  204.44999695,  215.35998535,  374.        ],
       [ 282.76000977,  179.24000549,  366.66998291,  239.02000427],
       [ 691.84002686,  178.36000061,  877.23999023,  269.36999512]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/006881.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1], dtype=int32), 'height': 375}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 258, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 337, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([-1.52999997], dtype=float32), 'gt_dims': array([[ 1.90999997,  1.64999998,  4.4000001 ]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000153.png', 'height': 370, 'orientation_ry': array([-1.52999997], dtype=float32), 'width': 1224, 'boxes': array([[ 669.59997559,  159.27999878,  704.34002686,  194.50999451]], dtype=float32), 'gt_position': array([[  4.69000006,   0.75      ,  40.86999893]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([-1.63999999], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 1L, 1L)
  data: (1L, 3L, 752L, 2488L)
  gt_angles: (1L, 1L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 35, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 261, in get_vgg_train
    angle_loss = mx.symbol.Reshape(data=angle_loss, shape=(config.TRAIN.BATCH_IMAGES, -1, num_bin*2), name='angle_loss_reshape')
UnboundLocalError: local variable 'angle_loss' referenced before assignment
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 5L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 5L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 5L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 5L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator conf: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2482L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 8L),
 'gt_boxes': (1L, 8L, 5L),
 'gt_confs': (1L, 8L, 1L),
 'gt_dims': (1L, 8L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 86, in train_net
    arg_params['fc6_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_dim_weight'])
KeyError: 'fc6_dim_weight'
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 2L),
 'gt_boxes': (1L, 2L, 5L),
 'gt_confs': (1L, 2L, 1L),
 'gt_dims': (1L, 2L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 204, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 129, in train_net
    conf_metric = metric.RCNNConfLossMetric()
AttributeError: 'module' object has no attribute 'RCNNConfLossMetric'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 2L),
 'gt_boxes': (1L, 2L, 5L),
 'gt_confs': (1L, 2L, 1L),
 'gt_dims': (1L, 2L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 85, in train_net
    if config.TRAIN.BBOX_OK: 
AttributeError: 'EasyDict' object has no attribute 'BBOX_OK'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 4L),
 'gt_boxes': (1L, 4L, 5L),
 'gt_confs': (1L, 4L, 1L),
 'gt_dims': (1L, 4L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 86, in train_net
    arg_params['fc6_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_dim_weight'])
KeyError: 'fc6_dim_weight'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 1L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 1L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 8L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_reshape_output': (1L, 128L, 1L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (128L,),
 'fc7_conf_weight': (128L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (1L,),
 'fc8_conf_weight': (1L, 128L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_angles': (1L, 1L),
 'gt_boxes': (1L, 1L, 5L),
 'gt_confs': (1L, 1L, 1L),
 'gt_dims': (1L, 1L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 150, in train_net
    if config.TRAIN.BBOX_OK: 
AttributeError: 'EasyDict' object has no attribute 'BBOX_OK'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
load 0  /  3424
size:  (375, 1242, 3)
load 1  /  3424
size:  (375, 1242, 3)
load 2  /  3424
size:  (375, 1242, 3)
load 3  /  3424
size:  (374, 1238, 3)
load 4  /  3424
size:  (375, 1242, 3)
load 5  /  3424
size:  (374, 1238, 3)
load 6  /  3424
size:  (375, 1242, 3)
load 7  /  3424
size:  (375, 1242, 3)
load 8  /  3424
size:  (375, 1242, 3)
load 9  /  3424
size:  (375, 1242, 3)
load 10  /  3424
size:  (376, 1241, 3)
load 11  /  3424
size:  (375, 1242, 3)
load 12  /  3424
size:  (375, 1242, 3)
load 13  /  3424
size:  (375, 1242, 3)
load 14  /  3424
size:  (375, 1242, 3)
load 15  /  3424
size:  (375, 1242, 3)
load 16  /  3424
size:  (376, 1241, 3)
load 17  /  3424
size:  (375, 1242, 3)
load 18  /  3424
size:  (375, 1242, 3)
load 19  /  3424
size:  (375, 1242, 3)
load 20  /  3424
size:  (376, 1241, 3)
load 21  /  3424
size:  (375, 1242, 3)
load 22  /  3424
size:  (375, 1242, 3)
load 23  /  3424
size:  (375, 1242, 3)
load 24  /  3424
size:  (375, 1242, 3)
load 25  /  3424
size:  (375, 1242, 3)
load 26  /  3424
size:  (375, 1242, 3)
load 27  /  3424
size:  (375, 1242, 3)
load 28  /  3424
size:  (375, 1242, 3)
load 29  /  3424
size:  (375, 1242, 3)
load 30  /  3424
size:  (375, 1242, 3)
load 31  /  3424
size:  (375, 1242, 3)
load 32  /  3424
size:  (375, 1242, 3)
load 33  /  3424
size:  (375, 1242, 3)
load 34  /  3424
size:  (375, 1242, 3)
load 35  /  3424
size:  (375, 1242, 3)
load 36  /  3424
size:  (376, 1241, 3)
load 37  /  3424
size:  (375, 1242, 3)
load 38  /  3424
size:  (375, 1242, 3)
load 39  /  3424
size:  (375, 1242, 3)
load 40  /  3424
size:  (375, 1242, 3)
load 41  /  3424
size:  (375, 1242, 3)
load 42  /  3424
size:  (375, 1242, 3)
load 43  /  3424
size:  (375, 1242, 3)
load 44  /  3424
size:  (375, 1242, 3)
load 45  /  3424
size:  (370, 1224, 3)
load 46  /  3424
size:  (375, 1242, 3)
load 47  /  3424
size:  (375, 1242, 3)
load 48  /  3424
size:  (376, 1241, 3)
load 49  /  3424
size:  (370, 1224, 3)
load 50  /  3424
size:  (375, 1242, 3)
load 51  /  3424
size:  (375, 1242, 3)
load 52  /  3424
size:  (375, 1242, 3)
load 53  /  3424
size:  (375, 1242, 3)
load 54  /  3424
size:  (375, 1242, 3)
load 55  /  3424
size:  (370, 1224, 3)
load 56  /  3424
size:  (375, 1242, 3)
load 57  /  3424
size:  (370, 1224, 3)
load 58  /  3424
size:  (375, 1242, 3)
load 59  /  3424
size:  (375, 1242, 3)
load 60  /  3424
size:  (375, 1242, 3)
load 61  /  3424
size:  (375, 1242, 3)
load 62  /  3424
size:  (376, 1241, 3)
load 63  /  3424
size:  (375, 1242, 3)
load 64  /  3424
size:  (375, 1242, 3)
load 65  /  3424
size:  (375, 1242, 3)
load 66  /  3424
size:  (375, 1242, 3)
load 67  /  3424
size:  (375, 1242, 3)
load 68  /  3424
size:  (375, 1242, 3)
load 69  /  3424
size:  (375, 1242, 3)
load 70  /  3424
size:  (375, 1242, 3)
load 71  /  3424
size:  (374, 1238, 3)
load 72  /  3424
size:  (376, 1241, 3)
load 73  /  3424
size:  (376, 1241, 3)
load 74  /  3424
size:  (375, 1242, 3)
load 75  /  3424
size:  (375, 1242, 3)
load 76  /  3424
size:  (375, 1242, 3)
load 77  /  3424
size:  (375, 1242, 3)
load 78  /  3424
size:  (375, 1242, 3)
load 79  /  3424
size:  (375, 1242, 3)
load 80  /  3424
size:  (375, 1242, 3)
load 81  /  3424
size:  (375, 1242, 3)
load 82  /  3424
size:  (375, 1242, 3)
load 83  /  3424
size:  (375, 1242, 3)
load 84  /  3424
size:  (375, 1242, 3)
load 85  /  3424
size:  (375, 1242, 3)
load 86  /  3424
size:  (375, 1242, 3)
load 87  /  3424
size:  (375, 1242, 3)
load 88  /  3424
size:  (375, 1242, 3)
load 89  /  3424
size:  (375, 1242, 3)
load 90  /  3424
size:  (375, 1242, 3)
load 91  /  3424
size:  (375, 1242, 3)
load 92  /  3424
size:  (375, 1242, 3)
load 93  /  3424
size:  (375, 1242, 3)
load 94  /  3424
size:  (376, 1241, 3)
load 95  /  3424
size:  (375, 1242, 3)
load 96  /  3424
size:  (375, 1242, 3)
load 97  /  3424
size:  (375, 1242, 3)
load 98  /  3424
size:  (376, 1241, 3)
load 99  /  3424
size:  (375, 1242, 3)
load 100  /  3424
size:  (376, 1241, 3)
load 101  /  3424
size:  (376, 1241, 3)
load 102  /  3424
size:  (375, 1242, 3)
load 103  /  3424
size:  (375, 1242, 3)
load 104  /  3424
size:  (375, 1242, 3)
load 105  /  3424
size:  (375, 1242, 3)
load 106  /  3424
size:  (375, 1242, 3)
load 107  /  3424
size:  (375, 1242, 3)
load 108  /  3424
size:  (375, 1242, 3)
load 109  /  3424
size:  (375, 1242, 3)
load 110  /  3424
size:  (375, 1242, 3)
load 111  /  3424
size:  (375, 1242, 3)
load 112  /  3424
size:  (375, 1242, 3)
load 113  /  3424
size:  (375, 1242, 3)
load 114  /  3424
size:  (375, 1242, 3)
load 115  /  3424
size:  (375, 1242, 3)
load 116  /  3424
size:  (375, 1242, 3)
load 117  /  3424
size:  (376, 1241, 3)
load 118  /  3424
size:  (375, 1242, 3)
load 119  /  3424
size:  (375, 1242, 3)
load 120  /  3424
size:  (375, 1242, 3)
load 121  /  3424
size:  (376, 1241, 3)
load 122  /  3424
size:  (374, 1238, 3)
load 123  /  3424
size:  (374, 1238, 3)
load 124  /  3424
size:  (375, 1242, 3)
load 125  /  3424
size:  (370, 1224, 3)
load 126  /  3424
size:  (375, 1242, 3)
load 127  /  3424
size:  (375, 1242, 3)
load 128  /  3424
size:  (375, 1242, 3)
load 129  /  3424
size:  (375, 1242, 3)
load 130  /  3424
size:  (375, 1242, 3)
load 131  /  3424
size:  (375, 1242, 3)
load 132  /  3424
size:  (375, 1242, 3)
load 133  /  3424
size:  (375, 1242, 3)
load 134  /  3424
size:  (375, 1242, 3)
load 135  /  3424
size:  (375, 1242, 3)
load 136  /  3424
size:  (375, 1242, 3)
load 137  /  3424
size:  (374, 1238, 3)
load 138  /  3424
size:  (370, 1224, 3)
load 139  /  3424
size:  (375, 1242, 3)
load 140  /  3424
size:  (374, 1238, 3)
load 141  /  3424
size:  (375, 1242, 3)
load 142  /  3424
size:  (375, 1242, 3)
load 143  /  3424
size:  (376, 1241, 3)
load 144  /  3424
size:  (375, 1242, 3)
load 145  /  3424
size:  (375, 1242, 3)
load 146  /  3424
size:  (375, 1242, 3)
load 147  /  3424
size:  (376, 1241, 3)
load 148  /  3424
size:  (375, 1242, 3)
load 149  /  3424
size:  (375, 1242, 3)
load 150  /  3424
size:  (375, 1242, 3)
load 151  /  3424
size:  (375, 1242, 3)
load 152  /  3424
size:  (376, 1241, 3)
load 153  /  3424
size:  (375, 1242, 3)
load 154  /  3424
size:  (375, 1242, 3)
load 155  /  3424
size:  (375, 1242, 3)
load 156  /  3424
size:  (375, 1242, 3)
load 157  /  3424
size:  (370, 1224, 3)
load 158  /  3424
size:  (376, 1241, 3)
load 159  /  3424
size:  (375, 1242, 3)
load 160  /  3424
size:  (375, 1242, 3)
load 161  /  3424
size:  (375, 1242, 3)
load 162  /  3424
size:  (375, 1242, 3)
load 163  /  3424
size:  (375, 1242, 3)
load 164  /  3424
size:  (375, 1242, 3)
load 165  /  3424
size:  (375, 1242, 3)
load 166  /  3424
size:  (375, 1242, 3)
load 167  /  3424
size:  (370, 1224, 3)
load 168  /  3424
size:  (375, 1242, 3)
load 169  /  3424
size:  (376, 1241, 3)
load 170  /  3424
size:  (375, 1242, 3)
load 171  /  3424
size:  (376, 1241, 3)
load 172  /  3424
size:  (375, 1242, 3)
load 173  /  3424
size:  (375, 1242, 3)
load 174  /  3424
size:  (375, 1242, 3)
load 175  /  3424
size:  (375, 1242, 3)
load 176  /  3424
size:  (375, 1242, 3)
load 177  /  3424
size:  (375, 1242, 3)
load 178  /  3424
size:  (375, 1242, 3)
load 179  /  3424
size:  (375, 1242, 3)
load 180  /  3424
size:  (375, 1242, 3)
load 181  /  3424
size:  (375, 1242, 3)
load 182  /  3424
size:  (376, 1241, 3)
load 183  /  3424
size:  (375, 1242, 3)
load 184  /  3424
size:  (375, 1242, 3)
load 185  /  3424
size:  (375, 1242, 3)
load 186  /  3424
size:  (375, 1242, 3)
load 187  /  3424
size:  (375, 1242, 3)
load 188  /  3424
size:  (376, 1241, 3)
load 189  /  3424
size:  (375, 1242, 3)
load 190  /  3424
size:  (374, 1238, 3)
load 191  /  3424
size:  (376, 1241, 3)
load 192  /  3424
size:  (370, 1224, 3)
load 193  /  3424
size:  (375, 1242, 3)
load 194  /  3424
size:  (375, 1242, 3)
load 195  /  3424
size:  (375, 1242, 3)
load 196  /  3424
size:  (375, 1242, 3)
load 197  /  3424
size:  (375, 1242, 3)
load 198  /  3424
size:  (375, 1242, 3)
load 199  /  3424
size:  (375, 1242, 3)
load 200  /  3424
size:  (370, 1224, 3)
load 201  /  3424
size:  (375, 1242, 3)
load 202  /  3424
size:  (375, 1242, 3)
load 203  /  3424
size:  (375, 1242, 3)
load 204  /  3424
size:  (370, 1224, 3)
load 205  /  3424
size:  (375, 1242, 3)
load 206  /  3424
size:  (375, 1242, 3)
load 207  /  3424
size:  (375, 1242, 3)
load 208  /  3424
size:  (375, 1242, 3)
load 209  /  3424
size:  (375, 1242, 3)
load 210  /  3424
size:  (375, 1242, 3)
load 211  /  3424
size:  (375, 1242, 3)
load 212  /  3424
size:  (375, 1242, 3)
load 213  /  3424
size:  (375, 1242, 3)
load 214  /  3424
size:  (375, 1242, 3)
load 215  /  3424
size:  (374, 1238, 3)
load 216  /  3424
size:  (375, 1242, 3)
load 217  /  3424
size:  (375, 1242, 3)
load 218  /  3424
size:  (375, 1242, 3)
load 219  /  3424
size:  (375, 1242, 3)
load 220  /  3424
size:  (375, 1242, 3)
load 221  /  3424
size:  (375, 1242, 3)
load 222  /  3424
size:  (375, 1242, 3)
load 223  /  3424
size:  (376, 1241, 3)
load 224  /  3424
size:  (375, 1242, 3)
load 225  /  3424
size:  (375, 1242, 3)
load 226  /  3424
size:  (370, 1224, 3)
load 227  /  3424
size:  (375, 1242, 3)
load 228  /  3424
size:  (375, 1242, 3)
load 229  /  3424
size:  (375, 1242, 3)
load 230  /  3424
size:  (375, 1242, 3)
load 231  /  3424
size:  (375, 1242, 3)
load 232  /  3424
size:  (375, 1242, 3)
load 233  /  3424
size:  (376, 1241, 3)
load 234  /  3424
size:  (374, 1238, 3)
load 235  /  3424
size:  (375, 1242, 3)
load 236  /  3424
size:  (375, 1242, 3)
load 237  /  3424
size:  (375, 1242, 3)
load 238  /  3424
size:  (376, 1241, 3)
load 239  /  3424
size:  (375, 1242, 3)
load 240  /  3424
size:  (370, 1224, 3)
load 241  /  3424
size:  (375, 1242, 3)
load 242  /  3424
size:  (375, 1242, 3)
load 243  /  3424
size:  (375, 1242, 3)
load 244  /  3424
size:  (375, 1242, 3)
load 245  /  3424
size:  (375, 1242, 3)
load 246  /  3424
size:  (375, 1242, 3)
load 247  /  3424
size:  (375, 1242, 3)
load 248  /  3424
size:  (375, 1242, 3)
load 249  /  3424
size:  (376, 1241, 3)
load 250  /  3424
size:  (375, 1242, 3)
load 251  /  3424
size:  (375, 1242, 3)
load 252  /  3424
size:  (376, 1241, 3)
load 253  /  3424
size:  (374, 1238, 3)
load 254  /  3424
size:  (375, 1242, 3)
load 255  /  3424
size:  (375, 1242, 3)
load 256  /  3424
size:  (375, 1242, 3)
load 257  /  3424
size:  (375, 1242, 3)
load 258  /  3424
size:  (375, 1242, 3)
load 259  /  3424
size:  (375, 1242, 3)
load 260  /  3424
size:  (375, 1242, 3)
load 261  /  3424
size:  (374, 1238, 3)
load 262  /  3424
size:  (376, 1241, 3)
load 263  /  3424
size:  (375, 1242, 3)
load 264  /  3424
size:  (375, 1242, 3)
load 265  /  3424
size:  (375, 1242, 3)
load 266  /  3424
size:  (375, 1242, 3)
load 267  /  3424
size:  (375, 1242, 3)
load 268  /  3424
size:  (375, 1242, 3)
load 269  /  3424
size:  (374, 1238, 3)
load 270  /  3424
size:  (376, 1241, 3)
load 271  /  3424
size:  (375, 1242, 3)
load 272  /  3424
size:  (375, 1242, 3)
load 273  /  3424
size:  (375, 1242, 3)
load 274  /  3424
size:  (375, 1242, 3)
load 275  /  3424
size:  (375, 1242, 3)
load 276  /  3424
size:  (375, 1242, 3)
load 277  /  3424
size:  (375, 1242, 3)
load 278  /  3424
size:  (375, 1242, 3)
load 279  /  3424
size:  (375, 1242, 3)
load 280  /  3424
size:  (375, 1242, 3)
load 281  /  3424
size:  (375, 1242, 3)
load 282  /  3424
size:  (375, 1242, 3)
load 283  /  3424
size:  (375, 1242, 3)
load 284  /  3424
size:  (375, 1242, 3)
load 285  /  3424
size:  (375, 1242, 3)
load 286  /  3424
size:  (375, 1242, 3)
load 287  /  3424
size:  (375, 1242, 3)
load 288  /  3424
size:  (375, 1242, 3)
load 289  /  3424
size:  (375, 1242, 3)
load 290  /  3424
size:  (375, 1242, 3)
load 291  /  3424
size:  (374, 1238, 3)
load 292  /  3424
size:  (376, 1241, 3)
load 293  /  3424
size:  (375, 1242, 3)
load 294  /  3424
size:  (375, 1242, 3)
load 295  /  3424
size:  (375, 1242, 3)
load 296  /  3424
size:  (375, 1242, 3)
load 297  /  3424
size:  (375, 1242, 3)
load 298  /  3424
size:  (375, 1242, 3)
load 299  /  3424
size:  (375, 1242, 3)
load 300  /  3424
size:  (375, 1242, 3)
load 301  /  3424
size:  (376, 1241, 3)
load 302  /  3424
size:  (375, 1242, 3)
load 303  /  3424
size:  (375, 1242, 3)
load 304  /  3424
size:  (375, 1242, 3)
load 305  /  3424
size:  (374, 1238, 3)
load 306  /  3424
size:  (375, 1242, 3)
load 307  /  3424
size:  (375, 1242, 3)
load 308  /  3424
size:  (375, 1242, 3)
load 309  /  3424
size:  (375, 1242, 3)
load 310  /  3424
size:  (375, 1242, 3)
load 311  /  3424
size:  (375, 1242, 3)
load 312  /  3424
size:  (375, 1242, 3)
load 313  /  3424
size:  (375, 1242, 3)
load 314  /  3424
size:  (375, 1242, 3)
load 315  /  3424
size:  (375, 1242, 3)
load 316  /  3424
size:  (375, 1242, 3)
load 317  /  3424
size:  (375, 1242, 3)
load 318  /  3424
size:  (375, 1242, 3)
load 319  /  3424
size:  (375, 1242, 3)
load 320  /  3424
size:  (375, 1242, 3)
load 321  /  3424
size:  (375, 1242, 3)
load 322  /  3424
size:  (374, 1238, 3)
load 323  /  3424
size:  (376, 1241, 3)
load 324  /  3424
size:  (374, 1238, 3)
load 325  /  3424
size:  (375, 1242, 3)
load 326  /  3424
size:  (375, 1242, 3)
load 327  /  3424
size:  (375, 1242, 3)
load 328  /  3424
size:  (375, 1242, 3)
load 329  /  3424
size:  (375, 1242, 3)
load 330  /  3424
size:  (375, 1242, 3)
load 331  /  3424
size:  (376, 1241, 3)
load 332  /  3424
size:  (376, 1241, 3)
load 333  /  3424
size:  (375, 1242, 3)
load 334  /  3424
size:  (375, 1242, 3)
load 335  /  3424
size:  (375, 1242, 3)
load 336  /  3424
size:  (376, 1241, 3)
load 337  /  3424
size:  (375, 1242, 3)
load 338  /  3424
size:  (376, 1241, 3)
load 339  /  3424
size:  (375, 1242, 3)
load 340  /  3424
size:  (370, 1224, 3)
load 341  /  3424
size:  (375, 1242, 3)
load 342  /  3424
size:  (375, 1242, 3)
load 343  /  3424
size:  (376, 1241, 3)
load 344  /  3424
size:  (370, 1224, 3)
load 345  /  3424
size:  (375, 1242, 3)
load 346  /  3424
size:  (375, 1242, 3)
load 347  /  3424
size:  (375, 1242, 3)
load 348  /  3424
size:  (375, 1242, 3)
load 349  /  3424
size:  (375, 1242, 3)
load 350  /  3424
size:  (375, 1242, 3)
load 351  /  3424
size:  (375, 1242, 3)
load 352  /  3424
size:  (375, 1242, 3)
load 353  /  3424
size:  (375, 1242, 3)
load 354  /  3424
size:  (375, 1242, 3)
load 355  /  3424
size:  (376, 1241, 3)
load 356  /  3424
size:  (375, 1242, 3)
load 357  /  3424
size:  (375, 1242, 3)
load 358  /  3424
size:  (375, 1242, 3)
load 359  /  3424
size:  (375, 1242, 3)
load 360  /  3424
size:  (376, 1241, 3)
load 361  /  3424
size:  (375, 1242, 3)
load 362  /  3424
size:  (375, 1242, 3)
load 363  /  3424
size:  (375, 1242, 3)
load 364  /  3424
size:  (375, 1242, 3)
load 365  /  3424
size:  (374, 1238, 3)
load 366  /  3424
size:  (376, 1241, 3)
load 367  /  3424
size:  (375, 1242, 3)
load 368  /  3424
size:  (375, 1242, 3)
load 369  /  3424
size:  (376, 1241, 3)
load 370  /  3424
size:  (375, 1242, 3)
load 371  /  3424
size:  (375, 1242, 3)
load 372  /  3424
size:  (375, 1242, 3)
load 373  /  3424
size:  (375, 1242, 3)
load 374  /  3424
size:  (375, 1242, 3)
load 375  /  3424
size:  (375, 1242, 3)
load 376  /  3424
size:  (376, 1241, 3)
load 377  /  3424
size:  (375, 1242, 3)
load 378  /  3424
size:  (375, 1242, 3)
load 379  /  3424
size:  (375, 1242, 3)
load 380  /  3424
size:  (375, 1242, 3)
load 381  /  3424
size:  (376, 1241, 3)
load 382  /  3424
size:  (375, 1242, 3)
load 383  /  3424
size:  (375, 1242, 3)
load 384  /  3424
size:  (376, 1241, 3)
load 385  /  3424
size:  (375, 1242, 3)
load 386  /  3424
size:  (375, 1242, 3)
load 387  /  3424
size:  (375, 1242, 3)
load 388  /  3424
size:  (375, 1242, 3)
load 389  /  3424
size:  (375, 1242, 3)
load 390  /  3424
size:  (375, 1242, 3)
load 391  /  3424
size:  (370, 1224, 3)
load 392  /  3424
size:  (375, 1242, 3)
load 393  /  3424
size:  (375, 1242, 3)
load 394  /  3424
size:  (375, 1242, 3)
load 395  /  3424
size:  (375, 1242, 3)
load 396  /  3424
size:  (375, 1242, 3)
load 397  /  3424
size:  (375, 1242, 3)
load 398  /  3424
size:  (375, 1242, 3)
load 399  /  3424
size:  (374, 1238, 3)
load 400  /  3424
size:  (375, 1242, 3)
load 401  /  3424
size:  (375, 1242, 3)
load 402  /  3424
size:  (375, 1242, 3)
load 403  /  3424
size:  (375, 1242, 3)
load 404  /  3424
size:  (375, 1242, 3)
load 405  /  3424
size:  (375, 1242, 3)
load 406  /  3424
size:  (375, 1242, 3)
load 407  /  3424
size:  (375, 1242, 3)
load 408  /  3424
size:  (375, 1242, 3)
load 409  /  3424
size:  (375, 1242, 3)
load 410  /  3424
size:  (375, 1242, 3)
load 411  /  3424
size:  (375, 1242, 3)
load 412  /  3424
size:  (375, 1242, 3)
load 413  /  3424
size:  (375, 1242, 3)
load 414  /  3424
size:  (375, 1242, 3)
load 415  /  3424
size:  (375, 1242, 3)
load 416  /  3424
size:  (375, 1242, 3)
load 417  /  3424
size:  (375, 1242, 3)
load 418  /  3424
size:  (375, 1242, 3)
load 419  /  3424
size:  (376, 1241, 3)
load 420  /  3424
size:  (375, 1242, 3)
load 421  /  3424
size:  (375, 1242, 3)
load 422  /  3424
size:  (374, 1238, 3)
load 423  /  3424
size:  (376, 1241, 3)
load 424  /  3424
size:  (375, 1242, 3)
load 425  /  3424
size:  (375, 1242, 3)
load 426  /  3424
size:  (375, 1242, 3)
load 427  /  3424
size:  (375, 1242, 3)
load 428  /  3424
size:  (375, 1242, 3)
load 429  /  3424
size:  (375, 1242, 3)
load 430  /  3424
size:  (375, 1242, 3)
load 431  /  3424
size:  (375, 1242, 3)
load 432  /  3424
size:  (375, 1242, 3)
load 433  /  3424
size:  (376, 1241, 3)
load 434  /  3424
size:  (375, 1242, 3)
load 435  /  3424
size:  (375, 1242, 3)
load 436  /  3424
size:  (375, 1242, 3)
load 437  /  3424
size:  (374, 1238, 3)
load 438  /  3424
size:  (375, 1242, 3)
load 439  /  3424
size:  (375, 1242, 3)
load 440  /  3424
size:  (375, 1242, 3)
load 441  /  3424
size:  (374, 1238, 3)
load 442  /  3424
size:  (375, 1242, 3)
load 443  /  3424
size:  (375, 1242, 3)
load 444  /  3424
size:  (375, 1242, 3)
load 445  /  3424
size:  (376, 1241, 3)
load 446  /  3424
size:  (375, 1242, 3)
load 447  /  3424
size:  (375, 1242, 3)
load 448  /  3424
size:  (375, 1242, 3)
load 449  /  3424
size:  (375, 1242, 3)
load 450  /  3424
size:  (370, 1224, 3)
load 451  /  3424
size:  (375, 1242, 3)
load 452  /  3424
size:  (375, 1242, 3)
load 453  /  3424
size:  (375, 1242, 3)
load 454  /  3424
size:  (375, 1242, 3)
load 455  /  3424
size:  (375, 1242, 3)
load 456  /  3424
size:  (375, 1242, 3)
load 457  /  3424
size:  (375, 1242, 3)
load 458  /  3424
size:  (374, 1238, 3)
load 459  /  3424
size:  (375, 1242, 3)
load 460  /  3424
size:  (375, 1242, 3)
load 461  /  3424
size:  (375, 1242, 3)
load 462  /  3424
size:  (376, 1241, 3)
load 463  /  3424
size:  (375, 1242, 3)
load 464  /  3424
size:  (375, 1242, 3)
load 465  /  3424
size:  (375, 1242, 3)
load 466  /  3424
size:  (375, 1242, 3)
load 467  /  3424
size:  (375, 1242, 3)
load 468  /  3424
size:  (375, 1242, 3)
load 469  /  3424
size:  (374, 1238, 3)
load 470  /  3424
size:  (370, 1224, 3)
load 471  /  3424
size:  (374, 1238, 3)
load 472  /  3424
size:  (375, 1242, 3)
load 473  /  3424
size:  (375, 1242, 3)
load 474  /  3424
size:  (375, 1242, 3)
load 475  /  3424
size:  (375, 1242, 3)
load 476  /  3424
size:  (375, 1242, 3)
load 477  /  3424
size:  (375, 1242, 3)
load 478  /  3424
size:  (375, 1242, 3)
load 479  /  3424
size:  (375, 1242, 3)
load 480  /  3424
size:  (375, 1242, 3)
load 481  /  3424
size:  (375, 1242, 3)
load 482  /  3424
size:  (375, 1242, 3)
load 483  /  3424
size:  (375, 1242, 3)
load 484  /  3424
size:  (375, 1242, 3)
load 485  /  3424
size:  (375, 1242, 3)
load 486  /  3424
size:  (374, 1238, 3)
load 487  /  3424
size:  (375, 1242, 3)
load 488  /  3424
size:  (376, 1241, 3)
load 489  /  3424
size:  (375, 1242, 3)
load 490  /  3424
size:  (375, 1242, 3)
load 491  /  3424
size:  (375, 1242, 3)
load 492  /  3424
size:  (375, 1242, 3)
load 493  /  3424
size:  (375, 1242, 3)
load 494  /  3424
size:  (375, 1242, 3)
load 495  /  3424
size:  (375, 1242, 3)
load 496  /  3424
size:  (375, 1242, 3)
load 497  /  3424
size:  (375, 1242, 3)
load 498  /  3424
size:  (375, 1242, 3)
load 499  /  3424
size:  (375, 1242, 3)
load 500  /  3424
size:  (374, 1238, 3)
load 501  /  3424
size:  (375, 1242, 3)
load 502  /  3424
size:  (375, 1242, 3)
load 503  /  3424
size:  (375, 1242, 3)
load 504  /  3424
size:  (375, 1242, 3)
load 505  /  3424
size:  (375, 1242, 3)
load 506  /  3424
size:  (376, 1241, 3)
load 507  /  3424
size:  (375, 1242, 3)
load 508  /  3424
size:  (375, 1242, 3)
load 509  /  3424
size:  (375, 1242, 3)
load 510  /  3424
size:  (375, 1242, 3)
load 511  /  3424
size:  (375, 1242, 3)
load 512  /  3424
size:  (375, 1242, 3)
load 513  /  3424
size:  (375, 1242, 3)
load 514  /  3424
size:  (375, 1242, 3)
load 515  /  3424
size:  (375, 1242, 3)
load 516  /  3424
size:  (375, 1242, 3)
load 517  /  3424
size:  (375, 1242, 3)
load 518  /  3424
size:  (375, 1242, 3)
load 519  /  3424
size:  (375, 1242, 3)
load 520  /  3424
size:  (376, 1241, 3)
load 521  /  3424
size:  (375, 1242, 3)
load 522  /  3424
size:  (375, 1242, 3)
load 523  /  3424
size:  (375, 1242, 3)
load 524  /  3424
size:  (375, 1242, 3)
load 525  /  3424
size:  (375, 1242, 3)
load 526  /  3424
size:  (375, 1242, 3)
load 527  /  3424
size:  (375, 1242, 3)
load 528  /  3424
size:  (375, 1242, 3)
load 529  /  3424
size:  (375, 1242, 3)
load 530  /  3424
size:  (375, 1242, 3)
load 531  /  3424
size:  (375, 1242, 3)
load 532  /  3424
size:  (375, 1242, 3)
load 533  /  3424
size:  (375, 1242, 3)
load 534  /  3424
size:  (370, 1224, 3)
load 535  /  3424
size:  (375, 1242, 3)
load 536  /  3424
size:  (374, 1238, 3)
load 537  /  3424
size:  (375, 1242, 3)
load 538  /  3424
size:  (376, 1241, 3)
load 539  /  3424
size:  (375, 1242, 3)
load 540  /  3424
size:  (375, 1242, 3)
load 541  /  3424
size:  (375, 1242, 3)
load 542  /  3424
size:  (375, 1242, 3)
load 543  /  3424
size:  (375, 1242, 3)
load 544  /  3424
size:  (375, 1242, 3)
load 545  /  3424
size:  (375, 1242, 3)
load 546  /  3424
size:  (375, 1242, 3)
load 547  /  3424
size:  (375, 1242, 3)
load 548  /  3424
size:  (375, 1242, 3)
load 549  /  3424
size:  (375, 1242, 3)
load 550  /  3424
size:  (375, 1242, 3)
load 551  /  3424
size:  (375, 1242, 3)
load 552  /  3424
size:  (375, 1242, 3)
load 553  /  3424
size:  (375, 1242, 3)
load 554  /  3424
size:  (375, 1242, 3)
load 555  /  3424
size:  (375, 1242, 3)
load 556  /  3424
size:  (375, 1242, 3)
load 557  /  3424
size:  (375, 1242, 3)
load 558  /  3424
size:  (375, 1242, 3)
load 559  /  3424
size:  (375, 1242, 3)
load 560  /  3424
size:  (375, 1242, 3)
load 561  /  3424
size:  (375, 1242, 3)
load 562  /  3424
size:  (376, 1241, 3)
load 563  /  3424
size:  (375, 1242, 3)
load 564  /  3424
size:  (375, 1242, 3)
load 565  /  3424
size:  (375, 1242, 3)
load 566  /  3424
size:  (374, 1238, 3)
load 567  /  3424
size:  (375, 1242, 3)
load 568  /  3424
size:  (375, 1242, 3)
load 569  /  3424
size:  (375, 1242, 3)
load 570  /  3424
size:  (375, 1242, 3)
load 571  /  3424
size:  (375, 1242, 3)
load 572  /  3424
size:  (375, 1242, 3)
load 573  /  3424
size:  (375, 1242, 3)
load 574  /  3424
size:  (375, 1242, 3)
load 575  /  3424
size:  (370, 1224, 3)
load 576  /  3424
size:  (375, 1242, 3)
load 577  /  3424
size:  (375, 1242, 3)
load 578  /  3424
size:  (375, 1242, 3)
load 579  /  3424
size:  (375, 1242, 3)
load 580  /  3424
size:  (375, 1242, 3)
load 581  /  3424
size:  (375, 1242, 3)
load 582  /  3424
size:  (375, 1242, 3)
load 583  /  3424
size:  (375, 1242, 3)
load 584  /  3424
size:  (375, 1242, 3)
load 585  /  3424
size:  (370, 1224, 3)
load 586  /  3424
size:  (376, 1241, 3)
load 587  /  3424
size:  (370, 1224, 3)
load 588  /  3424
size:  (376, 1241, 3)
load 589  /  3424
size:  (375, 1242, 3)
load 590  /  3424
size:  (375, 1242, 3)
load 591  /  3424
size:  (370, 1224, 3)
load 592  /  3424
size:  (375, 1242, 3)
load 593  /  3424
size:  (375, 1242, 3)
load 594  /  3424
size:  (375, 1242, 3)
load 595  /  3424
size:  (375, 1242, 3)
load 596  /  3424
size:  (376, 1241, 3)
load 597  /  3424
size:  (374, 1238, 3)
load 598  /  3424
size:  (370, 1224, 3)
load 599  /  3424
size:  (375, 1242, 3)
load 600  /  3424
size:  (375, 1242, 3)
load 601  /  3424
size:  (375, 1242, 3)
load 602  /  3424
size:  (375, 1242, 3)
load 603  /  3424
size:  (375, 1242, 3)
load 604  /  3424
size:  (374, 1238, 3)
load 605  /  3424
size:  (375, 1242, 3)
load 606  /  3424
size:  (375, 1242, 3)
load 607  /  3424
size:  (375, 1242, 3)
load 608  /  3424
size:  (375, 1242, 3)
load 609  /  3424
size:  (375, 1242, 3)
load 610  /  3424
size:  (375, 1242, 3)
load 611  /  3424
size:  (375, 1242, 3)
load 612  /  3424
size:  (375, 1242, 3)
load 613  /  3424
size:  (376, 1241, 3)
load 614  /  3424
size:  (375, 1242, 3)
load 615  /  3424
size:  (375, 1242, 3)
load 616  /  3424
size:  (375, 1242, 3)
load 617  /  3424
size:  (374, 1238, 3)
load 618  /  3424
size:  (375, 1242, 3)
load 619  /  3424
size:  (375, 1242, 3)
load 620  /  3424
size:  (375, 1242, 3)
load 621  /  3424
size:  (375, 1242, 3)
load 622  /  3424
size:  (375, 1242, 3)
load 623  /  3424
size:  (375, 1242, 3)
load 624  /  3424
size:  (375, 1242, 3)
load 625  /  3424
size:  (375, 1242, 3)
load 626  /  3424
size:  (375, 1242, 3)
load 627  /  3424
size:  (375, 1242, 3)
load 628  /  3424
size:  (375, 1242, 3)
load 629  /  3424
size:  (375, 1242, 3)
load 630  /  3424
size:  (375, 1242, 3)
load 631  /  3424
size:  (375, 1242, 3)
load 632  /  3424
size:  (375, 1242, 3)
load 633  /  3424
size:  (375, 1242, 3)
load 634  /  3424
size:  (375, 1242, 3)
load 635  /  3424
size:  (375, 1242, 3)
load 636  /  3424
size:  (375, 1242, 3)
load 637  /  3424
size:  (375, 1242, 3)
load 638  /  3424
size:  (375, 1242, 3)
load 639  /  3424
size:  (375, 1242, 3)
load 640  /  3424
size:  (375, 1242, 3)
load 641  /  3424
size:  (375, 1242, 3)
load 642  /  3424
size:  (374, 1238, 3)
load 643  /  3424
size:  (375, 1242, 3)
load 644  /  3424
size:  (375, 1242, 3)
load 645  /  3424
size:  (375, 1242, 3)
load 646  /  3424
size:  (375, 1242, 3)
load 647  /  3424
size:  (375, 1242, 3)
load 648  /  3424
size:  (375, 1242, 3)
load 649  /  3424
size:  (375, 1242, 3)
load 650  /  3424
size:  (375, 1242, 3)
load 651  /  3424
size:  (375, 1242, 3)
load 652  /  3424
size:  (375, 1242, 3)
load 653  /  3424
size:  (376, 1241, 3)
load 654  /  3424
size:  (374, 1238, 3)
load 655  /  3424
size:  (375, 1242, 3)
load 656  /  3424
size:  (375, 1242, 3)
load 657  /  3424
size:  (375, 1242, 3)
load 658  /  3424
size:  (375, 1242, 3)
load 659  /  3424
size:  (375, 1242, 3)
load 660  /  3424
size:  (370, 1224, 3)
load 661  /  3424
size:  (376, 1241, 3)
load 662  /  3424
size:  (375, 1242, 3)
load 663  /  3424
size:  (375, 1242, 3)
load 664  /  3424
size:  (375, 1242, 3)
load 665  /  3424
size:  (376, 1241, 3)
load 666  /  3424
size:  (375, 1242, 3)
load 667  /  3424
size:  (370, 1224, 3)
load 668  /  3424
size:  (375, 1242, 3)
load 669  /  3424
size:  (375, 1242, 3)
load 670  /  3424
size:  (375, 1242, 3)
load 671  /  3424
size:  (375, 1242, 3)
load 672  /  3424
size:  (375, 1242, 3)
load 673  /  3424
size:  (375, 1242, 3)
load 674  /  3424
size:  (375, 1242, 3)
load 675  /  3424
size:  (375, 1242, 3)
load 676  /  3424
size:  (375, 1242, 3)
load 677  /  3424
size:  (376, 1241, 3)
load 678  /  3424
size:  (375, 1242, 3)
load 679  /  3424
size:  (375, 1242, 3)
load 680  /  3424
size:  (375, 1242, 3)
load 681  /  3424
size:  (375, 1242, 3)
load 682  /  3424
size:  (375, 1242, 3)
load 683  /  3424
size:  (375, 1242, 3)
load 684  /  3424
size:  (375, 1242, 3)
load 685  /  3424
size:  (375, 1242, 3)
load 686  /  3424
size:  (376, 1241, 3)
load 687  /  3424
size:  (375, 1242, 3)
load 688  /  3424
size:  (375, 1242, 3)
load 689  /  3424
size:  (375, 1242, 3)
load 690  /  3424
size:  (375, 1242, 3)
load 691  /  3424
size:  (375, 1242, 3)
load 692  /  3424
size:  (375, 1242, 3)
load 693  /  3424
size:  (375, 1242, 3)
load 694  /  3424
size:  (375, 1242, 3)
load 695  /  3424
size:  (375, 1242, 3)
load 696  /  3424
size:  (375, 1242, 3)
load 697  /  3424
size:  (375, 1242, 3)
load 698  /  3424
size:  (375, 1242, 3)
load 699  /  3424
size:  (376, 1241, 3)
load 700  /  3424
size:  (376, 1241, 3)
load 701  /  3424
size:  (375, 1242, 3)
load 702  /  3424
size:  (375, 1242, 3)
load 703  /  3424
size:  (375, 1242, 3)
load 704  /  3424
size:  (376, 1241, 3)
load 705  /  3424
size:  (375, 1242, 3)
load 706  /  3424
size:  (375, 1242, 3)
load 707  /  3424
size:  (375, 1242, 3)
load 708  /  3424
size:  (375, 1242, 3)
load 709  /  3424
size:  (375, 1242, 3)
load 710  /  3424
size:  (375, 1242, 3)
load 711  /  3424
size:  (375, 1242, 3)
load 712  /  3424
size:  (375, 1242, 3)
load 713  /  3424
size:  (370, 1224, 3)
load 714  /  3424
size:  (375, 1242, 3)
load 715  /  3424
size:  (375, 1242, 3)
load 716  /  3424
size:  (375, 1242, 3)
load 717  /  3424
size:  (375, 1242, 3)
load 718  /  3424
size:  (375, 1242, 3)
load 719  /  3424
size:  (374, 1238, 3)
load 720  /  3424
size:  (370, 1224, 3)
load 721  /  3424
size:  (375, 1242, 3)
load 722  /  3424
size:  (376, 1241, 3)
load 723  /  3424
size:  (375, 1242, 3)
load 724  /  3424
size:  (375, 1242, 3)
load 725  /  3424
size:  (375, 1242, 3)
load 726  /  3424
size:  (375, 1242, 3)
load 727  /  3424
size:  (375, 1242, 3)
load 728  /  3424
size:  (376, 1241, 3)
load 729  /  3424
size:  (375, 1242, 3)
load 730  /  3424
size:  (375, 1242, 3)
load 731  /  3424
size:  (375, 1242, 3)
load 732  /  3424
size:  (376, 1241, 3)
load 733  /  3424
size:  (375, 1242, 3)
load 734  /  3424
size:  (375, 1242, 3)
load 735  /  3424
size:  (375, 1242, 3)
load 736  /  3424
size:  (375, 1242, 3)
load 737  /  3424
size:  (375, 1242, 3)
load 738  /  3424
size:  (375, 1242, 3)
load 739  /  3424
size:  (370, 1224, 3)
load 740  /  3424
size:  (375, 1242, 3)
load 741  /  3424
size:  (375, 1242, 3)
load 742  /  3424
size:  (375, 1242, 3)
load 743  /  3424
size:  (375, 1242, 3)
load 744  /  3424
size:  (375, 1242, 3)
load 745  /  3424
size:  (375, 1242, 3)
load 746  /  3424
size:  (375, 1242, 3)
load 747  /  3424
size:  (375, 1242, 3)
load 748  /  3424
size:  (375, 1242, 3)
load 749  /  3424
size:  (375, 1242, 3)
load 750  /  3424
size:  (375, 1242, 3)
load 751  /  3424
size:  (375, 1242, 3)
load 752  /  3424
size:  (375, 1242, 3)
load 753  /  3424
size:  (375, 1242, 3)
load 754  /  3424
size:  (375, 1242, 3)
load 755  /  3424
size:  (375, 1242, 3)
load 756  /  3424
size:  (375, 1242, 3)
load 757  /  3424
size:  (374, 1238, 3)
load 758  /  3424
size:  (375, 1242, 3)
load 759  /  3424
size:  (376, 1241, 3)
load 760  /  3424
size:  (375, 1242, 3)
load 761  /  3424
size:  (375, 1242, 3)
load 762  /  3424
size:  (375, 1242, 3)
load 763  /  3424
size:  (375, 1242, 3)
load 764  /  3424
size:  (376, 1241, 3)
load 765  /  3424
size:  (375, 1242, 3)
load 766  /  3424
size:  (375, 1242, 3)
load 767  /  3424
size:  (375, 1242, 3)
load 768  /  3424
size:  (375, 1242, 3)
load 769  /  3424
size:  (375, 1242, 3)
load 770  /  3424
size:  (375, 1242, 3)
load 771  /  3424
size:  (374, 1238, 3)
load 772  /  3424
size:  (370, 1224, 3)
load 773  /  3424
size:  (375, 1242, 3)
load 774  /  3424
size:  (375, 1242, 3)
load 775  /  3424
size:  (375, 1242, 3)
load 776  /  3424
size:  (375, 1242, 3)
load 777  /  3424
size:  (375, 1242, 3)
load 778  /  3424
size:  (375, 1242, 3)
load 779  /  3424
size:  (375, 1242, 3)
load 780  /  3424
size:  (375, 1242, 3)
load 781  /  3424
size:  (375, 1242, 3)
load 782  /  3424
size:  (375, 1242, 3)
load 783  /  3424
size:  (375, 1242, 3)
load 784  /  3424
size:  (376, 1241, 3)
load 785  /  3424
size:  (376, 1241, 3)
load 786  /  3424
size:  (375, 1242, 3)
load 787  /  3424
size:  (375, 1242, 3)
load 788  /  3424
size:  (375, 1242, 3)
load 789  /  3424
size:  (375, 1242, 3)
load 790  /  3424
size:  (375, 1242, 3)
load 791  /  3424
size:  (375, 1242, 3)
load 792  /  3424
size:  (375, 1242, 3)
load 793  /  3424
size:  (375, 1242, 3)
load 794  /  3424
size:  (376, 1241, 3)
load 795  /  3424
size:  (375, 1242, 3)
load 796  /  3424
size:  (375, 1242, 3)
load 797  /  3424
size:  (375, 1242, 3)
load 798  /  3424
size:  (375, 1242, 3)
load 799  /  3424
size:  (375, 1242, 3)
load 800  /  3424
size:  (374, 1238, 3)
load 801  /  3424
size:  (375, 1242, 3)
load 802  /  3424
size:  (375, 1242, 3)
load 803  /  3424
size:  (375, 1242, 3)
load 804  /  3424
size:  (375, 1242, 3)
load 805  /  3424
size:  (375, 1242, 3)
load 806  /  3424
size:  (375, 1242, 3)
load 807  /  3424
size:  (376, 1241, 3)
load 808  /  3424
size:  (375, 1242, 3)
load 809  /  3424
size:  (375, 1242, 3)
load 810  /  3424
size:  (375, 1242, 3)
load 811  /  3424
size:  (375, 1242, 3)
load 812  /  3424
size:  (375, 1242, 3)
load 813  /  3424
size:  (375, 1242, 3)
load 814  /  3424
size:  (375, 1242, 3)
load 815  /  3424
size:  (370, 1224, 3)
load 816  /  3424
size:  (375, 1242, 3)
load 817  /  3424
size:  (375, 1242, 3)
load 818  /  3424
size:  (375, 1242, 3)
load 819  /  3424
size:  (375, 1242, 3)
load 820  /  3424
size:  (375, 1242, 3)
load 821  /  3424
size:  (376, 1241, 3)
load 822  /  3424
size:  (374, 1238, 3)
load 823  /  3424
size:  (375, 1242, 3)
load 824  /  3424
size:  (375, 1242, 3)
load 825  /  3424
size:  (375, 1242, 3)
load 826  /  3424
size:  (375, 1242, 3)
load 827  /  3424
size:  (375, 1242, 3)
load 828  /  3424
size:  (374, 1238, 3)
load 829  /  3424
size:  (375, 1242, 3)
load 830  /  3424
size:  (376, 1241, 3)
load 831  /  3424
size:  (375, 1242, 3)
load 832  /  3424
size:  (376, 1241, 3)
load 833  /  3424
size:  (375, 1242, 3)
load 834  /  3424
size:  (375, 1242, 3)
load 835  /  3424
size:  (375, 1242, 3)
load 836  /  3424
size:  (375, 1242, 3)
load 837  /  3424
size:  (375, 1242, 3)
load 838  /  3424
size:  (375, 1242, 3)
load 839  /  3424
size:  (375, 1242, 3)
load 840  /  3424
size:  (375, 1242, 3)
load 841  /  3424
size:  (375, 1242, 3)
load 842  /  3424
size:  (370, 1224, 3)
load 843  /  3424
size:  (375, 1242, 3)
load 844  /  3424
size:  (375, 1242, 3)
load 845  /  3424
size:  (375, 1242, 3)
load 846  /  3424
size:  (375, 1242, 3)
load 847  /  3424
size:  (375, 1242, 3)
load 848  /  3424
size:  (375, 1242, 3)
load 849  /  3424
size:  (375, 1242, 3)
load 850  /  3424
size:  (370, 1224, 3)
load 851  /  3424
size:  (375, 1242, 3)
load 852  /  3424
size:  (375, 1242, 3)
load 853  /  3424
size:  (376, 1241, 3)
load 854  /  3424
size:  (375, 1242, 3)
load 855  /  3424
size:  (375, 1242, 3)
load 856  /  3424
size:  (375, 1242, 3)
load 857  /  3424
size:  (375, 1242, 3)
load 858  /  3424
size:  (375, 1242, 3)
load 859  /  3424
size:  (375, 1242, 3)
load 860  /  3424
size:  (375, 1242, 3)
load 861  /  3424
size:  (375, 1242, 3)
load 862  /  3424
size:  (375, 1242, 3)
load 863  /  3424
size:  (376, 1241, 3)
load 864  /  3424
size:  (375, 1242, 3)
load 865  /  3424
size:  (375, 1242, 3)
load 866  /  3424
size:  (376, 1241, 3)
load 867  /  3424
size:  (375, 1242, 3)
load 868  /  3424
size:  (374, 1238, 3)
load 869  /  3424
size:  (375, 1242, 3)
load 870  /  3424
size:  (375, 1242, 3)
load 871  /  3424
size:  (375, 1242, 3)
load 872  /  3424
size:  (375, 1242, 3)
load 873  /  3424
size:  (376, 1241, 3)
load 874  /  3424
size:  (375, 1242, 3)
load 875  /  3424
size:  (375, 1242, 3)
load 876  /  3424
size:  (376, 1241, 3)
load 877  /  3424
size:  (375, 1242, 3)
load 878  /  3424
size:  (375, 1242, 3)
load 879  /  3424
size:  (375, 1242, 3)
load 880  /  3424
size:  (375, 1242, 3)
load 881  /  3424
size:  (375, 1242, 3)
load 882  /  3424
size:  (375, 1242, 3)
load 883  /  3424
size:  (375, 1242, 3)
load 884  /  3424
size:  (375, 1242, 3)
load 885  /  3424
size:  (375, 1242, 3)
load 886  /  3424
size:  (375, 1242, 3)
load 887  /  3424
size:  (375, 1242, 3)
load 888  /  3424
size:  (375, 1242, 3)
load 889  /  3424
size:  (375, 1242, 3)
load 890  /  3424
size:  (375, 1242, 3)
load 891  /  3424
size:  (375, 1242, 3)
load 892  /  3424
size:  (375, 1242, 3)
load 893  /  3424
size:  (376, 1241, 3)
load 894  /  3424
size:  (375, 1242, 3)
load 895  /  3424
size:  (376, 1241, 3)
load 896  /  3424
size:  (375, 1242, 3)
load 897  /  3424
size:  (375, 1242, 3)
load 898  /  3424
size:  (375, 1242, 3)
load 899  /  3424
size:  (375, 1242, 3)
load 900  /  3424
size:  (370, 1224, 3)
load 901  /  3424
size:  (375, 1242, 3)
load 902  /  3424
size:  (375, 1242, 3)
load 903  /  3424
size:  (375, 1242, 3)
load 904  /  3424
size:  (375, 1242, 3)
load 905  /  3424
size:  (375, 1242, 3)
load 906  /  3424
size:  (375, 1242, 3)
load 907  /  3424
size:  (375, 1242, 3)
load 908  /  3424
size:  (375, 1242, 3)
load 909  /  3424
size:  (370, 1224, 3)
load 910  /  3424
size:  (375, 1242, 3)
load 911  /  3424
size:  (375, 1242, 3)
load 912  /  3424
size:  (375, 1242, 3)
load 913  /  3424
size:  (375, 1242, 3)
load 914  /  3424
size:  (375, 1242, 3)
load 915  /  3424
size:  (375, 1242, 3)
load 916  /  3424
size:  (375, 1242, 3)
load 917  /  3424
size:  (375, 1242, 3)
load 918  /  3424
size:  (375, 1242, 3)
load 919  /  3424
size:  (375, 1242, 3)
load 920  /  3424
size:  (375, 1242, 3)
load 921  /  3424
size:  (375, 1242, 3)
load 922  /  3424
size:  (375, 1242, 3)
load 923  /  3424
size:  (375, 1242, 3)
load 924  /  3424
size:  (376, 1241, 3)
load 925  /  3424
size:  (375, 1242, 3)
load 926  /  3424
size:  (375, 1242, 3)
load 927  /  3424
size:  (375, 1242, 3)
load 928  /  3424
size:  (375, 1242, 3)
load 929  /  3424
size:  (376, 1241, 3)
load 930  /  3424
size:  (375, 1242, 3)
load 931  /  3424
size:  (375, 1242, 3)
load 932  /  3424
size:  (375, 1242, 3)
load 933  /  3424
size:  (375, 1242, 3)
load 934  /  3424
size:  (375, 1242, 3)
load 935  /  3424
size:  (375, 1242, 3)
load 936  /  3424
size:  (370, 1224, 3)
load 937  /  3424
size:  (375, 1242, 3)
load 938  /  3424
size:  (375, 1242, 3)
load 939  /  3424
size:  (375, 1242, 3)
load 940  /  3424
size:  (375, 1242, 3)
load 941  /  3424
size:  (375, 1242, 3)
load 942  /  3424
size:  (375, 1242, 3)
load 943  /  3424
size:  (375, 1242, 3)
load 944  /  3424
size:  (375, 1242, 3)
load 945  /  3424
size:  (374, 1238, 3)
load 946  /  3424
size:  (375, 1242, 3)
load 947  /  3424
size:  (375, 1242, 3)
load 948  /  3424
size:  (375, 1242, 3)
load 949  /  3424
size:  (375, 1242, 3)
load 950  /  3424
size:  (375, 1242, 3)
load 951  /  3424
size:  (375, 1242, 3)
load 952  /  3424
size:  (375, 1242, 3)
load 953  /  3424
size:  (375, 1242, 3)
load 954  /  3424
size:  (375, 1242, 3)
load 955  /  3424
size:  (375, 1242, 3)
load 956  /  3424
size:  (375, 1242, 3)
load 957  /  3424
size:  (375, 1242, 3)
load 958  /  3424
size:  (375, 1242, 3)
load 959  /  3424
size:  (375, 1242, 3)
load 960  /  3424
size:  (376, 1241, 3)
load 961  /  3424
size:  (370, 1224, 3)
load 962  /  3424
size:  (375, 1242, 3)
load 963  /  3424
size:  (375, 1242, 3)
load 964  /  3424
size:  (375, 1242, 3)
load 965  /  3424
size:  (375, 1242, 3)
load 966  /  3424
size:  (375, 1242, 3)
load 967  /  3424
size:  (375, 1242, 3)
load 968  /  3424
size:  (375, 1242, 3)
load 969  /  3424
size:  (375, 1242, 3)
load 970  /  3424
size:  (376, 1241, 3)
load 971  /  3424
size:  (376, 1241, 3)
load 972  /  3424
size:  (376, 1241, 3)
load 973  /  3424
size:  (376, 1241, 3)
load 974  /  3424
size:  (375, 1242, 3)
load 975  /  3424
size:  (375, 1242, 3)
load 976  /  3424
size:  (375, 1242, 3)
load 977  /  3424
size:  (375, 1242, 3)
load 978  /  3424
size:  (375, 1242, 3)
load 979  /  3424
size:  (375, 1242, 3)
load 980  /  3424
size:  (375, 1242, 3)
load 981  /  3424
size:  (375, 1242, 3)
load 982  /  3424
size:  (375, 1242, 3)
load 983  /  3424
size:  (375, 1242, 3)
load 984  /  3424
size:  (376, 1241, 3)
load 985  /  3424
size:  (375, 1242, 3)
load 986  /  3424
size:  (375, 1242, 3)
load 987  /  3424
size:  (376, 1241, 3)
load 988  /  3424
size:  (375, 1242, 3)
load 989  /  3424
size:  (375, 1242, 3)
load 990  /  3424
size:  (375, 1242, 3)
load 991  /  3424
size:  (375, 1242, 3)
load 992  /  3424
size:  (375, 1242, 3)
load 993  /  3424
size:  (375, 1242, 3)
load 994  /  3424
size:  (375, 1242, 3)
load 995  /  3424
size:  (376, 1241, 3)
load 996  /  3424
size:  (375, 1242, 3)
load 997  /  3424
size:  (374, 1238, 3)
load 998  /  3424
size:  (375, 1242, 3)
load 999  /  3424
size:  (375, 1242, 3)
load 1000  /  3424
size:  (375, 1242, 3)
load 1001  /  3424
size:  (375, 1242, 3)
load 1002  /  3424
size:  (375, 1242, 3)
load 1003  /  3424
size:  (375, 1242, 3)
load 1004  /  3424
size:  (375, 1242, 3)
load 1005  /  3424
size:  (375, 1242, 3)
load 1006  /  3424
size:  (375, 1242, 3)
load 1007  /  3424
size:  (375, 1242, 3)
load 1008  /  3424
size:  (375, 1242, 3)
load 1009  /  3424
size:  (375, 1242, 3)
load 1010  /  3424
size:  (375, 1242, 3)
load 1011  /  3424
size:  (375, 1242, 3)
load 1012  /  3424
size:  (375, 1242, 3)
load 1013  /  3424
size:  (374, 1238, 3)
load 1014  /  3424
size:  (370, 1224, 3)
load 1015  /  3424
size:  (375, 1242, 3)
load 1016  /  3424
size:  (375, 1242, 3)
load 1017  /  3424
size:  (375, 1242, 3)
load 1018  /  3424
size:  (375, 1242, 3)
load 1019  /  3424
size:  (375, 1242, 3)
load 1020  /  3424
size:  (375, 1242, 3)
load 1021  /  3424
size:  (375, 1242, 3)
load 1022  /  3424
size:  (375, 1242, 3)
load 1023  /  3424
size:  (376, 1241, 3)
load 1024  /  3424
size:  (376, 1241, 3)
load 1025  /  3424
size:  (375, 1242, 3)
load 1026  /  3424
size:  (375, 1242, 3)
load 1027  /  3424
size:  (375, 1242, 3)
load 1028  /  3424
size:  (375, 1242, 3)
load 1029  /  3424
size:  (375, 1242, 3)
load 1030  /  3424
size:  (375, 1242, 3)
load 1031  /  3424
size:  (375, 1242, 3)
load 1032  /  3424
size:  (375, 1242, 3)
load 1033  /  3424
size:  (376, 1241, 3)
load 1034  /  3424
size:  (376, 1241, 3)
load 1035  /  3424
size:  (375, 1242, 3)
load 1036  /  3424
size:  (376, 1241, 3)
load 1037  /  3424
size:  (375, 1242, 3)
load 1038  /  3424
size:  (376, 1241, 3)
load 1039  /  3424
size:  (375, 1242, 3)
load 1040  /  3424
size:  (375, 1242, 3)
load 1041  /  3424
size:  (375, 1242, 3)
load 1042  /  3424
size:  (375, 1242, 3)
load 1043  /  3424
size:  (375, 1242, 3)
load 1044  /  3424
size:  (375, 1242, 3)
load 1045  /  3424
size:  (375, 1242, 3)
load 1046  /  3424
size:  (376, 1241, 3)
load 1047  /  3424
size:  (374, 1238, 3)
load 1048  /  3424
size:  (375, 1242, 3)
load 1049  /  3424
size:  (375, 1242, 3)
load 1050  /  3424
size:  (375, 1242, 3)
load 1051  /  3424
size:  (370, 1224, 3)
load 1052  /  3424
size:  (375, 1242, 3)
load 1053  /  3424
size:  (375, 1242, 3)
load 1054  /  3424
size:  (375, 1242, 3)
load 1055  /  3424
size:  (375, 1242, 3)
load 1056  /  3424
size:  (375, 1242, 3)
load 1057  /  3424
size:  (375, 1242, 3)
load 1058  /  3424
size:  (375, 1242, 3)
load 1059  /  3424
size:  (376, 1241, 3)
load 1060  /  3424
size:  (375, 1242, 3)
load 1061  /  3424
size:  (375, 1242, 3)
load 1062  /  3424
size:  (375, 1242, 3)
load 1063  /  3424
size:  (376, 1241, 3)
load 1064  /  3424
size:  (374, 1238, 3)
load 1065  /  3424
size:  (375, 1242, 3)
load 1066  /  3424
size:  (375, 1242, 3)
load 1067  /  3424
size:  (375, 1242, 3)
load 1068  /  3424
size:  (375, 1242, 3)
load 1069  /  3424
size:  (374, 1238, 3)
load 1070  /  3424
size:  (375, 1242, 3)
load 1071  /  3424
size:  (375, 1242, 3)
load 1072  /  3424
size:  (375, 1242, 3)
load 1073  /  3424
size:  (375, 1242, 3)
load 1074  /  3424
size:  (375, 1242, 3)
load 1075  /  3424
size:  (375, 1242, 3)
load 1076  /  3424
size:  (375, 1242, 3)
load 1077  /  3424
size:  (375, 1242, 3)
load 1078  /  3424
size:  (375, 1242, 3)
load 1079  /  3424
size:  (375, 1242, 3)
load 1080  /  3424
size:  (375, 1242, 3)
load 1081  /  3424
size:  (375, 1242, 3)
load 1082  /  3424
size:  (376, 1241, 3)
load 1083  /  3424
size:  (375, 1242, 3)
load 1084  /  3424
size:  (375, 1242, 3)
load 1085  /  3424
size:  (376, 1241, 3)
load 1086  /  3424
size:  (375, 1242, 3)
load 1087  /  3424
size:  (375, 1242, 3)
load 1088  /  3424
size:  (375, 1242, 3)
load 1089  /  3424
size:  (375, 1242, 3)
load 1090  /  3424
size:  (375, 1242, 3)
load 1091  /  3424
size:  (375, 1242, 3)
load 1092  /  3424
size:  (375, 1242, 3)
load 1093  /  3424
size:  (375, 1242, 3)
load 1094  /  3424
size:  (375, 1242, 3)
load 1095  /  3424
size:  (375, 1242, 3)
load 1096  /  3424
size:  (375, 1242, 3)
load 1097  /  3424
size:  (375, 1242, 3)
load 1098  /  3424
size:  (375, 1242, 3)
load 1099  /  3424
size:  (375, 1242, 3)
load 1100  /  3424
size:  (375, 1242, 3)
load 1101  /  3424
size:  (375, 1242, 3)
load 1102  /  3424
size:  (375, 1242, 3)
load 1103  /  3424
size:  (375, 1242, 3)
load 1104  /  3424
size:  (375, 1242, 3)
load 1105  /  3424
size:  (375, 1242, 3)
load 1106  /  3424
size:  (375, 1242, 3)
load 1107  /  3424
size:  (375, 1242, 3)
load 1108  /  3424
size:  (375, 1242, 3)
load 1109  /  3424
size:  (375, 1242, 3)
load 1110  /  3424
size:  (375, 1242, 3)
load 1111  /  3424
size:  (375, 1242, 3)
load 1112  /  3424
size:  (376, 1241, 3)
load 1113  /  3424
size:  (375, 1242, 3)
load 1114  /  3424
size:  (375, 1242, 3)
load 1115  /  3424
size:  (375, 1242, 3)
load 1116  /  3424
size:  (375, 1242, 3)
load 1117  /  3424
size:  (375, 1242, 3)
load 1118  /  3424
size:  (374, 1238, 3)
load 1119  /  3424
size:  (375, 1242, 3)
load 1120  /  3424
size:  (375, 1242, 3)
load 1121  /  3424
size:  (376, 1241, 3)
load 1122  /  3424
size:  (375, 1242, 3)
load 1123  /  3424
size:  (375, 1242, 3)
load 1124  /  3424
size:  (376, 1241, 3)
load 1125  /  3424
size:  (375, 1242, 3)
load 1126  /  3424
size:  (375, 1242, 3)
load 1127  /  3424
size:  (375, 1242, 3)
load 1128  /  3424
size:  (375, 1242, 3)
load 1129  /  3424
size:  (374, 1238, 3)
load 1130  /  3424
size:  (375, 1242, 3)
load 1131  /  3424
size:  (375, 1242, 3)
load 1132  /  3424
size:  (375, 1242, 3)
load 1133  /  3424
size:  (375, 1242, 3)
load 1134  /  3424
size:  (375, 1242, 3)
load 1135  /  3424
size:  (375, 1242, 3)
load 1136  /  3424
size:  (375, 1242, 3)
load 1137  /  3424
size:  (376, 1241, 3)
load 1138  /  3424
size:  (376, 1241, 3)
load 1139  /  3424
size:  (375, 1242, 3)
load 1140  /  3424
size:  (375, 1242, 3)
load 1141  /  3424
size:  (375, 1242, 3)
load 1142  /  3424
size:  (375, 1242, 3)
load 1143  /  3424
size:  (370, 1224, 3)
load 1144  /  3424
size:  (375, 1242, 3)
load 1145  /  3424
size:  (375, 1242, 3)
load 1146  /  3424
size:  (375, 1242, 3)
load 1147  /  3424
size:  (375, 1242, 3)
load 1148  /  3424
size:  (376, 1241, 3)
load 1149  /  3424
size:  (375, 1242, 3)
load 1150  /  3424
size:  (375, 1242, 3)
load 1151  /  3424
size:  (375, 1242, 3)
load 1152  /  3424
size:  (376, 1241, 3)
load 1153  /  3424
size:  (375, 1242, 3)
load 1154  /  3424
size:  (375, 1242, 3)
load 1155  /  3424
size:  (375, 1242, 3)
load 1156  /  3424
size:  (375, 1242, 3)
load 1157  /  3424
size:  (375, 1242, 3)
load 1158  /  3424
size:  (370, 1224, 3)
load 1159  /  3424
size:  (375, 1242, 3)
load 1160  /  3424
size:  (375, 1242, 3)
load 1161  /  3424
size:  (375, 1242, 3)
load 1162  /  3424
size:  (376, 1241, 3)
load 1163  /  3424
size:  (370, 1224, 3)
load 1164  /  3424
size:  (375, 1242, 3)
load 1165  /  3424
size:  (375, 1242, 3)
load 1166  /  3424
size:  (375, 1242, 3)
load 1167  /  3424
size:  (376, 1241, 3)
load 1168  /  3424
size:  (374, 1238, 3)
load 1169  /  3424
size:  (376, 1241, 3)
load 1170  /  3424
size:  (375, 1242, 3)
load 1171  /  3424
size:  (375, 1242, 3)
load 1172  /  3424
size:  (375, 1242, 3)
load 1173  /  3424
size:  (375, 1242, 3)
load 1174  /  3424
size:  (375, 1242, 3)
load 1175  /  3424
size:  (376, 1241, 3)
load 1176  /  3424
size:  (376, 1241, 3)
load 1177  /  3424
size:  (375, 1242, 3)
load 1178  /  3424
size:  (375, 1242, 3)
load 1179  /  3424
size:  (375, 1242, 3)
load 1180  /  3424
size:  (376, 1241, 3)
load 1181  /  3424
size:  (375, 1242, 3)
load 1182  /  3424
size:  (375, 1242, 3)
load 1183  /  3424
size:  (375, 1242, 3)
load 1184  /  3424
size:  (375, 1242, 3)
load 1185  /  3424
size:  (375, 1242, 3)
load 1186  /  3424
size:  (375, 1242, 3)
load 1187  /  3424
size:  (370, 1224, 3)
load 1188  /  3424
size:  (375, 1242, 3)
load 1189  /  3424
size:  (375, 1242, 3)
load 1190  /  3424
size:  (375, 1242, 3)
load 1191  /  3424
size:  (374, 1238, 3)
load 1192  /  3424
size:  (375, 1242, 3)
load 1193  /  3424
size:  (375, 1242, 3)
load 1194  /  3424
size:  (375, 1242, 3)
load 1195  /  3424
size:  (374, 1238, 3)
load 1196  /  3424
size:  (375, 1242, 3)
load 1197  /  3424
size:  (376, 1241, 3)
load 1198  /  3424
size:  (375, 1242, 3)
load 1199  /  3424
size:  (375, 1242, 3)
load 1200  /  3424
size:  (375, 1242, 3)
load 1201  /  3424
size:  (375, 1242, 3)
load 1202  /  3424
size:  (375, 1242, 3)
load 1203  /  3424
size:  (375, 1242, 3)
load 1204  /  3424
size:  (375, 1242, 3)
load 1205  /  3424
size:  (375, 1242, 3)
load 1206  /  3424
size:  (375, 1242, 3)
load 1207  /  3424
size:  (375, 1242, 3)
load 1208  /  3424
size:  (375, 1242, 3)
load 1209  /  3424
size:  (375, 1242, 3)
load 1210  /  3424
size:  (375, 1242, 3)
load 1211  /  3424
size:  (375, 1242, 3)
load 1212  /  3424
size:  (375, 1242, 3)
load 1213  /  3424
size:  (375, 1242, 3)
load 1214  /  3424
size:  (375, 1242, 3)
load 1215  /  3424
size:  (375, 1242, 3)
load 1216  /  3424
size:  (375, 1242, 3)
load 1217  /  3424
size:  (374, 1238, 3)
load 1218  /  3424
size:  (375, 1242, 3)
load 1219  /  3424
size:  (376, 1241, 3)
load 1220  /  3424
size:  (374, 1238, 3)
load 1221  /  3424
size:  (375, 1242, 3)
load 1222  /  3424
size:  (376, 1241, 3)
load 1223  /  3424
size:  (375, 1242, 3)
load 1224  /  3424
size:  (375, 1242, 3)
load 1225  /  3424
size:  (375, 1242, 3)
load 1226  /  3424
size:  (375, 1242, 3)
load 1227  /  3424
size:  (375, 1242, 3)
load 1228  /  3424
size:  (375, 1242, 3)
load 1229  /  3424
size:  (375, 1242, 3)
load 1230  /  3424
size:  (375, 1242, 3)
load 1231  /  3424
size:  (374, 1238, 3)
load 1232  /  3424
size:  (375, 1242, 3)
load 1233  /  3424
size:  (375, 1242, 3)
load 1234  /  3424
size:  (375, 1242, 3)
load 1235  /  3424
size:  (375, 1242, 3)
load 1236  /  3424
size:  (375, 1242, 3)
load 1237  /  3424
size:  (375, 1242, 3)
load 1238  /  3424
size:  (375, 1242, 3)
load 1239  /  3424
size:  (375, 1242, 3)
load 1240  /  3424
size:  (375, 1242, 3)
load 1241  /  3424
size:  (375, 1242, 3)
load 1242  /  3424
size:  (375, 1242, 3)
load 1243  /  3424
size:  (375, 1242, 3)
load 1244  /  3424
size:  (375, 1242, 3)
load 1245  /  3424
size:  (376, 1241, 3)
load 1246  /  3424
size:  (375, 1242, 3)
load 1247  /  3424
size:  (375, 1242, 3)
load 1248  /  3424
size:  (375, 1242, 3)
load 1249  /  3424
size:  (375, 1242, 3)
load 1250  /  3424
size:  (375, 1242, 3)
load 1251  /  3424
size:  (375, 1242, 3)
load 1252  /  3424
size:  (375, 1242, 3)
load 1253  /  3424
size:  (375, 1242, 3)
load 1254  /  3424
size:  (375, 1242, 3)
load 1255  /  3424
size:  (375, 1242, 3)
load 1256  /  3424
size:  (374, 1238, 3)
load 1257  /  3424
size:  (375, 1242, 3)
load 1258  /  3424
size:  (375, 1242, 3)
load 1259  /  3424
size:  (375, 1242, 3)
load 1260  /  3424
size:  (375, 1242, 3)
load 1261  /  3424
size:  (375, 1242, 3)
load 1262  /  3424
size:  (376, 1241, 3)
load 1263  /  3424
size:  (376, 1241, 3)
load 1264  /  3424
size:  (375, 1242, 3)
load 1265  /  3424
size:  (374, 1238, 3)
load 1266  /  3424
size:  (375, 1242, 3)
load 1267  /  3424
size:  (375, 1242, 3)
load 1268  /  3424
size:  (375, 1242, 3)
load 1269  /  3424
size:  (374, 1238, 3)
load 1270  /  3424
size:  (375, 1242, 3)
load 1271  /  3424
size:  (375, 1242, 3)
load 1272  /  3424
size:  (375, 1242, 3)
load 1273  /  3424
size:  (375, 1242, 3)
load 1274  /  3424
size:  (375, 1242, 3)
load 1275  /  3424
size:  (375, 1242, 3)
load 1276  /  3424
size:  (375, 1242, 3)
load 1277  /  3424
size:  (375, 1242, 3)
load 1278  /  3424
size:  (375, 1242, 3)
load 1279  /  3424
size:  (375, 1242, 3)
load 1280  /  3424
size:  (375, 1242, 3)
load 1281  /  3424
size:  (375, 1242, 3)
load 1282  /  3424
size:  (375, 1242, 3)
load 1283  /  3424
size:  (375, 1242, 3)
load 1284  /  3424
size:  (375, 1242, 3)
load 1285  /  3424
size:  (375, 1242, 3)
load 1286  /  3424
size:  (375, 1242, 3)
load 1287  /  3424
size:  (375, 1242, 3)
load 1288  /  3424
size:  (375, 1242, 3)
load 1289  /  3424
size:  (375, 1242, 3)
load 1290  /  3424
size:  (376, 1241, 3)
load 1291  /  3424
size:  (375, 1242, 3)
load 1292  /  3424
size:  (375, 1242, 3)
load 1293  /  3424
size:  (375, 1242, 3)
load 1294  /  3424
size:  (375, 1242, 3)
load 1295  /  3424
size:  (375, 1242, 3)
load 1296  /  3424
size:  (375, 1242, 3)
load 1297  /  3424
size:  (375, 1242, 3)
load 1298  /  3424
size:  (375, 1242, 3)
load 1299  /  3424
size:  (375, 1242, 3)
load 1300  /  3424
size:  (375, 1242, 3)
load 1301  /  3424
size:  (375, 1242, 3)
load 1302  /  3424
size:  (375, 1242, 3)
load 1303  /  3424
size:  (375, 1242, 3)
load 1304  /  3424
size:  (375, 1242, 3)
load 1305  /  3424
size:  (375, 1242, 3)
load 1306  /  3424
size:  (374, 1238, 3)
load 1307  /  3424
size:  (375, 1242, 3)
load 1308  /  3424
size:  (376, 1241, 3)
load 1309  /  3424
size:  (375, 1242, 3)
load 1310  /  3424
size:  (375, 1242, 3)
load 1311  /  3424
size:  (375, 1242, 3)
load 1312  /  3424
size:  (375, 1242, 3)
load 1313  /  3424
size:  (375, 1242, 3)
load 1314  /  3424
size:  (375, 1242, 3)
load 1315  /  3424
size:  (375, 1242, 3)
load 1316  /  3424
size:  (375, 1242, 3)
load 1317  /  3424
size:  (375, 1242, 3)
load 1318  /  3424
size:  (375, 1242, 3)
load 1319  /  3424
size:  (375, 1242, 3)
load 1320  /  3424
size:  (375, 1242, 3)
load 1321  /  3424
size:  (375, 1242, 3)
load 1322  /  3424
size:  (375, 1242, 3)
load 1323  /  3424
size:  (376, 1241, 3)
load 1324  /  3424
size:  (375, 1242, 3)
load 1325  /  3424
size:  (375, 1242, 3)
load 1326  /  3424
size:  (375, 1242, 3)
load 1327  /  3424
size:  (375, 1242, 3)
load 1328  /  3424
size:  (374, 1238, 3)
load 1329  /  3424
size:  (375, 1242, 3)
load 1330  /  3424
size:  (376, 1241, 3)
load 1331  /  3424
size:  (375, 1242, 3)
load 1332  /  3424
size:  (375, 1242, 3)
load 1333  /  3424
size:  (375, 1242, 3)
load 1334  /  3424
size:  (375, 1242, 3)
load 1335  /  3424
size:  (375, 1242, 3)
load 1336  /  3424
size:  (375, 1242, 3)
load 1337  /  3424
size:  (375, 1242, 3)
load 1338  /  3424
size:  (376, 1241, 3)
load 1339  /  3424
size:  (375, 1242, 3)
load 1340  /  3424
size:  (375, 1242, 3)
load 1341  /  3424
size:  (376, 1241, 3)
load 1342  /  3424
size:  (375, 1242, 3)
load 1343  /  3424
size:  (374, 1238, 3)
load 1344  /  3424
size:  (375, 1242, 3)
load 1345  /  3424
size:  (375, 1242, 3)
load 1346  /  3424
size:  (375, 1242, 3)
load 1347  /  3424
size:  (375, 1242, 3)
load 1348  /  3424
size:  (375, 1242, 3)
load 1349  /  3424
size:  (375, 1242, 3)
load 1350  /  3424
size:  (375, 1242, 3)
load 1351  /  3424
size:  (375, 1242, 3)
load 1352  /  3424
size:  (375, 1242, 3)
load 1353  /  3424
size:  (375, 1242, 3)
load 1354  /  3424
size:  (375, 1242, 3)
load 1355  /  3424
size:  (375, 1242, 3)
load 1356  /  3424
size:  (375, 1242, 3)
load 1357  /  3424
size:  (370, 1224, 3)
load 1358  /  3424
size:  (375, 1242, 3)
load 1359  /  3424
size:  (375, 1242, 3)
load 1360  /  3424
size:  (375, 1242, 3)
load 1361  /  3424
size:  (375, 1242, 3)
load 1362  /  3424
size:  (375, 1242, 3)
load 1363  /  3424
size:  (375, 1242, 3)
load 1364  /  3424
size:  (375, 1242, 3)
load 1365  /  3424
size:  (375, 1242, 3)
load 1366  /  3424
size:  (375, 1242, 3)
load 1367  /  3424
size:  (375, 1242, 3)
load 1368  /  3424
size:  (375, 1242, 3)
load 1369  /  3424
size:  (375, 1242, 3)
load 1370  /  3424
size:  (375, 1242, 3)
load 1371  /  3424
size:  (375, 1242, 3)
load 1372  /  3424
size:  (375, 1242, 3)
load 1373  /  3424
size:  (375, 1242, 3)
load 1374  /  3424
size:  (375, 1242, 3)
load 1375  /  3424
size:  (375, 1242, 3)
load 1376  /  3424
size:  (375, 1242, 3)
load 1377  /  3424
size:  (376, 1241, 3)
load 1378  /  3424
size:  (375, 1242, 3)
load 1379  /  3424
size:  (375, 1242, 3)
load 1380  /  3424
size:  (375, 1242, 3)
load 1381  /  3424
size:  (375, 1242, 3)
load 1382  /  3424
size:  (374, 1238, 3)
load 1383  /  3424
size:  (376, 1241, 3)
load 1384  /  3424
size:  (370, 1224, 3)
load 1385  /  3424
size:  (374, 1238, 3)
load 1386  /  3424
size:  (375, 1242, 3)
load 1387  /  3424
size:  (376, 1241, 3)
load 1388  /  3424
size:  (375, 1242, 3)
load 1389  /  3424
size:  (375, 1242, 3)
load 1390  /  3424
size:  (375, 1242, 3)
load 1391  /  3424
size:  (375, 1242, 3)
load 1392  /  3424
size:  (370, 1224, 3)
load 1393  /  3424
size:  (375, 1242, 3)
load 1394  /  3424
size:  (375, 1242, 3)
load 1395  /  3424
size:  (370, 1224, 3)
load 1396  /  3424
size:  (375, 1242, 3)
load 1397  /  3424
size:  (374, 1238, 3)
load 1398  /  3424
size:  (375, 1242, 3)
load 1399  /  3424
size:  (374, 1238, 3)
load 1400  /  3424
size:  (375, 1242, 3)
load 1401  /  3424
size:  (375, 1242, 3)
load 1402  /  3424
size:  (375, 1242, 3)
load 1403  /  3424
size:  (375, 1242, 3)
load 1404  /  3424
size:  (375, 1242, 3)
load 1405  /  3424
size:  (375, 1242, 3)
load 1406  /  3424
size:  (375, 1242, 3)
load 1407  /  3424
size:  (375, 1242, 3)
load 1408  /  3424
size:  (375, 1242, 3)
load 1409  /  3424
size:  (375, 1242, 3)
load 1410  /  3424
size:  (375, 1242, 3)
load 1411  /  3424
size:  (375, 1242, 3)
load 1412  /  3424
size:  (375, 1242, 3)
load 1413  /  3424
size:  (370, 1224, 3)
load 1414  /  3424
size:  (376, 1241, 3)
load 1415  /  3424
size:  (375, 1242, 3)
load 1416  /  3424
size:  (375, 1242, 3)
load 1417  /  3424
size:  (375, 1242, 3)
load 1418  /  3424
size:  (374, 1238, 3)
load 1419  /  3424
size:  (375, 1242, 3)
load 1420  /  3424
size:  (375, 1242, 3)
load 1421  /  3424
size:  (374, 1238, 3)
load 1422  /  3424
size:  (375, 1242, 3)
load 1423  /  3424
size:  (375, 1242, 3)
load 1424  /  3424
size:  (376, 1241, 3)
load 1425  /  3424
size:  (375, 1242, 3)
load 1426  /  3424
size:  (375, 1242, 3)
load 1427  /  3424
size:  (375, 1242, 3)
load 1428  /  3424
size:  (375, 1242, 3)
load 1429  /  3424
size:  (375, 1242, 3)
load 1430  /  3424
size:  (370, 1224, 3)
load 1431  /  3424
size:  (375, 1242, 3)
load 1432  /  3424
size:  (375, 1242, 3)
load 1433  /  3424
size:  (370, 1224, 3)
load 1434  /  3424
size:  (375, 1242, 3)
load 1435  /  3424
size:  (375, 1242, 3)
load 1436  /  3424
size:  (375, 1242, 3)
load 1437  /  3424
size:  (375, 1242, 3)
load 1438  /  3424
size:  (375, 1242, 3)
load 1439  /  3424
size:  (375, 1242, 3)
load 1440  /  3424
size:  (375, 1242, 3)
load 1441  /  3424
size:  (375, 1242, 3)
load 1442  /  3424
size:  (375, 1242, 3)
load 1443  /  3424
size:  (375, 1242, 3)
load 1444  /  3424
size:  (375, 1242, 3)
load 1445  /  3424
size:  (375, 1242, 3)
load 1446  /  3424
size:  (370, 1224, 3)
load 1447  /  3424
size:  (376, 1241, 3)
load 1448  /  3424
size:  (375, 1242, 3)
load 1449  /  3424
size:  (375, 1242, 3)
load 1450  /  3424
size:  (375, 1242, 3)
load 1451  /  3424
size:  (375, 1242, 3)
load 1452  /  3424
size:  (375, 1242, 3)
load 1453  /  3424
size:  (375, 1242, 3)
load 1454  /  3424
size:  (375, 1242, 3)
load 1455  /  3424
size:  (375, 1242, 3)
load 1456  /  3424
size:  (376, 1241, 3)
load 1457  /  3424
size:  (376, 1241, 3)
load 1458  /  3424
size:  (375, 1242, 3)
load 1459  /  3424
size:  (375, 1242, 3)
load 1460  /  3424
size:  (375, 1242, 3)
load 1461  /  3424
size:  (375, 1242, 3)
load 1462  /  3424
size:  (375, 1242, 3)
load 1463  /  3424
size:  (375, 1242, 3)
load 1464  /  3424
size:  (375, 1242, 3)
load 1465  /  3424
size:  (374, 1238, 3)
load 1466  /  3424
size:  (375, 1242, 3)
load 1467  /  3424
size:  (375, 1242, 3)
load 1468  /  3424
size:  (376, 1241, 3)
load 1469  /  3424
size:  (375, 1242, 3)
load 1470  /  3424
size:  (375, 1242, 3)
load 1471  /  3424
size:  (375, 1242, 3)
load 1472  /  3424
size:  (375, 1242, 3)
load 1473  /  3424
size:  (375, 1242, 3)
load 1474  /  3424
size:  (375, 1242, 3)
load 1475  /  3424
size:  (375, 1242, 3)
load 1476  /  3424
size:  (375, 1242, 3)
load 1477  /  3424
size:  (375, 1242, 3)
load 1478  /  3424
size:  (375, 1242, 3)
load 1479  /  3424
size:  (375, 1242, 3)
load 1480  /  3424
size:  (375, 1242, 3)
load 1481  /  3424
size:  (375, 1242, 3)
load 1482  /  3424
size:  (375, 1242, 3)
load 1483  /  3424
size:  (375, 1242, 3)
load 1484  /  3424
size:  (375, 1242, 3)
load 1485  /  3424
size:  (375, 1242, 3)
load 1486  /  3424
size:  (375, 1242, 3)
load 1487  /  3424
size:  (375, 1242, 3)
load 1488  /  3424
size:  (370, 1224, 3)
load 1489  /  3424
size:  (375, 1242, 3)
load 1490  /  3424
size:  (375, 1242, 3)
load 1491  /  3424
size:  (375, 1242, 3)
load 1492  /  3424
size:  (375, 1242, 3)
load 1493  /  3424
size:  (375, 1242, 3)
load 1494  /  3424
size:  (375, 1242, 3)
load 1495  /  3424
size:  (375, 1242, 3)
load 1496  /  3424
size:  (375, 1242, 3)
load 1497  /  3424
size:  (375, 1242, 3)
load 1498  /  3424
size:  (375, 1242, 3)
load 1499  /  3424
size:  (375, 1242, 3)
load 1500  /  3424
size:  (375, 1242, 3)
load 1501  /  3424
size:  (375, 1242, 3)
load 1502  /  3424
size:  (375, 1242, 3)
load 1503  /  3424
size:  (375, 1242, 3)
load 1504  /  3424
size:  (370, 1224, 3)
load 1505  /  3424
size:  (375, 1242, 3)
load 1506  /  3424
size:  (375, 1242, 3)
load 1507  /  3424
size:  (375, 1242, 3)
load 1508  /  3424
size:  (376, 1241, 3)
load 1509  /  3424
size:  (375, 1242, 3)
load 1510  /  3424
size:  (375, 1242, 3)
load 1511  /  3424
size:  (375, 1242, 3)
load 1512  /  3424
size:  (375, 1242, 3)
load 1513  /  3424
size:  (375, 1242, 3)
load 1514  /  3424
size:  (375, 1242, 3)
load 1515  /  3424
size:  (375, 1242, 3)
load 1516  /  3424
size:  (375, 1242, 3)
load 1517  /  3424
size:  (375, 1242, 3)
load 1518  /  3424
size:  (375, 1242, 3)
load 1519  /  3424
size:  (375, 1242, 3)
load 1520  /  3424
size:  (375, 1242, 3)
load 1521  /  3424
size:  (375, 1242, 3)
load 1522  /  3424
size:  (375, 1242, 3)
load 1523  /  3424
size:  (370, 1224, 3)
load 1524  /  3424
size:  (375, 1242, 3)
load 1525  /  3424
size:  (375, 1242, 3)
load 1526  /  3424
size:  (375, 1242, 3)
load 1527  /  3424
size:  (375, 1242, 3)
load 1528  /  3424
size:  (375, 1242, 3)
load 1529  /  3424
size:  (375, 1242, 3)
load 1530  /  3424
size:  (375, 1242, 3)
load 1531  /  3424
size:  (376, 1241, 3)
load 1532  /  3424
size:  (375, 1242, 3)
load 1533  /  3424
size:  (375, 1242, 3)
load 1534  /  3424
size:  (375, 1242, 3)
load 1535  /  3424
size:  (375, 1242, 3)
load 1536  /  3424
size:  (375, 1242, 3)
load 1537  /  3424
size:  (370, 1224, 3)
load 1538  /  3424
size:  (375, 1242, 3)
load 1539  /  3424
size:  (375, 1242, 3)
load 1540  /  3424
size:  (375, 1242, 3)
load 1541  /  3424
size:  (375, 1242, 3)
load 1542  /  3424
size:  (375, 1242, 3)
load 1543  /  3424
size:  (375, 1242, 3)
load 1544  /  3424
size:  (375, 1242, 3)
load 1545  /  3424
size:  (375, 1242, 3)
load 1546  /  3424
size:  (375, 1242, 3)
load 1547  /  3424
size:  (375, 1242, 3)
load 1548  /  3424
size:  (375, 1242, 3)
load 1549  /  3424
size:  (375, 1242, 3)
load 1550  /  3424
size:  (370, 1224, 3)
load 1551  /  3424
size:  (375, 1242, 3)
load 1552  /  3424
size:  (375, 1242, 3)
load 1553  /  3424
size:  (375, 1242, 3)
load 1554  /  3424
size:  (375, 1242, 3)
load 1555  /  3424
size:  (375, 1242, 3)
load 1556  /  3424
size:  (375, 1242, 3)
load 1557  /  3424
size:  (375, 1242, 3)
load 1558  /  3424
size:  (375, 1242, 3)
load 1559  /  3424
size:  (375, 1242, 3)
load 1560  /  3424
size:  (375, 1242, 3)
load 1561  /  3424
size:  (375, 1242, 3)
load 1562  /  3424
size:  (375, 1242, 3)
load 1563  /  3424
size:  (374, 1238, 3)
load 1564  /  3424
size:  (375, 1242, 3)
load 1565  /  3424
size:  (374, 1238, 3)
load 1566  /  3424
size:  (375, 1242, 3)
load 1567  /  3424
size:  (375, 1242, 3)
load 1568  /  3424
size:  (375, 1242, 3)
load 1569  /  3424
size:  (376, 1241, 3)
load 1570  /  3424
size:  (375, 1242, 3)
load 1571  /  3424
size:  (375, 1242, 3)
load 1572  /  3424
size:  (375, 1242, 3)
load 1573  /  3424
size:  (375, 1242, 3)
load 1574  /  3424
size:  (375, 1242, 3)
load 1575  /  3424
size:  (374, 1238, 3)
load 1576  /  3424
size:  (376, 1241, 3)
load 1577  /  3424
size:  (370, 1224, 3)
load 1578  /  3424
size:  (375, 1242, 3)
load 1579  /  3424
size:  (375, 1242, 3)
load 1580  /  3424
size:  (375, 1242, 3)
load 1581  /  3424
size:  (375, 1242, 3)
load 1582  /  3424
size:  (375, 1242, 3)
load 1583  /  3424
size:  (375, 1242, 3)
load 1584  /  3424
size:  (375, 1242, 3)
load 1585  /  3424
size:  (374, 1238, 3)
load 1586  /  3424
size:  (375, 1242, 3)
load 1587  /  3424
size:  (375, 1242, 3)
load 1588  /  3424
size:  (375, 1242, 3)
load 1589  /  3424
size:  (375, 1242, 3)
load 1590  /  3424
size:  (375, 1242, 3)
load 1591  /  3424
size:  (375, 1242, 3)
load 1592  /  3424
size:  (370, 1224, 3)
load 1593  /  3424
size:  (376, 1241, 3)
load 1594  /  3424
size:  (375, 1242, 3)
load 1595  /  3424
size:  (375, 1242, 3)
load 1596  /  3424
size:  (375, 1242, 3)
load 1597  /  3424
size:  (375, 1242, 3)
load 1598  /  3424
size:  (375, 1242, 3)
load 1599  /  3424
size:  (374, 1238, 3)
load 1600  /  3424
size:  (375, 1242, 3)
load 1601  /  3424
size:  (375, 1242, 3)
load 1602  /  3424
size:  (374, 1238, 3)
load 1603  /  3424
size:  (374, 1238, 3)
load 1604  /  3424
size:  (375, 1242, 3)
load 1605  /  3424
size:  (375, 1242, 3)
load 1606  /  3424
size:  (375, 1242, 3)
load 1607  /  3424
size:  (375, 1242, 3)
load 1608  /  3424
size:  (375, 1242, 3)
load 1609  /  3424
size:  (375, 1242, 3)
load 1610  /  3424
size:  (376, 1241, 3)
load 1611  /  3424
size:  (376, 1241, 3)
load 1612  /  3424
size:  (375, 1242, 3)
load 1613  /  3424
size:  (375, 1242, 3)
load 1614  /  3424
size:  (375, 1242, 3)
load 1615  /  3424
size:  (375, 1242, 3)
load 1616  /  3424
size:  (375, 1242, 3)
load 1617  /  3424
size:  (375, 1242, 3)
load 1618  /  3424
size:  (375, 1242, 3)
load 1619  /  3424
size:  (375, 1242, 3)
load 1620  /  3424
size:  (375, 1242, 3)
load 1621  /  3424
size:  (375, 1242, 3)
load 1622  /  3424
size:  (375, 1242, 3)
load 1623  /  3424
size:  (375, 1242, 3)
load 1624  /  3424
size:  (375, 1242, 3)
load 1625  /  3424
size:  (375, 1242, 3)
load 1626  /  3424
size:  (376, 1241, 3)
load 1627  /  3424
size:  (375, 1242, 3)
load 1628  /  3424
size:  (375, 1242, 3)
load 1629  /  3424
size:  (375, 1242, 3)
load 1630  /  3424
size:  (375, 1242, 3)
load 1631  /  3424
size:  (376, 1241, 3)
load 1632  /  3424
size:  (375, 1242, 3)
load 1633  /  3424
size:  (375, 1242, 3)
load 1634  /  3424
size:  (375, 1242, 3)
load 1635  /  3424
size:  (375, 1242, 3)
load 1636  /  3424
size:  (375, 1242, 3)
load 1637  /  3424
size:  (375, 1242, 3)
load 1638  /  3424
size:  (375, 1242, 3)
load 1639  /  3424
size:  (375, 1242, 3)
load 1640  /  3424
size:  (375, 1242, 3)
load 1641  /  3424
size:  (375, 1242, 3)
load 1642  /  3424
size:  (375, 1242, 3)
load 1643  /  3424
size:  (375, 1242, 3)
load 1644  /  3424
size:  (375, 1242, 3)
load 1645  /  3424
size:  (375, 1242, 3)
load 1646  /  3424
size:  (375, 1242, 3)
load 1647  /  3424
size:  (376, 1241, 3)
load 1648  /  3424
size:  (375, 1242, 3)
load 1649  /  3424
size:  (375, 1242, 3)
load 1650  /  3424
size:  (370, 1224, 3)
load 1651  /  3424
size:  (370, 1224, 3)
load 1652  /  3424
size:  (374, 1238, 3)
load 1653  /  3424
size:  (375, 1242, 3)
load 1654  /  3424
size:  (375, 1242, 3)
load 1655  /  3424
size:  (375, 1242, 3)
load 1656  /  3424
size:  (375, 1242, 3)
load 1657  /  3424
size:  (375, 1242, 3)
load 1658  /  3424
size:  (375, 1242, 3)
load 1659  /  3424
size:  (374, 1238, 3)
load 1660  /  3424
size:  (375, 1242, 3)
load 1661  /  3424
size:  (375, 1242, 3)
load 1662  /  3424
size:  (375, 1242, 3)
load 1663  /  3424
size:  (375, 1242, 3)
load 1664  /  3424
size:  (375, 1242, 3)
load 1665  /  3424
size:  (375, 1242, 3)
load 1666  /  3424
size:  (375, 1242, 3)
load 1667  /  3424
size:  (375, 1242, 3)
load 1668  /  3424
size:  (375, 1242, 3)
load 1669  /  3424
size:  (375, 1242, 3)
load 1670  /  3424
size:  (375, 1242, 3)
load 1671  /  3424
size:  (375, 1242, 3)
load 1672  /  3424
size:  (375, 1242, 3)
load 1673  /  3424
size:  (374, 1238, 3)
load 1674  /  3424
size:  (375, 1242, 3)
load 1675  /  3424
size:  (375, 1242, 3)
load 1676  /  3424
size:  (374, 1238, 3)
load 1677  /  3424
size:  (376, 1241, 3)
load 1678  /  3424
size:  (375, 1242, 3)
load 1679  /  3424
size:  (375, 1242, 3)
load 1680  /  3424
size:  (374, 1238, 3)
load 1681  /  3424
size:  (375, 1242, 3)
load 1682  /  3424
size:  (375, 1242, 3)
load 1683  /  3424
size:  (375, 1242, 3)
load 1684  /  3424
size:  (375, 1242, 3)
load 1685  /  3424
size:  (375, 1242, 3)
load 1686  /  3424
size:  (374, 1238, 3)
load 1687  /  3424
size:  (375, 1242, 3)
load 1688  /  3424
size:  (375, 1242, 3)
load 1689  /  3424
size:  (374, 1238, 3)
load 1690  /  3424
size:  (375, 1242, 3)
load 1691  /  3424
size:  (375, 1242, 3)
load 1692  /  3424
size:  (375, 1242, 3)
load 1693  /  3424
size:  (375, 1242, 3)
load 1694  /  3424
size:  (375, 1242, 3)
load 1695  /  3424
size:  (375, 1242, 3)
load 1696  /  3424
size:  (376, 1241, 3)
load 1697  /  3424
size:  (375, 1242, 3)
load 1698  /  3424
size:  (375, 1242, 3)
load 1699  /  3424
size:  (370, 1224, 3)
load 1700  /  3424
size:  (375, 1242, 3)
load 1701  /  3424
size:  (375, 1242, 3)
load 1702  /  3424
size:  (375, 1242, 3)
load 1703  /  3424
size:  (375, 1242, 3)
load 1704  /  3424
size:  (376, 1241, 3)
load 1705  /  3424
size:  (374, 1238, 3)
load 1706  /  3424
size:  (376, 1241, 3)
load 1707  /  3424
size:  (375, 1242, 3)
load 1708  /  3424
size:  (375, 1242, 3)
load 1709  /  3424
size:  (375, 1242, 3)
load 1710  /  3424
size:  (376, 1241, 3)
load 1711  /  3424
size:  (375, 1242, 3)
load 1712  /  3424
size:  (375, 1242, 3)
load 1713  /  3424
size:  (375, 1242, 3)
load 1714  /  3424
size:  (374, 1238, 3)
load 1715  /  3424
size:  (375, 1242, 3)
load 1716  /  3424
size:  (375, 1242, 3)
load 1717  /  3424
size:  (375, 1242, 3)
load 1718  /  3424
size:  (375, 1242, 3)
load 1719  /  3424
size:  (375, 1242, 3)
load 1720  /  3424
size:  (375, 1242, 3)
load 1721  /  3424
size:  (375, 1242, 3)
load 1722  /  3424
size:  (375, 1242, 3)
load 1723  /  3424
size:  (375, 1242, 3)
load 1724  /  3424
size:  (375, 1242, 3)
load 1725  /  3424
size:  (370, 1224, 3)
load 1726  /  3424
size:  (374, 1238, 3)
load 1727  /  3424
size:  (375, 1242, 3)
load 1728  /  3424
size:  (375, 1242, 3)
load 1729  /  3424
size:  (375, 1242, 3)
load 1730  /  3424
size:  (375, 1242, 3)
load 1731  /  3424
size:  (375, 1242, 3)
load 1732  /  3424
size:  (376, 1241, 3)
load 1733  /  3424
size:  (375, 1242, 3)
load 1734  /  3424
size:  (375, 1242, 3)
load 1735  /  3424
size:  (375, 1242, 3)
load 1736  /  3424
size:  (375, 1242, 3)
load 1737  /  3424
size:  (374, 1238, 3)
load 1738  /  3424
size:  (374, 1238, 3)
load 1739  /  3424
size:  (374, 1238, 3)
load 1740  /  3424
size:  (375, 1242, 3)
load 1741  /  3424
size:  (375, 1242, 3)
load 1742  /  3424
size:  (375, 1242, 3)
load 1743  /  3424
size:  (375, 1242, 3)
load 1744  /  3424
size:  (375, 1242, 3)
load 1745  /  3424
size:  (375, 1242, 3)
load 1746  /  3424
size:  (375, 1242, 3)
load 1747  /  3424
size:  (375, 1242, 3)
load 1748  /  3424
size:  (375, 1242, 3)
load 1749  /  3424
size:  (375, 1242, 3)
load 1750  /  3424
size:  (375, 1242, 3)
load 1751  /  3424
size:  (375, 1242, 3)
load 1752  /  3424
size:  (375, 1242, 3)
load 1753  /  3424
size:  (375, 1242, 3)
load 1754  /  3424
size:  (375, 1242, 3)
load 1755  /  3424
size:  (375, 1242, 3)
load 1756  /  3424
size:  (374, 1238, 3)
load 1757  /  3424
size:  (375, 1242, 3)
load 1758  /  3424
size:  (374, 1238, 3)
load 1759  /  3424
size:  (375, 1242, 3)
load 1760  /  3424
size:  (375, 1242, 3)
load 1761  /  3424
size:  (375, 1242, 3)
load 1762  /  3424
size:  (375, 1242, 3)
load 1763  /  3424
size:  (375, 1242, 3)
load 1764  /  3424
size:  (375, 1242, 3)
load 1765  /  3424
size:  (375, 1242, 3)
load 1766  /  3424
size:  (375, 1242, 3)
load 1767  /  3424
size:  (375, 1242, 3)
load 1768  /  3424
size:  (375, 1242, 3)
load 1769  /  3424
size:  (375, 1242, 3)
load 1770  /  3424
size:  (375, 1242, 3)
load 1771  /  3424
size:  (375, 1242, 3)
load 1772  /  3424
size:  (375, 1242, 3)
load 1773  /  3424
size:  (375, 1242, 3)
load 1774  /  3424
size:  (375, 1242, 3)
load 1775  /  3424
size:  (375, 1242, 3)
load 1776  /  3424
size:  (375, 1242, 3)
load 1777  /  3424
size:  (375, 1242, 3)
load 1778  /  3424
size:  (375, 1242, 3)
load 1779  /  3424
size:  (375, 1242, 3)
load 1780  /  3424
size:  (375, 1242, 3)
load 1781  /  3424
size:  (375, 1242, 3)
load 1782  /  3424
size:  (375, 1242, 3)
load 1783  /  3424
size:  (375, 1242, 3)
load 1784  /  3424
size:  (375, 1242, 3)
load 1785  /  3424
size:  (376, 1241, 3)
load 1786  /  3424
size:  (375, 1242, 3)
load 1787  /  3424
size:  (375, 1242, 3)
load 1788  /  3424
size:  (375, 1242, 3)
load 1789  /  3424
size:  (375, 1242, 3)
load 1790  /  3424
size:  (375, 1242, 3)
load 1791  /  3424
size:  (375, 1242, 3)
load 1792  /  3424
size:  (375, 1242, 3)
load 1793  /  3424
size:  (375, 1242, 3)
load 1794  /  3424
size:  (376, 1241, 3)
load 1795  /  3424
size:  (375, 1242, 3)
load 1796  /  3424
size:  (376, 1241, 3)
load 1797  /  3424
size:  (375, 1242, 3)
load 1798  /  3424
size:  (374, 1238, 3)
load 1799  /  3424
size:  (375, 1242, 3)
load 1800  /  3424
size:  (375, 1242, 3)
load 1801  /  3424
size:  (375, 1242, 3)
load 1802  /  3424
size:  (375, 1242, 3)
load 1803  /  3424
size:  (375, 1242, 3)
load 1804  /  3424
size:  (375, 1242, 3)
load 1805  /  3424
size:  (375, 1242, 3)
load 1806  /  3424
size:  (375, 1242, 3)
load 1807  /  3424
size:  (375, 1242, 3)
load 1808  /  3424
size:  (375, 1242, 3)
load 1809  /  3424
size:  (375, 1242, 3)
load 1810  /  3424
size:  (375, 1242, 3)
load 1811  /  3424
size:  (376, 1241, 3)
load 1812  /  3424
size:  (375, 1242, 3)
load 1813  /  3424
size:  (375, 1242, 3)
load 1814  /  3424
size:  (370, 1224, 3)
load 1815  /  3424
size:  (375, 1242, 3)
load 1816  /  3424
size:  (375, 1242, 3)
load 1817  /  3424
size:  (370, 1224, 3)
load 1818  /  3424
size:  (375, 1242, 3)
load 1819  /  3424
size:  (375, 1242, 3)
load 1820  /  3424
size:  (375, 1242, 3)
load 1821  /  3424
size:  (376, 1241, 3)
load 1822  /  3424
size:  (375, 1242, 3)
load 1823  /  3424
size:  (370, 1224, 3)
load 1824  /  3424
size:  (375, 1242, 3)
load 1825  /  3424
size:  (375, 1242, 3)
load 1826  /  3424
size:  (375, 1242, 3)
load 1827  /  3424
size:  (375, 1242, 3)
load 1828  /  3424
size:  (375, 1242, 3)
load 1829  /  3424
size:  (375, 1242, 3)
load 1830  /  3424
size:  (375, 1242, 3)
load 1831  /  3424
size:  (376, 1241, 3)
load 1832  /  3424
size:  (375, 1242, 3)
load 1833  /  3424
size:  (375, 1242, 3)
load 1834  /  3424
size:  (375, 1242, 3)
load 1835  /  3424
size:  (376, 1241, 3)
load 1836  /  3424
size:  (375, 1242, 3)
load 1837  /  3424
size:  (370, 1224, 3)
load 1838  /  3424
size:  (375, 1242, 3)
load 1839  /  3424
size:  (375, 1242, 3)
load 1840  /  3424
size:  (375, 1242, 3)
load 1841  /  3424
size:  (375, 1242, 3)
load 1842  /  3424
size:  (375, 1242, 3)
load 1843  /  3424
size:  (375, 1242, 3)
load 1844  /  3424
size:  (375, 1242, 3)
load 1845  /  3424
size:  (375, 1242, 3)
load 1846  /  3424
size:  (375, 1242, 3)
load 1847  /  3424
size:  (375, 1242, 3)
load 1848  /  3424
size:  (375, 1242, 3)
load 1849  /  3424
size:  (375, 1242, 3)
load 1850  /  3424
size:  (375, 1242, 3)
load 1851  /  3424
size:  (375, 1242, 3)
load 1852  /  3424
size:  (375, 1242, 3)
load 1853  /  3424
size:  (375, 1242, 3)
load 1854  /  3424
size:  (375, 1242, 3)
load 1855  /  3424
size:  (376, 1241, 3)
load 1856  /  3424
size:  (375, 1242, 3)
load 1857  /  3424
size:  (375, 1242, 3)
load 1858  /  3424
size:  (375, 1242, 3)
load 1859  /  3424
size:  (376, 1241, 3)
load 1860  /  3424
size:  (375, 1242, 3)
load 1861  /  3424
size:  (375, 1242, 3)
load 1862  /  3424
size:  (375, 1242, 3)
load 1863  /  3424
size:  (375, 1242, 3)
load 1864  /  3424
size:  (375, 1242, 3)
load 1865  /  3424
size:  (375, 1242, 3)
load 1866  /  3424
size:  (375, 1242, 3)
load 1867  /  3424
size:  (375, 1242, 3)
load 1868  /  3424
size:  (375, 1242, 3)
load 1869  /  3424
size:  (375, 1242, 3)
load 1870  /  3424
size:  (375, 1242, 3)
load 1871  /  3424
size:  (375, 1242, 3)
load 1872  /  3424
size:  (375, 1242, 3)
load 1873  /  3424
size:  (375, 1242, 3)
load 1874  /  3424
size:  (375, 1242, 3)
load 1875  /  3424
size:  (375, 1242, 3)
load 1876  /  3424
size:  (375, 1242, 3)
load 1877  /  3424
size:  (375, 1242, 3)
load 1878  /  3424
size:  (370, 1224, 3)
load 1879  /  3424
size:  (375, 1242, 3)
load 1880  /  3424
size:  (375, 1242, 3)
load 1881  /  3424
size:  (375, 1242, 3)
load 1882  /  3424
size:  (376, 1241, 3)
load 1883  /  3424
size:  (375, 1242, 3)
load 1884  /  3424
size:  (376, 1241, 3)
load 1885  /  3424
size:  (375, 1242, 3)
load 1886  /  3424
size:  (375, 1242, 3)
load 1887  /  3424
size:  (375, 1242, 3)
load 1888  /  3424
size:  (375, 1242, 3)
load 1889  /  3424
size:  (375, 1242, 3)
load 1890  /  3424
size:  (376, 1241, 3)
load 1891  /  3424
size:  (375, 1242, 3)
load 1892  /  3424
size:  (375, 1242, 3)
load 1893  /  3424
size:  (376, 1241, 3)
load 1894  /  3424
size:  (375, 1242, 3)
load 1895  /  3424
size:  (375, 1242, 3)
load 1896  /  3424
size:  (375, 1242, 3)
load 1897  /  3424
size:  (375, 1242, 3)
load 1898  /  3424
size:  (374, 1238, 3)
load 1899  /  3424
size:  (375, 1242, 3)
load 1900  /  3424
size:  (375, 1242, 3)
load 1901  /  3424
size:  (375, 1242, 3)
load 1902  /  3424
size:  (375, 1242, 3)
load 1903  /  3424
size:  (375, 1242, 3)
load 1904  /  3424
size:  (375, 1242, 3)
load 1905  /  3424
size:  (375, 1242, 3)
load 1906  /  3424
size:  (376, 1241, 3)
load 1907  /  3424
size:  (375, 1242, 3)
load 1908  /  3424
size:  (376, 1241, 3)
load 1909  /  3424
size:  (375, 1242, 3)
load 1910  /  3424
size:  (370, 1224, 3)
load 1911  /  3424
size:  (375, 1242, 3)
load 1912  /  3424
size:  (376, 1241, 3)
load 1913  /  3424
size:  (375, 1242, 3)
load 1914  /  3424
size:  (375, 1242, 3)
load 1915  /  3424
size:  (375, 1242, 3)
load 1916  /  3424
size:  (375, 1242, 3)
load 1917  /  3424
size:  (375, 1242, 3)
load 1918  /  3424
size:  (376, 1241, 3)
load 1919  /  3424
size:  (374, 1238, 3)
load 1920  /  3424
size:  (376, 1241, 3)
load 1921  /  3424
size:  (376, 1241, 3)
load 1922  /  3424
size:  (375, 1242, 3)
load 1923  /  3424
size:  (375, 1242, 3)
load 1924  /  3424
size:  (375, 1242, 3)
load 1925  /  3424
size:  (375, 1242, 3)
load 1926  /  3424
size:  (375, 1242, 3)
load 1927  /  3424
size:  (375, 1242, 3)
load 1928  /  3424
size:  (376, 1241, 3)
load 1929  /  3424
size:  (375, 1242, 3)
load 1930  /  3424
size:  (375, 1242, 3)
load 1931  /  3424
size:  (370, 1224, 3)
load 1932  /  3424
size:  (375, 1242, 3)
load 1933  /  3424
size:  (375, 1242, 3)
load 1934  /  3424
size:  (376, 1241, 3)
load 1935  /  3424
size:  (374, 1238, 3)
load 1936  /  3424
size:  (375, 1242, 3)
load 1937  /  3424
size:  (375, 1242, 3)
load 1938  /  3424
size:  (375, 1242, 3)
load 1939  /  3424
size:  (375, 1242, 3)
load 1940  /  3424
size:  (375, 1242, 3)
load 1941  /  3424
size:  (375, 1242, 3)
load 1942  /  3424
size:  (375, 1242, 3)
load 1943  /  3424
size:  (375, 1242, 3)
load 1944  /  3424
size:  (375, 1242, 3)
load 1945  /  3424
size:  (375, 1242, 3)
load 1946  /  3424
size:  (376, 1241, 3)
load 1947  /  3424
size:  (375, 1242, 3)
load 1948  /  3424
size:  (374, 1238, 3)
load 1949  /  3424
size:  (375, 1242, 3)
load 1950  /  3424
size:  (375, 1242, 3)
load 1951  /  3424
size:  (374, 1238, 3)
load 1952  /  3424
size:  (375, 1242, 3)
load 1953  /  3424
size:  (370, 1224, 3)
load 1954  /  3424
size:  (375, 1242, 3)
load 1955  /  3424
size:  (375, 1242, 3)
load 1956  /  3424
size:  (375, 1242, 3)
load 1957  /  3424
size:  (370, 1224, 3)
load 1958  /  3424
size:  (375, 1242, 3)
load 1959  /  3424
size:  (376, 1241, 3)
load 1960  /  3424
size:  (375, 1242, 3)
load 1961  /  3424
size:  (375, 1242, 3)
load 1962  /  3424
size:  (374, 1238, 3)
load 1963  /  3424
size:  (375, 1242, 3)
load 1964  /  3424
size:  (375, 1242, 3)
load 1965  /  3424
size:  (375, 1242, 3)
load 1966  /  3424
size:  (375, 1242, 3)
load 1967  /  3424
size:  (370, 1224, 3)
load 1968  /  3424
size:  (375, 1242, 3)
load 1969  /  3424
size:  (375, 1242, 3)
load 1970  /  3424
size:  (370, 1224, 3)
load 1971  /  3424
size:  (375, 1242, 3)
load 1972  /  3424
size:  (375, 1242, 3)
load 1973  /  3424
size:  (375, 1242, 3)
load 1974  /  3424
size:  (375, 1242, 3)
load 1975  /  3424
size:  (375, 1242, 3)
load 1976  /  3424
size:  (375, 1242, 3)
load 1977  /  3424
size:  (375, 1242, 3)
load 1978  /  3424
size:  (370, 1224, 3)
load 1979  /  3424
size:  (374, 1238, 3)
load 1980  /  3424
size:  (375, 1242, 3)
load 1981  /  3424
size:  (375, 1242, 3)
load 1982  /  3424
size:  (375, 1242, 3)
load 1983  /  3424
size:  (375, 1242, 3)
load 1984  /  3424
size:  (375, 1242, 3)
load 1985  /  3424
size:  (375, 1242, 3)
load 1986  /  3424
size:  (375, 1242, 3)
load 1987  /  3424
size:  (375, 1242, 3)
load 1988  /  3424
size:  (375, 1242, 3)
load 1989  /  3424
size:  (375, 1242, 3)
load 1990  /  3424
size:  (370, 1224, 3)
load 1991  /  3424
size:  (375, 1242, 3)
load 1992  /  3424
size:  (375, 1242, 3)
load 1993  /  3424
size:  (370, 1224, 3)
load 1994  /  3424
size:  (375, 1242, 3)
load 1995  /  3424
size:  (375, 1242, 3)
load 1996  /  3424
size:  (375, 1242, 3)
load 1997  /  3424
size:  (375, 1242, 3)
load 1998  /  3424
size:  (375, 1242, 3)
load 1999  /  3424
size:  (370, 1224, 3)
load 2000  /  3424
size:  (374, 1238, 3)
load 2001  /  3424
size:  (375, 1242, 3)
load 2002  /  3424
size:  (374, 1238, 3)
load 2003  /  3424
size:  (375, 1242, 3)
load 2004  /  3424
size:  (375, 1242, 3)
load 2005  /  3424
size:  (375, 1242, 3)
load 2006  /  3424
size:  (375, 1242, 3)
load 2007  /  3424
size:  (375, 1242, 3)
load 2008  /  3424
size:  (375, 1242, 3)
load 2009  /  3424
size:  (375, 1242, 3)
load 2010  /  3424
size:  (375, 1242, 3)
load 2011  /  3424
size:  (375, 1242, 3)
load 2012  /  3424
size:  (375, 1242, 3)
load 2013  /  3424
size:  (374, 1238, 3)
load 2014  /  3424
size:  (375, 1242, 3)
load 2015  /  3424
size:  (376, 1241, 3)
load 2016  /  3424
size:  (375, 1242, 3)
load 2017  /  3424
size:  (375, 1242, 3)
load 2018  /  3424
size:  (376, 1241, 3)
load 2019  /  3424
size:  (375, 1242, 3)
load 2020  /  3424
size:  (375, 1242, 3)
load 2021  /  3424
size:  (375, 1242, 3)
load 2022  /  3424
size:  (375, 1242, 3)
load 2023  /  3424
size:  (375, 1242, 3)
load 2024  /  3424
size:  (375, 1242, 3)
load 2025  /  3424
size:  (374, 1238, 3)
load 2026  /  3424
size:  (376, 1241, 3)
load 2027  /  3424
size:  (375, 1242, 3)
load 2028  /  3424
size:  (376, 1241, 3)
load 2029  /  3424
size:  (375, 1242, 3)
load 2030  /  3424
size:  (375, 1242, 3)
load 2031  /  3424
size:  (375, 1242, 3)
load 2032  /  3424
size:  (375, 1242, 3)
load 2033  /  3424
size:  (375, 1242, 3)
load 2034  /  3424
size:  (375, 1242, 3)
load 2035  /  3424
size:  (375, 1242, 3)
load 2036  /  3424
size:  (374, 1238, 3)
load 2037  /  3424
size:  (375, 1242, 3)
load 2038  /  3424
size:  (375, 1242, 3)
load 2039  /  3424
size:  (375, 1242, 3)
load 2040  /  3424
size:  (376, 1241, 3)
load 2041  /  3424
size:  (375, 1242, 3)
load 2042  /  3424
size:  (375, 1242, 3)
load 2043  /  3424
size:  (376, 1241, 3)
load 2044  /  3424
size:  (376, 1241, 3)
load 2045  /  3424
size:  (375, 1242, 3)
load 2046  /  3424
size:  (375, 1242, 3)
load 2047  /  3424
size:  (375, 1242, 3)
load 2048  /  3424
size:  (375, 1242, 3)
load 2049  /  3424
size:  (375, 1242, 3)
load 2050  /  3424
size:  (375, 1242, 3)
load 2051  /  3424
size:  (375, 1242, 3)
load 2052  /  3424
size:  (375, 1242, 3)
load 2053  /  3424
size:  (375, 1242, 3)
load 2054  /  3424
size:  (375, 1242, 3)
load 2055  /  3424
size:  (375, 1242, 3)
load 2056  /  3424
size:  (375, 1242, 3)
load 2057  /  3424
size:  (375, 1242, 3)
load 2058  /  3424
size:  (375, 1242, 3)
load 2059  /  3424
size:  (375, 1242, 3)
load 2060  /  3424
size:  (375, 1242, 3)
load 2061  /  3424
size:  (375, 1242, 3)
load 2062  /  3424
size:  (375, 1242, 3)
load 2063  /  3424
size:  (370, 1224, 3)
load 2064  /  3424
size:  (375, 1242, 3)
load 2065  /  3424
size:  (370, 1224, 3)
load 2066  /  3424
size:  (375, 1242, 3)
load 2067  /  3424
size:  (375, 1242, 3)
load 2068  /  3424
size:  (375, 1242, 3)
load 2069  /  3424
size:  (375, 1242, 3)
load 2070  /  3424
size:  (375, 1242, 3)
load 2071  /  3424
size:  (375, 1242, 3)
load 2072  /  3424
size:  (375, 1242, 3)
load 2073  /  3424
size:  (375, 1242, 3)
load 2074  /  3424
size:  (375, 1242, 3)
load 2075  /  3424
size:  (375, 1242, 3)
load 2076  /  3424
size:  (375, 1242, 3)
load 2077  /  3424
size:  (375, 1242, 3)
load 2078  /  3424
size:  (375, 1242, 3)
load 2079  /  3424
size:  (375, 1242, 3)
load 2080  /  3424
size:  (375, 1242, 3)
load 2081  /  3424
size:  (375, 1242, 3)
load 2082  /  3424
size:  (375, 1242, 3)
load 2083  /  3424
size:  (375, 1242, 3)
load 2084  /  3424
size:  (375, 1242, 3)
load 2085  /  3424
size:  (375, 1242, 3)
load 2086  /  3424
size:  (375, 1242, 3)
load 2087  /  3424
size:  (375, 1242, 3)
load 2088  /  3424
size:  (375, 1242, 3)
load 2089  /  3424
size:  (375, 1242, 3)
load 2090  /  3424
size:  (375, 1242, 3)
load 2091  /  3424
size:  (375, 1242, 3)
load 2092  /  3424
size:  (375, 1242, 3)
load 2093  /  3424
size:  (375, 1242, 3)
load 2094  /  3424
size:  (375, 1242, 3)
load 2095  /  3424
size:  (375, 1242, 3)
load 2096  /  3424
size:  (375, 1242, 3)
load 2097  /  3424
size:  (375, 1242, 3)
load 2098  /  3424
size:  (375, 1242, 3)
load 2099  /  3424
size:  (375, 1242, 3)
load 2100  /  3424
size:  (376, 1241, 3)
load 2101  /  3424
size:  (375, 1242, 3)
load 2102  /  3424
size:  (375, 1242, 3)
load 2103  /  3424
size:  (375, 1242, 3)
load 2104  /  3424
size:  (375, 1242, 3)
load 2105  /  3424
size:  (375, 1242, 3)
load 2106  /  3424
size:  (374, 1238, 3)
load 2107  /  3424
size:  (375, 1242, 3)
load 2108  /  3424
size:  (375, 1242, 3)
load 2109  /  3424
size:  (374, 1238, 3)
load 2110  /  3424
size:  (375, 1242, 3)
load 2111  /  3424
size:  (375, 1242, 3)
load 2112  /  3424
size:  (375, 1242, 3)
load 2113  /  3424
size:  (375, 1242, 3)
load 2114  /  3424
size:  (375, 1242, 3)
load 2115  /  3424
size:  (375, 1242, 3)
load 2116  /  3424
size:  (375, 1242, 3)
load 2117  /  3424
size:  (376, 1241, 3)
load 2118  /  3424
size:  (375, 1242, 3)
load 2119  /  3424
size:  (375, 1242, 3)
load 2120  /  3424
size:  (376, 1241, 3)
load 2121  /  3424
size:  (375, 1242, 3)
load 2122  /  3424
size:  (375, 1242, 3)
load 2123  /  3424
size:  (375, 1242, 3)
load 2124  /  3424
size:  (375, 1242, 3)
load 2125  /  3424
size:  (370, 1224, 3)
load 2126  /  3424
size:  (375, 1242, 3)
load 2127  /  3424
size:  (376, 1241, 3)
load 2128  /  3424
size:  (375, 1242, 3)
load 2129  /  3424
size:  (375, 1242, 3)
load 2130  /  3424
size:  (375, 1242, 3)
load 2131  /  3424
size:  (375, 1242, 3)
load 2132  /  3424
size:  (375, 1242, 3)
load 2133  /  3424
size:  (375, 1242, 3)
load 2134  /  3424
size:  (375, 1242, 3)
load 2135  /  3424
size:  (375, 1242, 3)
load 2136  /  3424
size:  (375, 1242, 3)
load 2137  /  3424
size:  (375, 1242, 3)
load 2138  /  3424
size:  (375, 1242, 3)
load 2139  /  3424
size:  (375, 1242, 3)
load 2140  /  3424
size:  (375, 1242, 3)
load 2141  /  3424
size:  (376, 1241, 3)
load 2142  /  3424
size:  (375, 1242, 3)
load 2143  /  3424
size:  (375, 1242, 3)
load 2144  /  3424
size:  (375, 1242, 3)
load 2145  /  3424
size:  (370, 1224, 3)
load 2146  /  3424
size:  (375, 1242, 3)
load 2147  /  3424
size:  (375, 1242, 3)
load 2148  /  3424
size:  (375, 1242, 3)
load 2149  /  3424
size:  (375, 1242, 3)
load 2150  /  3424
size:  (375, 1242, 3)
load 2151  /  3424
size:  (375, 1242, 3)
load 2152  /  3424
size:  (375, 1242, 3)
load 2153  /  3424
size:  (375, 1242, 3)
load 2154  /  3424
size:  (375, 1242, 3)
load 2155  /  3424
size:  (375, 1242, 3)
load 2156  /  3424
size:  (374, 1238, 3)
load 2157  /  3424
size:  (376, 1241, 3)
load 2158  /  3424
size:  (376, 1241, 3)
load 2159  /  3424
size:  (375, 1242, 3)
load 2160  /  3424
size:  (374, 1238, 3)
load 2161  /  3424
size:  (375, 1242, 3)
load 2162  /  3424
size:  (375, 1242, 3)
load 2163  /  3424
size:  (375, 1242, 3)
load 2164  /  3424
size:  (375, 1242, 3)
load 2165  /  3424
size:  (376, 1241, 3)
load 2166  /  3424
size:  (375, 1242, 3)
load 2167  /  3424
size:  (375, 1242, 3)
load 2168  /  3424
size:  (375, 1242, 3)
load 2169  /  3424
size:  (375, 1242, 3)
load 2170  /  3424
size:  (375, 1242, 3)
load 2171  /  3424
size:  (376, 1241, 3)
load 2172  /  3424
size:  (375, 1242, 3)
load 2173  /  3424
size:  (375, 1242, 3)
load 2174  /  3424
size:  (374, 1238, 3)
load 2175  /  3424
size:  (375, 1242, 3)
load 2176  /  3424
size:  (375, 1242, 3)
load 2177  /  3424
size:  (375, 1242, 3)
load 2178  /  3424
size:  (370, 1224, 3)
load 2179  /  3424
size:  (375, 1242, 3)
load 2180  /  3424
size:  (375, 1242, 3)
load 2181  /  3424
size:  (375, 1242, 3)
load 2182  /  3424
size:  (375, 1242, 3)
load 2183  /  3424
size:  (375, 1242, 3)
load 2184  /  3424
size:  (370, 1224, 3)
load 2185  /  3424
size:  (375, 1242, 3)
load 2186  /  3424
size:  (375, 1242, 3)
load 2187  /  3424
size:  (375, 1242, 3)
load 2188  /  3424
size:  (375, 1242, 3)
load 2189  /  3424
size:  (375, 1242, 3)
load 2190  /  3424
size:  (375, 1242, 3)
load 2191  /  3424
size:  (375, 1242, 3)
load 2192  /  3424
size:  (374, 1238, 3)
load 2193  /  3424
size:  (375, 1242, 3)
load 2194  /  3424
size:  (375, 1242, 3)
load 2195  /  3424
size:  (375, 1242, 3)
load 2196  /  3424
size:  (375, 1242, 3)
load 2197  /  3424
size:  (375, 1242, 3)
load 2198  /  3424
size:  (375, 1242, 3)
load 2199  /  3424
size:  (376, 1241, 3)
load 2200  /  3424
size:  (375, 1242, 3)
load 2201  /  3424
size:  (375, 1242, 3)
load 2202  /  3424
size:  (376, 1241, 3)
load 2203  /  3424
size:  (375, 1242, 3)
load 2204  /  3424
size:  (375, 1242, 3)
load 2205  /  3424
size:  (375, 1242, 3)
load 2206  /  3424
size:  (375, 1242, 3)
load 2207  /  3424
size:  (375, 1242, 3)
load 2208  /  3424
size:  (375, 1242, 3)
load 2209  /  3424
size:  (375, 1242, 3)
load 2210  /  3424
size:  (375, 1242, 3)
load 2211  /  3424
size:  (375, 1242, 3)
load 2212  /  3424
size:  (375, 1242, 3)
load 2213  /  3424
size:  (375, 1242, 3)
load 2214  /  3424
size:  (375, 1242, 3)
load 2215  /  3424
size:  (375, 1242, 3)
load 2216  /  3424
size:  (375, 1242, 3)
load 2217  /  3424
size:  (375, 1242, 3)
load 2218  /  3424
size:  (375, 1242, 3)
load 2219  /  3424
size:  (375, 1242, 3)
load 2220  /  3424
size:  (375, 1242, 3)
load 2221  /  3424
size:  (375, 1242, 3)
load 2222  /  3424
size:  (375, 1242, 3)
load 2223  /  3424
size:  (376, 1241, 3)
load 2224  /  3424
size:  (375, 1242, 3)
load 2225  /  3424
size:  (375, 1242, 3)
load 2226  /  3424
size:  (375, 1242, 3)
load 2227  /  3424
size:  (375, 1242, 3)
load 2228  /  3424
size:  (375, 1242, 3)
load 2229  /  3424
size:  (375, 1242, 3)
load 2230  /  3424
size:  (375, 1242, 3)
load 2231  /  3424
size:  (375, 1242, 3)
load 2232  /  3424
size:  (375, 1242, 3)
load 2233  /  3424
size:  (375, 1242, 3)
load 2234  /  3424
size:  (375, 1242, 3)
load 2235  /  3424
size:  (375, 1242, 3)
load 2236  /  3424
size:  (375, 1242, 3)
load 2237  /  3424
size:  (375, 1242, 3)
load 2238  /  3424
size:  (375, 1242, 3)
load 2239  /  3424
size:  (375, 1242, 3)
load 2240  /  3424
size:  (375, 1242, 3)
load 2241  /  3424
size:  (375, 1242, 3)
load 2242  /  3424
size:  (375, 1242, 3)
load 2243  /  3424
size:  (375, 1242, 3)
load 2244  /  3424
size:  (376, 1241, 3)
load 2245  /  3424
size:  (375, 1242, 3)
load 2246  /  3424
size:  (375, 1242, 3)
load 2247  /  3424
size:  (375, 1242, 3)
load 2248  /  3424
size:  (375, 1242, 3)
load 2249  /  3424
size:  (375, 1242, 3)
load 2250  /  3424
size:  (375, 1242, 3)
load 2251  /  3424
size:  (375, 1242, 3)
load 2252  /  3424
size:  (370, 1224, 3)
load 2253  /  3424
size:  (375, 1242, 3)
load 2254  /  3424
size:  (375, 1242, 3)
load 2255  /  3424
size:  (375, 1242, 3)
load 2256  /  3424
size:  (375, 1242, 3)
load 2257  /  3424
size:  (374, 1238, 3)
load 2258  /  3424
size:  (375, 1242, 3)
load 2259  /  3424
size:  (374, 1238, 3)
load 2260  /  3424
size:  (375, 1242, 3)
load 2261  /  3424
size:  (370, 1224, 3)
load 2262  /  3424
size:  (375, 1242, 3)
load 2263  /  3424
size:  (374, 1238, 3)
load 2264  /  3424
size:  (375, 1242, 3)
load 2265  /  3424
size:  (375, 1242, 3)
load 2266  /  3424
size:  (375, 1242, 3)
load 2267  /  3424
size:  (376, 1241, 3)
load 2268  /  3424
size:  (374, 1238, 3)
load 2269  /  3424
size:  (375, 1242, 3)
load 2270  /  3424
size:  (375, 1242, 3)
load 2271  /  3424
size:  (375, 1242, 3)
load 2272  /  3424
size:  (376, 1241, 3)
load 2273  /  3424
size:  (375, 1242, 3)
load 2274  /  3424
size:  (375, 1242, 3)
load 2275  /  3424
size:  (375, 1242, 3)
load 2276  /  3424
size:  (375, 1242, 3)
load 2277  /  3424
size:  (375, 1242, 3)
load 2278  /  3424
size:  (375, 1242, 3)
load 2279  /  3424
size:  (376, 1241, 3)
load 2280  /  3424
size:  (375, 1242, 3)
load 2281  /  3424
size:  (375, 1242, 3)
load 2282  /  3424
size:  (375, 1242, 3)
load 2283  /  3424
size:  (375, 1242, 3)
load 2284  /  3424
size:  (376, 1241, 3)
load 2285  /  3424
size:  (375, 1242, 3)
load 2286  /  3424
size:  (375, 1242, 3)
load 2287  /  3424
size:  (375, 1242, 3)
load 2288  /  3424
size:  (375, 1242, 3)
load 2289  /  3424
size:  (375, 1242, 3)
load 2290  /  3424
size:  (375, 1242, 3)
load 2291  /  3424
size:  (375, 1242, 3)
load 2292  /  3424
size:  (370, 1224, 3)
load 2293  /  3424
size:  (375, 1242, 3)
load 2294  /  3424
size:  (375, 1242, 3)
load 2295  /  3424
size:  (375, 1242, 3)
load 2296  /  3424
size:  (375, 1242, 3)
load 2297  /  3424
size:  (375, 1242, 3)
load 2298  /  3424
size:  (375, 1242, 3)
load 2299  /  3424
size:  (376, 1241, 3)
load 2300  /  3424
size:  (375, 1242, 3)
load 2301  /  3424
size:  (375, 1242, 3)
load 2302  /  3424
size:  (375, 1242, 3)
load 2303  /  3424
size:  (375, 1242, 3)
load 2304  /  3424
size:  (376, 1241, 3)
load 2305  /  3424
size:  (375, 1242, 3)
load 2306  /  3424
size:  (375, 1242, 3)
load 2307  /  3424
size:  (370, 1224, 3)
load 2308  /  3424
size:  (374, 1238, 3)
load 2309  /  3424
size:  (376, 1241, 3)
load 2310  /  3424
size:  (375, 1242, 3)
load 2311  /  3424
size:  (370, 1224, 3)
load 2312  /  3424
size:  (375, 1242, 3)
load 2313  /  3424
size:  (376, 1241, 3)
load 2314  /  3424
size:  (375, 1242, 3)
load 2315  /  3424
size:  (370, 1224, 3)
load 2316  /  3424
size:  (375, 1242, 3)
load 2317  /  3424
size:  (370, 1224, 3)
load 2318  /  3424
size:  (375, 1242, 3)
load 2319  /  3424
size:  (375, 1242, 3)
load 2320  /  3424
size:  (375, 1242, 3)
load 2321  /  3424
size:  (374, 1238, 3)
load 2322  /  3424
size:  (374, 1238, 3)
load 2323  /  3424
size:  (375, 1242, 3)
load 2324  /  3424
size:  (375, 1242, 3)
load 2325  /  3424
size:  (376, 1241, 3)
load 2326  /  3424
size:  (375, 1242, 3)
load 2327  /  3424
size:  (375, 1242, 3)
load 2328  /  3424
size:  (375, 1242, 3)
load 2329  /  3424
size:  (375, 1242, 3)
load 2330  /  3424
size:  (376, 1241, 3)
load 2331  /  3424
size:  (375, 1242, 3)
load 2332  /  3424
size:  (370, 1224, 3)
load 2333  /  3424
size:  (370, 1224, 3)
load 2334  /  3424
size:  (375, 1242, 3)
load 2335  /  3424
size:  (375, 1242, 3)
load 2336  /  3424
size:  (375, 1242, 3)
load 2337  /  3424
size:  (375, 1242, 3)
load 2338  /  3424
size:  (375, 1242, 3)
load 2339  /  3424
size:  (375, 1242, 3)
load 2340  /  3424
size:  (375, 1242, 3)
load 2341  /  3424
size:  (375, 1242, 3)
load 2342  /  3424
size:  (375, 1242, 3)
load 2343  /  3424
size:  (375, 1242, 3)
load 2344  /  3424
size:  (376, 1241, 3)
load 2345  /  3424
size:  (375, 1242, 3)
load 2346  /  3424
size:  (375, 1242, 3)
load 2347  /  3424
size:  (375, 1242, 3)
load 2348  /  3424
size:  (375, 1242, 3)
load 2349  /  3424
size:  (375, 1242, 3)
load 2350  /  3424
size:  (375, 1242, 3)
load 2351  /  3424
size:  (375, 1242, 3)
load 2352  /  3424
size:  (375, 1242, 3)
load 2353  /  3424
size:  (375, 1242, 3)
load 2354  /  3424
size:  (375, 1242, 3)
load 2355  /  3424
size:  (375, 1242, 3)
load 2356  /  3424
size:  (375, 1242, 3)
load 2357  /  3424
size:  (375, 1242, 3)
load 2358  /  3424
size:  (375, 1242, 3)
load 2359  /  3424
size:  (375, 1242, 3)
load 2360  /  3424
size:  (376, 1241, 3)
load 2361  /  3424
size:  (375, 1242, 3)
load 2362  /  3424
size:  (375, 1242, 3)
load 2363  /  3424
size:  (370, 1224, 3)
load 2364  /  3424
size:  (374, 1238, 3)
load 2365  /  3424
size:  (375, 1242, 3)
load 2366  /  3424
size:  (375, 1242, 3)
load 2367  /  3424
size:  (374, 1238, 3)
load 2368  /  3424
size:  (375, 1242, 3)
load 2369  /  3424
size:  (375, 1242, 3)
load 2370  /  3424
size:  (375, 1242, 3)
load 2371  /  3424
size:  (375, 1242, 3)
load 2372  /  3424
size:  (375, 1242, 3)
load 2373  /  3424
size:  (375, 1242, 3)
load 2374  /  3424
size:  (375, 1242, 3)
load 2375  /  3424
size:  (375, 1242, 3)
load 2376  /  3424
size:  (375, 1242, 3)
load 2377  /  3424
size:  (375, 1242, 3)
load 2378  /  3424
size:  (376, 1241, 3)
load 2379  /  3424
size:  (375, 1242, 3)
load 2380  /  3424
size:  (375, 1242, 3)
load 2381  /  3424
size:  (375, 1242, 3)
load 2382  /  3424
size:  (375, 1242, 3)
load 2383  /  3424
size:  (375, 1242, 3)
load 2384  /  3424
size:  (375, 1242, 3)
load 2385  /  3424
size:  (375, 1242, 3)
load 2386  /  3424
size:  (376, 1241, 3)
load 2387  /  3424
size:  (375, 1242, 3)
load 2388  /  3424
size:  (375, 1242, 3)
load 2389  /  3424
size:  (375, 1242, 3)
load 2390  /  3424
size:  (375, 1242, 3)
load 2391  /  3424
size:  (375, 1242, 3)
load 2392  /  3424
size:  (376, 1241, 3)
load 2393  /  3424
size:  (375, 1242, 3)
load 2394  /  3424
size:  (375, 1242, 3)
load 2395  /  3424
size:  (375, 1242, 3)
load 2396  /  3424
size:  (375, 1242, 3)
load 2397  /  3424
size:  (370, 1224, 3)
load 2398  /  3424
size:  (375, 1242, 3)
load 2399  /  3424
size:  (375, 1242, 3)
load 2400  /  3424
size:  (375, 1242, 3)
load 2401  /  3424
size:  (375, 1242, 3)
load 2402  /  3424
size:  (375, 1242, 3)
load 2403  /  3424
size:  (375, 1242, 3)
load 2404  /  3424
size:  (375, 1242, 3)
load 2405  /  3424
size:  (375, 1242, 3)
load 2406  /  3424
size:  (376, 1241, 3)
load 2407  /  3424
size:  (375, 1242, 3)
load 2408  /  3424
size:  (375, 1242, 3)
load 2409  /  3424
size:  (375, 1242, 3)
load 2410  /  3424
size:  (375, 1242, 3)
load 2411  /  3424
size:  (370, 1224, 3)
load 2412  /  3424
size:  (375, 1242, 3)
load 2413  /  3424
size:  (375, 1242, 3)
load 2414  /  3424
size:  (375, 1242, 3)
load 2415  /  3424
size:  (375, 1242, 3)
load 2416  /  3424
size:  (375, 1242, 3)
load 2417  /  3424
size:  (375, 1242, 3)
load 2418  /  3424
size:  (375, 1242, 3)
load 2419  /  3424
size:  (375, 1242, 3)
load 2420  /  3424
size:  (375, 1242, 3)
load 2421  /  3424
size:  (375, 1242, 3)
load 2422  /  3424
size:  (375, 1242, 3)
load 2423  /  3424
size:  (375, 1242, 3)
load 2424  /  3424
size:  (375, 1242, 3)
load 2425  /  3424
size:  (375, 1242, 3)
load 2426  /  3424
size:  (375, 1242, 3)
load 2427  /  3424
size:  (375, 1242, 3)
load 2428  /  3424
size:  (375, 1242, 3)
load 2429  /  3424
size:  (375, 1242, 3)
load 2430  /  3424
size:  (375, 1242, 3)
load 2431  /  3424
size:  (375, 1242, 3)
load 2432  /  3424
size:  (375, 1242, 3)
load 2433  /  3424
size:  (375, 1242, 3)
load 2434  /  3424
size:  (375, 1242, 3)
load 2435  /  3424
size:  (376, 1241, 3)
load 2436  /  3424
size:  (375, 1242, 3)
load 2437  /  3424
size:  (376, 1241, 3)
load 2438  /  3424
size:  (375, 1242, 3)
load 2439  /  3424
size:  (375, 1242, 3)
load 2440  /  3424
size:  (375, 1242, 3)
load 2441  /  3424
size:  (375, 1242, 3)
load 2442  /  3424
size:  (375, 1242, 3)
load 2443  /  3424
size:  (375, 1242, 3)
load 2444  /  3424
size:  (375, 1242, 3)
load 2445  /  3424
size:  (375, 1242, 3)
load 2446  /  3424
size:  (374, 1238, 3)
load 2447  /  3424
size:  (375, 1242, 3)
load 2448  /  3424
size:  (375, 1242, 3)
load 2449  /  3424
size:  (375, 1242, 3)
load 2450  /  3424
size:  (375, 1242, 3)
load 2451  /  3424
size:  (375, 1242, 3)
load 2452  /  3424
size:  (375, 1242, 3)
load 2453  /  3424
size:  (375, 1242, 3)
load 2454  /  3424
size:  (375, 1242, 3)
load 2455  /  3424
size:  (375, 1242, 3)
load 2456  /  3424
size:  (375, 1242, 3)
load 2457  /  3424
size:  (375, 1242, 3)
load 2458  /  3424
size:  (376, 1241, 3)
load 2459  /  3424
size:  (375, 1242, 3)
load 2460  /  3424
size:  (374, 1238, 3)
load 2461  /  3424
size:  (375, 1242, 3)
load 2462  /  3424
size:  (375, 1242, 3)
load 2463  /  3424
size:  (375, 1242, 3)
load 2464  /  3424
size:  (375, 1242, 3)
load 2465  /  3424
size:  (375, 1242, 3)
load 2466  /  3424
size:  (375, 1242, 3)
load 2467  /  3424
size:  (375, 1242, 3)
load 2468  /  3424
size:  (375, 1242, 3)
load 2469  /  3424
size:  (375, 1242, 3)
load 2470  /  3424
size:  (375, 1242, 3)
load 2471  /  3424
size:  (375, 1242, 3)
load 2472  /  3424
size:  (370, 1224, 3)
load 2473  /  3424
size:  (375, 1242, 3)
load 2474  /  3424
size:  (375, 1242, 3)
load 2475  /  3424
size:  (375, 1242, 3)
load 2476  /  3424
size:  (375, 1242, 3)
load 2477  /  3424
size:  (375, 1242, 3)
load 2478  /  3424
size:  (375, 1242, 3)
load 2479  /  3424
size:  (375, 1242, 3)
load 2480  /  3424
size:  (375, 1242, 3)
load 2481  /  3424
size:  (376, 1241, 3)
load 2482  /  3424
size:  (375, 1242, 3)
load 2483  /  3424
size:  (375, 1242, 3)
load 2484  /  3424
size:  (375, 1242, 3)
load 2485  /  3424
size:  (376, 1241, 3)
load 2486  /  3424
size:  (375, 1242, 3)
load 2487  /  3424
size:  (375, 1242, 3)
load 2488  /  3424
size:  (375, 1242, 3)
load 2489  /  3424
size:  (375, 1242, 3)
load 2490  /  3424
size:  (375, 1242, 3)
load 2491  /  3424
size:  (375, 1242, 3)
load 2492  /  3424
size:  (375, 1242, 3)
load 2493  /  3424
size:  (375, 1242, 3)
load 2494  /  3424
size:  (374, 1238, 3)
load 2495  /  3424
size:  (375, 1242, 3)
load 2496  /  3424
size:  (375, 1242, 3)
load 2497  /  3424
size:  (375, 1242, 3)
load 2498  /  3424
size:  (375, 1242, 3)
load 2499  /  3424
size:  (374, 1238, 3)
load 2500  /  3424
size:  (375, 1242, 3)
load 2501  /  3424
size:  (374, 1238, 3)
load 2502  /  3424
size:  (375, 1242, 3)
load 2503  /  3424
size:  (375, 1242, 3)
load 2504  /  3424
size:  (375, 1242, 3)
load 2505  /  3424
size:  (375, 1242, 3)
load 2506  /  3424
size:  (375, 1242, 3)
load 2507  /  3424
size:  (375, 1242, 3)
load 2508  /  3424
size:  (370, 1224, 3)
load 2509  /  3424
size:  (375, 1242, 3)
load 2510  /  3424
size:  (375, 1242, 3)
load 2511  /  3424
size:  (375, 1242, 3)
load 2512  /  3424
size:  (375, 1242, 3)
load 2513  /  3424
size:  (375, 1242, 3)
load 2514  /  3424
size:  (370, 1224, 3)
load 2515  /  3424
size:  (376, 1241, 3)
load 2516  /  3424
size:  (375, 1242, 3)
load 2517  /  3424
size:  (374, 1238, 3)
load 2518  /  3424
size:  (370, 1224, 3)
load 2519  /  3424
size:  (375, 1242, 3)
load 2520  /  3424
size:  (375, 1242, 3)
load 2521  /  3424
size:  (375, 1242, 3)
load 2522  /  3424
size:  (375, 1242, 3)
load 2523  /  3424
size:  (375, 1242, 3)
load 2524  /  3424
size:  (375, 1242, 3)
load 2525  /  3424
size:  (375, 1242, 3)
load 2526  /  3424
size:  (375, 1242, 3)
load 2527  /  3424
size:  (376, 1241, 3)
load 2528  /  3424
size:  (375, 1242, 3)
load 2529  /  3424
size:  (374, 1238, 3)
load 2530  /  3424
size:  (375, 1242, 3)
load 2531  /  3424
size:  (375, 1242, 3)
load 2532  /  3424
size:  (375, 1242, 3)
load 2533  /  3424
size:  (375, 1242, 3)
load 2534  /  3424
size:  (375, 1242, 3)
load 2535  /  3424
size:  (376, 1241, 3)
load 2536  /  3424
size:  (376, 1241, 3)
load 2537  /  3424
size:  (375, 1242, 3)
load 2538  /  3424
size:  (375, 1242, 3)
load 2539  /  3424
size:  (375, 1242, 3)
load 2540  /  3424
size:  (375, 1242, 3)
load 2541  /  3424
size:  (375, 1242, 3)
load 2542  /  3424
size:  (375, 1242, 3)
load 2543  /  3424
size:  (376, 1241, 3)
load 2544  /  3424
size:  (375, 1242, 3)
load 2545  /  3424
size:  (375, 1242, 3)
load 2546  /  3424
size:  (375, 1242, 3)
load 2547  /  3424
size:  (375, 1242, 3)
load 2548  /  3424
size:  (375, 1242, 3)
load 2549  /  3424
size:  (375, 1242, 3)
load 2550  /  3424
size:  (375, 1242, 3)
load 2551  /  3424
size:  (375, 1242, 3)
load 2552  /  3424
size:  (375, 1242, 3)
load 2553  /  3424
size:  (375, 1242, 3)
load 2554  /  3424
size:  (375, 1242, 3)
load 2555  /  3424
size:  (374, 1238, 3)
load 2556  /  3424
size:  (375, 1242, 3)
load 2557  /  3424
size:  (375, 1242, 3)
load 2558  /  3424
size:  (375, 1242, 3)
load 2559  /  3424
size:  (375, 1242, 3)
load 2560  /  3424
size:  (375, 1242, 3)
load 2561  /  3424
size:  (375, 1242, 3)
load 2562  /  3424
size:  (374, 1238, 3)
load 2563  /  3424
size:  (375, 1242, 3)
load 2564  /  3424
size:  (375, 1242, 3)
load 2565  /  3424
size:  (375, 1242, 3)
load 2566  /  3424
size:  (375, 1242, 3)
load 2567  /  3424
size:  (375, 1242, 3)
load 2568  /  3424
size:  (375, 1242, 3)
load 2569  /  3424
size:  (370, 1224, 3)
load 2570  /  3424
size:  (375, 1242, 3)
load 2571  /  3424
size:  (376, 1241, 3)
load 2572  /  3424
size:  (375, 1242, 3)
load 2573  /  3424
size:  (375, 1242, 3)
load 2574  /  3424
size:  (375, 1242, 3)
load 2575  /  3424
size:  (375, 1242, 3)
load 2576  /  3424
size:  (375, 1242, 3)
load 2577  /  3424
size:  (375, 1242, 3)
load 2578  /  3424
size:  (375, 1242, 3)
load 2579  /  3424
size:  (376, 1241, 3)
load 2580  /  3424
size:  (375, 1242, 3)
load 2581  /  3424
size:  (375, 1242, 3)
load 2582  /  3424
size:  (375, 1242, 3)
load 2583  /  3424
size:  (375, 1242, 3)
load 2584  /  3424
size:  (375, 1242, 3)
load 2585  /  3424
size:  (375, 1242, 3)
load 2586  /  3424
size:  (375, 1242, 3)
load 2587  /  3424
size:  (375, 1242, 3)
load 2588  /  3424
size:  (375, 1242, 3)
load 2589  /  3424
size:  (375, 1242, 3)
load 2590  /  3424
size:  (375, 1242, 3)
load 2591  /  3424
size:  (375, 1242, 3)
load 2592  /  3424
size:  (375, 1242, 3)
load 2593  /  3424
size:  (376, 1241, 3)
load 2594  /  3424
size:  (376, 1241, 3)
load 2595  /  3424
size:  (375, 1242, 3)
load 2596  /  3424
size:  (375, 1242, 3)
load 2597  /  3424
size:  (375, 1242, 3)
load 2598  /  3424
size:  (375, 1242, 3)
load 2599  /  3424
size:  (376, 1241, 3)
load 2600  /  3424
size:  (375, 1242, 3)
load 2601  /  3424
size:  (375, 1242, 3)
load 2602  /  3424
size:  (376, 1241, 3)
load 2603  /  3424
size:  (375, 1242, 3)
load 2604  /  3424
size:  (375, 1242, 3)
load 2605  /  3424
size:  (375, 1242, 3)
load 2606  /  3424
size:  (375, 1242, 3)
load 2607  /  3424
size:  (375, 1242, 3)
load 2608  /  3424
size:  (374, 1238, 3)
load 2609  /  3424
size:  (375, 1242, 3)
load 2610  /  3424
size:  (375, 1242, 3)
load 2611  /  3424
size:  (375, 1242, 3)
load 2612  /  3424
size:  (376, 1241, 3)
load 2613  /  3424
size:  (375, 1242, 3)
load 2614  /  3424
size:  (375, 1242, 3)
load 2615  /  3424
size:  (375, 1242, 3)
load 2616  /  3424
size:  (375, 1242, 3)
load 2617  /  3424
size:  (375, 1242, 3)
load 2618  /  3424
size:  (375, 1242, 3)
load 2619  /  3424
size:  (375, 1242, 3)
load 2620  /  3424
size:  (375, 1242, 3)
load 2621  /  3424
size:  (375, 1242, 3)
load 2622  /  3424
size:  (376, 1241, 3)
load 2623  /  3424
size:  (375, 1242, 3)
load 2624  /  3424
size:  (375, 1242, 3)
load 2625  /  3424
size:  (370, 1224, 3)
load 2626  /  3424
size:  (374, 1238, 3)
load 2627  /  3424
size:  (375, 1242, 3)
load 2628  /  3424
size:  (375, 1242, 3)
load 2629  /  3424
size:  (375, 1242, 3)
load 2630  /  3424
size:  (375, 1242, 3)
load 2631  /  3424
size:  (375, 1242, 3)
load 2632  /  3424
size:  (375, 1242, 3)
load 2633  /  3424
size:  (375, 1242, 3)
load 2634  /  3424
size:  (370, 1224, 3)
load 2635  /  3424
size:  (375, 1242, 3)
load 2636  /  3424
size:  (375, 1242, 3)
load 2637  /  3424
size:  (370, 1224, 3)
load 2638  /  3424
size:  (375, 1242, 3)
load 2639  /  3424
size:  (375, 1242, 3)
load 2640  /  3424
size:  (375, 1242, 3)
load 2641  /  3424
size:  (375, 1242, 3)
load 2642  /  3424
size:  (376, 1241, 3)
load 2643  /  3424
size:  (375, 1242, 3)
load 2644  /  3424
size:  (375, 1242, 3)
load 2645  /  3424
size:  (375, 1242, 3)
load 2646  /  3424
size:  (375, 1242, 3)
load 2647  /  3424
size:  (375, 1242, 3)
load 2648  /  3424
size:  (375, 1242, 3)
load 2649  /  3424
size:  (375, 1242, 3)
load 2650  /  3424
size:  (376, 1241, 3)
load 2651  /  3424
size:  (376, 1241, 3)
load 2652  /  3424
size:  (370, 1224, 3)
load 2653  /  3424
size:  (375, 1242, 3)
load 2654  /  3424
size:  (375, 1242, 3)
load 2655  /  3424
size:  (375, 1242, 3)
load 2656  /  3424
size:  (375, 1242, 3)
load 2657  /  3424
size:  (376, 1241, 3)
load 2658  /  3424
size:  (375, 1242, 3)
load 2659  /  3424
size:  (375, 1242, 3)
load 2660  /  3424
size:  (375, 1242, 3)
load 2661  /  3424
size:  (375, 1242, 3)
load 2662  /  3424
size:  (375, 1242, 3)
load 2663  /  3424
size:  (375, 1242, 3)
load 2664  /  3424
size:  (375, 1242, 3)
load 2665  /  3424
size:  (375, 1242, 3)
load 2666  /  3424
size:  (375, 1242, 3)
load 2667  /  3424
size:  (375, 1242, 3)
load 2668  /  3424
size:  (375, 1242, 3)
load 2669  /  3424
size:  (375, 1242, 3)
load 2670  /  3424
size:  (375, 1242, 3)
load 2671  /  3424
size:  (375, 1242, 3)
load 2672  /  3424
size:  (375, 1242, 3)
load 2673  /  3424
size:  (376, 1241, 3)
load 2674  /  3424
size:  (375, 1242, 3)
load 2675  /  3424
size:  (375, 1242, 3)
load 2676  /  3424
size:  (375, 1242, 3)
load 2677  /  3424
size:  (375, 1242, 3)
load 2678  /  3424
size:  (375, 1242, 3)
load 2679  /  3424
size:  (375, 1242, 3)
load 2680  /  3424
size:  (375, 1242, 3)
load 2681  /  3424
size:  (375, 1242, 3)
load 2682  /  3424
size:  (375, 1242, 3)
load 2683  /  3424
size:  (376, 1241, 3)
load 2684  /  3424
size:  (375, 1242, 3)
load 2685  /  3424
size:  (375, 1242, 3)
load 2686  /  3424
size:  (375, 1242, 3)
load 2687  /  3424
size:  (375, 1242, 3)
load 2688  /  3424
size:  (375, 1242, 3)
load 2689  /  3424
size:  (375, 1242, 3)
load 2690  /  3424
size:  (375, 1242, 3)
load 2691  /  3424
size:  (375, 1242, 3)
load 2692  /  3424
size:  (375, 1242, 3)
load 2693  /  3424
size:  (375, 1242, 3)
load 2694  /  3424
size:  (375, 1242, 3)
load 2695  /  3424
size:  (375, 1242, 3)
load 2696  /  3424
size:  (376, 1241, 3)
load 2697  /  3424
size:  (375, 1242, 3)
load 2698  /  3424
size:  (375, 1242, 3)
load 2699  /  3424
size:  (375, 1242, 3)
load 2700  /  3424
size:  (375, 1242, 3)
load 2701  /  3424
size:  (375, 1242, 3)
load 2702  /  3424
size:  (375, 1242, 3)
load 2703  /  3424
size:  (376, 1241, 3)
load 2704  /  3424
size:  (375, 1242, 3)
load 2705  /  3424
size:  (375, 1242, 3)
load 2706  /  3424
size:  (375, 1242, 3)
load 2707  /  3424
size:  (375, 1242, 3)
load 2708  /  3424
size:  (370, 1224, 3)
load 2709  /  3424
size:  (375, 1242, 3)
load 2710  /  3424
size:  (375, 1242, 3)
load 2711  /  3424
size:  (374, 1238, 3)
load 2712  /  3424
size:  (375, 1242, 3)
load 2713  /  3424
size:  (375, 1242, 3)
load 2714  /  3424
size:  (376, 1241, 3)
load 2715  /  3424
size:  (375, 1242, 3)
load 2716  /  3424
size:  (375, 1242, 3)
load 2717  /  3424
size:  (376, 1241, 3)
load 2718  /  3424
size:  (370, 1224, 3)
load 2719  /  3424
size:  (375, 1242, 3)
load 2720  /  3424
size:  (375, 1242, 3)
load 2721  /  3424
size:  (375, 1242, 3)
load 2722  /  3424
size:  (375, 1242, 3)
load 2723  /  3424
size:  (375, 1242, 3)
load 2724  /  3424
size:  (375, 1242, 3)
load 2725  /  3424
size:  (375, 1242, 3)
load 2726  /  3424
size:  (376, 1241, 3)
load 2727  /  3424
size:  (375, 1242, 3)
load 2728  /  3424
size:  (375, 1242, 3)
load 2729  /  3424
size:  (375, 1242, 3)
load 2730  /  3424
size:  (375, 1242, 3)
load 2731  /  3424
size:  (375, 1242, 3)
load 2732  /  3424
size:  (375, 1242, 3)
load 2733  /  3424
size:  (375, 1242, 3)
load 2734  /  3424
size:  (370, 1224, 3)
load 2735  /  3424
size:  (375, 1242, 3)
load 2736  /  3424
size:  (375, 1242, 3)
load 2737  /  3424
size:  (375, 1242, 3)
load 2738  /  3424
size:  (375, 1242, 3)
load 2739  /  3424
size:  (375, 1242, 3)
load 2740  /  3424
size:  (375, 1242, 3)
load 2741  /  3424
size:  (375, 1242, 3)
load 2742  /  3424
size:  (375, 1242, 3)
load 2743  /  3424
size:  (375, 1242, 3)
load 2744  /  3424
size:  (375, 1242, 3)
load 2745  /  3424
size:  (376, 1241, 3)
load 2746  /  3424
size:  (375, 1242, 3)
load 2747  /  3424
size:  (375, 1242, 3)
load 2748  /  3424
size:  (375, 1242, 3)
load 2749  /  3424
size:  (376, 1241, 3)
load 2750  /  3424
size:  (375, 1242, 3)
load 2751  /  3424
size:  (375, 1242, 3)
load 2752  /  3424
size:  (376, 1241, 3)
load 2753  /  3424
size:  (375, 1242, 3)
load 2754  /  3424
size:  (375, 1242, 3)
load 2755  /  3424
size:  (375, 1242, 3)
load 2756  /  3424
size:  (375, 1242, 3)
load 2757  /  3424
size:  (375, 1242, 3)
load 2758  /  3424
size:  (375, 1242, 3)
load 2759  /  3424
size:  (375, 1242, 3)
load 2760  /  3424
size:  (375, 1242, 3)
load 2761  /  3424
size:  (376, 1241, 3)
load 2762  /  3424
size:  (375, 1242, 3)
load 2763  /  3424
size:  (375, 1242, 3)
load 2764  /  3424
size:  (375, 1242, 3)
load 2765  /  3424
size:  (374, 1238, 3)
load 2766  /  3424
size:  (375, 1242, 3)
load 2767  /  3424
size:  (370, 1224, 3)
load 2768  /  3424
size:  (375, 1242, 3)
load 2769  /  3424
size:  (375, 1242, 3)
load 2770  /  3424
size:  (375, 1242, 3)
load 2771  /  3424
size:  (375, 1242, 3)
load 2772  /  3424
size:  (370, 1224, 3)
load 2773  /  3424
size:  (374, 1238, 3)
load 2774  /  3424
size:  (375, 1242, 3)
load 2775  /  3424
size:  (375, 1242, 3)
load 2776  /  3424
size:  (375, 1242, 3)
load 2777  /  3424
size:  (375, 1242, 3)
load 2778  /  3424
size:  (375, 1242, 3)
load 2779  /  3424
size:  (375, 1242, 3)
load 2780  /  3424
size:  (375, 1242, 3)
load 2781  /  3424
size:  (375, 1242, 3)
load 2782  /  3424
size:  (375, 1242, 3)
load 2783  /  3424
size:  (375, 1242, 3)
load 2784  /  3424
size:  (375, 1242, 3)
load 2785  /  3424
size:  (375, 1242, 3)
load 2786  /  3424
size:  (375, 1242, 3)
load 2787  /  3424
size:  (375, 1242, 3)
load 2788  /  3424
size:  (375, 1242, 3)
load 2789  /  3424
size:  (370, 1224, 3)
load 2790  /  3424
size:  (375, 1242, 3)
load 2791  /  3424
size:  (375, 1242, 3)
load 2792  /  3424
size:  (375, 1242, 3)
load 2793  /  3424
size:  (376, 1241, 3)
load 2794  /  3424
size:  (375, 1242, 3)
load 2795  /  3424
size:  (375, 1242, 3)
load 2796  /  3424
size:  (376, 1241, 3)
load 2797  /  3424
size:  (375, 1242, 3)
load 2798  /  3424
size:  (370, 1224, 3)
load 2799  /  3424
size:  (376, 1241, 3)
load 2800  /  3424
size:  (375, 1242, 3)
load 2801  /  3424
size:  (375, 1242, 3)
load 2802  /  3424
size:  (375, 1242, 3)
load 2803  /  3424
size:  (375, 1242, 3)
load 2804  /  3424
size:  (375, 1242, 3)
load 2805  /  3424
size:  (375, 1242, 3)
load 2806  /  3424
size:  (375, 1242, 3)
load 2807  /  3424
size:  (375, 1242, 3)
load 2808  /  3424
size:  (374, 1238, 3)
load 2809  /  3424
size:  (375, 1242, 3)
load 2810  /  3424
size:  (374, 1238, 3)
load 2811  /  3424
size:  (375, 1242, 3)
load 2812  /  3424
size:  (375, 1242, 3)
load 2813  /  3424
size:  (375, 1242, 3)
load 2814  /  3424
size:  (375, 1242, 3)
load 2815  /  3424
size:  (370, 1224, 3)
load 2816  /  3424
size:  (375, 1242, 3)
load 2817  /  3424
size:  (376, 1241, 3)
load 2818  /  3424
size:  (375, 1242, 3)
load 2819  /  3424
size:  (375, 1242, 3)
load 2820  /  3424
size:  (374, 1238, 3)
load 2821  /  3424
size:  (375, 1242, 3)
load 2822  /  3424
size:  (375, 1242, 3)
load 2823  /  3424
size:  (375, 1242, 3)
load 2824  /  3424
size:  (375, 1242, 3)
load 2825  /  3424
size:  (375, 1242, 3)
load 2826  /  3424
size:  (376, 1241, 3)
load 2827  /  3424
size:  (375, 1242, 3)
load 2828  /  3424
size:  (375, 1242, 3)
load 2829  /  3424
size:  (375, 1242, 3)
load 2830  /  3424
size:  (375, 1242, 3)
load 2831  /  3424
size:  (375, 1242, 3)
load 2832  /  3424
size:  (375, 1242, 3)
load 2833  /  3424
size:  (375, 1242, 3)
load 2834  /  3424
size:  (375, 1242, 3)
load 2835  /  3424
size:  (375, 1242, 3)
load 2836  /  3424
size:  (375, 1242, 3)
load 2837  /  3424
size:  (375, 1242, 3)
load 2838  /  3424
size:  (375, 1242, 3)
load 2839  /  3424
size:  (375, 1242, 3)
load 2840  /  3424
size:  (375, 1242, 3)
load 2841  /  3424
size:  (375, 1242, 3)
load 2842  /  3424
size:  (370, 1224, 3)
load 2843  /  3424
size:  (375, 1242, 3)
load 2844  /  3424
size:  (375, 1242, 3)
load 2845  /  3424
size:  (375, 1242, 3)
load 2846  /  3424
size:  (375, 1242, 3)
load 2847  /  3424
size:  (375, 1242, 3)
load 2848  /  3424
size:  (375, 1242, 3)
load 2849  /  3424
size:  (375, 1242, 3)
load 2850  /  3424
size:  (375, 1242, 3)
load 2851  /  3424
size:  (375, 1242, 3)
load 2852  /  3424
size:  (375, 1242, 3)
load 2853  /  3424
size:  (375, 1242, 3)
load 2854  /  3424
size:  (375, 1242, 3)
load 2855  /  3424
size:  (376, 1241, 3)
load 2856  /  3424
size:  (375, 1242, 3)
load 2857  /  3424
size:  (375, 1242, 3)
load 2858  /  3424
size:  (375, 1242, 3)
load 2859  /  3424
size:  (375, 1242, 3)
load 2860  /  3424
size:  (375, 1242, 3)
load 2861  /  3424
size:  (375, 1242, 3)
load 2862  /  3424
size:  (375, 1242, 3)
load 2863  /  3424
size:  (375, 1242, 3)
load 2864  /  3424
size:  (375, 1242, 3)
load 2865  /  3424
size:  (375, 1242, 3)
load 2866  /  3424
size:  (375, 1242, 3)
load 2867  /  3424
size:  (375, 1242, 3)
load 2868  /  3424
size:  (375, 1242, 3)
load 2869  /  3424
size:  (375, 1242, 3)
load 2870  /  3424
size:  (375, 1242, 3)
load 2871  /  3424
size:  (375, 1242, 3)
load 2872  /  3424
size:  (376, 1241, 3)
load 2873  /  3424
size:  (376, 1241, 3)
load 2874  /  3424
size:  (375, 1242, 3)
load 2875  /  3424
size:  (375, 1242, 3)
load 2876  /  3424
size:  (375, 1242, 3)
load 2877  /  3424
size:  (375, 1242, 3)
load 2878  /  3424
size:  (375, 1242, 3)
load 2879  /  3424
size:  (375, 1242, 3)
load 2880  /  3424
size:  (375, 1242, 3)
load 2881  /  3424
size:  (375, 1242, 3)
load 2882  /  3424
size:  (375, 1242, 3)
load 2883  /  3424
size:  (375, 1242, 3)
load 2884  /  3424
size:  (375, 1242, 3)
load 2885  /  3424
size:  (375, 1242, 3)
load 2886  /  3424
size:  (375, 1242, 3)
load 2887  /  3424
size:  (375, 1242, 3)
load 2888  /  3424
size:  (375, 1242, 3)
load 2889  /  3424
size:  (375, 1242, 3)
load 2890  /  3424
size:  (375, 1242, 3)
load 2891  /  3424
size:  (375, 1242, 3)
load 2892  /  3424
size:  (375, 1242, 3)
load 2893  /  3424
size:  (375, 1242, 3)
load 2894  /  3424
size:  (375, 1242, 3)
load 2895  /  3424
size:  (375, 1242, 3)
load 2896  /  3424
size:  (375, 1242, 3)
load 2897  /  3424
size:  (375, 1242, 3)
load 2898  /  3424
size:  (376, 1241, 3)
load 2899  /  3424
size:  (370, 1224, 3)
load 2900  /  3424
size:  (375, 1242, 3)
load 2901  /  3424
size:  (375, 1242, 3)
load 2902  /  3424
size:  (375, 1242, 3)
load 2903  /  3424
size:  (370, 1224, 3)
load 2904  /  3424
size:  (375, 1242, 3)
load 2905  /  3424
size:  (375, 1242, 3)
load 2906  /  3424
size:  (375, 1242, 3)
load 2907  /  3424
size:  (375, 1242, 3)
load 2908  /  3424
size:  (375, 1242, 3)
load 2909  /  3424
size:  (376, 1241, 3)
load 2910  /  3424
size:  (376, 1241, 3)
load 2911  /  3424
size:  (374, 1238, 3)
load 2912  /  3424
size:  (375, 1242, 3)
load 2913  /  3424
size:  (375, 1242, 3)
load 2914  /  3424
size:  (374, 1238, 3)
load 2915  /  3424
size:  (370, 1224, 3)
load 2916  /  3424
size:  (375, 1242, 3)
load 2917  /  3424
size:  (375, 1242, 3)
load 2918  /  3424
size:  (375, 1242, 3)
load 2919  /  3424
size:  (375, 1242, 3)
load 2920  /  3424
size:  (375, 1242, 3)
load 2921  /  3424
size:  (374, 1238, 3)
load 2922  /  3424
size:  (375, 1242, 3)
load 2923  /  3424
size:  (374, 1238, 3)
load 2924  /  3424
size:  (375, 1242, 3)
load 2925  /  3424
size:  (375, 1242, 3)
load 2926  /  3424
size:  (375, 1242, 3)
load 2927  /  3424
size:  (375, 1242, 3)
load 2928  /  3424
size:  (375, 1242, 3)
load 2929  /  3424
size:  (375, 1242, 3)
load 2930  /  3424
size:  (375, 1242, 3)
load 2931  /  3424
size:  (376, 1241, 3)
load 2932  /  3424
size:  (375, 1242, 3)
load 2933  /  3424
size:  (375, 1242, 3)
load 2934  /  3424
size:  (375, 1242, 3)
load 2935  /  3424
size:  (374, 1238, 3)
load 2936  /  3424
size:  (375, 1242, 3)
load 2937  /  3424
size:  (374, 1238, 3)
load 2938  /  3424
size:  (375, 1242, 3)
load 2939  /  3424
size:  (375, 1242, 3)
load 2940  /  3424
size:  (375, 1242, 3)
load 2941  /  3424
size:  (375, 1242, 3)
load 2942  /  3424
size:  (374, 1238, 3)
load 2943  /  3424
size:  (375, 1242, 3)
load 2944  /  3424
size:  (375, 1242, 3)
load 2945  /  3424
size:  (370, 1224, 3)
load 2946  /  3424
size:  (376, 1241, 3)
load 2947  /  3424
size:  (375, 1242, 3)
load 2948  /  3424
size:  (370, 1224, 3)
load 2949  /  3424
size:  (375, 1242, 3)
load 2950  /  3424
size:  (374, 1238, 3)
load 2951  /  3424
size:  (375, 1242, 3)
load 2952  /  3424
size:  (375, 1242, 3)
load 2953  /  3424
size:  (375, 1242, 3)
load 2954  /  3424
size:  (375, 1242, 3)
load 2955  /  3424
size:  (375, 1242, 3)
load 2956  /  3424
size:  (375, 1242, 3)
load 2957  /  3424
size:  (375, 1242, 3)
load 2958  /  3424
size:  (375, 1242, 3)
load 2959  /  3424
size:  (375, 1242, 3)
load 2960  /  3424
size:  (375, 1242, 3)
load 2961  /  3424
size:  (375, 1242, 3)
load 2962  /  3424
size:  (375, 1242, 3)
load 2963  /  3424
size:  (375, 1242, 3)
load 2964  /  3424
size:  (375, 1242, 3)
load 2965  /  3424
size:  (375, 1242, 3)
load 2966  /  3424
size:  (375, 1242, 3)
load 2967  /  3424
size:  (375, 1242, 3)
load 2968  /  3424
size:  (375, 1242, 3)
load 2969  /  3424
size:  (375, 1242, 3)
load 2970  /  3424
size:  (375, 1242, 3)
load 2971  /  3424
size:  (375, 1242, 3)
load 2972  /  3424
size:  (375, 1242, 3)
load 2973  /  3424
size:  (375, 1242, 3)
load 2974  /  3424
size:  (375, 1242, 3)
load 2975  /  3424
size:  (375, 1242, 3)
load 2976  /  3424
size:  (375, 1242, 3)
load 2977  /  3424
size:  (375, 1242, 3)
load 2978  /  3424
size:  (375, 1242, 3)
load 2979  /  3424
size:  (375, 1242, 3)
load 2980  /  3424
size:  (375, 1242, 3)
load 2981  /  3424
size:  (375, 1242, 3)
load 2982  /  3424
size:  (375, 1242, 3)
load 2983  /  3424
size:  (375, 1242, 3)
load 2984  /  3424
size:  (375, 1242, 3)
load 2985  /  3424
size:  (375, 1242, 3)
load 2986  /  3424
size:  (375, 1242, 3)
load 2987  /  3424
size:  (375, 1242, 3)
load 2988  /  3424
size:  (375, 1242, 3)
load 2989  /  3424
size:  (375, 1242, 3)
load 2990  /  3424
size:  (375, 1242, 3)
load 2991  /  3424
size:  (375, 1242, 3)
load 2992  /  3424
size:  (375, 1242, 3)
load 2993  /  3424
size:  (375, 1242, 3)
load 2994  /  3424
size:  (375, 1242, 3)
load 2995  /  3424
size:  (375, 1242, 3)
load 2996  /  3424
size:  (375, 1242, 3)
load 2997  /  3424
size:  (375, 1242, 3)
load 2998  /  3424
size:  (375, 1242, 3)
load 2999  /  3424
size:  (375, 1242, 3)
load 3000  /  3424
size:  (375, 1242, 3)
load 3001  /  3424
size:  (375, 1242, 3)
load 3002  /  3424
size:  (375, 1242, 3)
load 3003  /  3424
size:  (375, 1242, 3)
load 3004  /  3424
size:  (375, 1242, 3)
load 3005  /  3424
size:  (375, 1242, 3)
load 3006  /  3424
size:  (375, 1242, 3)
load 3007  /  3424
size:  (376, 1241, 3)
load 3008  /  3424
size:  (375, 1242, 3)
load 3009  /  3424
size:  (375, 1242, 3)
load 3010  /  3424
size:  (375, 1242, 3)
load 3011  /  3424
size:  (375, 1242, 3)
load 3012  /  3424
size:  (375, 1242, 3)
load 3013  /  3424
size:  (375, 1242, 3)
load 3014  /  3424
size:  (375, 1242, 3)
load 3015  /  3424
size:  (375, 1242, 3)
load 3016  /  3424
size:  (376, 1241, 3)
load 3017  /  3424
size:  (375, 1242, 3)
load 3018  /  3424
size:  (375, 1242, 3)
load 3019  /  3424
size:  (375, 1242, 3)
load 3020  /  3424
size:  (375, 1242, 3)
load 3021  /  3424
size:  (375, 1242, 3)
load 3022  /  3424
size:  (375, 1242, 3)
load 3023  /  3424
size:  (375, 1242, 3)
load 3024  /  3424
size:  (376, 1241, 3)
load 3025  /  3424
size:  (375, 1242, 3)
load 3026  /  3424
size:  (375, 1242, 3)
load 3027  /  3424
size:  (374, 1238, 3)
load 3028  /  3424
size:  (375, 1242, 3)
load 3029  /  3424
size:  (375, 1242, 3)
load 3030  /  3424
size:  (376, 1241, 3)
load 3031  /  3424
size:  (375, 1242, 3)
load 3032  /  3424
size:  (375, 1242, 3)
load 3033  /  3424
size:  (375, 1242, 3)
load 3034  /  3424
size:  (375, 1242, 3)
load 3035  /  3424
size:  (370, 1224, 3)
load 3036  /  3424
size:  (375, 1242, 3)
load 3037  /  3424
size:  (375, 1242, 3)
load 3038  /  3424
size:  (375, 1242, 3)
load 3039  /  3424
size:  (375, 1242, 3)
load 3040  /  3424
size:  (375, 1242, 3)
load 3041  /  3424
size:  (375, 1242, 3)
load 3042  /  3424
size:  (375, 1242, 3)
load 3043  /  3424
size:  (375, 1242, 3)
load 3044  /  3424
size:  (375, 1242, 3)
load 3045  /  3424
size:  (375, 1242, 3)
load 3046  /  3424
size:  (375, 1242, 3)
load 3047  /  3424
size:  (375, 1242, 3)
load 3048  /  3424
size:  (375, 1242, 3)
load 3049  /  3424
size:  (375, 1242, 3)
load 3050  /  3424
size:  (375, 1242, 3)
load 3051  /  3424
size:  (375, 1242, 3)
load 3052  /  3424
size:  (375, 1242, 3)
load 3053  /  3424
size:  (375, 1242, 3)
load 3054  /  3424
size:  (375, 1242, 3)
load 3055  /  3424
size:  (376, 1241, 3)
load 3056  /  3424
size:  (375, 1242, 3)
load 3057  /  3424
size:  (375, 1242, 3)
load 3058  /  3424
size:  (375, 1242, 3)
load 3059  /  3424
size:  (375, 1242, 3)
load 3060  /  3424
size:  (375, 1242, 3)
load 3061  /  3424
size:  (375, 1242, 3)
load 3062  /  3424
size:  (375, 1242, 3)
load 3063  /  3424
size:  (375, 1242, 3)
load 3064  /  3424
size:  (370, 1224, 3)
load 3065  /  3424
size:  (374, 1238, 3)
load 3066  /  3424
size:  (375, 1242, 3)
load 3067  /  3424
size:  (375, 1242, 3)
load 3068  /  3424
size:  (375, 1242, 3)
load 3069  /  3424
size:  (375, 1242, 3)
load 3070  /  3424
size:  (375, 1242, 3)
load 3071  /  3424
size:  (375, 1242, 3)
load 3072  /  3424
size:  (375, 1242, 3)
load 3073  /  3424
size:  (375, 1242, 3)
load 3074  /  3424
size:  (375, 1242, 3)
load 3075  /  3424
size:  (375, 1242, 3)
load 3076  /  3424
size:  (375, 1242, 3)
load 3077  /  3424
size:  (375, 1242, 3)
load 3078  /  3424
size:  (375, 1242, 3)
load 3079  /  3424
size:  (375, 1242, 3)
load 3080  /  3424
size:  (375, 1242, 3)
load 3081  /  3424
size:  (374, 1238, 3)
load 3082  /  3424
size:  (375, 1242, 3)
load 3083  /  3424
size:  (375, 1242, 3)
load 3084  /  3424
size:  (375, 1242, 3)
load 3085  /  3424
size:  (376, 1241, 3)
load 3086  /  3424
size:  (375, 1242, 3)
load 3087  /  3424
size:  (375, 1242, 3)
load 3088  /  3424
size:  (376, 1241, 3)
load 3089  /  3424
size:  (376, 1241, 3)
load 3090  /  3424
size:  (375, 1242, 3)
load 3091  /  3424
size:  (375, 1242, 3)
load 3092  /  3424
size:  (375, 1242, 3)
load 3093  /  3424
size:  (375, 1242, 3)
load 3094  /  3424
size:  (376, 1241, 3)
load 3095  /  3424
size:  (375, 1242, 3)
load 3096  /  3424
size:  (375, 1242, 3)
load 3097  /  3424
size:  (375, 1242, 3)
load 3098  /  3424
size:  (375, 1242, 3)
load 3099  /  3424
size:  (375, 1242, 3)
load 3100  /  3424
size:  (375, 1242, 3)
load 3101  /  3424
size:  (374, 1238, 3)
load 3102  /  3424
size:  (375, 1242, 3)
load 3103  /  3424
size:  (375, 1242, 3)
load 3104  /  3424
size:  (375, 1242, 3)
load 3105  /  3424
size:  (375, 1242, 3)
load 3106  /  3424
size:  (375, 1242, 3)
load 3107  /  3424
size:  (370, 1224, 3)
load 3108  /  3424
size:  (375, 1242, 3)
load 3109  /  3424
size:  (375, 1242, 3)
load 3110  /  3424
size:  (374, 1238, 3)
load 3111  /  3424
size:  (375, 1242, 3)
load 3112  /  3424
size:  (375, 1242, 3)
load 3113  /  3424
size:  (375, 1242, 3)
load 3114  /  3424
size:  (375, 1242, 3)
load 3115  /  3424
size:  (375, 1242, 3)
load 3116  /  3424
size:  (375, 1242, 3)
load 3117  /  3424
size:  (375, 1242, 3)
load 3118  /  3424
size:  (375, 1242, 3)
load 3119  /  3424
size:  (375, 1242, 3)
load 3120  /  3424
size:  (375, 1242, 3)
load 3121  /  3424
size:  (375, 1242, 3)
load 3122  /  3424
size:  (376, 1241, 3)
load 3123  /  3424
size:  (376, 1241, 3)
load 3124  /  3424
size:  (375, 1242, 3)
load 3125  /  3424
size:  (375, 1242, 3)
load 3126  /  3424
size:  (376, 1241, 3)
load 3127  /  3424
size:  (375, 1242, 3)
load 3128  /  3424
size:  (375, 1242, 3)
load 3129  /  3424
size:  (376, 1241, 3)
load 3130  /  3424
size:  (375, 1242, 3)
load 3131  /  3424
size:  (375, 1242, 3)
load 3132  /  3424
size:  (375, 1242, 3)
load 3133  /  3424
size:  (375, 1242, 3)
load 3134  /  3424
size:  (375, 1242, 3)
load 3135  /  3424
size:  (375, 1242, 3)
load 3136  /  3424
size:  (375, 1242, 3)
load 3137  /  3424
size:  (375, 1242, 3)
load 3138  /  3424
size:  (375, 1242, 3)
load 3139  /  3424
size:  (375, 1242, 3)
load 3140  /  3424
size:  (375, 1242, 3)
load 3141  /  3424
size:  (375, 1242, 3)
load 3142  /  3424
size:  (376, 1241, 3)
load 3143  /  3424
size:  (375, 1242, 3)
load 3144  /  3424
size:  (375, 1242, 3)
load 3145  /  3424
size:  (375, 1242, 3)
load 3146  /  3424
size:  (375, 1242, 3)
load 3147  /  3424
size:  (375, 1242, 3)
load 3148  /  3424
size:  (375, 1242, 3)
load 3149  /  3424
size:  (375, 1242, 3)
load 3150  /  3424
size:  (375, 1242, 3)
load 3151  /  3424
size:  (376, 1241, 3)
load 3152  /  3424
size:  (374, 1238, 3)
load 3153  /  3424
size:  (375, 1242, 3)
load 3154  /  3424
size:  (375, 1242, 3)
load 3155  /  3424
size:  (375, 1242, 3)
load 3156  /  3424
size:  (375, 1242, 3)
load 3157  /  3424
size:  (375, 1242, 3)
load 3158  /  3424
size:  (376, 1241, 3)
load 3159  /  3424
size:  (375, 1242, 3)
load 3160  /  3424
size:  (375, 1242, 3)
load 3161  /  3424
size:  (374, 1238, 3)
load 3162  /  3424
size:  (375, 1242, 3)
load 3163  /  3424
size:  (375, 1242, 3)
load 3164  /  3424
size:  (376, 1241, 3)
load 3165  /  3424
size:  (375, 1242, 3)
load 3166  /  3424
size:  (375, 1242, 3)
load 3167  /  3424
size:  (375, 1242, 3)
load 3168  /  3424
size:  (375, 1242, 3)
load 3169  /  3424
size:  (376, 1241, 3)
load 3170  /  3424
size:  (375, 1242, 3)
load 3171  /  3424
size:  (375, 1242, 3)
load 3172  /  3424
size:  (375, 1242, 3)
load 3173  /  3424
size:  (375, 1242, 3)
load 3174  /  3424
size:  (375, 1242, 3)
load 3175  /  3424
size:  (375, 1242, 3)
load 3176  /  3424
size:  (375, 1242, 3)
load 3177  /  3424
size:  (375, 1242, 3)
load 3178  /  3424
size:  (375, 1242, 3)
load 3179  /  3424
size:  (376, 1241, 3)
load 3180  /  3424
size:  (375, 1242, 3)
load 3181  /  3424
size:  (375, 1242, 3)
load 3182  /  3424
size:  (375, 1242, 3)
load 3183  /  3424
size:  (375, 1242, 3)
load 3184  /  3424
size:  (375, 1242, 3)
load 3185  /  3424
size:  (375, 1242, 3)
load 3186  /  3424
size:  (370, 1224, 3)
load 3187  /  3424
size:  (375, 1242, 3)
load 3188  /  3424
size:  (375, 1242, 3)
load 3189  /  3424
size:  (375, 1242, 3)
load 3190  /  3424
size:  (375, 1242, 3)
load 3191  /  3424
size:  (375, 1242, 3)
load 3192  /  3424
size:  (375, 1242, 3)
load 3193  /  3424
size:  (376, 1241, 3)
load 3194  /  3424
size:  (375, 1242, 3)
load 3195  /  3424
size:  (375, 1242, 3)
load 3196  /  3424
size:  (375, 1242, 3)
load 3197  /  3424
size:  (375, 1242, 3)
load 3198  /  3424
size:  (376, 1241, 3)
load 3199  /  3424
size:  (375, 1242, 3)
load 3200  /  3424
size:  (375, 1242, 3)
load 3201  /  3424
size:  (375, 1242, 3)
load 3202  /  3424
size:  (375, 1242, 3)
load 3203  /  3424
size:  (375, 1242, 3)
load 3204  /  3424
size:  (375, 1242, 3)
load 3205  /  3424
size:  (375, 1242, 3)
load 3206  /  3424
size:  (375, 1242, 3)
load 3207  /  3424
size:  (375, 1242, 3)
load 3208  /  3424
size:  (375, 1242, 3)
load 3209  /  3424
size:  (375, 1242, 3)
load 3210  /  3424
size:  (375, 1242, 3)
load 3211  /  3424
size:  (375, 1242, 3)
load 3212  /  3424
size:  (375, 1242, 3)
load 3213  /  3424
size:  (375, 1242, 3)
load 3214  /  3424
size:  (375, 1242, 3)
load 3215  /  3424
size:  (375, 1242, 3)
load 3216  /  3424
size:  (375, 1242, 3)
load 3217  /  3424
size:  (375, 1242, 3)
load 3218  /  3424
size:  (375, 1242, 3)
load 3219  /  3424
size:  (375, 1242, 3)
load 3220  /  3424
size:  (375, 1242, 3)
load 3221  /  3424
size:  (375, 1242, 3)
load 3222  /  3424
size:  (375, 1242, 3)
load 3223  /  3424
size:  (375, 1242, 3)
load 3224  /  3424
size:  (375, 1242, 3)
load 3225  /  3424
size:  (375, 1242, 3)
load 3226  /  3424
size:  (375, 1242, 3)
load 3227  /  3424
size:  (375, 1242, 3)
load 3228  /  3424
size:  (375, 1242, 3)
load 3229  /  3424
size:  (375, 1242, 3)
load 3230  /  3424
size:  (375, 1242, 3)
load 3231  /  3424
size:  (375, 1242, 3)
load 3232  /  3424
size:  (375, 1242, 3)
load 3233  /  3424
size:  (375, 1242, 3)
load 3234  /  3424
size:  (375, 1242, 3)
load 3235  /  3424
size:  (375, 1242, 3)
load 3236  /  3424
size:  (375, 1242, 3)
load 3237  /  3424
size:  (375, 1242, 3)
load 3238  /  3424
size:  (375, 1242, 3)
load 3239  /  3424
size:  (375, 1242, 3)
load 3240  /  3424
size:  (375, 1242, 3)
load 3241  /  3424
size:  (375, 1242, 3)
load 3242  /  3424
size:  (375, 1242, 3)
load 3243  /  3424
size:  (375, 1242, 3)
load 3244  /  3424
size:  (375, 1242, 3)
load 3245  /  3424
size:  (375, 1242, 3)
load 3246  /  3424
size:  (374, 1238, 3)
load 3247  /  3424
size:  (375, 1242, 3)
load 3248  /  3424
size:  (375, 1242, 3)
load 3249  /  3424
size:  (375, 1242, 3)
load 3250  /  3424
size:  (375, 1242, 3)
load 3251  /  3424
size:  (375, 1242, 3)
load 3252  /  3424
size:  (375, 1242, 3)
load 3253  /  3424
size:  (375, 1242, 3)
load 3254  /  3424
size:  (375, 1242, 3)
load 3255  /  3424
size:  (375, 1242, 3)
load 3256  /  3424
size:  (375, 1242, 3)
load 3257  /  3424
size:  (375, 1242, 3)
load 3258  /  3424
size:  (375, 1242, 3)
load 3259  /  3424
size:  (375, 1242, 3)
load 3260  /  3424
size:  (375, 1242, 3)
load 3261  /  3424
size:  (375, 1242, 3)
load 3262  /  3424
size:  (375, 1242, 3)
load 3263  /  3424
size:  (375, 1242, 3)
load 3264  /  3424
size:  (375, 1242, 3)
load 3265  /  3424
size:  (375, 1242, 3)
load 3266  /  3424
size:  (374, 1238, 3)
load 3267  /  3424
size:  (376, 1241, 3)
load 3268  /  3424
size:  (375, 1242, 3)
load 3269  /  3424
size:  (375, 1242, 3)
load 3270  /  3424
size:  (375, 1242, 3)
load 3271  /  3424
size:  (375, 1242, 3)
load 3272  /  3424
size:  (375, 1242, 3)
load 3273  /  3424
size:  (375, 1242, 3)
load 3274  /  3424
size:  (374, 1238, 3)
load 3275  /  3424
size:  (375, 1242, 3)
load 3276  /  3424
size:  (375, 1242, 3)
load 3277  /  3424
size:  (375, 1242, 3)
load 3278  /  3424
size:  (375, 1242, 3)
load 3279  /  3424
size:  (375, 1242, 3)
load 3280  /  3424
size:  (375, 1242, 3)
load 3281  /  3424
size:  (375, 1242, 3)
load 3282  /  3424
size:  (375, 1242, 3)
load 3283  /  3424
size:  (375, 1242, 3)
load 3284  /  3424
size:  (375, 1242, 3)
load 3285  /  3424
size:  (375, 1242, 3)
load 3286  /  3424
size:  (375, 1242, 3)
load 3287  /  3424
size:  (375, 1242, 3)
load 3288  /  3424
size:  (375, 1242, 3)
load 3289  /  3424
size:  (375, 1242, 3)
load 3290  /  3424
size:  (375, 1242, 3)
load 3291  /  3424
size:  (375, 1242, 3)
load 3292  /  3424
size:  (375, 1242, 3)
load 3293  /  3424
size:  (375, 1242, 3)
load 3294  /  3424
size:  (375, 1242, 3)
load 3295  /  3424
size:  (374, 1238, 3)
load 3296  /  3424
size:  (375, 1242, 3)
load 3297  /  3424
size:  (375, 1242, 3)
load 3298  /  3424
size:  (375, 1242, 3)
load 3299  /  3424
size:  (375, 1242, 3)
load 3300  /  3424
size:  (375, 1242, 3)
load 3301  /  3424
size:  (375, 1242, 3)
load 3302  /  3424
size:  (375, 1242, 3)
load 3303  /  3424
size:  (375, 1242, 3)
load 3304  /  3424
size:  (375, 1242, 3)
load 3305  /  3424
size:  (375, 1242, 3)
load 3306  /  3424
size:  (375, 1242, 3)
load 3307  /  3424
size:  (374, 1238, 3)
load 3308  /  3424
size:  (375, 1242, 3)
load 3309  /  3424
size:  (375, 1242, 3)
load 3310  /  3424
size:  (375, 1242, 3)
load 3311  /  3424
size:  (370, 1224, 3)
load 3312  /  3424
size:  (375, 1242, 3)
load 3313  /  3424
size:  (375, 1242, 3)
load 3314  /  3424
size:  (375, 1242, 3)
load 3315  /  3424
size:  (375, 1242, 3)
load 3316  /  3424
size:  (375, 1242, 3)
load 3317  /  3424
size:  (375, 1242, 3)
load 3318  /  3424
size:  (375, 1242, 3)
load 3319  /  3424
size:  (375, 1242, 3)
load 3320  /  3424
size:  (376, 1241, 3)
load 3321  /  3424
size:  (376, 1241, 3)
load 3322  /  3424
size:  (375, 1242, 3)
load 3323  /  3424
size:  (375, 1242, 3)
load 3324  /  3424
size:  (375, 1242, 3)
load 3325  /  3424
size:  (375, 1242, 3)
load 3326  /  3424
size:  (375, 1242, 3)
load 3327  /  3424
size:  (375, 1242, 3)
load 3328  /  3424
size:  (375, 1242, 3)
load 3329  /  3424
size:  (375, 1242, 3)
load 3330  /  3424
size:  (370, 1224, 3)
load 3331  /  3424
size:  (375, 1242, 3)
load 3332  /  3424
size:  (375, 1242, 3)
load 3333  /  3424
size:  (375, 1242, 3)
load 3334  /  3424
size:  (375, 1242, 3)
load 3335  /  3424
size:  (375, 1242, 3)
load 3336  /  3424
size:  (375, 1242, 3)
load 3337  /  3424
size:  (375, 1242, 3)
load 3338  /  3424
size:  (375, 1242, 3)
load 3339  /  3424
size:  (375, 1242, 3)
load 3340  /  3424
size:  (375, 1242, 3)
load 3341  /  3424
size:  (374, 1238, 3)
load 3342  /  3424
size:  (375, 1242, 3)
load 3343  /  3424
size:  (375, 1242, 3)
load 3344  /  3424
size:  (375, 1242, 3)
load 3345  /  3424
size:  (370, 1224, 3)
load 3346  /  3424
size:  (376, 1241, 3)
load 3347  /  3424
size:  (375, 1242, 3)
load 3348  /  3424
size:  (375, 1242, 3)
load 3349  /  3424
size:  (375, 1242, 3)
load 3350  /  3424
size:  (375, 1242, 3)
load 3351  /  3424
size:  (376, 1241, 3)
load 3352  /  3424
size:  (375, 1242, 3)
load 3353  /  3424
size:  (375, 1242, 3)
load 3354  /  3424
size:  (375, 1242, 3)
load 3355  /  3424
size:  (370, 1224, 3)
load 3356  /  3424
size:  (375, 1242, 3)
load 3357  /  3424
size:  (375, 1242, 3)
load 3358  /  3424
size:  (376, 1241, 3)
load 3359  /  3424
size:  (375, 1242, 3)
load 3360  /  3424
size:  (370, 1224, 3)
load 3361  /  3424
size:  (376, 1241, 3)
load 3362  /  3424
size:  (376, 1241, 3)
load 3363  /  3424
size:  (375, 1242, 3)
load 3364  /  3424
size:  (375, 1242, 3)
load 3365  /  3424
size:  (375, 1242, 3)
load 3366  /  3424
size:  (375, 1242, 3)
load 3367  /  3424
size:  (375, 1242, 3)
load 3368  /  3424
size:  (375, 1242, 3)
load 3369  /  3424
size:  (374, 1238, 3)
load 3370  /  3424
size:  (375, 1242, 3)
load 3371  /  3424
size:  (375, 1242, 3)
load 3372  /  3424
size:  (375, 1242, 3)
load 3373  /  3424
size:  (376, 1241, 3)
load 3374  /  3424
size:  (375, 1242, 3)
load 3375  /  3424
size:  (375, 1242, 3)
load 3376  /  3424
size:  (376, 1241, 3)
load 3377  /  3424
size:  (375, 1242, 3)
load 3378  /  3424
size:  (375, 1242, 3)
load 3379  /  3424
size:  (375, 1242, 3)
load 3380  /  3424
size:  (375, 1242, 3)
load 3381  /  3424
size:  (375, 1242, 3)
load 3382  /  3424
size:  (374, 1238, 3)
load 3383  /  3424
size:  (375, 1242, 3)
load 3384  /  3424
size:  (375, 1242, 3)
load 3385  /  3424
size:  (374, 1238, 3)
load 3386  /  3424
size:  (375, 1242, 3)
load 3387  /  3424
size:  (375, 1242, 3)
load 3388  /  3424
size:  (375, 1242, 3)
load 3389  /  3424
size:  (375, 1242, 3)
load 3390  /  3424
size:  (375, 1242, 3)
load 3391  /  3424
size:  (374, 1238, 3)
load 3392  /  3424
size:  (375, 1242, 3)
load 3393  /  3424
size:  (375, 1242, 3)
load 3394  /  3424
size:  (375, 1242, 3)
load 3395  /  3424
size:  (375, 1242, 3)
load 3396  /  3424
size:  (374, 1238, 3)
load 3397  /  3424
size:  (375, 1242, 3)
load 3398  /  3424
size:  (374, 1238, 3)
load 3399  /  3424
size:  (375, 1242, 3)
load 3400  /  3424
size:  (375, 1242, 3)
load 3401  /  3424
size:  (375, 1242, 3)
load 3402  /  3424
size:  (375, 1242, 3)
load 3403  /  3424
size:  (375, 1242, 3)
load 3404  /  3424
size:  (375, 1242, 3)
load 3405  /  3424
size:  (375, 1242, 3)
load 3406  /  3424
size:  (375, 1242, 3)
load 3407  /  3424
size:  (376, 1241, 3)
load 3408  /  3424
size:  (375, 1242, 3)
load 3409  /  3424
size:  (375, 1242, 3)
load 3410  /  3424
size:  (375, 1242, 3)
load 3411  /  3424
size:  (375, 1242, 3)
load 3412  /  3424
size:  (375, 1242, 3)
load 3413  /  3424
size:  (375, 1242, 3)
load 3414  /  3424
size:  (374, 1238, 3)
load 3415  /  3424
size:  (374, 1238, 3)
load 3416  /  3424
size:  (375, 1242, 3)
load 3417  /  3424
size:  (376, 1241, 3)
load 3418  /  3424
size:  (374, 1238, 3)
load 3419  /  3424
size:  (375, 1242, 3)
load 3420  /  3424
size:  (370, 1224, 3)
load 3421  /  3424
size:  (376, 1241, 3)
load 3422  /  3424
size:  (375, 1242, 3)
load 3423  /  3424
size:  (375, 1242, 3)
append flipped images to roidb
752
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 47, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/pre3D/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/pre3D/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/val.lst
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 47, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/pre3D/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/pre3D/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/val.lst
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 6684
load 0  /  6684
size:  (375, 1242, 3)
load 1  /  6684
size:  (375, 1242, 3)
load 2  /  6684
size:  (375, 1242, 3)
load 3  /  6684
size:  (375, 1242, 3)
load 4  /  6684
size:  (374, 1238, 3)
load 5  /  6684
size:  (375, 1242, 3)
load 6  /  6684
size:  (375, 1242, 3)
load 7  /  6684
size:  (375, 1242, 3)
load 8  /  6684
size:  (375, 1242, 3)
load 9  /  6684
size:  (375, 1242, 3)
load 10  /  6684
size:  (375, 1242, 3)
load 11  /  6684
size:  (375, 1242, 3)
load 12  /  6684
size:  (375, 1242, 3)
load 13  /  6684
size:  (374, 1238, 3)
load 14  /  6684
size:  (375, 1242, 3)
load 15  /  6684
size:  (375, 1242, 3)
load 16  /  6684
size:  (375, 1242, 3)
load 17  /  6684
size:  (375, 1242, 3)
load 18  /  6684
size:  (375, 1242, 3)
load 19  /  6684
size:  (375, 1242, 3)
load 20  /  6684
size:  (375, 1242, 3)
load 21  /  6684
size:  (375, 1242, 3)
load 22  /  6684
size:  (376, 1241, 3)
load 23  /  6684
size:  (375, 1242, 3)
load 24  /  6684
size:  (375, 1242, 3)
load 25  /  6684
size:  (375, 1242, 3)
load 26  /  6684
size:  (375, 1242, 3)
load 27  /  6684
size:  (375, 1242, 3)
load 28  /  6684
size:  (375, 1242, 3)
load 29  /  6684
size:  (375, 1242, 3)
load 30  /  6684
size:  (375, 1242, 3)
load 31  /  6684
size:  (375, 1242, 3)
load 32  /  6684
size:  (375, 1242, 3)
load 33  /  6684
size:  (375, 1242, 3)
load 34  /  6684
size:  (376, 1241, 3)
load 35  /  6684
size:  (375, 1242, 3)
load 36  /  6684
size:  (375, 1242, 3)
load 37  /  6684
size:  (375, 1242, 3)
load 38  /  6684
size:  (375, 1242, 3)
load 39  /  6684
size:  (375, 1242, 3)
load 40  /  6684
size:  (375, 1242, 3)
load 41  /  6684
size:  (375, 1242, 3)
load 42  /  6684
size:  (375, 1242, 3)
load 43  /  6684
size:  (376, 1241, 3)
load 44  /  6684
size:  (375, 1242, 3)
load 45  /  6684
size:  (375, 1242, 3)
load 46  /  6684
size:  (375, 1242, 3)
load 47  /  6684
size:  (375, 1242, 3)
load 48  /  6684
size:  (375, 1242, 3)
load 49  /  6684
size:  (375, 1242, 3)
load 50  /  6684
size:  (375, 1242, 3)
load 51  /  6684
size:  (375, 1242, 3)
load 52  /  6684
size:  (375, 1242, 3)
load 53  /  6684
size:  (375, 1242, 3)
load 54  /  6684
size:  (375, 1242, 3)
load 55  /  6684
size:  (375, 1242, 3)
load 56  /  6684
size:  (375, 1242, 3)
load 57  /  6684
size:  (375, 1242, 3)
load 58  /  6684
size:  (375, 1242, 3)
load 59  /  6684
size:  (375, 1242, 3)
load 60  /  6684
size:  (375, 1242, 3)
load 61  /  6684
size:  (375, 1242, 3)
load 62  /  6684
size:  (375, 1242, 3)
load 63  /  6684
size:  (375, 1242, 3)
load 64  /  6684
size:  (375, 1242, 3)
load 65  /  6684
size:  (375, 1242, 3)
load 66  /  6684
size:  (375, 1242, 3)
load 67  /  6684
size:  (375, 1242, 3)
load 68  /  6684
size:  (375, 1242, 3)
load 69  /  6684
size:  (375, 1242, 3)
load 70  /  6684
size:  (375, 1242, 3)
load 71  /  6684
size:  (374, 1238, 3)
load 72  /  6684
size:  (375, 1242, 3)
load 73  /  6684
size:  (375, 1242, 3)
load 74  /  6684
size:  (375, 1242, 3)
load 75  /  6684
size:  (375, 1242, 3)
load 76  /  6684
size:  (375, 1242, 3)
load 77  /  6684
size:  (375, 1242, 3)
load 78  /  6684
size:  (375, 1242, 3)
load 79  /  6684
size:  (375, 1242, 3)
load 80  /  6684
size:  (375, 1242, 3)
load 81  /  6684
size:  (375, 1242, 3)
load 82  /  6684
size:  (375, 1242, 3)
load 83  /  6684
size:  (375, 1242, 3)
load 84  /  6684
size:  (375, 1242, 3)
load 85  /  6684
size:  (375, 1242, 3)
load 86  /  6684
size:  (376, 1241, 3)
load 87  /  6684
size:  (375, 1242, 3)
load 88  /  6684
size:  (375, 1242, 3)
load 89  /  6684
size:  (375, 1242, 3)
load 90  /  6684
size:  (375, 1242, 3)
load 91  /  6684
size:  (375, 1242, 3)
load 92  /  6684
size:  (375, 1242, 3)
load 93  /  6684
size:  (375, 1242, 3)
load 94  /  6684
size:  (375, 1242, 3)
load 95  /  6684
size:  (375, 1242, 3)
load 96  /  6684
size:  (375, 1242, 3)
load 97  /  6684
size:  (375, 1242, 3)
load 98  /  6684
size:  (375, 1242, 3)
load 99  /  6684
size:  (375, 1242, 3)
load 100  /  6684
size:  (375, 1242, 3)
load 101  /  6684
size:  (375, 1242, 3)
load 102  /  6684
size:  (375, 1242, 3)
load 103  /  6684
size:  (375, 1242, 3)
load 104  /  6684
size:  (375, 1242, 3)
load 105  /  6684
size:  (375, 1242, 3)
load 106  /  6684
size:  (375, 1242, 3)
load 107  /  6684
size:  (375, 1242, 3)
load 108  /  6684
size:  (375, 1242, 3)
load 109  /  6684
size:  (370, 1224, 3)
load 110  /  6684
size:  (375, 1242, 3)
load 111  /  6684
size:  (375, 1242, 3)
load 112  /  6684
size:  (375, 1242, 3)
load 113  /  6684
size:  (375, 1242, 3)
load 114  /  6684
size:  (375, 1242, 3)
load 115  /  6684
size:  (375, 1242, 3)
load 116  /  6684
size:  (376, 1241, 3)
load 117  /  6684
size:  (375, 1242, 3)
load 118  /  6684
size:  (370, 1224, 3)
load 119  /  6684
size:  (375, 1242, 3)
load 120  /  6684
size:  (375, 1242, 3)
load 121  /  6684
size:  (375, 1242, 3)
load 122  /  6684
size:  (375, 1242, 3)
load 123  /  6684
size:  (375, 1242, 3)
load 124  /  6684
size:  (375, 1242, 3)
load 125  /  6684
size:  (375, 1242, 3)
load 126  /  6684
size:  (375, 1242, 3)
load 127  /  6684
size:  (375, 1242, 3)
load 128  /  6684
size:  (375, 1242, 3)
load 129  /  6684
size:  (370, 1224, 3)
load 130  /  6684
size:  (375, 1242, 3)
load 131  /  6684
size:  (375, 1242, 3)
load 132  /  6684
size:  (375, 1242, 3)
load 133  /  6684
size:  (375, 1242, 3)
load 134  /  6684
size:  (370, 1224, 3)
load 135  /  6684
size:  (375, 1242, 3)
load 136  /  6684
size:  (370, 1224, 3)
load 137  /  6684
size:  (375, 1242, 3)
load 138  /  6684
size:  (375, 1242, 3)
load 139  /  6684
size:  (375, 1242, 3)
load 140  /  6684
size:  (375, 1242, 3)
load 141  /  6684
size:  (375, 1242, 3)
load 142  /  6684
size:  (375, 1242, 3)
load 143  /  6684
size:  (375, 1242, 3)
load 144  /  6684
size:  (375, 1242, 3)
load 145  /  6684
size:  (375, 1242, 3)
load 146  /  6684
size:  (375, 1242, 3)
load 147  /  6684
size:  (375, 1242, 3)
load 148  /  6684
size:  (375, 1242, 3)
load 149  /  6684
size:  (375, 1242, 3)
load 150  /  6684
size:  (375, 1242, 3)
load 151  /  6684
size:  (376, 1241, 3)
load 152  /  6684
size:  (375, 1242, 3)
load 153  /  6684
size:  (375, 1242, 3)
load 154  /  6684
size:  (375, 1242, 3)
load 155  /  6684
size:  (375, 1242, 3)
load 156  /  6684
size:  (375, 1242, 3)
load 157  /  6684
size:  (375, 1242, 3)
load 158  /  6684
size:  (375, 1242, 3)
load 159  /  6684
size:  (375, 1242, 3)
load 160  /  6684
size:  (375, 1242, 3)
load 161  /  6684
size:  (375, 1242, 3)
load 162  /  6684
size:  (375, 1242, 3)
load 163  /  6684
size:  (375, 1242, 3)
load 164  /  6684
size:  (375, 1242, 3)
load 165  /  6684
size:  (375, 1242, 3)
load 166  /  6684
size:  (375, 1242, 3)
load 167  /  6684
size:  (375, 1242, 3)
load 168  /  6684
size:  (375, 1242, 3)
load 169  /  6684
size:  (374, 1238, 3)
load 170  /  6684
size:  (376, 1241, 3)
load 171  /  6684
size:  (376, 1241, 3)
load 172  /  6684
size:  (375, 1242, 3)
load 173  /  6684
size:  (375, 1242, 3)
load 174  /  6684
size:  (375, 1242, 3)
load 175  /  6684
size:  (375, 1242, 3)
load 176  /  6684
size:  (375, 1242, 3)
load 177  /  6684
size:  (375, 1242, 3)
load 178  /  6684
size:  (375, 1242, 3)
load 179  /  6684
size:  (375, 1242, 3)
load 180  /  6684
size:  (375, 1242, 3)
load 181  /  6684
size:  (375, 1242, 3)
load 182  /  6684
size:  (370, 1224, 3)
load 183  /  6684
size:  (375, 1242, 3)
load 184  /  6684
size:  (375, 1242, 3)
load 185  /  6684
size:  (375, 1242, 3)
load 186  /  6684
size:  (375, 1242, 3)
load 187  /  6684
size:  (375, 1242, 3)
load 188  /  6684
size:  (375, 1242, 3)
load 189  /  6684
size:  (375, 1242, 3)
load 190  /  6684
size:  (375, 1242, 3)
load 191  /  6684
size:  (375, 1242, 3)
load 192  /  6684
size:  (375, 1242, 3)
load 193  /  6684
size:  (375, 1242, 3)
load 194  /  6684
size:  (375, 1242, 3)
load 195  /  6684
size:  (375, 1242, 3)
load 196  /  6684
size:  (375, 1242, 3)
load 197  /  6684
size:  (375, 1242, 3)
load 198  /  6684
size:  (375, 1242, 3)
load 199  /  6684
size:  (375, 1242, 3)
load 200  /  6684
size:  (375, 1242, 3)
load 201  /  6684
size:  (375, 1242, 3)
load 202  /  6684
size:  (375, 1242, 3)
load 203  /  6684
size:  (375, 1242, 3)
load 204  /  6684
size:  (375, 1242, 3)
load 205  /  6684
size:  (375, 1242, 3)
load 206  /  6684
size:  (375, 1242, 3)
load 207  /  6684
size:  (375, 1242, 3)
load 208  /  6684
size:  (375, 1242, 3)
load 209  /  6684
size:  (375, 1242, 3)
load 210  /  6684
size:  (375, 1242, 3)
load 211  /  6684
size:  (376, 1241, 3)
load 212  /  6684
size:  (375, 1242, 3)
load 213  /  6684
size:  (375, 1242, 3)
load 214  /  6684
size:  (375, 1242, 3)
load 215  /  6684
size:  (375, 1242, 3)
load 216  /  6684
size:  (375, 1242, 3)
load 217  /  6684
size:  (375, 1242, 3)
load 218  /  6684
size:  (375, 1242, 3)
load 219  /  6684
size:  (375, 1242, 3)
load 220  /  6684
size:  (375, 1242, 3)
load 221  /  6684
size:  (376, 1241, 3)
load 222  /  6684
size:  (375, 1242, 3)
load 223  /  6684
size:  (376, 1241, 3)
load 224  /  6684
size:  (376, 1241, 3)
load 225  /  6684
size:  (375, 1242, 3)
load 226  /  6684
size:  (375, 1242, 3)
load 227  /  6684
size:  (375, 1242, 3)
load 228  /  6684
size:  (375, 1242, 3)
load 229  /  6684
size:  (375, 1242, 3)
load 230  /  6684
size:  (375, 1242, 3)
load 231  /  6684
size:  (375, 1242, 3)
load 232  /  6684
size:  (375, 1242, 3)
load 233  /  6684
size:  (374, 1238, 3)
load 234  /  6684
size:  (375, 1242, 3)
load 235  /  6684
size:  (375, 1242, 3)
load 236  /  6684
size:  (375, 1242, 3)
load 237  /  6684
size:  (375, 1242, 3)
load 238  /  6684
size:  (375, 1242, 3)
load 239  /  6684
size:  (375, 1242, 3)
load 240  /  6684
size:  (375, 1242, 3)
load 241  /  6684
size:  (375, 1242, 3)
load 242  /  6684
size:  (375, 1242, 3)
load 243  /  6684
size:  (375, 1242, 3)
load 244  /  6684
size:  (375, 1242, 3)
load 245  /  6684
size:  (375, 1242, 3)
load 246  /  6684
size:  (375, 1242, 3)
load 247  /  6684
size:  (375, 1242, 3)
load 248  /  6684
size:  (375, 1242, 3)
load 249  /  6684
size:  (375, 1242, 3)
load 250  /  6684
size:  (375, 1242, 3)
load 251  /  6684
size:  (375, 1242, 3)
load 252  /  6684
size:  (375, 1242, 3)
load 253  /  6684
size:  (375, 1242, 3)
load 254  /  6684
size:  (375, 1242, 3)
load 255  /  6684
size:  (375, 1242, 3)
load 256  /  6684
size:  (375, 1242, 3)
load 257  /  6684
size:  (375, 1242, 3)
load 258  /  6684
size:  (376, 1241, 3)
load 259  /  6684
size:  (375, 1242, 3)
load 260  /  6684
size:  (375, 1242, 3)
load 261  /  6684
size:  (375, 1242, 3)
load 262  /  6684
size:  (375, 1242, 3)
load 263  /  6684
size:  (375, 1242, 3)
load 264  /  6684
size:  (375, 1242, 3)
load 265  /  6684
size:  (375, 1242, 3)
load 266  /  6684
size:  (375, 1242, 3)
load 267  /  6684
size:  (376, 1241, 3)
load 268  /  6684
size:  (374, 1238, 3)
load 269  /  6684
size:  (375, 1242, 3)
load 270  /  6684
size:  (375, 1242, 3)
load 271  /  6684
size:  (374, 1238, 3)
load 272  /  6684
size:  (375, 1242, 3)
load 273  /  6684
size:  (375, 1242, 3)
load 274  /  6684
size:  (370, 1224, 3)
load 275  /  6684
size:  (375, 1242, 3)
load 276  /  6684
size:  (375, 1242, 3)
load 277  /  6684
size:  (375, 1242, 3)
load 278  /  6684
size:  (375, 1242, 3)
load 279  /  6684
size:  (375, 1242, 3)
load 280  /  6684
size:  (375, 1242, 3)
load 281  /  6684
size:  (375, 1242, 3)
load 282  /  6684
size:  (375, 1242, 3)
load 283  /  6684
size:  (375, 1242, 3)
load 284  /  6684
size:  (375, 1242, 3)
load 285  /  6684
size:  (375, 1242, 3)
load 286  /  6684
size:  (375, 1242, 3)
load 287  /  6684
size:  (375, 1242, 3)
load 288  /  6684
size:  (375, 1242, 3)
load 289  /  6684
size:  (375, 1242, 3)
load 290  /  6684
size:  (375, 1242, 3)
load 291  /  6684
size:  (375, 1242, 3)
load 292  /  6684
size:  (375, 1242, 3)
load 293  /  6684
size:  (375, 1242, 3)
load 294  /  6684
size:  (375, 1242, 3)
load 295  /  6684
size:  (374, 1238, 3)
load 296  /  6684
size:  (370, 1224, 3)
load 297  /  6684
size:  (375, 1242, 3)
load 298  /  6684
size:  (375, 1242, 3)
load 299  /  6684
size:  (374, 1238, 3)
load 300  /  6684
size:  (370, 1224, 3)
load 301  /  6684
size:  (375, 1242, 3)
load 302  /  6684
size:  (375, 1242, 3)
load 303  /  6684
size:  (375, 1242, 3)
load 304  /  6684
size:  (375, 1242, 3)
load 305  /  6684
size:  (376, 1241, 3)
load 306  /  6684
size:  (375, 1242, 3)
load 307  /  6684
size:  (375, 1242, 3)
load 308  /  6684
size:  (375, 1242, 3)
load 309  /  6684
size:  (375, 1242, 3)
load 310  /  6684
size:  (375, 1242, 3)
load 311  /  6684
size:  (376, 1241, 3)
load 312  /  6684
size:  (375, 1242, 3)
load 313  /  6684
size:  (375, 1242, 3)
load 314  /  6684
size:  (375, 1242, 3)
load 315  /  6684
size:  (375, 1242, 3)
load 316  /  6684
size:  (375, 1242, 3)
load 317  /  6684
size:  (376, 1241, 3)
load 318  /  6684
size:  (375, 1242, 3)
load 319  /  6684
size:  (375, 1242, 3)
load 320  /  6684
size:  (375, 1242, 3)
load 321  /  6684
size:  (375, 1242, 3)
load 322  /  6684
size:  (375, 1242, 3)
load 323  /  6684
size:  (375, 1242, 3)
load 324  /  6684
size:  (370, 1224, 3)
load 325  /  6684
size:  (375, 1242, 3)
load 326  /  6684
size:  (376, 1241, 3)
load 327  /  6684
size:  (375, 1242, 3)
load 328  /  6684
size:  (375, 1242, 3)
load 329  /  6684
size:  (375, 1242, 3)
load 330  /  6684
size:  (375, 1242, 3)
load 331  /  6684
size:  (375, 1242, 3)
load 332  /  6684
size:  (374, 1238, 3)
load 333  /  6684
size:  (375, 1242, 3)
load 334  /  6684
size:  (375, 1242, 3)
load 335  /  6684
size:  (375, 1242, 3)
load 336  /  6684
size:  (375, 1242, 3)
load 337  /  6684
size:  (375, 1242, 3)
load 338  /  6684
size:  (375, 1242, 3)
load 339  /  6684
size:  (370, 1224, 3)
load 340  /  6684
size:  (370, 1224, 3)
load 341  /  6684
size:  (375, 1242, 3)
load 342  /  6684
size:  (376, 1241, 3)
load 343  /  6684
size:  (375, 1242, 3)
load 344  /  6684
size:  (375, 1242, 3)
load 345  /  6684
size:  (375, 1242, 3)
load 346  /  6684
size:  (375, 1242, 3)
load 347  /  6684
size:  (376, 1241, 3)
load 348  /  6684
size:  (375, 1242, 3)
load 349  /  6684
size:  (375, 1242, 3)
load 350  /  6684
size:  (375, 1242, 3)
load 351  /  6684
size:  (375, 1242, 3)
load 352  /  6684
size:  (375, 1242, 3)
load 353  /  6684
size:  (375, 1242, 3)
load 354  /  6684
size:  (375, 1242, 3)
load 355  /  6684
size:  (375, 1242, 3)
load 356  /  6684
size:  (375, 1242, 3)
load 357  /  6684
size:  (375, 1242, 3)
load 358  /  6684
size:  (375, 1242, 3)
load 359  /  6684
size:  (376, 1241, 3)
load 360  /  6684
size:  (375, 1242, 3)
load 361  /  6684
size:  (375, 1242, 3)
load 362  /  6684
size:  (375, 1242, 3)
load 363  /  6684
size:  (375, 1242, 3)
load 364  /  6684
size:  (375, 1242, 3)
load 365  /  6684
size:  (375, 1242, 3)
load 366  /  6684
size:  (375, 1242, 3)
load 367  /  6684
size:  (375, 1242, 3)
load 368  /  6684
size:  (375, 1242, 3)
load 369  /  6684
size:  (375, 1242, 3)
load 370  /  6684
size:  (375, 1242, 3)
load 371  /  6684
size:  (375, 1242, 3)
load 372  /  6684
size:  (375, 1242, 3)
load 373  /  6684
size:  (376, 1241, 3)
load 374  /  6684
size:  (375, 1242, 3)
load 375  /  6684
size:  (375, 1242, 3)
load 376  /  6684
size:  (374, 1238, 3)
load 377  /  6684
size:  (375, 1242, 3)
load 378  /  6684
size:  (375, 1242, 3)
load 379  /  6684
size:  (375, 1242, 3)
load 380  /  6684
size:  (375, 1242, 3)
load 381  /  6684
size:  (376, 1241, 3)
load 382  /  6684
size:  (370, 1224, 3)
load 383  /  6684
size:  (375, 1242, 3)
load 384  /  6684
size:  (375, 1242, 3)
load 385  /  6684
size:  (375, 1242, 3)
load 386  /  6684
size:  (375, 1242, 3)
load 387  /  6684
size:  (375, 1242, 3)
load 388  /  6684
size:  (375, 1242, 3)
load 389  /  6684
size:  (375, 1242, 3)
load 390  /  6684
size:  (375, 1242, 3)
load 391  /  6684
size:  (375, 1242, 3)
load 392  /  6684
size:  (375, 1242, 3)
load 393  /  6684
size:  (370, 1224, 3)
load 394  /  6684
size:  (375, 1242, 3)
load 395  /  6684
size:  (375, 1242, 3)
load 396  /  6684
size:  (375, 1242, 3)
load 397  /  6684
size:  (375, 1242, 3)
load 398  /  6684
size:  (375, 1242, 3)
load 399  /  6684
size:  (375, 1242, 3)
load 400  /  6684
size:  (375, 1242, 3)
load 401  /  6684
size:  (375, 1242, 3)
load 402  /  6684
size:  (370, 1224, 3)
load 403  /  6684
size:  (375, 1242, 3)
load 404  /  6684
size:  (375, 1242, 3)
load 405  /  6684
size:  (375, 1242, 3)
load 406  /  6684
size:  (375, 1242, 3)
load 407  /  6684
size:  (370, 1224, 3)
load 408  /  6684
size:  (375, 1242, 3)
load 409  /  6684
size:  (375, 1242, 3)
load 410  /  6684
size:  (375, 1242, 3)
load 411  /  6684
size:  (375, 1242, 3)
load 412  /  6684
size:  (375, 1242, 3)
load 413  /  6684
size:  (375, 1242, 3)
load 414  /  6684
size:  (370, 1224, 3)
load 415  /  6684
size:  (375, 1242, 3)
load 416  /  6684
size:  (375, 1242, 3)
load 417  /  6684
size:  (375, 1242, 3)
load 418  /  6684
size:  (375, 1242, 3)
load 419  /  6684
size:  (375, 1242, 3)
load 420  /  6684
size:  (375, 1242, 3)
load 421  /  6684
size:  (375, 1242, 3)
load 422  /  6684
size:  (375, 1242, 3)
load 423  /  6684
size:  (375, 1242, 3)
load 424  /  6684
size:  (375, 1242, 3)
load 425  /  6684
size:  (375, 1242, 3)
load 426  /  6684
size:  (375, 1242, 3)
load 427  /  6684
size:  (375, 1242, 3)
load 428  /  6684
size:  (375, 1242, 3)
load 429  /  6684
size:  (374, 1238, 3)
load 430  /  6684
size:  (375, 1242, 3)
load 431  /  6684
size:  (375, 1242, 3)
load 432  /  6684
size:  (375, 1242, 3)
load 433  /  6684
size:  (375, 1242, 3)
load 434  /  6684
size:  (375, 1242, 3)
load 435  /  6684
size:  (375, 1242, 3)
load 436  /  6684
size:  (375, 1242, 3)
load 437  /  6684
size:  (375, 1242, 3)
load 438  /  6684
size:  (375, 1242, 3)
load 439  /  6684
size:  (375, 1242, 3)
load 440  /  6684
size:  (375, 1242, 3)
load 441  /  6684
size:  (375, 1242, 3)
load 442  /  6684
size:  (376, 1241, 3)
load 443  /  6684
size:  (375, 1242, 3)
load 444  /  6684
size:  (375, 1242, 3)
load 445  /  6684
size:  (370, 1224, 3)
load 446  /  6684
size:  (375, 1242, 3)
load 447  /  6684
size:  (375, 1242, 3)
load 448  /  6684
size:  (375, 1242, 3)
load 449  /  6684
size:  (375, 1242, 3)
load 450  /  6684
size:  (375, 1242, 3)
load 451  /  6684
size:  (375, 1242, 3)
load 452  /  6684
size:  (370, 1224, 3)
load 453  /  6684
size:  (375, 1242, 3)
load 454  /  6684
size:  (375, 1242, 3)
load 455  /  6684
size:  (375, 1242, 3)
load 456  /  6684
size:  (375, 1242, 3)
load 457  /  6684
size:  (375, 1242, 3)
load 458  /  6684
size:  (375, 1242, 3)
load 459  /  6684
size:  (375, 1242, 3)
load 460  /  6684
size:  (375, 1242, 3)
load 461  /  6684
size:  (376, 1241, 3)
load 462  /  6684
size:  (375, 1242, 3)
load 463  /  6684
size:  (374, 1238, 3)
load 464  /  6684
size:  (375, 1242, 3)
load 465  /  6684
size:  (375, 1242, 3)
load 466  /  6684
size:  (375, 1242, 3)
load 467  /  6684
size:  (375, 1242, 3)
load 468  /  6684
size:  (375, 1242, 3)
load 469  /  6684
size:  (375, 1242, 3)
load 470  /  6684
size:  (374, 1238, 3)
load 471  /  6684
size:  (376, 1241, 3)
load 472  /  6684
size:  (375, 1242, 3)
load 473  /  6684
size:  (375, 1242, 3)
load 474  /  6684
size:  (370, 1224, 3)
load 475  /  6684
size:  (375, 1242, 3)
load 476  /  6684
size:  (375, 1242, 3)
load 477  /  6684
size:  (375, 1242, 3)
load 478  /  6684
size:  (370, 1224, 3)
load 479  /  6684
size:  (375, 1242, 3)
load 480  /  6684
size:  (375, 1242, 3)
load 481  /  6684
size:  (375, 1242, 3)
load 482  /  6684
size:  (375, 1242, 3)
load 483  /  6684
size:  (375, 1242, 3)
load 484  /  6684
size:  (375, 1242, 3)
load 485  /  6684
size:  (375, 1242, 3)
load 486  /  6684
size:  (375, 1242, 3)
load 487  /  6684
size:  (375, 1242, 3)
load 488  /  6684
size:  (375, 1242, 3)
load 489  /  6684
size:  (375, 1242, 3)
load 490  /  6684
size:  (375, 1242, 3)
load 491  /  6684
size:  (375, 1242, 3)
load 492  /  6684
size:  (375, 1242, 3)
load 493  /  6684
size:  (375, 1242, 3)
load 494  /  6684
size:  (376, 1241, 3)
load 495  /  6684
size:  (375, 1242, 3)
load 496  /  6684
size:  (375, 1242, 3)
load 497  /  6684
size:  (375, 1242, 3)
load 498  /  6684
size:  (375, 1242, 3)
load 499  /  6684
size:  (375, 1242, 3)
load 500  /  6684
size:  (374, 1238, 3)
load 501  /  6684
size:  (376, 1241, 3)
load 502  /  6684
size:  (374, 1238, 3)
load 503  /  6684
size:  (375, 1242, 3)
load 504  /  6684
size:  (375, 1242, 3)
load 505  /  6684
size:  (375, 1242, 3)
load 506  /  6684
size:  (375, 1242, 3)
load 507  /  6684
size:  (375, 1242, 3)
load 508  /  6684
size:  (375, 1242, 3)
load 509  /  6684
size:  (375, 1242, 3)
load 510  /  6684
size:  (375, 1242, 3)
load 511  /  6684
size:  (375, 1242, 3)
load 512  /  6684
size:  (375, 1242, 3)
load 513  /  6684
size:  (375, 1242, 3)
load 514  /  6684
size:  (374, 1238, 3)
load 515  /  6684
size:  (376, 1241, 3)
load 516  /  6684
size:  (375, 1242, 3)
load 517  /  6684
size:  (375, 1242, 3)
load 518  /  6684
size:  (375, 1242, 3)
load 519  /  6684
size:  (375, 1242, 3)
load 520  /  6684
size:  (375, 1242, 3)
load 521  /  6684
size:  (375, 1242, 3)
load 522  /  6684
size:  (375, 1242, 3)
load 523  /  6684
size:  (375, 1242, 3)
load 524  /  6684
size:  (375, 1242, 3)
load 525  /  6684
size:  (375, 1242, 3)
load 526  /  6684
size:  (375, 1242, 3)
load 527  /  6684
size:  (375, 1242, 3)
load 528  /  6684
size:  (375, 1242, 3)
load 529  /  6684
size:  (375, 1242, 3)
load 530  /  6684
size:  (375, 1242, 3)
load 531  /  6684
size:  (375, 1242, 3)
load 532  /  6684
size:  (375, 1242, 3)
load 533  /  6684
size:  (375, 1242, 3)
load 534  /  6684
size:  (375, 1242, 3)
load 535  /  6684
size:  (375, 1242, 3)
load 536  /  6684
size:  (375, 1242, 3)
load 537  /  6684
size:  (375, 1242, 3)
load 538  /  6684
size:  (374, 1238, 3)
load 539  /  6684
size:  (375, 1242, 3)
load 540  /  6684
size:  (375, 1242, 3)
load 541  /  6684
size:  (376, 1241, 3)
load 542  /  6684
size:  (375, 1242, 3)
load 543  /  6684
size:  (375, 1242, 3)
load 544  /  6684
size:  (370, 1224, 3)
load 545  /  6684
size:  (375, 1242, 3)
load 546  /  6684
size:  (375, 1242, 3)
load 547  /  6684
size:  (375, 1242, 3)
load 548  /  6684
size:  (375, 1242, 3)
load 549  /  6684
size:  (375, 1242, 3)
load 550  /  6684
size:  (375, 1242, 3)
load 551  /  6684
size:  (375, 1242, 3)
load 552  /  6684
size:  (375, 1242, 3)
load 553  /  6684
size:  (375, 1242, 3)
load 554  /  6684
size:  (375, 1242, 3)
load 555  /  6684
size:  (375, 1242, 3)
load 556  /  6684
size:  (375, 1242, 3)
load 557  /  6684
size:  (375, 1242, 3)
load 558  /  6684
size:  (375, 1242, 3)
load 559  /  6684
size:  (375, 1242, 3)
load 560  /  6684
size:  (375, 1242, 3)
load 561  /  6684
size:  (375, 1242, 3)
load 562  /  6684
size:  (375, 1242, 3)
load 563  /  6684
size:  (375, 1242, 3)
load 564  /  6684
size:  (375, 1242, 3)
load 565  /  6684
size:  (375, 1242, 3)
load 566  /  6684
size:  (375, 1242, 3)
load 567  /  6684
size:  (375, 1242, 3)
load 568  /  6684
size:  (375, 1242, 3)
load 569  /  6684
size:  (375, 1242, 3)
load 570  /  6684
size:  (375, 1242, 3)
load 571  /  6684
size:  (375, 1242, 3)
load 572  /  6684
size:  (375, 1242, 3)
load 573  /  6684
size:  (375, 1242, 3)
load 574  /  6684
size:  (375, 1242, 3)
load 575  /  6684
size:  (370, 1224, 3)
load 576  /  6684
size:  (375, 1242, 3)
load 577  /  6684
size:  (375, 1242, 3)
load 578  /  6684
size:  (374, 1238, 3)
load 579  /  6684
size:  (375, 1242, 3)
load 580  /  6684
size:  (375, 1242, 3)
load 581  /  6684
size:  (375, 1242, 3)
load 582  /  6684
size:  (375, 1242, 3)
load 583  /  6684
size:  (374, 1238, 3)
load 584  /  6684
size:  (376, 1241, 3)
load 585  /  6684
size:  (375, 1242, 3)
load 586  /  6684
size:  (375, 1242, 3)
load 587  /  6684
size:  (375, 1242, 3)
load 588  /  6684
size:  (375, 1242, 3)
load 589  /  6684
size:  (375, 1242, 3)
load 590  /  6684
size:  (375, 1242, 3)
load 591  /  6684
size:  (375, 1242, 3)
load 592  /  6684
size:  (375, 1242, 3)
load 593  /  6684
size:  (374, 1238, 3)
load 594  /  6684
size:  (375, 1242, 3)
load 595  /  6684
size:  (375, 1242, 3)
load 596  /  6684
size:  (375, 1242, 3)
load 597  /  6684
size:  (375, 1242, 3)
load 598  /  6684
size:  (375, 1242, 3)
load 599  /  6684
size:  (375, 1242, 3)
load 600  /  6684
size:  (374, 1238, 3)
load 601  /  6684
size:  (375, 1242, 3)
load 602  /  6684
size:  (375, 1242, 3)
load 603  /  6684
size:  (375, 1242, 3)
load 604  /  6684
size:  (375, 1242, 3)
load 605  /  6684
size:  (376, 1241, 3)
load 606  /  6684
size:  (375, 1242, 3)
load 607  /  6684
size:  (375, 1242, 3)
load 608  /  6684
size:  (375, 1242, 3)
load 609  /  6684
size:  (375, 1242, 3)
load 610  /  6684
size:  (374, 1238, 3)
load 611  /  6684
size:  (375, 1242, 3)
load 612  /  6684
size:  (375, 1242, 3)
load 613  /  6684
size:  (374, 1238, 3)
load 614  /  6684
size:  (375, 1242, 3)
load 615  /  6684
size:  (375, 1242, 3)
load 616  /  6684
size:  (375, 1242, 3)
load 617  /  6684
size:  (375, 1242, 3)
load 618  /  6684
size:  (375, 1242, 3)
load 619  /  6684
size:  (375, 1242, 3)
load 620  /  6684
size:  (375, 1242, 3)
load 621  /  6684
size:  (375, 1242, 3)
load 622  /  6684
size:  (375, 1242, 3)
load 623  /  6684
size:  (375, 1242, 3)
load 624  /  6684
size:  (375, 1242, 3)
load 625  /  6684
size:  (375, 1242, 3)
load 626  /  6684
size:  (375, 1242, 3)
load 627  /  6684
size:  (375, 1242, 3)
load 628  /  6684
size:  (375, 1242, 3)
load 629  /  6684
size:  (375, 1242, 3)
load 630  /  6684
size:  (375, 1242, 3)
load 631  /  6684
size:  (375, 1242, 3)
load 632  /  6684
size:  (375, 1242, 3)
load 633  /  6684
size:  (375, 1242, 3)
load 634  /  6684
size:  (375, 1242, 3)
load 635  /  6684
size:  (375, 1242, 3)
load 636  /  6684
size:  (375, 1242, 3)
load 637  /  6684
size:  (375, 1242, 3)
load 638  /  6684
size:  (375, 1242, 3)
load 639  /  6684
size:  (375, 1242, 3)
load 640  /  6684
size:  (375, 1242, 3)
load 641  /  6684
size:  (375, 1242, 3)
load 642  /  6684
size:  (375, 1242, 3)
load 643  /  6684
size:  (375, 1242, 3)
load 644  /  6684
size:  (375, 1242, 3)
load 645  /  6684
size:  (375, 1242, 3)
load 646  /  6684
size:  (375, 1242, 3)
load 647  /  6684
size:  (375, 1242, 3)
load 648  /  6684
size:  (375, 1242, 3)
load 649  /  6684
size:  (374, 1238, 3)
load 650  /  6684
size:  (375, 1242, 3)
load 651  /  6684
size:  (375, 1242, 3)
load 652  /  6684
size:  (375, 1242, 3)
load 653  /  6684
size:  (376, 1241, 3)
load 654  /  6684
size:  (374, 1238, 3)
load 655  /  6684
size:  (375, 1242, 3)
load 656  /  6684
size:  (375, 1242, 3)
load 657  /  6684
size:  (375, 1242, 3)
load 658  /  6684
size:  (375, 1242, 3)
load 659  /  6684
size:  (375, 1242, 3)
load 660  /  6684
size:  (375, 1242, 3)
load 661  /  6684
size:  (375, 1242, 3)
load 662  /  6684
size:  (375, 1242, 3)
load 663  /  6684
size:  (375, 1242, 3)
load 664  /  6684
size:  (375, 1242, 3)
load 665  /  6684
size:  (375, 1242, 3)
load 666  /  6684
size:  (375, 1242, 3)
load 667  /  6684
size:  (376, 1241, 3)
load 668  /  6684
size:  (375, 1242, 3)
load 669  /  6684
size:  (375, 1242, 3)
load 670  /  6684
size:  (376, 1241, 3)
load 671  /  6684
size:  (375, 1242, 3)
load 672  /  6684
size:  (375, 1242, 3)
load 673  /  6684
size:  (375, 1242, 3)
load 674  /  6684
size:  (375, 1242, 3)
load 675  /  6684
size:  (375, 1242, 3)
load 676  /  6684
size:  (376, 1241, 3)
load 677  /  6684
size:  (375, 1242, 3)
load 678  /  6684
size:  (375, 1242, 3)
load 679  /  6684
size:  (375, 1242, 3)
load 680  /  6684
size:  (376, 1241, 3)
load 681  /  6684
size:  (375, 1242, 3)
load 682  /  6684
size:  (375, 1242, 3)
load 683  /  6684
size:  (375, 1242, 3)
load 684  /  6684
size:  (375, 1242, 3)
load 685  /  6684
size:  (375, 1242, 3)
load 686  /  6684
size:  (375, 1242, 3)
load 687  /  6684
size:  (375, 1242, 3)
load 688  /  6684
size:  (370, 1224, 3)
load 689  /  6684
size:  (370, 1224, 3)
load 690  /  6684
size:  (375, 1242, 3)
load 691  /  6684
size:  (375, 1242, 3)
load 692  /  6684
size:  (376, 1241, 3)
load 693  /  6684
size:  (370, 1224, 3)
load 694  /  6684
size:  (375, 1242, 3)
load 695  /  6684
size:  (375, 1242, 3)
load 696  /  6684
size:  (375, 1242, 3)
load 697  /  6684
size:  (375, 1242, 3)
load 698  /  6684
size:  (375, 1242, 3)
load 699  /  6684
size:  (375, 1242, 3)
load 700  /  6684
size:  (375, 1242, 3)
load 701  /  6684
size:  (375, 1242, 3)
load 702  /  6684
size:  (375, 1242, 3)
load 703  /  6684
size:  (375, 1242, 3)
load 704  /  6684
size:  (375, 1242, 3)
load 705  /  6684
size:  (375, 1242, 3)
load 706  /  6684
size:  (375, 1242, 3)
load 707  /  6684
size:  (375, 1242, 3)
load 708  /  6684
size:  (375, 1242, 3)
load 709  /  6684
size:  (375, 1242, 3)
load 710  /  6684
size:  (375, 1242, 3)
load 711  /  6684
size:  (375, 1242, 3)
load 712  /  6684
size:  (375, 1242, 3)
load 713  /  6684
size:  (374, 1238, 3)
load 714  /  6684
size:  (375, 1242, 3)
load 715  /  6684
size:  (375, 1242, 3)
load 716  /  6684
size:  (375, 1242, 3)
load 717  /  6684
size:  (375, 1242, 3)
load 718  /  6684
size:  (375, 1242, 3)
load 719  /  6684
size:  (375, 1242, 3)
load 720  /  6684
size:  (376, 1241, 3)
load 721  /  6684
size:  (375, 1242, 3)
load 722  /  6684
size:  (375, 1242, 3)
load 723  /  6684
size:  (375, 1242, 3)
load 724  /  6684
size:  (375, 1242, 3)
load 725  /  6684
size:  (376, 1241, 3)
load 726  /  6684
size:  (375, 1242, 3)
load 727  /  6684
size:  (375, 1242, 3)
load 728  /  6684
size:  (375, 1242, 3)
load 729  /  6684
size:  (375, 1242, 3)
load 730  /  6684
size:  (375, 1242, 3)
load 731  /  6684
size:  (375, 1242, 3)
load 732  /  6684
size:  (375, 1242, 3)
load 733  /  6684
size:  (375, 1242, 3)
load 734  /  6684
size:  (374, 1238, 3)
load 735  /  6684
size:  (375, 1242, 3)
load 736  /  6684
size:  (375, 1242, 3)
load 737  /  6684
size:  (376, 1241, 3)
load 738  /  6684
size:  (375, 1242, 3)
load 739  /  6684
size:  (375, 1242, 3)
load 740  /  6684
size:  (374, 1238, 3)
load 741  /  6684
size:  (375, 1242, 3)
load 742  /  6684
size:  (375, 1242, 3)
load 743  /  6684
size:  (375, 1242, 3)
load 744  /  6684
size:  (375, 1242, 3)
load 745  /  6684
size:  (375, 1242, 3)
load 746  /  6684
size:  (375, 1242, 3)
load 747  /  6684
size:  (375, 1242, 3)
load 748  /  6684
size:  (375, 1242, 3)
load 749  /  6684
size:  (375, 1242, 3)
load 750  /  6684
size:  (375, 1242, 3)
load 751  /  6684
size:  (375, 1242, 3)
load 752  /  6684
size:  (376, 1241, 3)
load 753  /  6684
size:  (375, 1242, 3)
load 754  /  6684
size:  (375, 1242, 3)
load 755  /  6684
size:  (375, 1242, 3)
load 756  /  6684
size:  (375, 1242, 3)
load 757  /  6684
size:  (375, 1242, 3)
load 758  /  6684
size:  (375, 1242, 3)
load 759  /  6684
size:  (375, 1242, 3)
load 760  /  6684
size:  (375, 1242, 3)
load 761  /  6684
size:  (375, 1242, 3)
load 762  /  6684
size:  (375, 1242, 3)
load 763  /  6684
size:  (376, 1241, 3)
load 764  /  6684
size:  (375, 1242, 3)
load 765  /  6684
size:  (375, 1242, 3)
load 766  /  6684
size:  (375, 1242, 3)
load 767  /  6684
size:  (375, 1242, 3)
load 768  /  6684
size:  (375, 1242, 3)
load 769  /  6684
size:  (375, 1242, 3)
load 770  /  6684
size:  (375, 1242, 3)
load 771  /  6684
size:  (375, 1242, 3)
load 772  /  6684
size:  (375, 1242, 3)
load 773  /  6684
size:  (375, 1242, 3)
load 774  /  6684
size:  (375, 1242, 3)
load 775  /  6684
size:  (375, 1242, 3)
load 776  /  6684
size:  (375, 1242, 3)
load 777  /  6684
size:  (375, 1242, 3)
load 778  /  6684
size:  (375, 1242, 3)
load 779  /  6684
size:  (375, 1242, 3)
load 780  /  6684
size:  (376, 1241, 3)
load 781  /  6684
size:  (375, 1242, 3)
load 782  /  6684
size:  (375, 1242, 3)
load 783  /  6684
size:  (375, 1242, 3)
load 784  /  6684
size:  (375, 1242, 3)
load 785  /  6684
size:  (375, 1242, 3)
load 786  /  6684
size:  (376, 1241, 3)
load 787  /  6684
size:  (375, 1242, 3)
load 788  /  6684
size:  (375, 1242, 3)
load 789  /  6684
size:  (375, 1242, 3)
load 790  /  6684
size:  (375, 1242, 3)
load 791  /  6684
size:  (375, 1242, 3)
load 792  /  6684
size:  (375, 1242, 3)
load 793  /  6684
size:  (375, 1242, 3)
load 794  /  6684
size:  (375, 1242, 3)
load 795  /  6684
size:  (375, 1242, 3)
load 796  /  6684
size:  (375, 1242, 3)
load 797  /  6684
size:  (375, 1242, 3)
load 798  /  6684
size:  (375, 1242, 3)
load 799  /  6684
size:  (370, 1224, 3)
load 800  /  6684
size:  (375, 1242, 3)
load 801  /  6684
size:  (375, 1242, 3)
load 802  /  6684
size:  (375, 1242, 3)
load 803  /  6684
size:  (375, 1242, 3)
load 804  /  6684
size:  (375, 1242, 3)
load 805  /  6684
size:  (375, 1242, 3)
load 806  /  6684
size:  (375, 1242, 3)
load 807  /  6684
size:  (375, 1242, 3)
load 808  /  6684
size:  (375, 1242, 3)
load 809  /  6684
size:  (375, 1242, 3)
load 810  /  6684
size:  (375, 1242, 3)
load 811  /  6684
size:  (375, 1242, 3)
load 812  /  6684
size:  (375, 1242, 3)
load 813  /  6684
size:  (375, 1242, 3)
load 814  /  6684
size:  (375, 1242, 3)
load 815  /  6684
size:  (375, 1242, 3)
load 816  /  6684
size:  (375, 1242, 3)
load 817  /  6684
size:  (375, 1242, 3)
load 818  /  6684
size:  (375, 1242, 3)
load 819  /  6684
size:  (375, 1242, 3)
load 820  /  6684
size:  (374, 1238, 3)
load 821  /  6684
size:  (375, 1242, 3)
load 822  /  6684
size:  (375, 1242, 3)
load 823  /  6684
size:  (375, 1242, 3)
load 824  /  6684
size:  (375, 1242, 3)
load 825  /  6684
size:  (375, 1242, 3)
load 826  /  6684
size:  (375, 1242, 3)
load 827  /  6684
size:  (375, 1242, 3)
load 828  /  6684
size:  (375, 1242, 3)
load 829  /  6684
size:  (375, 1242, 3)
load 830  /  6684
size:  (375, 1242, 3)
load 831  /  6684
size:  (375, 1242, 3)
load 832  /  6684
size:  (375, 1242, 3)
load 833  /  6684
size:  (370, 1224, 3)
load 834  /  6684
size:  (375, 1242, 3)
load 835  /  6684
size:  (375, 1242, 3)
load 836  /  6684
size:  (375, 1242, 3)
load 837  /  6684
size:  (375, 1242, 3)
load 838  /  6684
size:  (375, 1242, 3)
load 839  /  6684
size:  (375, 1242, 3)
load 840  /  6684
size:  (375, 1242, 3)
load 841  /  6684
size:  (375, 1242, 3)
load 842  /  6684
size:  (375, 1242, 3)
load 843  /  6684
size:  (375, 1242, 3)
load 844  /  6684
size:  (375, 1242, 3)
load 845  /  6684
size:  (375, 1242, 3)
load 846  /  6684
size:  (375, 1242, 3)
load 847  /  6684
size:  (375, 1242, 3)
load 848  /  6684
size:  (375, 1242, 3)
load 849  /  6684
size:  (375, 1242, 3)
load 850  /  6684
size:  (375, 1242, 3)
load 851  /  6684
size:  (375, 1242, 3)
load 852  /  6684
size:  (375, 1242, 3)
load 853  /  6684
size:  (375, 1242, 3)
load 854  /  6684
size:  (375, 1242, 3)
load 855  /  6684
size:  (375, 1242, 3)
load 856  /  6684
size:  (375, 1242, 3)
load 857  /  6684
size:  (375, 1242, 3)
load 858  /  6684
size:  (375, 1242, 3)
load 859  /  6684
size:  (375, 1242, 3)
load 860  /  6684
size:  (376, 1241, 3)
load 861  /  6684
size:  (375, 1242, 3)
load 862  /  6684
size:  (375, 1242, 3)
load 863  /  6684
size:  (375, 1242, 3)
load 864  /  6684
size:  (375, 1242, 3)
load 865  /  6684
size:  (375, 1242, 3)
load 866  /  6684
size:  (374, 1238, 3)
load 867  /  6684
size:  (375, 1242, 3)
load 868  /  6684
size:  (376, 1241, 3)
load 869  /  6684
size:  (375, 1242, 3)
load 870  /  6684
size:  (375, 1242, 3)
load 871  /  6684
size:  (375, 1242, 3)
load 872  /  6684
size:  (375, 1242, 3)
load 873  /  6684
size:  (375, 1242, 3)
load 874  /  6684
size:  (375, 1242, 3)
load 875  /  6684
size:  (375, 1242, 3)
load 876  /  6684
size:  (375, 1242, 3)
load 877  /  6684
size:  (375, 1242, 3)
load 878  /  6684
size:  (375, 1242, 3)
load 879  /  6684
size:  (375, 1242, 3)
load 880  /  6684
size:  (375, 1242, 3)
load 881  /  6684
size:  (375, 1242, 3)
load 882  /  6684
size:  (375, 1242, 3)
load 883  /  6684
size:  (375, 1242, 3)
load 884  /  6684
size:  (375, 1242, 3)
load 885  /  6684
size:  (376, 1241, 3)
load 886  /  6684
size:  (375, 1242, 3)
load 887  /  6684
size:  (375, 1242, 3)
load 888  /  6684
size:  (375, 1242, 3)
load 889  /  6684
size:  (374, 1238, 3)
load 890  /  6684
size:  (375, 1242, 3)
load 891  /  6684
size:  (375, 1242, 3)
load 892  /  6684
size:  (375, 1242, 3)
load 893  /  6684
size:  (375, 1242, 3)
load 894  /  6684
size:  (375, 1242, 3)
load 895  /  6684
size:  (374, 1238, 3)
load 896  /  6684
size:  (375, 1242, 3)
load 897  /  6684
size:  (375, 1242, 3)
load 898  /  6684
size:  (375, 1242, 3)
load 899  /  6684
size:  (374, 1238, 3)
load 900  /  6684
size:  (375, 1242, 3)
load 901  /  6684
size:  (375, 1242, 3)
load 902  /  6684
size:  (375, 1242, 3)
load 903  /  6684
size:  (375, 1242, 3)
load 904  /  6684
size:  (375, 1242, 3)
load 905  /  6684
size:  (375, 1242, 3)
load 906  /  6684
size:  (375, 1242, 3)
load 907  /  6684
size:  (375, 1242, 3)
load 908  /  6684
size:  (374, 1238, 3)
load 909  /  6684
size:  (374, 1238, 3)
load 910  /  6684
size:  (375, 1242, 3)
load 911  /  6684
size:  (375, 1242, 3)
load 912  /  6684
size:  (375, 1242, 3)
load 913  /  6684
size:  (376, 1241, 3)
load 914  /  6684
size:  (375, 1242, 3)
load 915  /  6684
size:  (375, 1242, 3)
load 916  /  6684
size:  (375, 1242, 3)
load 917  /  6684
size:  (375, 1242, 3)
load 918  /  6684
size:  (375, 1242, 3)
load 919  /  6684
size:  (374, 1238, 3)
load 920  /  6684
size:  (375, 1242, 3)
load 921  /  6684
size:  (370, 1224, 3)
load 922  /  6684
size:  (375, 1242, 3)
load 923  /  6684
size:  (375, 1242, 3)
load 924  /  6684
size:  (375, 1242, 3)
load 925  /  6684
size:  (375, 1242, 3)
load 926  /  6684
size:  (375, 1242, 3)
load 927  /  6684
size:  (370, 1224, 3)
load 928  /  6684
size:  (375, 1242, 3)
load 929  /  6684
size:  (375, 1242, 3)
load 930  /  6684
size:  (375, 1242, 3)
load 931  /  6684
size:  (375, 1242, 3)
load 932  /  6684
size:  (375, 1242, 3)
load 933  /  6684
size:  (375, 1242, 3)
load 934  /  6684
size:  (375, 1242, 3)
load 935  /  6684
size:  (375, 1242, 3)
load 936  /  6684
size:  (375, 1242, 3)
load 937  /  6684
size:  (375, 1242, 3)
load 938  /  6684
size:  (375, 1242, 3)
load 939  /  6684
size:  (375, 1242, 3)
load 940  /  6684
size:  (374, 1238, 3)
load 941  /  6684
size:  (375, 1242, 3)
load 942  /  6684
size:  (375, 1242, 3)
load 943  /  6684
size:  (370, 1224, 3)
load 944  /  6684
size:  (375, 1242, 3)
load 945  /  6684
size:  (375, 1242, 3)
load 946  /  6684
size:  (375, 1242, 3)
load 947  /  6684
size:  (375, 1242, 3)
load 948  /  6684
size:  (376, 1241, 3)
load 949  /  6684
size:  (375, 1242, 3)
load 950  /  6684
size:  (375, 1242, 3)
load 951  /  6684
size:  (375, 1242, 3)
load 952  /  6684
size:  (375, 1242, 3)
load 953  /  6684
size:  (375, 1242, 3)
load 954  /  6684
size:  (375, 1242, 3)
load 955  /  6684
size:  (375, 1242, 3)
load 956  /  6684
size:  (375, 1242, 3)
load 957  /  6684
size:  (375, 1242, 3)
load 958  /  6684
size:  (375, 1242, 3)
load 959  /  6684
size:  (375, 1242, 3)
load 960  /  6684
size:  (375, 1242, 3)
load 961  /  6684
size:  (374, 1238, 3)
load 962  /  6684
size:  (370, 1224, 3)
load 963  /  6684
size:  (374, 1238, 3)
load 964  /  6684
size:  (375, 1242, 3)
load 965  /  6684
size:  (375, 1242, 3)
load 966  /  6684
size:  (375, 1242, 3)
load 967  /  6684
size:  (375, 1242, 3)
load 968  /  6684
size:  (375, 1242, 3)
load 969  /  6684
size:  (375, 1242, 3)
load 970  /  6684
size:  (375, 1242, 3)
load 971  /  6684
size:  (375, 1242, 3)
load 972  /  6684
size:  (375, 1242, 3)
load 973  /  6684
size:  (375, 1242, 3)
load 974  /  6684
size:  (375, 1242, 3)
load 975  /  6684
size:  (375, 1242, 3)
load 976  /  6684
size:  (375, 1242, 3)
load 977  /  6684
size:  (375, 1242, 3)
load 978  /  6684
size:  (374, 1238, 3)
load 979  /  6684
size:  (375, 1242, 3)
load 980  /  6684
size:  (375, 1242, 3)
load 981  /  6684
size:  (375, 1242, 3)
load 982  /  6684
size:  (375, 1242, 3)
load 983  /  6684
size:  (375, 1242, 3)
load 984  /  6684
size:  (375, 1242, 3)
load 985  /  6684
size:  (375, 1242, 3)
load 986  /  6684
size:  (375, 1242, 3)
load 987  /  6684
size:  (375, 1242, 3)
load 988  /  6684
size:  (375, 1242, 3)
load 989  /  6684
size:  (375, 1242, 3)
load 990  /  6684
size:  (375, 1242, 3)
load 991  /  6684
size:  (375, 1242, 3)
load 992  /  6684
size:  (374, 1238, 3)
load 993  /  6684
size:  (375, 1242, 3)
load 994  /  6684
size:  (375, 1242, 3)
load 995  /  6684
size:  (376, 1241, 3)
load 996  /  6684
size:  (375, 1242, 3)
load 997  /  6684
size:  (375, 1242, 3)
load 998  /  6684
size:  (375, 1242, 3)
load 999  /  6684
size:  (375, 1242, 3)
load 1000  /  6684
size:  (375, 1242, 3)
load 1001  /  6684
size:  (375, 1242, 3)
load 1002  /  6684
size:  (375, 1242, 3)
load 1003  /  6684
size:  (375, 1242, 3)
load 1004  /  6684
size:  (375, 1242, 3)
load 1005  /  6684
size:  (375, 1242, 3)
load 1006  /  6684
size:  (375, 1242, 3)
load 1007  /  6684
size:  (375, 1242, 3)
load 1008  /  6684
size:  (375, 1242, 3)
load 1009  /  6684
size:  (375, 1242, 3)
load 1010  /  6684
size:  (375, 1242, 3)
load 1011  /  6684
size:  (375, 1242, 3)
load 1012  /  6684
size:  (375, 1242, 3)
load 1013  /  6684
size:  (375, 1242, 3)
load 1014  /  6684
size:  (375, 1242, 3)
load 1015  /  6684
size:  (375, 1242, 3)
load 1016  /  6684
size:  (375, 1242, 3)
load 1017  /  6684
size:  (374, 1238, 3)
load 1018  /  6684
size:  (375, 1242, 3)
load 1019  /  6684
size:  (375, 1242, 3)
load 1020  /  6684
size:  (375, 1242, 3)
load 1021  /  6684
size:  (375, 1242, 3)
load 1022  /  6684
size:  (375, 1242, 3)
load 1023  /  6684
size:  (375, 1242, 3)
load 1024  /  6684
size:  (375, 1242, 3)
load 1025  /  6684
size:  (376, 1241, 3)
load 1026  /  6684
size:  (375, 1242, 3)
load 1027  /  6684
size:  (375, 1242, 3)
load 1028  /  6684
size:  (375, 1242, 3)
load 1029  /  6684
size:  (375, 1242, 3)
load 1030  /  6684
size:  (375, 1242, 3)
load 1031  /  6684
size:  (375, 1242, 3)
load 1032  /  6684
size:  (375, 1242, 3)
load 1033  /  6684
size:  (375, 1242, 3)
load 1034  /  6684
size:  (375, 1242, 3)
load 1035  /  6684
size:  (375, 1242, 3)
load 1036  /  6684
size:  (375, 1242, 3)
load 1037  /  6684
size:  (374, 1238, 3)
load 1038  /  6684
size:  (375, 1242, 3)
load 1039  /  6684
size:  (375, 1242, 3)
load 1040  /  6684
size:  (375, 1242, 3)
load 1041  /  6684
size:  (375, 1242, 3)
load 1042  /  6684
size:  (375, 1242, 3)
load 1043  /  6684
size:  (375, 1242, 3)
load 1044  /  6684
size:  (376, 1241, 3)
load 1045  /  6684
size:  (375, 1242, 3)
load 1046  /  6684
size:  (375, 1242, 3)
load 1047  /  6684
size:  (375, 1242, 3)
load 1048  /  6684
size:  (374, 1238, 3)
load 1049  /  6684
size:  (375, 1242, 3)
load 1050  /  6684
size:  (375, 1242, 3)
load 1051  /  6684
size:  (375, 1242, 3)
load 1052  /  6684
size:  (375, 1242, 3)
load 1053  /  6684
size:  (375, 1242, 3)
load 1054  /  6684
size:  (375, 1242, 3)
load 1055  /  6684
size:  (375, 1242, 3)
load 1056  /  6684
size:  (375, 1242, 3)
load 1057  /  6684
size:  (375, 1242, 3)
load 1058  /  6684
size:  (375, 1242, 3)
load 1059  /  6684
size:  (375, 1242, 3)
load 1060  /  6684
size:  (375, 1242, 3)
load 1061  /  6684
size:  (375, 1242, 3)
load 1062  /  6684
size:  (375, 1242, 3)
load 1063  /  6684
size:  (370, 1224, 3)
load 1064  /  6684
size:  (375, 1242, 3)
load 1065  /  6684
size:  (375, 1242, 3)
load 1066  /  6684
size:  (375, 1242, 3)
load 1067  /  6684
size:  (370, 1224, 3)
load 1068  /  6684
size:  (375, 1242, 3)
load 1069  /  6684
size:  (375, 1242, 3)
load 1070  /  6684
size:  (370, 1224, 3)
load 1071  /  6684
size:  (375, 1242, 3)
load 1072  /  6684
size:  (375, 1242, 3)
load 1073  /  6684
size:  (374, 1238, 3)
load 1074  /  6684
size:  (375, 1242, 3)
load 1075  /  6684
size:  (376, 1241, 3)
load 1076  /  6684
size:  (375, 1242, 3)
load 1077  /  6684
size:  (375, 1242, 3)
load 1078  /  6684
size:  (375, 1242, 3)
load 1079  /  6684
size:  (375, 1242, 3)
load 1080  /  6684
size:  (375, 1242, 3)
load 1081  /  6684
size:  (375, 1242, 3)
load 1082  /  6684
size:  (375, 1242, 3)
load 1083  /  6684
size:  (375, 1242, 3)
load 1084  /  6684
size:  (375, 1242, 3)
load 1085  /  6684
size:  (375, 1242, 3)
load 1086  /  6684
size:  (375, 1242, 3)
load 1087  /  6684
size:  (375, 1242, 3)
load 1088  /  6684
size:  (375, 1242, 3)
load 1089  /  6684
size:  (375, 1242, 3)
load 1090  /  6684
size:  (375, 1242, 3)
load 1091  /  6684
size:  (375, 1242, 3)
load 1092  /  6684
size:  (375, 1242, 3)
load 1093  /  6684
size:  (375, 1242, 3)
load 1094  /  6684
size:  (375, 1242, 3)
load 1095  /  6684
size:  (375, 1242, 3)
load 1096  /  6684
size:  (375, 1242, 3)
load 1097  /  6684
size:  (375, 1242, 3)
load 1098  /  6684
size:  (375, 1242, 3)
load 1099  /  6684
size:  (375, 1242, 3)
load 1100  /  6684
size:  (375, 1242, 3)
load 1101  /  6684
size:  (375, 1242, 3)
load 1102  /  6684
size:  (375, 1242, 3)
load 1103  /  6684
size:  (375, 1242, 3)
load 1104  /  6684
size:  (375, 1242, 3)
load 1105  /  6684
size:  (375, 1242, 3)
load 1106  /  6684
size:  (375, 1242, 3)
load 1107  /  6684
size:  (375, 1242, 3)
load 1108  /  6684
size:  (375, 1242, 3)
load 1109  /  6684
size:  (375, 1242, 3)
load 1110  /  6684
size:  (375, 1242, 3)
load 1111  /  6684
size:  (375, 1242, 3)
load 1112  /  6684
size:  (374, 1238, 3)
load 1113  /  6684
size:  (375, 1242, 3)
load 1114  /  6684
size:  (375, 1242, 3)
load 1115  /  6684
size:  (375, 1242, 3)
load 1116  /  6684
size:  (376, 1241, 3)
load 1117  /  6684
size:  (375, 1242, 3)
load 1118  /  6684
size:  (375, 1242, 3)
load 1119  /  6684
size:  (375, 1242, 3)
load 1120  /  6684
size:  (375, 1242, 3)
load 1121  /  6684
size:  (375, 1242, 3)
load 1122  /  6684
size:  (375, 1242, 3)
load 1123  /  6684
size:  (374, 1238, 3)
load 1124  /  6684
size:  (375, 1242, 3)
load 1125  /  6684
size:  (375, 1242, 3)
load 1126  /  6684
size:  (375, 1242, 3)
load 1127  /  6684
size:  (375, 1242, 3)
load 1128  /  6684
size:  (375, 1242, 3)
load 1129  /  6684
size:  (375, 1242, 3)
load 1130  /  6684
size:  (375, 1242, 3)
load 1131  /  6684
size:  (375, 1242, 3)
load 1132  /  6684
size:  (375, 1242, 3)
load 1133  /  6684
size:  (375, 1242, 3)
load 1134  /  6684
size:  (375, 1242, 3)
load 1135  /  6684
size:  (370, 1224, 3)
load 1136  /  6684
size:  (375, 1242, 3)
load 1137  /  6684
size:  (375, 1242, 3)
load 1138  /  6684
size:  (375, 1242, 3)
load 1139  /  6684
size:  (375, 1242, 3)
load 1140  /  6684
size:  (375, 1242, 3)
load 1141  /  6684
size:  (375, 1242, 3)
load 1142  /  6684
size:  (375, 1242, 3)
load 1143  /  6684
size:  (375, 1242, 3)
load 1144  /  6684
size:  (375, 1242, 3)
load 1145  /  6684
size:  (375, 1242, 3)
load 1146  /  6684
size:  (375, 1242, 3)
load 1147  /  6684
size:  (375, 1242, 3)
load 1148  /  6684
size:  (375, 1242, 3)
load 1149  /  6684
size:  (375, 1242, 3)
load 1150  /  6684
size:  (375, 1242, 3)
load 1151  /  6684
size:  (375, 1242, 3)
load 1152  /  6684
size:  (370, 1224, 3)
load 1153  /  6684
size:  (376, 1241, 3)
load 1154  /  6684
size:  (375, 1242, 3)
load 1155  /  6684
size:  (370, 1224, 3)
load 1156  /  6684
size:  (375, 1242, 3)
load 1157  /  6684
size:  (376, 1241, 3)
load 1158  /  6684
size:  (375, 1242, 3)
load 1159  /  6684
size:  (375, 1242, 3)
load 1160  /  6684
size:  (375, 1242, 3)
load 1161  /  6684
size:  (370, 1224, 3)
load 1162  /  6684
size:  (375, 1242, 3)
load 1163  /  6684
size:  (375, 1242, 3)
load 1164  /  6684
size:  (375, 1242, 3)
load 1165  /  6684
size:  (375, 1242, 3)
load 1166  /  6684
size:  (375, 1242, 3)
load 1167  /  6684
size:  (375, 1242, 3)
load 1168  /  6684
size:  (375, 1242, 3)
load 1169  /  6684
size:  (375, 1242, 3)
load 1170  /  6684
size:  (375, 1242, 3)
load 1171  /  6684
size:  (376, 1241, 3)
load 1172  /  6684
size:  (374, 1238, 3)
load 1173  /  6684
size:  (370, 1224, 3)
load 1174  /  6684
size:  (374, 1238, 3)
load 1175  /  6684
size:  (375, 1242, 3)
load 1176  /  6684
size:  (375, 1242, 3)
load 1177  /  6684
size:  (375, 1242, 3)
load 1178  /  6684
size:  (375, 1242, 3)
load 1179  /  6684
size:  (375, 1242, 3)
load 1180  /  6684
size:  (375, 1242, 3)
load 1181  /  6684
size:  (375, 1242, 3)
load 1182  /  6684
size:  (375, 1242, 3)
load 1183  /  6684
size:  (375, 1242, 3)
load 1184  /  6684
size:  (375, 1242, 3)
load 1185  /  6684
size:  (375, 1242, 3)
load 1186  /  6684
size:  (375, 1242, 3)
load 1187  /  6684
size:  (375, 1242, 3)
load 1188  /  6684
size:  (375, 1242, 3)
load 1189  /  6684
size:  (375, 1242, 3)
load 1190  /  6684
size:  (375, 1242, 3)
load 1191  /  6684
size:  (375, 1242, 3)
load 1192  /  6684
size:  (375, 1242, 3)
load 1193  /  6684
size:  (375, 1242, 3)
load 1194  /  6684
size:  (375, 1242, 3)
load 1195  /  6684
size:  (374, 1238, 3)
load 1196  /  6684
size:  (375, 1242, 3)
load 1197  /  6684
size:  (375, 1242, 3)
load 1198  /  6684
size:  (375, 1242, 3)
load 1199  /  6684
size:  (375, 1242, 3)
load 1200  /  6684
size:  (375, 1242, 3)
load 1201  /  6684
size:  (375, 1242, 3)
load 1202  /  6684
size:  (375, 1242, 3)
load 1203  /  6684
size:  (375, 1242, 3)
load 1204  /  6684
size:  (375, 1242, 3)
load 1205  /  6684
size:  (375, 1242, 3)
load 1206  /  6684
size:  (375, 1242, 3)
load 1207  /  6684
size:  (375, 1242, 3)
load 1208  /  6684
size:  (376, 1241, 3)
load 1209  /  6684
size:  (375, 1242, 3)
load 1210  /  6684
size:  (375, 1242, 3)
load 1211  /  6684
size:  (375, 1242, 3)
load 1212  /  6684
size:  (375, 1242, 3)
load 1213  /  6684
size:  (375, 1242, 3)
load 1214  /  6684
size:  (374, 1238, 3)
load 1215  /  6684
size:  (375, 1242, 3)
load 1216  /  6684
size:  (370, 1224, 3)
load 1217  /  6684
size:  (375, 1242, 3)
load 1218  /  6684
size:  (375, 1242, 3)
load 1219  /  6684
size:  (374, 1238, 3)
load 1220  /  6684
size:  (375, 1242, 3)
load 1221  /  6684
size:  (375, 1242, 3)
load 1222  /  6684
size:  (375, 1242, 3)
load 1223  /  6684
size:  (375, 1242, 3)
load 1224  /  6684
size:  (370, 1224, 3)
load 1225  /  6684
size:  (375, 1242, 3)
load 1226  /  6684
size:  (375, 1242, 3)
load 1227  /  6684
size:  (375, 1242, 3)
load 1228  /  6684
size:  (375, 1242, 3)
load 1229  /  6684
size:  (375, 1242, 3)
load 1230  /  6684
size:  (375, 1242, 3)
load 1231  /  6684
size:  (375, 1242, 3)
load 1232  /  6684
size:  (375, 1242, 3)
load 1233  /  6684
size:  (375, 1242, 3)
load 1234  /  6684
size:  (375, 1242, 3)
load 1235  /  6684
size:  (375, 1242, 3)
load 1236  /  6684
size:  (375, 1242, 3)
load 1237  /  6684
size:  (375, 1242, 3)
load 1238  /  6684
size:  (375, 1242, 3)
load 1239  /  6684
size:  (375, 1242, 3)
load 1240  /  6684
size:  (375, 1242, 3)
load 1241  /  6684
size:  (375, 1242, 3)
load 1242  /  6684
size:  (375, 1242, 3)
load 1243  /  6684
size:  (375, 1242, 3)
load 1244  /  6684
size:  (375, 1242, 3)
load 1245  /  6684
size:  (375, 1242, 3)
load 1246  /  6684
size:  (375, 1242, 3)
load 1247  /  6684
size:  (375, 1242, 3)
load 1248  /  6684
size:  (375, 1242, 3)
load 1249  /  6684
size:  (375, 1242, 3)
load 1250  /  6684
size:  (375, 1242, 3)
load 1251  /  6684
size:  (375, 1242, 3)
load 1252  /  6684
size:  (375, 1242, 3)
load 1253  /  6684
size:  (375, 1242, 3)
load 1254  /  6684
size:  (375, 1242, 3)
load 1255  /  6684
size:  (375, 1242, 3)
load 1256  /  6684
size:  (375, 1242, 3)
load 1257  /  6684
size:  (375, 1242, 3)
load 1258  /  6684
size:  (375, 1242, 3)
load 1259  /  6684
size:  (375, 1242, 3)
load 1260  /  6684
size:  (375, 1242, 3)
load 1261  /  6684
size:  (375, 1242, 3)
load 1262  /  6684
size:  (375, 1242, 3)
load 1263  /  6684
size:  (375, 1242, 3)
load 1264  /  6684
size:  (375, 1242, 3)
load 1265  /  6684
size:  (375, 1242, 3)
load 1266  /  6684
size:  (375, 1242, 3)
load 1267  /  6684
size:  (375, 1242, 3)
load 1268  /  6684
size:  (375, 1242, 3)
load 1269  /  6684
size:  (375, 1242, 3)
load 1270  /  6684
size:  (375, 1242, 3)
load 1271  /  6684
size:  (374, 1238, 3)
load 1272  /  6684
size:  (375, 1242, 3)
load 1273  /  6684
size:  (375, 1242, 3)
load 1274  /  6684
size:  (375, 1242, 3)
load 1275  /  6684
size:  (375, 1242, 3)
load 1276  /  6684
size:  (375, 1242, 3)
load 1277  /  6684
size:  (375, 1242, 3)
load 1278  /  6684
size:  (375, 1242, 3)
load 1279  /  6684
size:  (375, 1242, 3)
load 1280  /  6684
size:  (370, 1224, 3)
load 1281  /  6684
size:  (375, 1242, 3)
load 1282  /  6684
size:  (375, 1242, 3)
load 1283  /  6684
size:  (375, 1242, 3)
load 1284  /  6684
size:  (375, 1242, 3)
load 1285  /  6684
size:  (375, 1242, 3)
load 1286  /  6684
size:  (375, 1242, 3)
load 1287  /  6684
size:  (375, 1242, 3)
load 1288  /  6684
size:  (375, 1242, 3)
load 1289  /  6684
size:  (375, 1242, 3)
load 1290  /  6684
size:  (375, 1242, 3)
load 1291  /  6684
size:  (376, 1241, 3)
load 1292  /  6684
size:  (375, 1242, 3)
load 1293  /  6684
size:  (374, 1238, 3)
load 1294  /  6684
size:  (375, 1242, 3)
load 1295  /  6684
size:  (375, 1242, 3)
load 1296  /  6684
size:  (375, 1242, 3)
load 1297  /  6684
size:  (375, 1242, 3)
load 1298  /  6684
size:  (375, 1242, 3)
load 1299  /  6684
size:  (375, 1242, 3)
load 1300  /  6684
size:  (375, 1242, 3)
load 1301  /  6684
size:  (375, 1242, 3)
load 1302  /  6684
size:  (375, 1242, 3)
load 1303  /  6684
size:  (375, 1242, 3)
load 1304  /  6684
size:  (375, 1242, 3)
load 1305  /  6684
size:  (375, 1242, 3)
load 1306  /  6684
size:  (375, 1242, 3)
load 1307  /  6684
size:  (375, 1242, 3)
load 1308  /  6684
size:  (375, 1242, 3)
load 1309  /  6684
size:  (370, 1224, 3)
load 1310  /  6684
size:  (375, 1242, 3)
load 1311  /  6684
size:  (376, 1241, 3)
load 1312  /  6684
size:  (375, 1242, 3)
load 1313  /  6684
size:  (375, 1242, 3)
load 1314  /  6684
size:  (375, 1242, 3)
load 1315  /  6684
size:  (375, 1242, 3)
load 1316  /  6684
size:  (375, 1242, 3)
load 1317  /  6684
size:  (375, 1242, 3)
load 1318  /  6684
size:  (375, 1242, 3)
load 1319  /  6684
size:  (375, 1242, 3)
load 1320  /  6684
size:  (375, 1242, 3)
load 1321  /  6684
size:  (375, 1242, 3)
load 1322  /  6684
size:  (376, 1241, 3)
load 1323  /  6684
size:  (375, 1242, 3)
load 1324  /  6684
size:  (375, 1242, 3)
load 1325  /  6684
size:  (375, 1242, 3)
load 1326  /  6684
size:  (375, 1242, 3)
load 1327  /  6684
size:  (374, 1238, 3)
load 1328  /  6684
size:  (370, 1224, 3)
load 1329  /  6684
size:  (375, 1242, 3)
load 1330  /  6684
size:  (375, 1242, 3)
load 1331  /  6684
size:  (375, 1242, 3)
load 1332  /  6684
size:  (375, 1242, 3)
load 1333  /  6684
size:  (375, 1242, 3)
load 1334  /  6684
size:  (375, 1242, 3)
load 1335  /  6684
size:  (375, 1242, 3)
load 1336  /  6684
size:  (370, 1224, 3)
load 1337  /  6684
size:  (375, 1242, 3)
load 1338  /  6684
size:  (375, 1242, 3)
load 1339  /  6684
size:  (375, 1242, 3)
load 1340  /  6684
size:  (374, 1238, 3)
load 1341  /  6684
size:  (375, 1242, 3)
load 1342  /  6684
size:  (375, 1242, 3)
load 1343  /  6684
size:  (375, 1242, 3)
load 1344  /  6684
size:  (375, 1242, 3)
load 1345  /  6684
size:  (375, 1242, 3)
load 1346  /  6684
size:  (375, 1242, 3)
load 1347  /  6684
size:  (375, 1242, 3)
load 1348  /  6684
size:  (375, 1242, 3)
load 1349  /  6684
size:  (375, 1242, 3)
load 1350  /  6684
size:  (375, 1242, 3)
load 1351  /  6684
size:  (375, 1242, 3)
load 1352  /  6684
size:  (376, 1241, 3)
load 1353  /  6684
size:  (375, 1242, 3)
load 1354  /  6684
size:  (375, 1242, 3)
load 1355  /  6684
size:  (375, 1242, 3)
load 1356  /  6684
size:  (375, 1242, 3)
load 1357  /  6684
size:  (375, 1242, 3)
load 1358  /  6684
size:  (375, 1242, 3)
load 1359  /  6684
size:  (375, 1242, 3)
load 1360  /  6684
size:  (375, 1242, 3)
load 1361  /  6684
size:  (375, 1242, 3)
load 1362  /  6684
size:  (375, 1242, 3)
load 1363  /  6684
size:  (375, 1242, 3)
load 1364  /  6684
size:  (375, 1242, 3)
load 1365  /  6684
size:  (375, 1242, 3)
load 1366  /  6684
size:  (375, 1242, 3)
load 1367  /  6684
size:  (375, 1242, 3)
load 1368  /  6684
size:  (376, 1241, 3)
load 1369  /  6684
size:  (375, 1242, 3)
load 1370  /  6684
size:  (375, 1242, 3)
load 1371  /  6684
size:  (375, 1242, 3)
load 1372  /  6684
size:  (375, 1242, 3)
load 1373  /  6684
size:  (375, 1242, 3)
load 1374  /  6684
size:  (375, 1242, 3)
load 1375  /  6684
size:  (375, 1242, 3)
load 1376  /  6684
size:  (375, 1242, 3)
load 1377  /  6684
size:  (375, 1242, 3)
load 1378  /  6684
size:  (375, 1242, 3)
load 1379  /  6684
size:  (370, 1224, 3)
load 1380  /  6684
size:  (375, 1242, 3)
load 1381  /  6684
size:  (375, 1242, 3)
load 1382  /  6684
size:  (375, 1242, 3)
load 1383  /  6684
size:  (375, 1242, 3)
load 1384  /  6684
size:  (375, 1242, 3)
load 1385  /  6684
size:  (375, 1242, 3)
load 1386  /  6684
size:  (375, 1242, 3)
load 1387  /  6684
size:  (375, 1242, 3)
load 1388  /  6684
size:  (375, 1242, 3)
load 1389  /  6684
size:  (375, 1242, 3)
load 1390  /  6684
size:  (375, 1242, 3)
load 1391  /  6684
size:  (375, 1242, 3)
load 1392  /  6684
size:  (376, 1241, 3)
load 1393  /  6684
size:  (376, 1241, 3)
load 1394  /  6684
size:  (375, 1242, 3)
load 1395  /  6684
size:  (375, 1242, 3)
load 1396  /  6684
size:  (375, 1242, 3)
load 1397  /  6684
size:  (370, 1224, 3)
load 1398  /  6684
size:  (375, 1242, 3)
load 1399  /  6684
size:  (375, 1242, 3)
load 1400  /  6684
size:  (376, 1241, 3)
load 1401  /  6684
size:  (375, 1242, 3)
load 1402  /  6684
size:  (375, 1242, 3)
load 1403  /  6684
size:  (375, 1242, 3)
load 1404  /  6684
size:  (375, 1242, 3)
load 1405  /  6684
size:  (375, 1242, 3)
load 1406  /  6684
size:  (375, 1242, 3)
load 1407  /  6684
size:  (375, 1242, 3)
load 1408  /  6684
size:  (375, 1242, 3)
load 1409  /  6684
size:  (375, 1242, 3)
load 1410  /  6684
size:  (375, 1242, 3)
load 1411  /  6684
size:  (375, 1242, 3)
load 1412  /  6684
size:  (375, 1242, 3)
load 1413  /  6684
size:  (370, 1224, 3)
load 1414  /  6684
size:  (375, 1242, 3)
load 1415  /  6684
size:  (375, 1242, 3)
load 1416  /  6684
size:  (375, 1242, 3)
load 1417  /  6684
size:  (375, 1242, 3)
load 1418  /  6684
size:  (375, 1242, 3)
load 1419  /  6684
size:  (375, 1242, 3)
load 1420  /  6684
size:  (375, 1242, 3)
load 1421  /  6684
size:  (374, 1238, 3)
load 1422  /  6684
size:  (375, 1242, 3)
load 1423  /  6684
size:  (375, 1242, 3)
load 1424  /  6684
size:  (370, 1224, 3)
load 1425  /  6684
size:  (375, 1242, 3)
load 1426  /  6684
size:  (375, 1242, 3)
load 1427  /  6684
size:  (376, 1241, 3)
load 1428  /  6684
size:  (375, 1242, 3)
load 1429  /  6684
size:  (375, 1242, 3)
load 1430  /  6684
size:  (375, 1242, 3)
load 1431  /  6684
size:  (375, 1242, 3)
load 1432  /  6684
size:  (375, 1242, 3)
load 1433  /  6684
size:  (375, 1242, 3)
load 1434  /  6684
size:  (375, 1242, 3)
load 1435  /  6684
size:  (375, 1242, 3)
load 1436  /  6684
size:  (375, 1242, 3)
load 1437  /  6684
size:  (375, 1242, 3)
load 1438  /  6684
size:  (376, 1241, 3)
load 1439  /  6684
size:  (375, 1242, 3)
load 1440  /  6684
size:  (375, 1242, 3)
load 1441  /  6684
size:  (375, 1242, 3)
load 1442  /  6684
size:  (375, 1242, 3)
load 1443  /  6684
size:  (375, 1242, 3)
load 1444  /  6684
size:  (375, 1242, 3)
load 1445  /  6684
size:  (376, 1241, 3)
load 1446  /  6684
size:  (375, 1242, 3)
load 1447  /  6684
size:  (375, 1242, 3)
load 1448  /  6684
size:  (375, 1242, 3)
load 1449  /  6684
size:  (375, 1242, 3)
load 1450  /  6684
size:  (375, 1242, 3)
load 1451  /  6684
size:  (375, 1242, 3)
load 1452  /  6684
size:  (375, 1242, 3)
load 1453  /  6684
size:  (375, 1242, 3)
load 1454  /  6684
size:  (375, 1242, 3)
load 1455  /  6684
size:  (375, 1242, 3)
load 1456  /  6684
size:  (375, 1242, 3)
load 1457  /  6684
size:  (375, 1242, 3)
load 1458  /  6684
size:  (375, 1242, 3)
load 1459  /  6684
size:  (370, 1224, 3)
load 1460  /  6684
size:  (375, 1242, 3)
load 1461  /  6684
size:  (375, 1242, 3)
load 1462  /  6684
size:  (375, 1242, 3)
load 1463  /  6684
size:  (375, 1242, 3)
load 1464  /  6684
size:  (375, 1242, 3)
load 1465  /  6684
size:  (375, 1242, 3)
load 1466  /  6684
size:  (375, 1242, 3)
load 1467  /  6684
size:  (370, 1224, 3)
load 1468  /  6684
size:  (375, 1242, 3)
load 1469  /  6684
size:  (375, 1242, 3)
load 1470  /  6684
size:  (375, 1242, 3)
load 1471  /  6684
size:  (375, 1242, 3)
load 1472  /  6684
size:  (375, 1242, 3)
load 1473  /  6684
size:  (370, 1224, 3)
load 1474  /  6684
size:  (375, 1242, 3)
load 1475  /  6684
size:  (375, 1242, 3)
load 1476  /  6684
size:  (375, 1242, 3)
load 1477  /  6684
size:  (375, 1242, 3)
load 1478  /  6684
size:  (375, 1242, 3)
load 1479  /  6684
size:  (375, 1242, 3)
load 1480  /  6684
size:  (375, 1242, 3)
load 1481  /  6684
size:  (375, 1242, 3)
load 1482  /  6684
size:  (375, 1242, 3)
load 1483  /  6684
size:  (375, 1242, 3)
load 1484  /  6684
size:  (374, 1238, 3)
load 1485  /  6684
size:  (375, 1242, 3)
load 1486  /  6684
size:  (375, 1242, 3)
load 1487  /  6684
size:  (375, 1242, 3)
load 1488  /  6684
size:  (370, 1224, 3)
load 1489  /  6684
size:  (375, 1242, 3)
load 1490  /  6684
size:  (375, 1242, 3)
load 1491  /  6684
size:  (375, 1242, 3)
load 1492  /  6684
size:  (375, 1242, 3)
load 1493  /  6684
size:  (375, 1242, 3)
load 1494  /  6684
size:  (375, 1242, 3)
load 1495  /  6684
size:  (374, 1238, 3)
load 1496  /  6684
size:  (375, 1242, 3)
load 1497  /  6684
size:  (375, 1242, 3)
load 1498  /  6684
size:  (375, 1242, 3)
load 1499  /  6684
size:  (375, 1242, 3)
load 1500  /  6684
size:  (375, 1242, 3)
load 1501  /  6684
size:  (375, 1242, 3)
load 1502  /  6684
size:  (375, 1242, 3)
load 1503  /  6684
size:  (375, 1242, 3)
load 1504  /  6684
size:  (375, 1242, 3)
load 1505  /  6684
size:  (375, 1242, 3)
load 1506  /  6684
size:  (375, 1242, 3)
load 1507  /  6684
size:  (374, 1238, 3)
load 1508  /  6684
size:  (375, 1242, 3)
load 1509  /  6684
size:  (375, 1242, 3)
load 1510  /  6684
size:  (375, 1242, 3)
load 1511  /  6684
size:  (376, 1241, 3)
load 1512  /  6684
size:  (375, 1242, 3)
load 1513  /  6684
size:  (375, 1242, 3)
load 1514  /  6684
size:  (370, 1224, 3)
load 1515  /  6684
size:  (375, 1242, 3)
load 1516  /  6684
size:  (375, 1242, 3)
load 1517  /  6684
size:  (375, 1242, 3)
load 1518  /  6684
size:  (375, 1242, 3)
load 1519  /  6684
size:  (376, 1241, 3)
load 1520  /  6684
size:  (375, 1242, 3)
load 1521  /  6684
size:  (375, 1242, 3)
load 1522  /  6684
size:  (375, 1242, 3)
load 1523  /  6684
size:  (375, 1242, 3)
load 1524  /  6684
size:  (375, 1242, 3)
load 1525  /  6684
size:  (375, 1242, 3)
load 1526  /  6684
size:  (375, 1242, 3)
load 1527  /  6684
size:  (374, 1238, 3)
load 1528  /  6684
size:  (370, 1224, 3)
load 1529  /  6684
size:  (375, 1242, 3)
load 1530  /  6684
size:  (370, 1224, 3)
load 1531  /  6684
size:  (375, 1242, 3)
load 1532  /  6684
size:  (375, 1242, 3)
load 1533  /  6684
size:  (375, 1242, 3)
load 1534  /  6684
size:  (375, 1242, 3)
load 1535  /  6684
size:  (375, 1242, 3)
load 1536  /  6684
size:  (375, 1242, 3)
load 1537  /  6684
size:  (375, 1242, 3)
load 1538  /  6684
size:  (375, 1242, 3)
load 1539  /  6684
size:  (375, 1242, 3)
load 1540  /  6684
size:  (375, 1242, 3)
load 1541  /  6684
size:  (375, 1242, 3)
load 1542  /  6684
size:  (375, 1242, 3)
load 1543  /  6684
size:  (375, 1242, 3)
load 1544  /  6684
size:  (375, 1242, 3)
load 1545  /  6684
size:  (375, 1242, 3)
load 1546  /  6684
size:  (375, 1242, 3)
load 1547  /  6684
size:  (370, 1224, 3)
load 1548  /  6684
size:  (375, 1242, 3)
load 1549  /  6684
size:  (375, 1242, 3)
load 1550  /  6684
size:  (375, 1242, 3)
load 1551  /  6684
size:  (375, 1242, 3)
load 1552  /  6684
size:  (375, 1242, 3)
load 1553  /  6684
size:  (375, 1242, 3)
load 1554  /  6684
size:  (376, 1241, 3)
load 1555  /  6684
size:  (376, 1241, 3)
load 1556  /  6684
size:  (375, 1242, 3)
load 1557  /  6684
size:  (375, 1242, 3)
load 1558  /  6684
size:  (375, 1242, 3)
load 1559  /  6684
size:  (375, 1242, 3)
load 1560  /  6684
size:  (375, 1242, 3)
load 1561  /  6684
size:  (370, 1224, 3)
load 1562  /  6684
size:  (375, 1242, 3)
load 1563  /  6684
size:  (375, 1242, 3)
load 1564  /  6684
size:  (375, 1242, 3)
load 1565  /  6684
size:  (375, 1242, 3)
load 1566  /  6684
size:  (375, 1242, 3)
load 1567  /  6684
size:  (375, 1242, 3)
load 1568  /  6684
size:  (375, 1242, 3)
load 1569  /  6684
size:  (375, 1242, 3)
load 1570  /  6684
size:  (375, 1242, 3)
load 1571  /  6684
size:  (375, 1242, 3)
load 1572  /  6684
size:  (375, 1242, 3)
load 1573  /  6684
size:  (375, 1242, 3)
load 1574  /  6684
size:  (375, 1242, 3)
load 1575  /  6684
size:  (375, 1242, 3)
load 1576  /  6684
size:  (376, 1241, 3)
load 1577  /  6684
size:  (375, 1242, 3)
load 1578  /  6684
size:  (375, 1242, 3)
load 1579  /  6684
size:  (375, 1242, 3)
load 1580  /  6684
size:  (375, 1242, 3)
load 1581  /  6684
size:  (375, 1242, 3)
load 1582  /  6684
size:  (375, 1242, 3)
load 1583  /  6684
size:  (375, 1242, 3)
load 1584  /  6684
size:  (375, 1242, 3)
load 1585  /  6684
size:  (375, 1242, 3)
load 1586  /  6684
size:  (375, 1242, 3)
load 1587  /  6684
size:  (374, 1238, 3)
load 1588  /  6684
size:  (374, 1238, 3)
load 1589  /  6684
size:  (375, 1242, 3)
load 1590  /  6684
size:  (375, 1242, 3)
load 1591  /  6684
size:  (375, 1242, 3)
load 1592  /  6684
size:  (375, 1242, 3)
load 1593  /  6684
size:  (375, 1242, 3)
load 1594  /  6684
size:  (375, 1242, 3)
load 1595  /  6684
size:  (370, 1224, 3)
load 1596  /  6684
size:  (375, 1242, 3)
load 1597  /  6684
size:  (375, 1242, 3)
load 1598  /  6684
size:  (375, 1242, 3)
load 1599  /  6684
size:  (375, 1242, 3)
load 1600  /  6684
size:  (375, 1242, 3)
load 1601  /  6684
size:  (375, 1242, 3)
load 1602  /  6684
size:  (375, 1242, 3)
load 1603  /  6684
size:  (376, 1241, 3)
load 1604  /  6684
size:  (375, 1242, 3)
load 1605  /  6684
size:  (375, 1242, 3)
load 1606  /  6684
size:  (375, 1242, 3)
load 1607  /  6684
size:  (375, 1242, 3)
load 1608  /  6684
size:  (375, 1242, 3)
load 1609  /  6684
size:  (375, 1242, 3)
load 1610  /  6684
size:  (375, 1242, 3)
load 1611  /  6684
size:  (375, 1242, 3)
load 1612  /  6684
size:  (375, 1242, 3)
load 1613  /  6684
size:  (375, 1242, 3)
load 1614  /  6684
size:  (375, 1242, 3)
load 1615  /  6684
size:  (375, 1242, 3)
load 1616  /  6684
size:  (375, 1242, 3)
load 1617  /  6684
size:  (375, 1242, 3)
load 1618  /  6684
size:  (375, 1242, 3)
load 1619  /  6684
size:  (375, 1242, 3)
load 1620  /  6684
size:  (375, 1242, 3)
load 1621  /  6684
size:  (370, 1224, 3)
load 1622  /  6684
size:  (375, 1242, 3)
load 1623  /  6684
size:  (375, 1242, 3)
load 1624  /  6684
size:  (375, 1242, 3)
load 1625  /  6684
size:  (375, 1242, 3)
load 1626  /  6684
size:  (375, 1242, 3)
load 1627  /  6684
size:  (375, 1242, 3)
load 1628  /  6684
size:  (375, 1242, 3)
load 1629  /  6684
size:  (375, 1242, 3)
load 1630  /  6684
size:  (375, 1242, 3)
load 1631  /  6684
size:  (375, 1242, 3)
load 1632  /  6684
size:  (376, 1241, 3)
load 1633  /  6684
size:  (375, 1242, 3)
load 1634  /  6684
size:  (375, 1242, 3)
load 1635  /  6684
size:  (374, 1238, 3)
load 1636  /  6684
size:  (375, 1242, 3)
load 1637  /  6684
size:  (375, 1242, 3)
load 1638  /  6684
size:  (375, 1242, 3)
load 1639  /  6684
size:  (375, 1242, 3)
load 1640  /  6684
size:  (375, 1242, 3)
load 1641  /  6684
size:  (375, 1242, 3)
load 1642  /  6684
size:  (375, 1242, 3)
load 1643  /  6684
size:  (375, 1242, 3)
load 1644  /  6684
size:  (375, 1242, 3)
load 1645  /  6684
size:  (375, 1242, 3)
load 1646  /  6684
size:  (375, 1242, 3)
load 1647  /  6684
size:  (375, 1242, 3)
load 1648  /  6684
size:  (375, 1242, 3)
load 1649  /  6684
size:  (375, 1242, 3)
load 1650  /  6684
size:  (375, 1242, 3)
load 1651  /  6684
size:  (375, 1242, 3)
load 1652  /  6684
size:  (375, 1242, 3)
load 1653  /  6684
size:  (375, 1242, 3)
load 1654  /  6684
size:  (375, 1242, 3)
load 1655  /  6684
size:  (374, 1238, 3)
load 1656  /  6684
size:  (375, 1242, 3)
load 1657  /  6684
size:  (376, 1241, 3)
load 1658  /  6684
size:  (375, 1242, 3)
load 1659  /  6684
size:  (375, 1242, 3)
load 1660  /  6684
size:  (376, 1241, 3)
load 1661  /  6684
size:  (375, 1242, 3)
load 1662  /  6684
size:  (375, 1242, 3)
load 1663  /  6684
size:  (375, 1242, 3)
load 1664  /  6684
size:  (375, 1242, 3)
load 1665  /  6684
size:  (375, 1242, 3)
load 1666  /  6684
size:  (374, 1238, 3)
load 1667  /  6684
size:  (375, 1242, 3)
load 1668  /  6684
size:  (375, 1242, 3)
load 1669  /  6684
size:  (375, 1242, 3)
load 1670  /  6684
size:  (375, 1242, 3)
load 1671  /  6684
size:  (375, 1242, 3)
load 1672  /  6684
size:  (375, 1242, 3)
load 1673  /  6684
size:  (375, 1242, 3)
load 1674  /  6684
size:  (375, 1242, 3)
load 1675  /  6684
size:  (375, 1242, 3)
load 1676  /  6684
size:  (375, 1242, 3)
load 1677  /  6684
size:  (370, 1224, 3)
load 1678  /  6684
size:  (375, 1242, 3)
load 1679  /  6684
size:  (375, 1242, 3)
load 1680  /  6684
size:  (375, 1242, 3)
load 1681  /  6684
size:  (375, 1242, 3)
load 1682  /  6684
size:  (375, 1242, 3)
load 1683  /  6684
size:  (375, 1242, 3)
load 1684  /  6684
size:  (375, 1242, 3)
load 1685  /  6684
size:  (375, 1242, 3)
load 1686  /  6684
size:  (375, 1242, 3)
load 1687  /  6684
size:  (370, 1224, 3)
load 1688  /  6684
size:  (375, 1242, 3)
load 1689  /  6684
size:  (375, 1242, 3)
load 1690  /  6684
size:  (375, 1242, 3)
load 1691  /  6684
size:  (375, 1242, 3)
load 1692  /  6684
size:  (376, 1241, 3)
load 1693  /  6684
size:  (375, 1242, 3)
load 1694  /  6684
size:  (375, 1242, 3)
load 1695  /  6684
size:  (375, 1242, 3)
load 1696  /  6684
size:  (375, 1242, 3)
load 1697  /  6684
size:  (375, 1242, 3)
load 1698  /  6684
size:  (375, 1242, 3)
load 1699  /  6684
size:  (375, 1242, 3)
load 1700  /  6684
size:  (375, 1242, 3)
load 1701  /  6684
size:  (375, 1242, 3)
load 1702  /  6684
size:  (375, 1242, 3)
load 1703  /  6684
size:  (375, 1242, 3)
load 1704  /  6684
size:  (375, 1242, 3)
load 1705  /  6684
size:  (375, 1242, 3)
load 1706  /  6684
size:  (375, 1242, 3)
load 1707  /  6684
size:  (375, 1242, 3)
load 1708  /  6684
size:  (370, 1224, 3)
load 1709  /  6684
size:  (375, 1242, 3)
load 1710  /  6684
size:  (375, 1242, 3)
load 1711  /  6684
size:  (375, 1242, 3)
load 1712  /  6684
size:  (375, 1242, 3)
load 1713  /  6684
size:  (375, 1242, 3)
load 1714  /  6684
size:  (375, 1242, 3)
load 1715  /  6684
size:  (375, 1242, 3)
load 1716  /  6684
size:  (375, 1242, 3)
load 1717  /  6684
size:  (375, 1242, 3)
load 1718  /  6684
size:  (375, 1242, 3)
load 1719  /  6684
size:  (376, 1241, 3)
load 1720  /  6684
size:  (375, 1242, 3)
load 1721  /  6684
size:  (375, 1242, 3)
load 1722  /  6684
size:  (376, 1241, 3)
load 1723  /  6684
size:  (375, 1242, 3)
load 1724  /  6684
size:  (375, 1242, 3)
load 1725  /  6684
size:  (374, 1238, 3)
load 1726  /  6684
size:  (375, 1242, 3)
load 1727  /  6684
size:  (375, 1242, 3)
load 1728  /  6684
size:  (375, 1242, 3)
load 1729  /  6684
size:  (375, 1242, 3)
load 1730  /  6684
size:  (375, 1242, 3)
load 1731  /  6684
size:  (376, 1241, 3)
load 1732  /  6684
size:  (375, 1242, 3)
load 1733  /  6684
size:  (375, 1242, 3)
load 1734  /  6684
size:  (375, 1242, 3)
load 1735  /  6684
size:  (375, 1242, 3)
load 1736  /  6684
size:  (376, 1241, 3)
load 1737  /  6684
size:  (375, 1242, 3)
load 1738  /  6684
size:  (375, 1242, 3)
load 1739  /  6684
size:  (375, 1242, 3)
load 1740  /  6684
size:  (375, 1242, 3)
load 1741  /  6684
size:  (370, 1224, 3)
load 1742  /  6684
size:  (375, 1242, 3)
load 1743  /  6684
size:  (375, 1242, 3)
load 1744  /  6684
size:  (375, 1242, 3)
load 1745  /  6684
size:  (375, 1242, 3)
load 1746  /  6684
size:  (375, 1242, 3)
load 1747  /  6684
size:  (375, 1242, 3)
load 1748  /  6684
size:  (375, 1242, 3)
load 1749  /  6684
size:  (375, 1242, 3)
load 1750  /  6684
size:  (375, 1242, 3)
load 1751  /  6684
size:  (375, 1242, 3)
load 1752  /  6684
size:  (375, 1242, 3)
load 1753  /  6684
size:  (375, 1242, 3)
load 1754  /  6684
size:  (375, 1242, 3)
load 1755  /  6684
size:  (375, 1242, 3)
load 1756  /  6684
size:  (375, 1242, 3)
load 1757  /  6684
size:  (375, 1242, 3)
load 1758  /  6684
size:  (375, 1242, 3)
load 1759  /  6684
size:  (375, 1242, 3)
load 1760  /  6684
size:  (375, 1242, 3)
load 1761  /  6684
size:  (375, 1242, 3)
load 1762  /  6684
size:  (375, 1242, 3)
load 1763  /  6684
size:  (375, 1242, 3)
load 1764  /  6684
size:  (375, 1242, 3)
load 1765  /  6684
size:  (375, 1242, 3)
load 1766  /  6684
size:  (375, 1242, 3)
load 1767  /  6684
size:  (375, 1242, 3)
load 1768  /  6684
size:  (375, 1242, 3)
load 1769  /  6684
size:  (375, 1242, 3)
load 1770  /  6684
size:  (375, 1242, 3)
load 1771  /  6684
size:  (375, 1242, 3)
load 1772  /  6684
size:  (375, 1242, 3)
load 1773  /  6684
size:  (376, 1241, 3)
load 1774  /  6684
size:  (375, 1242, 3)
load 1775  /  6684
size:  (375, 1242, 3)
load 1776  /  6684
size:  (375, 1242, 3)
load 1777  /  6684
size:  (375, 1242, 3)
load 1778  /  6684
size:  (376, 1241, 3)
load 1779  /  6684
size:  (375, 1242, 3)
load 1780  /  6684
size:  (375, 1242, 3)
load 1781  /  6684
size:  (375, 1242, 3)
load 1782  /  6684
size:  (375, 1242, 3)
load 1783  /  6684
size:  (375, 1242, 3)
load 1784  /  6684
size:  (375, 1242, 3)
load 1785  /  6684
size:  (370, 1224, 3)
load 1786  /  6684
size:  (375, 1242, 3)
load 1787  /  6684
size:  (375, 1242, 3)
load 1788  /  6684
size:  (375, 1242, 3)
load 1789  /  6684
size:  (375, 1242, 3)
load 1790  /  6684
size:  (375, 1242, 3)
load 1791  /  6684
size:  (375, 1242, 3)
load 1792  /  6684
size:  (375, 1242, 3)
load 1793  /  6684
size:  (375, 1242, 3)
load 1794  /  6684
size:  (375, 1242, 3)
load 1795  /  6684
size:  (375, 1242, 3)
load 1796  /  6684
size:  (375, 1242, 3)
load 1797  /  6684
size:  (370, 1224, 3)
load 1798  /  6684
size:  (375, 1242, 3)
load 1799  /  6684
size:  (375, 1242, 3)
load 1800  /  6684
size:  (375, 1242, 3)
load 1801  /  6684
size:  (375, 1242, 3)
load 1802  /  6684
size:  (375, 1242, 3)
load 1803  /  6684
size:  (375, 1242, 3)
load 1804  /  6684
size:  (375, 1242, 3)
load 1805  /  6684
size:  (375, 1242, 3)
load 1806  /  6684
size:  (375, 1242, 3)
load 1807  /  6684
size:  (375, 1242, 3)
load 1808  /  6684
size:  (375, 1242, 3)
load 1809  /  6684
size:  (375, 1242, 3)
load 1810  /  6684
size:  (375, 1242, 3)
load 1811  /  6684
size:  (375, 1242, 3)
load 1812  /  6684
size:  (375, 1242, 3)
load 1813  /  6684
size:  (375, 1242, 3)
load 1814  /  6684
size:  (375, 1242, 3)
load 1815  /  6684
size:  (375, 1242, 3)
load 1816  /  6684
size:  (375, 1242, 3)
load 1817  /  6684
size:  (375, 1242, 3)
load 1818  /  6684
size:  (375, 1242, 3)
load 1819  /  6684
size:  (375, 1242, 3)
load 1820  /  6684
size:  (375, 1242, 3)
load 1821  /  6684
size:  (375, 1242, 3)
load 1822  /  6684
size:  (375, 1242, 3)
load 1823  /  6684
size:  (376, 1241, 3)
load 1824  /  6684
size:  (375, 1242, 3)
load 1825  /  6684
size:  (375, 1242, 3)
load 1826  /  6684
size:  (375, 1242, 3)
load 1827  /  6684
size:  (375, 1242, 3)
load 1828  /  6684
size:  (375, 1242, 3)
load 1829  /  6684
size:  (375, 1242, 3)
load 1830  /  6684
size:  (376, 1241, 3)
load 1831  /  6684
size:  (375, 1242, 3)
load 1832  /  6684
size:  (375, 1242, 3)
load 1833  /  6684
size:  (375, 1242, 3)
load 1834  /  6684
size:  (375, 1242, 3)
load 1835  /  6684
size:  (375, 1242, 3)
load 1836  /  6684
size:  (375, 1242, 3)
load 1837  /  6684
size:  (375, 1242, 3)
load 1838  /  6684
size:  (375, 1242, 3)
load 1839  /  6684
size:  (370, 1224, 3)
load 1840  /  6684
size:  (375, 1242, 3)
load 1841  /  6684
size:  (375, 1242, 3)
load 1842  /  6684
size:  (375, 1242, 3)
load 1843  /  6684
size:  (375, 1242, 3)
load 1844  /  6684
size:  (375, 1242, 3)
load 1845  /  6684
size:  (375, 1242, 3)
load 1846  /  6684
size:  (374, 1238, 3)
load 1847  /  6684
size:  (375, 1242, 3)
load 1848  /  6684
size:  (370, 1224, 3)
load 1849  /  6684
size:  (375, 1242, 3)
load 1850  /  6684
size:  (375, 1242, 3)
load 1851  /  6684
size:  (375, 1242, 3)
load 1852  /  6684
size:  (375, 1242, 3)
load 1853  /  6684
size:  (375, 1242, 3)
load 1854  /  6684
size:  (375, 1242, 3)
load 1855  /  6684
size:  (375, 1242, 3)
load 1856  /  6684
size:  (375, 1242, 3)
load 1857  /  6684
size:  (375, 1242, 3)
load 1858  /  6684
size:  (375, 1242, 3)
load 1859  /  6684
size:  (375, 1242, 3)
load 1860  /  6684
size:  (375, 1242, 3)
load 1861  /  6684
size:  (375, 1242, 3)
load 1862  /  6684
size:  (375, 1242, 3)
load 1863  /  6684
size:  (374, 1238, 3)
load 1864  /  6684
size:  (375, 1242, 3)
load 1865  /  6684
size:  (375, 1242, 3)
load 1866  /  6684
size:  (375, 1242, 3)
load 1867  /  6684
size:  (370, 1224, 3)
load 1868  /  6684
size:  (375, 1242, 3)
load 1869  /  6684
size:  (375, 1242, 3)
load 1870  /  6684
size:  (374, 1238, 3)
load 1871  /  6684
size:  (375, 1242, 3)
load 1872  /  6684
size:  (375, 1242, 3)
load 1873  /  6684
size:  (375, 1242, 3)
load 1874  /  6684
size:  (375, 1242, 3)
load 1875  /  6684
size:  (375, 1242, 3)
load 1876  /  6684
size:  (375, 1242, 3)
load 1877  /  6684
size:  (375, 1242, 3)
load 1878  /  6684
size:  (375, 1242, 3)
load 1879  /  6684
size:  (375, 1242, 3)
load 1880  /  6684
size:  (375, 1242, 3)
load 1881  /  6684
size:  (375, 1242, 3)
load 1882  /  6684
size:  (375, 1242, 3)
load 1883  /  6684
size:  (375, 1242, 3)
load 1884  /  6684
size:  (375, 1242, 3)
load 1885  /  6684
size:  (375, 1242, 3)
load 1886  /  6684
size:  (375, 1242, 3)
load 1887  /  6684
size:  (375, 1242, 3)
load 1888  /  6684
size:  (375, 1242, 3)
load 1889  /  6684
size:  (375, 1242, 3)
load 1890  /  6684
size:  (375, 1242, 3)
load 1891  /  6684
size:  (375, 1242, 3)
load 1892  /  6684
size:  (375, 1242, 3)
load 1893  /  6684
size:  (376, 1241, 3)
load 1894  /  6684
size:  (370, 1224, 3)
load 1895  /  6684
size:  (375, 1242, 3)
load 1896  /  6684
size:  (375, 1242, 3)
load 1897  /  6684
size:  (375, 1242, 3)
load 1898  /  6684
size:  (375, 1242, 3)
load 1899  /  6684
size:  (375, 1242, 3)
load 1900  /  6684
size:  (375, 1242, 3)
load 1901  /  6684
size:  (375, 1242, 3)
load 1902  /  6684
size:  (375, 1242, 3)
load 1903  /  6684
size:  (375, 1242, 3)
load 1904  /  6684
size:  (375, 1242, 3)
load 1905  /  6684
size:  (375, 1242, 3)
load 1906  /  6684
size:  (375, 1242, 3)
load 1907  /  6684
size:  (375, 1242, 3)
load 1908  /  6684
size:  (376, 1241, 3)
load 1909  /  6684
size:  (376, 1241, 3)
load 1910  /  6684
size:  (375, 1242, 3)
load 1911  /  6684
size:  (376, 1241, 3)
load 1912  /  6684
size:  (375, 1242, 3)
load 1913  /  6684
size:  (374, 1238, 3)
load 1914  /  6684
size:  (375, 1242, 3)
load 1915  /  6684
size:  (375, 1242, 3)
load 1916  /  6684
size:  (374, 1238, 3)
load 1917  /  6684
size:  (375, 1242, 3)
load 1918  /  6684
size:  (376, 1241, 3)
load 1919  /  6684
size:  (375, 1242, 3)
load 1920  /  6684
size:  (375, 1242, 3)
load 1921  /  6684
size:  (375, 1242, 3)
load 1922  /  6684
size:  (375, 1242, 3)
load 1923  /  6684
size:  (375, 1242, 3)
load 1924  /  6684
size:  (375, 1242, 3)
load 1925  /  6684
size:  (375, 1242, 3)
load 1926  /  6684
size:  (375, 1242, 3)
load 1927  /  6684
size:  (375, 1242, 3)
load 1928  /  6684
size:  (375, 1242, 3)
load 1929  /  6684
size:  (375, 1242, 3)
load 1930  /  6684
size:  (375, 1242, 3)
load 1931  /  6684
size:  (375, 1242, 3)
load 1932  /  6684
size:  (375, 1242, 3)
load 1933  /  6684
size:  (375, 1242, 3)
load 1934  /  6684
size:  (375, 1242, 3)
load 1935  /  6684
size:  (370, 1224, 3)
load 1936  /  6684
size:  (375, 1242, 3)
load 1937  /  6684
size:  (376, 1241, 3)
load 1938  /  6684
size:  (375, 1242, 3)
load 1939  /  6684
size:  (370, 1224, 3)
load 1940  /  6684
size:  (375, 1242, 3)
load 1941  /  6684
size:  (375, 1242, 3)
load 1942  /  6684
size:  (375, 1242, 3)
load 1943  /  6684
size:  (375, 1242, 3)
load 1944  /  6684
size:  (376, 1241, 3)
load 1945  /  6684
size:  (375, 1242, 3)
load 1946  /  6684
size:  (375, 1242, 3)
load 1947  /  6684
size:  (375, 1242, 3)
load 1948  /  6684
size:  (375, 1242, 3)
load 1949  /  6684
size:  (375, 1242, 3)
load 1950  /  6684
size:  (375, 1242, 3)
load 1951  /  6684
size:  (375, 1242, 3)
load 1952  /  6684
size:  (375, 1242, 3)
load 1953  /  6684
size:  (375, 1242, 3)
load 1954  /  6684
size:  (375, 1242, 3)
load 1955  /  6684
size:  (375, 1242, 3)
load 1956  /  6684
size:  (374, 1238, 3)
load 1957  /  6684
size:  (375, 1242, 3)
load 1958  /  6684
size:  (375, 1242, 3)
load 1959  /  6684
size:  (375, 1242, 3)
load 1960  /  6684
size:  (375, 1242, 3)
load 1961  /  6684
size:  (375, 1242, 3)
load 1962  /  6684
size:  (376, 1241, 3)
load 1963  /  6684
size:  (375, 1242, 3)
load 1964  /  6684
size:  (375, 1242, 3)
load 1965  /  6684
size:  (375, 1242, 3)
load 1966  /  6684
size:  (375, 1242, 3)
load 1967  /  6684
size:  (374, 1238, 3)
load 1968  /  6684
size:  (375, 1242, 3)
load 1969  /  6684
size:  (375, 1242, 3)
load 1970  /  6684
size:  (375, 1242, 3)
load 1971  /  6684
size:  (375, 1242, 3)
load 1972  /  6684
size:  (375, 1242, 3)
load 1973  /  6684
size:  (375, 1242, 3)
load 1974  /  6684
size:  (375, 1242, 3)
load 1975  /  6684
size:  (374, 1238, 3)
load 1976  /  6684
size:  (375, 1242, 3)
load 1977  /  6684
size:  (375, 1242, 3)
load 1978  /  6684
size:  (375, 1242, 3)
load 1979  /  6684
size:  (375, 1242, 3)
load 1980  /  6684
size:  (375, 1242, 3)
load 1981  /  6684
size:  (375, 1242, 3)
load 1982  /  6684
size:  (375, 1242, 3)
load 1983  /  6684
size:  (375, 1242, 3)
load 1984  /  6684
size:  (375, 1242, 3)
load 1985  /  6684
size:  (375, 1242, 3)
load 1986  /  6684
size:  (375, 1242, 3)
load 1987  /  6684
size:  (375, 1242, 3)
load 1988  /  6684
size:  (375, 1242, 3)
load 1989  /  6684
size:  (375, 1242, 3)
load 1990  /  6684
size:  (375, 1242, 3)
load 1991  /  6684
size:  (375, 1242, 3)
load 1992  /  6684
size:  (375, 1242, 3)
load 1993  /  6684
size:  (375, 1242, 3)
load 1994  /  6684
size:  (375, 1242, 3)
load 1995  /  6684
size:  (375, 1242, 3)
load 1996  /  6684
size:  (375, 1242, 3)
load 1997  /  6684
size:  (375, 1242, 3)
load 1998  /  6684
size:  (375, 1242, 3)
load 1999  /  6684
size:  (375, 1242, 3)
load 2000  /  6684
size:  (375, 1242, 3)
load 2001  /  6684
size:  (375, 1242, 3)
load 2002  /  6684
size:  (375, 1242, 3)
load 2003  /  6684
size:  (374, 1238, 3)
load 2004  /  6684
size:  (375, 1242, 3)
load 2005  /  6684
size:  (370, 1224, 3)
load 2006  /  6684
size:  (375, 1242, 3)
load 2007  /  6684
size:  (375, 1242, 3)
load 2008  /  6684
size:  (375, 1242, 3)
load 2009  /  6684
size:  (375, 1242, 3)
load 2010  /  6684
size:  (375, 1242, 3)
load 2011  /  6684
size:  (375, 1242, 3)
load 2012  /  6684
size:  (375, 1242, 3)
load 2013  /  6684
size:  (375, 1242, 3)
load 2014  /  6684
size:  (375, 1242, 3)
load 2015  /  6684
size:  (375, 1242, 3)
load 2016  /  6684
size:  (375, 1242, 3)
load 2017  /  6684
size:  (375, 1242, 3)
load 2018  /  6684
size:  (376, 1241, 3)
load 2019  /  6684
size:  (375, 1242, 3)
load 2020  /  6684
size:  (376, 1241, 3)
load 2021  /  6684
size:  (375, 1242, 3)
load 2022  /  6684
size:  (375, 1242, 3)
load 2023  /  6684
size:  (375, 1242, 3)
load 2024  /  6684
size:  (375, 1242, 3)
load 2025  /  6684
size:  (375, 1242, 3)
load 2026  /  6684
size:  (375, 1242, 3)
load 2027  /  6684
size:  (370, 1224, 3)
load 2028  /  6684
size:  (375, 1242, 3)
load 2029  /  6684
size:  (375, 1242, 3)
load 2030  /  6684
size:  (374, 1238, 3)
load 2031  /  6684
size:  (375, 1242, 3)
load 2032  /  6684
size:  (375, 1242, 3)
load 2033  /  6684
size:  (375, 1242, 3)
load 2034  /  6684
size:  (375, 1242, 3)
load 2035  /  6684
size:  (375, 1242, 3)
load 2036  /  6684
size:  (375, 1242, 3)
load 2037  /  6684
size:  (375, 1242, 3)
load 2038  /  6684
size:  (375, 1242, 3)
load 2039  /  6684
size:  (375, 1242, 3)
load 2040  /  6684
size:  (375, 1242, 3)
load 2041  /  6684
size:  (375, 1242, 3)
load 2042  /  6684
size:  (376, 1241, 3)
load 2043  /  6684
size:  (376, 1241, 3)
load 2044  /  6684
size:  (375, 1242, 3)
load 2045  /  6684
size:  (376, 1241, 3)
load 2046  /  6684
size:  (375, 1242, 3)
load 2047  /  6684
size:  (376, 1241, 3)
load 2048  /  6684
size:  (375, 1242, 3)
load 2049  /  6684
size:  (375, 1242, 3)
load 2050  /  6684
size:  (375, 1242, 3)
load 2051  /  6684
size:  (375, 1242, 3)
load 2052  /  6684
size:  (375, 1242, 3)
load 2053  /  6684
size:  (375, 1242, 3)
load 2054  /  6684
size:  (375, 1242, 3)
load 2055  /  6684
size:  (375, 1242, 3)
load 2056  /  6684
size:  (375, 1242, 3)
load 2057  /  6684
size:  (375, 1242, 3)
load 2058  /  6684
size:  (375, 1242, 3)
load 2059  /  6684
size:  (375, 1242, 3)
load 2060  /  6684
size:  (375, 1242, 3)
load 2061  /  6684
size:  (375, 1242, 3)
load 2062  /  6684
size:  (375, 1242, 3)
load 2063  /  6684
size:  (375, 1242, 3)
load 2064  /  6684
size:  (376, 1241, 3)
load 2065  /  6684
size:  (374, 1238, 3)
load 2066  /  6684
size:  (375, 1242, 3)
load 2067  /  6684
size:  (375, 1242, 3)
load 2068  /  6684
size:  (375, 1242, 3)
load 2069  /  6684
size:  (375, 1242, 3)
load 2070  /  6684
size:  (375, 1242, 3)
load 2071  /  6684
size:  (375, 1242, 3)
load 2072  /  6684
size:  (375, 1242, 3)
load 2073  /  6684
size:  (375, 1242, 3)
load 2074  /  6684
size:  (375, 1242, 3)
load 2075  /  6684
size:  (375, 1242, 3)
load 2076  /  6684
size:  (370, 1224, 3)
load 2077  /  6684
size:  (375, 1242, 3)
load 2078  /  6684
size:  (375, 1242, 3)
load 2079  /  6684
size:  (375, 1242, 3)
load 2080  /  6684
size:  (375, 1242, 3)
load 2081  /  6684
size:  (375, 1242, 3)
load 2082  /  6684
size:  (375, 1242, 3)
load 2083  /  6684
size:  (375, 1242, 3)
load 2084  /  6684
size:  (375, 1242, 3)
load 2085  /  6684
size:  (375, 1242, 3)
load 2086  /  6684
size:  (375, 1242, 3)
load 2087  /  6684
size:  (375, 1242, 3)
load 2088  /  6684
size:  (375, 1242, 3)
load 2089  /  6684
size:  (376, 1241, 3)
load 2090  /  6684
size:  (375, 1242, 3)
load 2091  /  6684
size:  (375, 1242, 3)
load 2092  /  6684
size:  (375, 1242, 3)
load 2093  /  6684
size:  (375, 1242, 3)
load 2094  /  6684
size:  (376, 1241, 3)
load 2095  /  6684
size:  (374, 1238, 3)
load 2096  /  6684
size:  (375, 1242, 3)
load 2097  /  6684
size:  (375, 1242, 3)
load 2098  /  6684
size:  (375, 1242, 3)
load 2099  /  6684
size:  (375, 1242, 3)
load 2100  /  6684
size:  (375, 1242, 3)
load 2101  /  6684
size:  (375, 1242, 3)
load 2102  /  6684
size:  (375, 1242, 3)
load 2103  /  6684
size:  (375, 1242, 3)
load 2104  /  6684
size:  (375, 1242, 3)
load 2105  /  6684
size:  (375, 1242, 3)
load 2106  /  6684
size:  (375, 1242, 3)
load 2107  /  6684
size:  (374, 1238, 3)
load 2108  /  6684
size:  (375, 1242, 3)
load 2109  /  6684
size:  (375, 1242, 3)
load 2110  /  6684
size:  (375, 1242, 3)
load 2111  /  6684
size:  (375, 1242, 3)
load 2112  /  6684
size:  (375, 1242, 3)
load 2113  /  6684
size:  (375, 1242, 3)
load 2114  /  6684
size:  (375, 1242, 3)
load 2115  /  6684
size:  (375, 1242, 3)
load 2116  /  6684
size:  (375, 1242, 3)
load 2117  /  6684
size:  (375, 1242, 3)
load 2118  /  6684
size:  (375, 1242, 3)
load 2119  /  6684
size:  (375, 1242, 3)
load 2120  /  6684
size:  (375, 1242, 3)
load 2121  /  6684
size:  (375, 1242, 3)
load 2122  /  6684
size:  (375, 1242, 3)
load 2123  /  6684
size:  (375, 1242, 3)
load 2124  /  6684
size:  (375, 1242, 3)
load 2125  /  6684
size:  (375, 1242, 3)
load 2126  /  6684
size:  (375, 1242, 3)
load 2127  /  6684
size:  (375, 1242, 3)
load 2128  /  6684
size:  (375, 1242, 3)
load 2129  /  6684
size:  (376, 1241, 3)
load 2130  /  6684
size:  (375, 1242, 3)
load 2131  /  6684
size:  (375, 1242, 3)
load 2132  /  6684
size:  (375, 1242, 3)
load 2133  /  6684
size:  (375, 1242, 3)
load 2134  /  6684
size:  (375, 1242, 3)
load 2135  /  6684
size:  (375, 1242, 3)
load 2136  /  6684
size:  (375, 1242, 3)
load 2137  /  6684
size:  (375, 1242, 3)
load 2138  /  6684
size:  (376, 1241, 3)
load 2139  /  6684
size:  (375, 1242, 3)
load 2140  /  6684
size:  (375, 1242, 3)
load 2141  /  6684
size:  (375, 1242, 3)
load 2142  /  6684
size:  (375, 1242, 3)
load 2143  /  6684
size:  (375, 1242, 3)
load 2144  /  6684
size:  (375, 1242, 3)
load 2145  /  6684
size:  (370, 1224, 3)
load 2146  /  6684
size:  (375, 1242, 3)
load 2147  /  6684
size:  (375, 1242, 3)
load 2148  /  6684
size:  (375, 1242, 3)
load 2149  /  6684
size:  (375, 1242, 3)
load 2150  /  6684
size:  (375, 1242, 3)
load 2151  /  6684
size:  (375, 1242, 3)
load 2152  /  6684
size:  (375, 1242, 3)
load 2153  /  6684
size:  (375, 1242, 3)
load 2154  /  6684
size:  (375, 1242, 3)
load 2155  /  6684
size:  (375, 1242, 3)
load 2156  /  6684
size:  (375, 1242, 3)
load 2157  /  6684
size:  (375, 1242, 3)
load 2158  /  6684
size:  (375, 1242, 3)
load 2159  /  6684
size:  (375, 1242, 3)
load 2160  /  6684
size:  (375, 1242, 3)
load 2161  /  6684
size:  (375, 1242, 3)
load 2162  /  6684
size:  (375, 1242, 3)
load 2163  /  6684
size:  (375, 1242, 3)
load 2164  /  6684
size:  (375, 1242, 3)
load 2165  /  6684
size:  (375, 1242, 3)
load 2166  /  6684
size:  (375, 1242, 3)
load 2167  /  6684
size:  (375, 1242, 3)
load 2168  /  6684
size:  (375, 1242, 3)
load 2169  /  6684
size:  (375, 1242, 3)
load 2170  /  6684
size:  (375, 1242, 3)
load 2171  /  6684
size:  (375, 1242, 3)
load 2172  /  6684
size:  (375, 1242, 3)
load 2173  /  6684
size:  (374, 1238, 3)
load 2174  /  6684
size:  (375, 1242, 3)
load 2175  /  6684
size:  (375, 1242, 3)
load 2176  /  6684
size:  (375, 1242, 3)
load 2177  /  6684
size:  (375, 1242, 3)
load 2178  /  6684
size:  (375, 1242, 3)
load 2179  /  6684
size:  (375, 1242, 3)
load 2180  /  6684
size:  (375, 1242, 3)
load 2181  /  6684
size:  (375, 1242, 3)
load 2182  /  6684
size:  (375, 1242, 3)
load 2183  /  6684
size:  (375, 1242, 3)
load 2184  /  6684
size:  (375, 1242, 3)
load 2185  /  6684
size:  (375, 1242, 3)
load 2186  /  6684
size:  (375, 1242, 3)
load 2187  /  6684
size:  (375, 1242, 3)
load 2188  /  6684
size:  (375, 1242, 3)
load 2189  /  6684
size:  (375, 1242, 3)
load 2190  /  6684
size:  (375, 1242, 3)
load 2191  /  6684
size:  (375, 1242, 3)
load 2192  /  6684
size:  (375, 1242, 3)
load 2193  /  6684
size:  (375, 1242, 3)
load 2194  /  6684
size:  (376, 1241, 3)
load 2195  /  6684
size:  (375, 1242, 3)
load 2196  /  6684
size:  (375, 1242, 3)
load 2197  /  6684
size:  (375, 1242, 3)
load 2198  /  6684
size:  (375, 1242, 3)
load 2199  /  6684
size:  (375, 1242, 3)
load 2200  /  6684
size:  (375, 1242, 3)
load 2201  /  6684
size:  (375, 1242, 3)
load 2202  /  6684
size:  (375, 1242, 3)
load 2203  /  6684
size:  (375, 1242, 3)
load 2204  /  6684
size:  (375, 1242, 3)
load 2205  /  6684
size:  (375, 1242, 3)
load 2206  /  6684
size:  (375, 1242, 3)
load 2207  /  6684
size:  (375, 1242, 3)
load 2208  /  6684
size:  (375, 1242, 3)
load 2209  /  6684
size:  (375, 1242, 3)
load 2210  /  6684
size:  (374, 1238, 3)
load 2211  /  6684
size:  (375, 1242, 3)
load 2212  /  6684
size:  (375, 1242, 3)
load 2213  /  6684
size:  (375, 1242, 3)
load 2214  /  6684
size:  (375, 1242, 3)
load 2215  /  6684
size:  (375, 1242, 3)
load 2216  /  6684
size:  (374, 1238, 3)
load 2217  /  6684
size:  (376, 1241, 3)
load 2218  /  6684
size:  (370, 1224, 3)
load 2219  /  6684
size:  (375, 1242, 3)
load 2220  /  6684
size:  (375, 1242, 3)
load 2221  /  6684
size:  (375, 1242, 3)
load 2222  /  6684
size:  (375, 1242, 3)
load 2223  /  6684
size:  (376, 1241, 3)
load 2224  /  6684
size:  (375, 1242, 3)
load 2225  /  6684
size:  (375, 1242, 3)
load 2226  /  6684
size:  (375, 1242, 3)
load 2227  /  6684
size:  (375, 1242, 3)
load 2228  /  6684
size:  (375, 1242, 3)
load 2229  /  6684
size:  (375, 1242, 3)
load 2230  /  6684
size:  (375, 1242, 3)
load 2231  /  6684
size:  (374, 1238, 3)
load 2232  /  6684
size:  (375, 1242, 3)
load 2233  /  6684
size:  (375, 1242, 3)
load 2234  /  6684
size:  (375, 1242, 3)
load 2235  /  6684
size:  (375, 1242, 3)
load 2236  /  6684
size:  (375, 1242, 3)
load 2237  /  6684
size:  (375, 1242, 3)
load 2238  /  6684
size:  (375, 1242, 3)
load 2239  /  6684
size:  (375, 1242, 3)
load 2240  /  6684
size:  (375, 1242, 3)
load 2241  /  6684
size:  (375, 1242, 3)
load 2242  /  6684
size:  (375, 1242, 3)
load 2243  /  6684
size:  (375, 1242, 3)
load 2244  /  6684
size:  (375, 1242, 3)
load 2245  /  6684
size:  (375, 1242, 3)
load 2246  /  6684
size:  (375, 1242, 3)
load 2247  /  6684
size:  (376, 1241, 3)
load 2248  /  6684
size:  (376, 1241, 3)
load 2249  /  6684
size:  (375, 1242, 3)
load 2250  /  6684
size:  (375, 1242, 3)
load 2251  /  6684
size:  (375, 1242, 3)
load 2252  /  6684
size:  (375, 1242, 3)
load 2253  /  6684
size:  (375, 1242, 3)
load 2254  /  6684
size:  (375, 1242, 3)
load 2255  /  6684
size:  (375, 1242, 3)
load 2256  /  6684
size:  (370, 1224, 3)
load 2257  /  6684
size:  (375, 1242, 3)
load 2258  /  6684
size:  (375, 1242, 3)
load 2259  /  6684
size:  (375, 1242, 3)
load 2260  /  6684
size:  (375, 1242, 3)
load 2261  /  6684
size:  (375, 1242, 3)
load 2262  /  6684
size:  (375, 1242, 3)
load 2263  /  6684
size:  (375, 1242, 3)
load 2264  /  6684
size:  (376, 1241, 3)
load 2265  /  6684
size:  (375, 1242, 3)
load 2266  /  6684
size:  (375, 1242, 3)
load 2267  /  6684
size:  (375, 1242, 3)
load 2268  /  6684
size:  (375, 1242, 3)
load 2269  /  6684
size:  (375, 1242, 3)
load 2270  /  6684
size:  (375, 1242, 3)
load 2271  /  6684
size:  (375, 1242, 3)
load 2272  /  6684
size:  (375, 1242, 3)
load 2273  /  6684
size:  (375, 1242, 3)
load 2274  /  6684
size:  (375, 1242, 3)
load 2275  /  6684
size:  (376, 1241, 3)
load 2276  /  6684
size:  (375, 1242, 3)
load 2277  /  6684
size:  (375, 1242, 3)
load 2278  /  6684
size:  (375, 1242, 3)
load 2279  /  6684
size:  (375, 1242, 3)
load 2280  /  6684
size:  (375, 1242, 3)
load 2281  /  6684
size:  (375, 1242, 3)
load 2282  /  6684
size:  (375, 1242, 3)
load 2283  /  6684
size:  (375, 1242, 3)
load 2284  /  6684
size:  (375, 1242, 3)
load 2285  /  6684
size:  (375, 1242, 3)
load 2286  /  6684
size:  (370, 1224, 3)
load 2287  /  6684
size:  (374, 1238, 3)
load 2288  /  6684
size:  (375, 1242, 3)
load 2289  /  6684
size:  (375, 1242, 3)
load 2290  /  6684
size:  (375, 1242, 3)
load 2291  /  6684
size:  (375, 1242, 3)
load 2292  /  6684
size:  (375, 1242, 3)
load 2293  /  6684
size:  (376, 1241, 3)
load 2294  /  6684
size:  (375, 1242, 3)
load 2295  /  6684
size:  (370, 1224, 3)
load 2296  /  6684
size:  (375, 1242, 3)
load 2297  /  6684
size:  (375, 1242, 3)
load 2298  /  6684
size:  (375, 1242, 3)
load 2299  /  6684
size:  (375, 1242, 3)
load 2300  /  6684
size:  (375, 1242, 3)
load 2301  /  6684
size:  (375, 1242, 3)
load 2302  /  6684
size:  (376, 1241, 3)
load 2303  /  6684
size:  (375, 1242, 3)
load 2304  /  6684
size:  (374, 1238, 3)
load 2305  /  6684
size:  (376, 1241, 3)
load 2306  /  6684
size:  (375, 1242, 3)
load 2307  /  6684
size:  (375, 1242, 3)
load 2308  /  6684
size:  (375, 1242, 3)
load 2309  /  6684
size:  (375, 1242, 3)
load 2310  /  6684
size:  (375, 1242, 3)
load 2311  /  6684
size:  (375, 1242, 3)
load 2312  /  6684
size:  (375, 1242, 3)
load 2313  /  6684
size:  (374, 1238, 3)
load 2314  /  6684
size:  (375, 1242, 3)
load 2315  /  6684
size:  (375, 1242, 3)
load 2316  /  6684
size:  (375, 1242, 3)
load 2317  /  6684
size:  (375, 1242, 3)
load 2318  /  6684
size:  (374, 1238, 3)
load 2319  /  6684
size:  (375, 1242, 3)
load 2320  /  6684
size:  (376, 1241, 3)
load 2321  /  6684
size:  (376, 1241, 3)
load 2322  /  6684
size:  (375, 1242, 3)
load 2323  /  6684
size:  (375, 1242, 3)
load 2324  /  6684
size:  (375, 1242, 3)
load 2325  /  6684
size:  (376, 1241, 3)
load 2326  /  6684
size:  (375, 1242, 3)
load 2327  /  6684
size:  (375, 1242, 3)
load 2328  /  6684
size:  (375, 1242, 3)
load 2329  /  6684
size:  (375, 1242, 3)
load 2330  /  6684
size:  (375, 1242, 3)
load 2331  /  6684
size:  (375, 1242, 3)
load 2332  /  6684
size:  (375, 1242, 3)
load 2333  /  6684
size:  (375, 1242, 3)
load 2334  /  6684
size:  (375, 1242, 3)
load 2335  /  6684
size:  (375, 1242, 3)
load 2336  /  6684
size:  (375, 1242, 3)
load 2337  /  6684
size:  (375, 1242, 3)
load 2338  /  6684
size:  (375, 1242, 3)
load 2339  /  6684
size:  (375, 1242, 3)
load 2340  /  6684
size:  (375, 1242, 3)
load 2341  /  6684
size:  (370, 1224, 3)
load 2342  /  6684
size:  (375, 1242, 3)
load 2343  /  6684
size:  (375, 1242, 3)
load 2344  /  6684
size:  (375, 1242, 3)
load 2345  /  6684
size:  (375, 1242, 3)
load 2346  /  6684
size:  (375, 1242, 3)
load 2347  /  6684
size:  (375, 1242, 3)
load 2348  /  6684
size:  (374, 1238, 3)
load 2349  /  6684
size:  (375, 1242, 3)
load 2350  /  6684
size:  (375, 1242, 3)
load 2351  /  6684
size:  (375, 1242, 3)
load 2352  /  6684
size:  (375, 1242, 3)
load 2353  /  6684
size:  (375, 1242, 3)
load 2354  /  6684
size:  (374, 1238, 3)
load 2355  /  6684
size:  (375, 1242, 3)
load 2356  /  6684
size:  (375, 1242, 3)
load 2357  /  6684
size:  (376, 1241, 3)
load 2358  /  6684
size:  (375, 1242, 3)
load 2359  /  6684
size:  (375, 1242, 3)
load 2360  /  6684
size:  (375, 1242, 3)
load 2361  /  6684
size:  (375, 1242, 3)
load 2362  /  6684
size:  (375, 1242, 3)
load 2363  /  6684
size:  (375, 1242, 3)
load 2364  /  6684
size:  (375, 1242, 3)
load 2365  /  6684
size:  (375, 1242, 3)
load 2366  /  6684
size:  (375, 1242, 3)
load 2367  /  6684
size:  (375, 1242, 3)
load 2368  /  6684
size:  (375, 1242, 3)
load 2369  /  6684
size:  (375, 1242, 3)
load 2370  /  6684
size:  (375, 1242, 3)
load 2371  /  6684
size:  (375, 1242, 3)
load 2372  /  6684
size:  (375, 1242, 3)
load 2373  /  6684
size:  (375, 1242, 3)
load 2374  /  6684
size:  (375, 1242, 3)
load 2375  /  6684
size:  (375, 1242, 3)
load 2376  /  6684
size:  (370, 1224, 3)
load 2377  /  6684
size:  (375, 1242, 3)
load 2378  /  6684
size:  (375, 1242, 3)
load 2379  /  6684
size:  (375, 1242, 3)
load 2380  /  6684
size:  (375, 1242, 3)
load 2381  /  6684
size:  (375, 1242, 3)
load 2382  /  6684
size:  (375, 1242, 3)
load 2383  /  6684
size:  (375, 1242, 3)
load 2384  /  6684
size:  (375, 1242, 3)
load 2385  /  6684
size:  (375, 1242, 3)
load 2386  /  6684
size:  (375, 1242, 3)
load 2387  /  6684
size:  (375, 1242, 3)
load 2388  /  6684
size:  (375, 1242, 3)
load 2389  /  6684
size:  (375, 1242, 3)
load 2390  /  6684
size:  (375, 1242, 3)
load 2391  /  6684
size:  (375, 1242, 3)
load 2392  /  6684
size:  (375, 1242, 3)
load 2393  /  6684
size:  (375, 1242, 3)
load 2394  /  6684
size:  (375, 1242, 3)
load 2395  /  6684
size:  (375, 1242, 3)
load 2396  /  6684
size:  (375, 1242, 3)
load 2397  /  6684
size:  (375, 1242, 3)
load 2398  /  6684
size:  (375, 1242, 3)
load 2399  /  6684
size:  (375, 1242, 3)
load 2400  /  6684
size:  (375, 1242, 3)
load 2401  /  6684
size:  (375, 1242, 3)
load 2402  /  6684
size:  (375, 1242, 3)
load 2403  /  6684
size:  (375, 1242, 3)
load 2404  /  6684
size:  (374, 1238, 3)
load 2405  /  6684
size:  (375, 1242, 3)
load 2406  /  6684
size:  (375, 1242, 3)
load 2407  /  6684
size:  (375, 1242, 3)
load 2408  /  6684
size:  (375, 1242, 3)
load 2409  /  6684
size:  (375, 1242, 3)
load 2410  /  6684
size:  (375, 1242, 3)
load 2411  /  6684
size:  (376, 1241, 3)
load 2412  /  6684
size:  (375, 1242, 3)
load 2413  /  6684
size:  (374, 1238, 3)
load 2414  /  6684
size:  (375, 1242, 3)
load 2415  /  6684
size:  (376, 1241, 3)
load 2416  /  6684
size:  (375, 1242, 3)
load 2417  /  6684
size:  (375, 1242, 3)
load 2418  /  6684
size:  (375, 1242, 3)
load 2419  /  6684
size:  (375, 1242, 3)
load 2420  /  6684
size:  (375, 1242, 3)
load 2421  /  6684
size:  (375, 1242, 3)
load 2422  /  6684
size:  (374, 1238, 3)
load 2423  /  6684
size:  (375, 1242, 3)
load 2424  /  6684
size:  (375, 1242, 3)
load 2425  /  6684
size:  (375, 1242, 3)
load 2426  /  6684
size:  (375, 1242, 3)
load 2427  /  6684
size:  (375, 1242, 3)
load 2428  /  6684
size:  (374, 1238, 3)
load 2429  /  6684
size:  (375, 1242, 3)
load 2430  /  6684
size:  (375, 1242, 3)
load 2431  /  6684
size:  (375, 1242, 3)
load 2432  /  6684
size:  (375, 1242, 3)
load 2433  /  6684
size:  (375, 1242, 3)
load 2434  /  6684
size:  (375, 1242, 3)
load 2435  /  6684
size:  (375, 1242, 3)
load 2436  /  6684
size:  (375, 1242, 3)
load 2437  /  6684
size:  (375, 1242, 3)
load 2438  /  6684
size:  (375, 1242, 3)
load 2439  /  6684
size:  (375, 1242, 3)
load 2440  /  6684
size:  (375, 1242, 3)
load 2441  /  6684
size:  (375, 1242, 3)
load 2442  /  6684
size:  (375, 1242, 3)
load 2443  /  6684
size:  (375, 1242, 3)
load 2444  /  6684
size:  (375, 1242, 3)
load 2445  /  6684
size:  (375, 1242, 3)
load 2446  /  6684
size:  (375, 1242, 3)
load 2447  /  6684
size:  (375, 1242, 3)
load 2448  /  6684
size:  (375, 1242, 3)
load 2449  /  6684
size:  (375, 1242, 3)
load 2450  /  6684
size:  (375, 1242, 3)
load 2451  /  6684
size:  (375, 1242, 3)
load 2452  /  6684
size:  (376, 1241, 3)
load 2453  /  6684
size:  (375, 1242, 3)
load 2454  /  6684
size:  (375, 1242, 3)
load 2455  /  6684
size:  (375, 1242, 3)
load 2456  /  6684
size:  (374, 1238, 3)
load 2457  /  6684
size:  (375, 1242, 3)
load 2458  /  6684
size:  (375, 1242, 3)
load 2459  /  6684
size:  (375, 1242, 3)
load 2460  /  6684
size:  (375, 1242, 3)
load 2461  /  6684
size:  (375, 1242, 3)
load 2462  /  6684
size:  (375, 1242, 3)
load 2463  /  6684
size:  (375, 1242, 3)
load 2464  /  6684
size:  (375, 1242, 3)
load 2465  /  6684
size:  (375, 1242, 3)
load 2466  /  6684
size:  (375, 1242, 3)
load 2467  /  6684
size:  (375, 1242, 3)
load 2468  /  6684
size:  (375, 1242, 3)
load 2469  /  6684
size:  (375, 1242, 3)
load 2470  /  6684
size:  (375, 1242, 3)
load 2471  /  6684
size:  (374, 1238, 3)
load 2472  /  6684
size:  (375, 1242, 3)
load 2473  /  6684
size:  (374, 1238, 3)
load 2474  /  6684
size:  (375, 1242, 3)
load 2475  /  6684
size:  (375, 1242, 3)
load 2476  /  6684
size:  (375, 1242, 3)
load 2477  /  6684
size:  (375, 1242, 3)
load 2478  /  6684
size:  (375, 1242, 3)
load 2479  /  6684
size:  (375, 1242, 3)
load 2480  /  6684
size:  (375, 1242, 3)
load 2481  /  6684
size:  (375, 1242, 3)
load 2482  /  6684
size:  (375, 1242, 3)
load 2483  /  6684
size:  (375, 1242, 3)
load 2484  /  6684
size:  (375, 1242, 3)
load 2485  /  6684
size:  (375, 1242, 3)
load 2486  /  6684
size:  (375, 1242, 3)
load 2487  /  6684
size:  (375, 1242, 3)
load 2488  /  6684
size:  (376, 1241, 3)
load 2489  /  6684
size:  (374, 1238, 3)
load 2490  /  6684
size:  (376, 1241, 3)
load 2491  /  6684
size:  (375, 1242, 3)
load 2492  /  6684
size:  (375, 1242, 3)
load 2493  /  6684
size:  (374, 1238, 3)
load 2494  /  6684
size:  (375, 1242, 3)
load 2495  /  6684
size:  (375, 1242, 3)
load 2496  /  6684
size:  (375, 1242, 3)
load 2497  /  6684
size:  (375, 1242, 3)
load 2498  /  6684
size:  (375, 1242, 3)
load 2499  /  6684
size:  (374, 1238, 3)
load 2500  /  6684
size:  (375, 1242, 3)
load 2501  /  6684
size:  (375, 1242, 3)
load 2502  /  6684
size:  (375, 1242, 3)
load 2503  /  6684
size:  (375, 1242, 3)
load 2504  /  6684
size:  (375, 1242, 3)
load 2505  /  6684
size:  (375, 1242, 3)
load 2506  /  6684
size:  (375, 1242, 3)
load 2507  /  6684
size:  (375, 1242, 3)
load 2508  /  6684
size:  (375, 1242, 3)
load 2509  /  6684
size:  (375, 1242, 3)
load 2510  /  6684
size:  (375, 1242, 3)
load 2511  /  6684
size:  (375, 1242, 3)
load 2512  /  6684
size:  (375, 1242, 3)
load 2513  /  6684
size:  (375, 1242, 3)
load 2514  /  6684
size:  (375, 1242, 3)
load 2515  /  6684
size:  (375, 1242, 3)
load 2516  /  6684
size:  (375, 1242, 3)
load 2517  /  6684
size:  (375, 1242, 3)
load 2518  /  6684
size:  (375, 1242, 3)
load 2519  /  6684
size:  (375, 1242, 3)
load 2520  /  6684
size:  (375, 1242, 3)
load 2521  /  6684
size:  (375, 1242, 3)
load 2522  /  6684
size:  (375, 1242, 3)
load 2523  /  6684
size:  (375, 1242, 3)
load 2524  /  6684
size:  (375, 1242, 3)
load 2525  /  6684
size:  (375, 1242, 3)
load 2526  /  6684
size:  (375, 1242, 3)
load 2527  /  6684
size:  (375, 1242, 3)
load 2528  /  6684
size:  (375, 1242, 3)
load 2529  /  6684
size:  (375, 1242, 3)
load 2530  /  6684
size:  (375, 1242, 3)
load 2531  /  6684
size:  (375, 1242, 3)
load 2532  /  6684
size:  (375, 1242, 3)
load 2533  /  6684
size:  (375, 1242, 3)
load 2534  /  6684
size:  (375, 1242, 3)
load 2535  /  6684
size:  (375, 1242, 3)
load 2536  /  6684
size:  (375, 1242, 3)
load 2537  /  6684
size:  (375, 1242, 3)
load 2538  /  6684
size:  (376, 1241, 3)
load 2539  /  6684
size:  (375, 1242, 3)
load 2540  /  6684
size:  (375, 1242, 3)
load 2541  /  6684
size:  (375, 1242, 3)
load 2542  /  6684
size:  (375, 1242, 3)
load 2543  /  6684
size:  (375, 1242, 3)
load 2544  /  6684
size:  (375, 1242, 3)
load 2545  /  6684
size:  (375, 1242, 3)
load 2546  /  6684
size:  (375, 1242, 3)
load 2547  /  6684
size:  (375, 1242, 3)
load 2548  /  6684
size:  (375, 1242, 3)
load 2549  /  6684
size:  (375, 1242, 3)
load 2550  /  6684
size:  (375, 1242, 3)
load 2551  /  6684
size:  (375, 1242, 3)
load 2552  /  6684
size:  (375, 1242, 3)
load 2553  /  6684
size:  (375, 1242, 3)
load 2554  /  6684
size:  (375, 1242, 3)
load 2555  /  6684
size:  (375, 1242, 3)
load 2556  /  6684
size:  (375, 1242, 3)
load 2557  /  6684
size:  (375, 1242, 3)
load 2558  /  6684
size:  (375, 1242, 3)
load 2559  /  6684
size:  (375, 1242, 3)
load 2560  /  6684
size:  (375, 1242, 3)
load 2561  /  6684
size:  (375, 1242, 3)
load 2562  /  6684
size:  (375, 1242, 3)
load 2563  /  6684
size:  (375, 1242, 3)
load 2564  /  6684
size:  (375, 1242, 3)
load 2565  /  6684
size:  (375, 1242, 3)
load 2566  /  6684
size:  (375, 1242, 3)
load 2567  /  6684
size:  (375, 1242, 3)
load 2568  /  6684
size:  (375, 1242, 3)
load 2569  /  6684
size:  (375, 1242, 3)
load 2570  /  6684
size:  (375, 1242, 3)
load 2571  /  6684
size:  (375, 1242, 3)
load 2572  /  6684
size:  (374, 1238, 3)
load 2573  /  6684
size:  (375, 1242, 3)
load 2574  /  6684
size:  (376, 1241, 3)
load 2575  /  6684
size:  (375, 1242, 3)
load 2576  /  6684
size:  (375, 1242, 3)
load 2577  /  6684
size:  (375, 1242, 3)
load 2578  /  6684
size:  (375, 1242, 3)
load 2579  /  6684
size:  (375, 1242, 3)
load 2580  /  6684
size:  (375, 1242, 3)
load 2581  /  6684
size:  (375, 1242, 3)
load 2582  /  6684
size:  (375, 1242, 3)
load 2583  /  6684
size:  (375, 1242, 3)
load 2584  /  6684
size:  (375, 1242, 3)
load 2585  /  6684
size:  (375, 1242, 3)
load 2586  /  6684
size:  (375, 1242, 3)
load 2587  /  6684
size:  (375, 1242, 3)
load 2588  /  6684
size:  (375, 1242, 3)
load 2589  /  6684
size:  (375, 1242, 3)
load 2590  /  6684
size:  (375, 1242, 3)
load 2591  /  6684
size:  (375, 1242, 3)
load 2592  /  6684
size:  (375, 1242, 3)
load 2593  /  6684
size:  (370, 1224, 3)
load 2594  /  6684
size:  (375, 1242, 3)
load 2595  /  6684
size:  (375, 1242, 3)
load 2596  /  6684
size:  (375, 1242, 3)
load 2597  /  6684
size:  (375, 1242, 3)
load 2598  /  6684
size:  (375, 1242, 3)
load 2599  /  6684
size:  (375, 1242, 3)
load 2600  /  6684
size:  (375, 1242, 3)
load 2601  /  6684
size:  (375, 1242, 3)
load 2602  /  6684
size:  (375, 1242, 3)
load 2603  /  6684
size:  (376, 1241, 3)
load 2604  /  6684
size:  (375, 1242, 3)
load 2605  /  6684
size:  (375, 1242, 3)
load 2606  /  6684
size:  (375, 1242, 3)
load 2607  /  6684
size:  (375, 1242, 3)
load 2608  /  6684
size:  (375, 1242, 3)
load 2609  /  6684
size:  (375, 1242, 3)
load 2610  /  6684
size:  (375, 1242, 3)
load 2611  /  6684
size:  (375, 1242, 3)
load 2612  /  6684
size:  (375, 1242, 3)
load 2613  /  6684
size:  (375, 1242, 3)
load 2614  /  6684
size:  (375, 1242, 3)
load 2615  /  6684
size:  (375, 1242, 3)
load 2616  /  6684
size:  (374, 1238, 3)
load 2617  /  6684
size:  (375, 1242, 3)
load 2618  /  6684
size:  (375, 1242, 3)
load 2619  /  6684
size:  (376, 1241, 3)
load 2620  /  6684
size:  (375, 1242, 3)
load 2621  /  6684
size:  (375, 1242, 3)
load 2622  /  6684
size:  (375, 1242, 3)
load 2623  /  6684
size:  (375, 1242, 3)
load 2624  /  6684
size:  (375, 1242, 3)
load 2625  /  6684
size:  (375, 1242, 3)
load 2626  /  6684
size:  (375, 1242, 3)
load 2627  /  6684
size:  (375, 1242, 3)
load 2628  /  6684
size:  (375, 1242, 3)
load 2629  /  6684
size:  (376, 1241, 3)
load 2630  /  6684
size:  (375, 1242, 3)
load 2631  /  6684
size:  (375, 1242, 3)
load 2632  /  6684
size:  (376, 1241, 3)
load 2633  /  6684
size:  (375, 1242, 3)
load 2634  /  6684
size:  (375, 1242, 3)
load 2635  /  6684
size:  (374, 1238, 3)
load 2636  /  6684
size:  (375, 1242, 3)
load 2637  /  6684
size:  (375, 1242, 3)
load 2638  /  6684
size:  (375, 1242, 3)
load 2639  /  6684
size:  (375, 1242, 3)
load 2640  /  6684
size:  (375, 1242, 3)
load 2641  /  6684
size:  (375, 1242, 3)
load 2642  /  6684
size:  (375, 1242, 3)
load 2643  /  6684
size:  (375, 1242, 3)
load 2644  /  6684
size:  (375, 1242, 3)
load 2645  /  6684
size:  (375, 1242, 3)
load 2646  /  6684
size:  (375, 1242, 3)
load 2647  /  6684
size:  (375, 1242, 3)
load 2648  /  6684
size:  (375, 1242, 3)
load 2649  /  6684
size:  (375, 1242, 3)
load 2650  /  6684
size:  (375, 1242, 3)
load 2651  /  6684
size:  (375, 1242, 3)
load 2652  /  6684
size:  (375, 1242, 3)
load 2653  /  6684
size:  (375, 1242, 3)
load 2654  /  6684
size:  (375, 1242, 3)
load 2655  /  6684
size:  (375, 1242, 3)
load 2656  /  6684
size:  (375, 1242, 3)
load 2657  /  6684
size:  (375, 1242, 3)
load 2658  /  6684
size:  (375, 1242, 3)
load 2659  /  6684
size:  (375, 1242, 3)
load 2660  /  6684
size:  (375, 1242, 3)
load 2661  /  6684
size:  (375, 1242, 3)
load 2662  /  6684
size:  (375, 1242, 3)
load 2663  /  6684
size:  (375, 1242, 3)
load 2664  /  6684
size:  (375, 1242, 3)
load 2665  /  6684
size:  (375, 1242, 3)
load 2666  /  6684
size:  (370, 1224, 3)
load 2667  /  6684
size:  (375, 1242, 3)
load 2668  /  6684
size:  (375, 1242, 3)
load 2669  /  6684
size:  (375, 1242, 3)
load 2670  /  6684
size:  (375, 1242, 3)
load 2671  /  6684
size:  (375, 1242, 3)
load 2672  /  6684
size:  (375, 1242, 3)
load 2673  /  6684
size:  (375, 1242, 3)
load 2674  /  6684
size:  (375, 1242, 3)
load 2675  /  6684
size:  (375, 1242, 3)
load 2676  /  6684
size:  (375, 1242, 3)
load 2677  /  6684
size:  (375, 1242, 3)
load 2678  /  6684
size:  (375, 1242, 3)
load 2679  /  6684
size:  (375, 1242, 3)
load 2680  /  6684
size:  (375, 1242, 3)
load 2681  /  6684
size:  (375, 1242, 3)
load 2682  /  6684
size:  (375, 1242, 3)
load 2683  /  6684
size:  (375, 1242, 3)
load 2684  /  6684
size:  (375, 1242, 3)
load 2685  /  6684
size:  (375, 1242, 3)
load 2686  /  6684
size:  (375, 1242, 3)
load 2687  /  6684
size:  (375, 1242, 3)
load 2688  /  6684
size:  (375, 1242, 3)
load 2689  /  6684
size:  (375, 1242, 3)
load 2690  /  6684
size:  (375, 1242, 3)
load 2691  /  6684
size:  (370, 1224, 3)
load 2692  /  6684
size:  (375, 1242, 3)
load 2693  /  6684
size:  (375, 1242, 3)
load 2694  /  6684
size:  (375, 1242, 3)
load 2695  /  6684
size:  (375, 1242, 3)
load 2696  /  6684
size:  (375, 1242, 3)
load 2697  /  6684
size:  (375, 1242, 3)
load 2698  /  6684
size:  (376, 1241, 3)
load 2699  /  6684
size:  (375, 1242, 3)
load 2700  /  6684
size:  (375, 1242, 3)
load 2701  /  6684
size:  (375, 1242, 3)
load 2702  /  6684
size:  (375, 1242, 3)
load 2703  /  6684
size:  (375, 1242, 3)
load 2704  /  6684
size:  (375, 1242, 3)
load 2705  /  6684
size:  (375, 1242, 3)
load 2706  /  6684
size:  (375, 1242, 3)
load 2707  /  6684
size:  (375, 1242, 3)
load 2708  /  6684
size:  (375, 1242, 3)
load 2709  /  6684
size:  (375, 1242, 3)
load 2710  /  6684
size:  (374, 1238, 3)
load 2711  /  6684
size:  (376, 1241, 3)
load 2712  /  6684
size:  (375, 1242, 3)
load 2713  /  6684
size:  (370, 1224, 3)
load 2714  /  6684
size:  (375, 1242, 3)
load 2715  /  6684
size:  (374, 1238, 3)
load 2716  /  6684
size:  (375, 1242, 3)
load 2717  /  6684
size:  (376, 1241, 3)
load 2718  /  6684
size:  (375, 1242, 3)
load 2719  /  6684
size:  (375, 1242, 3)
load 2720  /  6684
size:  (375, 1242, 3)
load 2721  /  6684
size:  (375, 1242, 3)
load 2722  /  6684
size:  (375, 1242, 3)
load 2723  /  6684
size:  (375, 1242, 3)
load 2724  /  6684
size:  (375, 1242, 3)
load 2725  /  6684
size:  (375, 1242, 3)
load 2726  /  6684
size:  (370, 1224, 3)
load 2727  /  6684
size:  (375, 1242, 3)
load 2728  /  6684
size:  (375, 1242, 3)
load 2729  /  6684
size:  (375, 1242, 3)
load 2730  /  6684
size:  (374, 1238, 3)
load 2731  /  6684
size:  (375, 1242, 3)
load 2732  /  6684
size:  (370, 1224, 3)
load 2733  /  6684
size:  (375, 1242, 3)
load 2734  /  6684
size:  (375, 1242, 3)
load 2735  /  6684
size:  (374, 1238, 3)
load 2736  /  6684
size:  (375, 1242, 3)
load 2737  /  6684
size:  (375, 1242, 3)
load 2738  /  6684
size:  (375, 1242, 3)
load 2739  /  6684
size:  (375, 1242, 3)
load 2740  /  6684
size:  (374, 1238, 3)
load 2741  /  6684
size:  (374, 1238, 3)
load 2742  /  6684
size:  (375, 1242, 3)
load 2743  /  6684
size:  (375, 1242, 3)
load 2744  /  6684
size:  (375, 1242, 3)
load 2745  /  6684
size:  (375, 1242, 3)
load 2746  /  6684
size:  (375, 1242, 3)
load 2747  /  6684
size:  (375, 1242, 3)
load 2748  /  6684
size:  (375, 1242, 3)
load 2749  /  6684
size:  (375, 1242, 3)
load 2750  /  6684
size:  (375, 1242, 3)
load 2751  /  6684
size:  (375, 1242, 3)
load 2752  /  6684
size:  (375, 1242, 3)
load 2753  /  6684
size:  (375, 1242, 3)
load 2754  /  6684
size:  (375, 1242, 3)
load 2755  /  6684
size:  (375, 1242, 3)
load 2756  /  6684
size:  (375, 1242, 3)
load 2757  /  6684
size:  (374, 1238, 3)
load 2758  /  6684
size:  (375, 1242, 3)
load 2759  /  6684
size:  (375, 1242, 3)
load 2760  /  6684
size:  (375, 1242, 3)
load 2761  /  6684
size:  (375, 1242, 3)
load 2762  /  6684
size:  (375, 1242, 3)
load 2763  /  6684
size:  (375, 1242, 3)
load 2764  /  6684
size:  (375, 1242, 3)
load 2765  /  6684
size:  (375, 1242, 3)
load 2766  /  6684
size:  (375, 1242, 3)
load 2767  /  6684
size:  (375, 1242, 3)
load 2768  /  6684
size:  (375, 1242, 3)
load 2769  /  6684
size:  (375, 1242, 3)
load 2770  /  6684
size:  (375, 1242, 3)
load 2771  /  6684
size:  (375, 1242, 3)
load 2772  /  6684
size:  (370, 1224, 3)
load 2773  /  6684
size:  (375, 1242, 3)
load 2774  /  6684
size:  (376, 1241, 3)
load 2775  /  6684
size:  (375, 1242, 3)
load 2776  /  6684
size:  (375, 1242, 3)
load 2777  /  6684
size:  (375, 1242, 3)
load 2778  /  6684
size:  (375, 1242, 3)
load 2779  /  6684
size:  (375, 1242, 3)
load 2780  /  6684
size:  (375, 1242, 3)
load 2781  /  6684
size:  (375, 1242, 3)
load 2782  /  6684
size:  (375, 1242, 3)
load 2783  /  6684
size:  (374, 1238, 3)
load 2784  /  6684
size:  (375, 1242, 3)
load 2785  /  6684
size:  (375, 1242, 3)
load 2786  /  6684
size:  (375, 1242, 3)
load 2787  /  6684
size:  (375, 1242, 3)
load 2788  /  6684
size:  (374, 1238, 3)
load 2789  /  6684
size:  (375, 1242, 3)
load 2790  /  6684
size:  (375, 1242, 3)
load 2791  /  6684
size:  (376, 1241, 3)
load 2792  /  6684
size:  (375, 1242, 3)
load 2793  /  6684
size:  (375, 1242, 3)
load 2794  /  6684
size:  (375, 1242, 3)
load 2795  /  6684
size:  (375, 1242, 3)
load 2796  /  6684
size:  (375, 1242, 3)
load 2797  /  6684
size:  (375, 1242, 3)
load 2798  /  6684
size:  (375, 1242, 3)
load 2799  /  6684
size:  (375, 1242, 3)
load 2800  /  6684
size:  (375, 1242, 3)
load 2801  /  6684
size:  (375, 1242, 3)
load 2802  /  6684
size:  (370, 1224, 3)
load 2803  /  6684
size:  (375, 1242, 3)
load 2804  /  6684
size:  (375, 1242, 3)
load 2805  /  6684
size:  (375, 1242, 3)
load 2806  /  6684
size:  (375, 1242, 3)
load 2807  /  6684
size:  (375, 1242, 3)
load 2808  /  6684
size:  (375, 1242, 3)
load 2809  /  6684
size:  (370, 1224, 3)
load 2810  /  6684
size:  (375, 1242, 3)
load 2811  /  6684
size:  (375, 1242, 3)
load 2812  /  6684
size:  (375, 1242, 3)
load 2813  /  6684
size:  (375, 1242, 3)
load 2814  /  6684
size:  (375, 1242, 3)
load 2815  /  6684
size:  (375, 1242, 3)
load 2816  /  6684
size:  (375, 1242, 3)
load 2817  /  6684
size:  (375, 1242, 3)
load 2818  /  6684
size:  (375, 1242, 3)
load 2819  /  6684
size:  (375, 1242, 3)
load 2820  /  6684
size:  (375, 1242, 3)
load 2821  /  6684
size:  (375, 1242, 3)
load 2822  /  6684
size:  (375, 1242, 3)
load 2823  /  6684
size:  (375, 1242, 3)
load 2824  /  6684
size:  (375, 1242, 3)
load 2825  /  6684
size:  (375, 1242, 3)
load 2826  /  6684
size:  (375, 1242, 3)
load 2827  /  6684
size:  (375, 1242, 3)
load 2828  /  6684
size:  (375, 1242, 3)
load 2829  /  6684
size:  (375, 1242, 3)
load 2830  /  6684
size:  (375, 1242, 3)
load 2831  /  6684
size:  (375, 1242, 3)
load 2832  /  6684
size:  (370, 1224, 3)
load 2833  /  6684
size:  (375, 1242, 3)
load 2834  /  6684
size:  (375, 1242, 3)
load 2835  /  6684
size:  (376, 1241, 3)
load 2836  /  6684
size:  (375, 1242, 3)
load 2837  /  6684
size:  (375, 1242, 3)
load 2838  /  6684
size:  (375, 1242, 3)
load 2839  /  6684
size:  (375, 1242, 3)
load 2840  /  6684
size:  (375, 1242, 3)
load 2841  /  6684
size:  (375, 1242, 3)
load 2842  /  6684
size:  (375, 1242, 3)
load 2843  /  6684
size:  (375, 1242, 3)
load 2844  /  6684
size:  (375, 1242, 3)
load 2845  /  6684
size:  (375, 1242, 3)
load 2846  /  6684
size:  (375, 1242, 3)
load 2847  /  6684
size:  (375, 1242, 3)
load 2848  /  6684
size:  (375, 1242, 3)
load 2849  /  6684
size:  (375, 1242, 3)
load 2850  /  6684
size:  (375, 1242, 3)
load 2851  /  6684
size:  (375, 1242, 3)
load 2852  /  6684
size:  (375, 1242, 3)
load 2853  /  6684
size:  (375, 1242, 3)
load 2854  /  6684
size:  (375, 1242, 3)
load 2855  /  6684
size:  (375, 1242, 3)
load 2856  /  6684
size:  (375, 1242, 3)
load 2857  /  6684
size:  (375, 1242, 3)
load 2858  /  6684
size:  (376, 1241, 3)
load 2859  /  6684
size:  (375, 1242, 3)
load 2860  /  6684
size:  (376, 1241, 3)
load 2861  /  6684
size:  (375, 1242, 3)
load 2862  /  6684
size:  (375, 1242, 3)
load 2863  /  6684
size:  (375, 1242, 3)
load 2864  /  6684
size:  (375, 1242, 3)
load 2865  /  6684
size:  (375, 1242, 3)
load 2866  /  6684
size:  (375, 1242, 3)
load 2867  /  6684
size:  (375, 1242, 3)
load 2868  /  6684
size:  (375, 1242, 3)
load 2869  /  6684
size:  (375, 1242, 3)
load 2870  /  6684
size:  (375, 1242, 3)
load 2871  /  6684
size:  (375, 1242, 3)
load 2872  /  6684
size:  (374, 1238, 3)
load 2873  /  6684
size:  (375, 1242, 3)
load 2874  /  6684
size:  (375, 1242, 3)
load 2875  /  6684
size:  (370, 1224, 3)
load 2876  /  6684
size:  (375, 1242, 3)
load 2877  /  6684
size:  (375, 1242, 3)
load 2878  /  6684
size:  (375, 1242, 3)
load 2879  /  6684
size:  (376, 1241, 3)
load 2880  /  6684
size:  (375, 1242, 3)
load 2881  /  6684
size:  (374, 1238, 3)
load 2882  /  6684
size:  (375, 1242, 3)
load 2883  /  6684
size:  (375, 1242, 3)
load 2884  /  6684
size:  (375, 1242, 3)
load 2885  /  6684
size:  (375, 1242, 3)
load 2886  /  6684
size:  (375, 1242, 3)
load 2887  /  6684
size:  (375, 1242, 3)
load 2888  /  6684
size:  (375, 1242, 3)
load 2889  /  6684
size:  (375, 1242, 3)
load 2890  /  6684
size:  (375, 1242, 3)
load 2891  /  6684
size:  (375, 1242, 3)
load 2892  /  6684
size:  (375, 1242, 3)
load 2893  /  6684
size:  (375, 1242, 3)
load 2894  /  6684
size:  (375, 1242, 3)
load 2895  /  6684
size:  (375, 1242, 3)
load 2896  /  6684
size:  (375, 1242, 3)
load 2897  /  6684
size:  (375, 1242, 3)
load 2898  /  6684
size:  (375, 1242, 3)
load 2899  /  6684
size:  (375, 1242, 3)
load 2900  /  6684
size:  (375, 1242, 3)
load 2901  /  6684
size:  (375, 1242, 3)
load 2902  /  6684
size:  (375, 1242, 3)
load 2903  /  6684
size:  (375, 1242, 3)
load 2904  /  6684
size:  (375, 1242, 3)
load 2905  /  6684
size:  (374, 1238, 3)
load 2906  /  6684
size:  (375, 1242, 3)
load 2907  /  6684
size:  (375, 1242, 3)
load 2908  /  6684
size:  (375, 1242, 3)
load 2909  /  6684
size:  (375, 1242, 3)
load 2910  /  6684
size:  (375, 1242, 3)
load 2911  /  6684
size:  (375, 1242, 3)
load 2912  /  6684
size:  (375, 1242, 3)
load 2913  /  6684
size:  (375, 1242, 3)
load 2914  /  6684
size:  (375, 1242, 3)
load 2915  /  6684
size:  (375, 1242, 3)
load 2916  /  6684
size:  (375, 1242, 3)
load 2917  /  6684
size:  (375, 1242, 3)
load 2918  /  6684
size:  (375, 1242, 3)
load 2919  /  6684
size:  (375, 1242, 3)
load 2920  /  6684
size:  (375, 1242, 3)
load 2921  /  6684
size:  (375, 1242, 3)
load 2922  /  6684
size:  (370, 1224, 3)
load 2923  /  6684
size:  (375, 1242, 3)
load 2924  /  6684
size:  (375, 1242, 3)
load 2925  /  6684
size:  (375, 1242, 3)
load 2926  /  6684
size:  (370, 1224, 3)
load 2927  /  6684
size:  (375, 1242, 3)
load 2928  /  6684
size:  (375, 1242, 3)
load 2929  /  6684
size:  (370, 1224, 3)
load 2930  /  6684
size:  (375, 1242, 3)
load 2931  /  6684
size:  (375, 1242, 3)
load 2932  /  6684
size:  (375, 1242, 3)
load 2933  /  6684
size:  (375, 1242, 3)
load 2934  /  6684
size:  (375, 1242, 3)
load 2935  /  6684
size:  (375, 1242, 3)
load 2936  /  6684
size:  (374, 1238, 3)
load 2937  /  6684
size:  (375, 1242, 3)
load 2938  /  6684
size:  (375, 1242, 3)
load 2939  /  6684
size:  (375, 1242, 3)
load 2940  /  6684
size:  (375, 1242, 3)
load 2941  /  6684
size:  (375, 1242, 3)
load 2942  /  6684
size:  (375, 1242, 3)
load 2943  /  6684
size:  (375, 1242, 3)
load 2944  /  6684
size:  (375, 1242, 3)
load 2945  /  6684
size:  (375, 1242, 3)
load 2946  /  6684
size:  (375, 1242, 3)
load 2947  /  6684
size:  (375, 1242, 3)
load 2948  /  6684
size:  (375, 1242, 3)
load 2949  /  6684
size:  (375, 1242, 3)
load 2950  /  6684
size:  (375, 1242, 3)
load 2951  /  6684
size:  (375, 1242, 3)
load 2952  /  6684
size:  (375, 1242, 3)
load 2953  /  6684
size:  (370, 1224, 3)
load 2954  /  6684
size:  (375, 1242, 3)
load 2955  /  6684
size:  (375, 1242, 3)
load 2956  /  6684
size:  (375, 1242, 3)
load 2957  /  6684
size:  (375, 1242, 3)
load 2958  /  6684
size:  (375, 1242, 3)
load 2959  /  6684
size:  (375, 1242, 3)
load 2960  /  6684
size:  (375, 1242, 3)
load 2961  /  6684
size:  (375, 1242, 3)
load 2962  /  6684
size:  (375, 1242, 3)
load 2963  /  6684
size:  (375, 1242, 3)
load 2964  /  6684
size:  (375, 1242, 3)
load 2965  /  6684
size:  (376, 1241, 3)
load 2966  /  6684
size:  (375, 1242, 3)
load 2967  /  6684
size:  (375, 1242, 3)
load 2968  /  6684
size:  (375, 1242, 3)
load 2969  /  6684
size:  (375, 1242, 3)
load 2970  /  6684
size:  (375, 1242, 3)
load 2971  /  6684
size:  (375, 1242, 3)
load 2972  /  6684
size:  (375, 1242, 3)
load 2973  /  6684
size:  (375, 1242, 3)
load 2974  /  6684
size:  (375, 1242, 3)
load 2975  /  6684
size:  (375, 1242, 3)
load 2976  /  6684
size:  (375, 1242, 3)
load 2977  /  6684
size:  (375, 1242, 3)
load 2978  /  6684
size:  (375, 1242, 3)
load 2979  /  6684
size:  (375, 1242, 3)
load 2980  /  6684
size:  (375, 1242, 3)
load 2981  /  6684
size:  (375, 1242, 3)
load 2982  /  6684
size:  (375, 1242, 3)
load 2983  /  6684
size:  (375, 1242, 3)
load 2984  /  6684
size:  (375, 1242, 3)
load 2985  /  6684
size:  (375, 1242, 3)
load 2986  /  6684
size:  (375, 1242, 3)
load 2987  /  6684
size:  (375, 1242, 3)
load 2988  /  6684
size:  (375, 1242, 3)
load 2989  /  6684
size:  (375, 1242, 3)
load 2990  /  6684
size:  (375, 1242, 3)
load 2991  /  6684
size:  (370, 1224, 3)
load 2992  /  6684
size:  (375, 1242, 3)
load 2993  /  6684
size:  (375, 1242, 3)
load 2994  /  6684
size:  (375, 1242, 3)
load 2995  /  6684
size:  (375, 1242, 3)
load 2996  /  6684
size:  (375, 1242, 3)
load 2997  /  6684
size:  (370, 1224, 3)
load 2998  /  6684
size:  (375, 1242, 3)
load 2999  /  6684
size:  (375, 1242, 3)
load 3000  /  6684
size:  (375, 1242, 3)
load 3001  /  6684
size:  (375, 1242, 3)
load 3002  /  6684
size:  (375, 1242, 3)
load 3003  /  6684
size:  (375, 1242, 3)
load 3004  /  6684
size:  (375, 1242, 3)
load 3005  /  6684
size:  (375, 1242, 3)
load 3006  /  6684
size:  (375, 1242, 3)
load 3007  /  6684
size:  (375, 1242, 3)
load 3008  /  6684
size:  (370, 1224, 3)
load 3009  /  6684
size:  (375, 1242, 3)
load 3010  /  6684
size:  (375, 1242, 3)
load 3011  /  6684
size:  (375, 1242, 3)
load 3012  /  6684
size:  (375, 1242, 3)
load 3013  /  6684
size:  (370, 1224, 3)
load 3014  /  6684
size:  (375, 1242, 3)
load 3015  /  6684
size:  (375, 1242, 3)
load 3016  /  6684
size:  (376, 1241, 3)
load 3017  /  6684
size:  (375, 1242, 3)
load 3018  /  6684
size:  (370, 1224, 3)
load 3019  /  6684
size:  (375, 1242, 3)
load 3020  /  6684
size:  (375, 1242, 3)
load 3021  /  6684
size:  (375, 1242, 3)
load 3022  /  6684
size:  (375, 1242, 3)
load 3023  /  6684
size:  (375, 1242, 3)
load 3024  /  6684
size:  (370, 1224, 3)
load 3025  /  6684
size:  (375, 1242, 3)
load 3026  /  6684
size:  (375, 1242, 3)
load 3027  /  6684
size:  (375, 1242, 3)
load 3028  /  6684
size:  (375, 1242, 3)
load 3029  /  6684
size:  (375, 1242, 3)
load 3030  /  6684
size:  (375, 1242, 3)
load 3031  /  6684
size:  (375, 1242, 3)
load 3032  /  6684
size:  (375, 1242, 3)
load 3033  /  6684
size:  (375, 1242, 3)
load 3034  /  6684
size:  (375, 1242, 3)
load 3035  /  6684
size:  (375, 1242, 3)
load 3036  /  6684
size:  (375, 1242, 3)
load 3037  /  6684
size:  (375, 1242, 3)
load 3038  /  6684
size:  (375, 1242, 3)
load 3039  /  6684
size:  (375, 1242, 3)
load 3040  /  6684
size:  (375, 1242, 3)
load 3041  /  6684
size:  (375, 1242, 3)
load 3042  /  6684
size:  (375, 1242, 3)
load 3043  /  6684
size:  (375, 1242, 3)
load 3044  /  6684
size:  (375, 1242, 3)
load 3045  /  6684
size:  (370, 1224, 3)
load 3046  /  6684
size:  (375, 1242, 3)
load 3047  /  6684
size:  (375, 1242, 3)
load 3048  /  6684
size:  (375, 1242, 3)
load 3049  /  6684
size:  (375, 1242, 3)
load 3050  /  6684
size:  (375, 1242, 3)
load 3051  /  6684
size:  (375, 1242, 3)
load 3052  /  6684
size:  (375, 1242, 3)
load 3053  /  6684
size:  (375, 1242, 3)
load 3054  /  6684
size:  (375, 1242, 3)
load 3055  /  6684
size:  (375, 1242, 3)
load 3056  /  6684
size:  (375, 1242, 3)
load 3057  /  6684
size:  (375, 1242, 3)
load 3058  /  6684
size:  (375, 1242, 3)
load 3059  /  6684
size:  (375, 1242, 3)
load 3060  /  6684
size:  (375, 1242, 3)
load 3061  /  6684
size:  (375, 1242, 3)
load 3062  /  6684
size:  (375, 1242, 3)
load 3063  /  6684
size:  (375, 1242, 3)
load 3064  /  6684
size:  (375, 1242, 3)
load 3065  /  6684
size:  (375, 1242, 3)
load 3066  /  6684
size:  (375, 1242, 3)
load 3067  /  6684
size:  (375, 1242, 3)
load 3068  /  6684
size:  (375, 1242, 3)
load 3069  /  6684
size:  (375, 1242, 3)
load 3070  /  6684
size:  (375, 1242, 3)
load 3071  /  6684
size:  (375, 1242, 3)
load 3072  /  6684
size:  (375, 1242, 3)
load 3073  /  6684
size:  (375, 1242, 3)
load 3074  /  6684
size:  (375, 1242, 3)
load 3075  /  6684
size:  (375, 1242, 3)
load 3076  /  6684
size:  (374, 1238, 3)
load 3077  /  6684
size:  (375, 1242, 3)
load 3078  /  6684
size:  (375, 1242, 3)
load 3079  /  6684
size:  (375, 1242, 3)
load 3080  /  6684
size:  (374, 1238, 3)
load 3081  /  6684
size:  (375, 1242, 3)
load 3082  /  6684
size:  (375, 1242, 3)
load 3083  /  6684
size:  (375, 1242, 3)
load 3084  /  6684
size:  (375, 1242, 3)
load 3085  /  6684
size:  (376, 1241, 3)
load 3086  /  6684
size:  (370, 1224, 3)
load 3087  /  6684
size:  (375, 1242, 3)
load 3088  /  6684
size:  (375, 1242, 3)
load 3089  /  6684
size:  (375, 1242, 3)
load 3090  /  6684
size:  (375, 1242, 3)
load 3091  /  6684
size:  (375, 1242, 3)
load 3092  /  6684
size:  (375, 1242, 3)
load 3093  /  6684
size:  (375, 1242, 3)
load 3094  /  6684
size:  (375, 1242, 3)
load 3095  /  6684
size:  (375, 1242, 3)
load 3096  /  6684
size:  (375, 1242, 3)
load 3097  /  6684
size:  (375, 1242, 3)
load 3098  /  6684
size:  (374, 1238, 3)
load 3099  /  6684
size:  (376, 1241, 3)
load 3100  /  6684
size:  (370, 1224, 3)
load 3101  /  6684
size:  (375, 1242, 3)
load 3102  /  6684
size:  (375, 1242, 3)
load 3103  /  6684
size:  (375, 1242, 3)
load 3104  /  6684
size:  (375, 1242, 3)
load 3105  /  6684
size:  (375, 1242, 3)
load 3106  /  6684
size:  (375, 1242, 3)
load 3107  /  6684
size:  (375, 1242, 3)
load 3108  /  6684
size:  (375, 1242, 3)
load 3109  /  6684
size:  (375, 1242, 3)
load 3110  /  6684
size:  (375, 1242, 3)
load 3111  /  6684
size:  (375, 1242, 3)
load 3112  /  6684
size:  (375, 1242, 3)
load 3113  /  6684
size:  (375, 1242, 3)
load 3114  /  6684
size:  (375, 1242, 3)
load 3115  /  6684
size:  (375, 1242, 3)
load 3116  /  6684
size:  (375, 1242, 3)
load 3117  /  6684
size:  (375, 1242, 3)
load 3118  /  6684
size:  (375, 1242, 3)
load 3119  /  6684
size:  (374, 1238, 3)
load 3120  /  6684
size:  (375, 1242, 3)
load 3121  /  6684
size:  (375, 1242, 3)
load 3122  /  6684
size:  (375, 1242, 3)
load 3123  /  6684
size:  (375, 1242, 3)
load 3124  /  6684
size:  (375, 1242, 3)
load 3125  /  6684
size:  (375, 1242, 3)
load 3126  /  6684
size:  (375, 1242, 3)
load 3127  /  6684
size:  (375, 1242, 3)
load 3128  /  6684
size:  (375, 1242, 3)
load 3129  /  6684
size:  (375, 1242, 3)
load 3130  /  6684
size:  (375, 1242, 3)
load 3131  /  6684
size:  (375, 1242, 3)
load 3132  /  6684
size:  (375, 1242, 3)
load 3133  /  6684
size:  (375, 1242, 3)
load 3134  /  6684
size:  (370, 1224, 3)
load 3135  /  6684
size:  (376, 1241, 3)
load 3136  /  6684
size:  (375, 1242, 3)
load 3137  /  6684
size:  (375, 1242, 3)
load 3138  /  6684
size:  (375, 1242, 3)
load 3139  /  6684
size:  (375, 1242, 3)
load 3140  /  6684
size:  (375, 1242, 3)
load 3141  /  6684
size:  (375, 1242, 3)
load 3142  /  6684
size:  (375, 1242, 3)
load 3143  /  6684
size:  (375, 1242, 3)
load 3144  /  6684
size:  (375, 1242, 3)
load 3145  /  6684
size:  (375, 1242, 3)
load 3146  /  6684
size:  (375, 1242, 3)
load 3147  /  6684
size:  (375, 1242, 3)
load 3148  /  6684
size:  (375, 1242, 3)
load 3149  /  6684
size:  (375, 1242, 3)
load 3150  /  6684
size:  (374, 1238, 3)
load 3151  /  6684
size:  (375, 1242, 3)
load 3152  /  6684
size:  (375, 1242, 3)
load 3153  /  6684
size:  (375, 1242, 3)
load 3154  /  6684
size:  (375, 1242, 3)
load 3155  /  6684
size:  (375, 1242, 3)
load 3156  /  6684
size:  (375, 1242, 3)
load 3157  /  6684
size:  (374, 1238, 3)
load 3158  /  6684
size:  (375, 1242, 3)
load 3159  /  6684
size:  (374, 1238, 3)
load 3160  /  6684
size:  (375, 1242, 3)
load 3161  /  6684
size:  (375, 1242, 3)
load 3162  /  6684
size:  (375, 1242, 3)
load 3163  /  6684
size:  (375, 1242, 3)
load 3164  /  6684
size:  (375, 1242, 3)
load 3165  /  6684
size:  (375, 1242, 3)
load 3166  /  6684
size:  (375, 1242, 3)
load 3167  /  6684
size:  (375, 1242, 3)
load 3168  /  6684
size:  (375, 1242, 3)
load 3169  /  6684
size:  (376, 1241, 3)
load 3170  /  6684
size:  (375, 1242, 3)
load 3171  /  6684
size:  (375, 1242, 3)
load 3172  /  6684
size:  (375, 1242, 3)
load 3173  /  6684
size:  (375, 1242, 3)
load 3174  /  6684
size:  (376, 1241, 3)
load 3175  /  6684
size:  (375, 1242, 3)
load 3176  /  6684
size:  (374, 1238, 3)
load 3177  /  6684
size:  (375, 1242, 3)
load 3178  /  6684
size:  (375, 1242, 3)
load 3179  /  6684
size:  (375, 1242, 3)
load 3180  /  6684
size:  (375, 1242, 3)
load 3181  /  6684
size:  (375, 1242, 3)
load 3182  /  6684
size:  (375, 1242, 3)
load 3183  /  6684
size:  (375, 1242, 3)
load 3184  /  6684
size:  (375, 1242, 3)
load 3185  /  6684
size:  (375, 1242, 3)
load 3186  /  6684
size:  (375, 1242, 3)
load 3187  /  6684
size:  (375, 1242, 3)
load 3188  /  6684
size:  (375, 1242, 3)
load 3189  /  6684
size:  (375, 1242, 3)
load 3190  /  6684
size:  (375, 1242, 3)
load 3191  /  6684
size:  (375, 1242, 3)
load 3192  /  6684
size:  (375, 1242, 3)
load 3193  /  6684
size:  (375, 1242, 3)
load 3194  /  6684
size:  (375, 1242, 3)
load 3195  /  6684
size:  (375, 1242, 3)
load 3196  /  6684
size:  (375, 1242, 3)
load 3197  /  6684
size:  (375, 1242, 3)
load 3198  /  6684
size:  (375, 1242, 3)
load 3199  /  6684
size:  (375, 1242, 3)
load 3200  /  6684
size:  (375, 1242, 3)
load 3201  /  6684
size:  (375, 1242, 3)
load 3202  /  6684
size:  (375, 1242, 3)
load 3203  /  6684
size:  (375, 1242, 3)
load 3204  /  6684
size:  (375, 1242, 3)
load 3205  /  6684
size:  (375, 1242, 3)
load 3206  /  6684
size:  (375, 1242, 3)
load 3207  /  6684
size:  (375, 1242, 3)
load 3208  /  6684
size:  (375, 1242, 3)
load 3209  /  6684
size:  (375, 1242, 3)
load 3210  /  6684
size:  (375, 1242, 3)
load 3211  /  6684
size:  (375, 1242, 3)
load 3212  /  6684
size:  (375, 1242, 3)
load 3213  /  6684
size:  (376, 1241, 3)
load 3214  /  6684
size:  (375, 1242, 3)
load 3215  /  6684
size:  (375, 1242, 3)
load 3216  /  6684
size:  (375, 1242, 3)
load 3217  /  6684
size:  (375, 1242, 3)
load 3218  /  6684
size:  (375, 1242, 3)
load 3219  /  6684
size:  (375, 1242, 3)
load 3220  /  6684
size:  (376, 1241, 3)
load 3221  /  6684
size:  (375, 1242, 3)
load 3222  /  6684
size:  (375, 1242, 3)
load 3223  /  6684
size:  (370, 1224, 3)
load 3224  /  6684
size:  (375, 1242, 3)
load 3225  /  6684
size:  (375, 1242, 3)
load 3226  /  6684
size:  (370, 1224, 3)
load 3227  /  6684
size:  (375, 1242, 3)
load 3228  /  6684
size:  (375, 1242, 3)
load 3229  /  6684
size:  (375, 1242, 3)
load 3230  /  6684
size:  (375, 1242, 3)
load 3231  /  6684
size:  (375, 1242, 3)
load 3232  /  6684
size:  (375, 1242, 3)
load 3233  /  6684
size:  (375, 1242, 3)
load 3234  /  6684
size:  (375, 1242, 3)
load 3235  /  6684
size:  (375, 1242, 3)
load 3236  /  6684
size:  (375, 1242, 3)
load 3237  /  6684
size:  (375, 1242, 3)
load 3238  /  6684
size:  (375, 1242, 3)
load 3239  /  6684
size:  (375, 1242, 3)
load 3240  /  6684
size:  (375, 1242, 3)
load 3241  /  6684
size:  (375, 1242, 3)
load 3242  /  6684
size:  (375, 1242, 3)
load 3243  /  6684
size:  (375, 1242, 3)
load 3244  /  6684
size:  (375, 1242, 3)
load 3245  /  6684
size:  (375, 1242, 3)
load 3246  /  6684
size:  (375, 1242, 3)
load 3247  /  6684
size:  (375, 1242, 3)
load 3248  /  6684
size:  (375, 1242, 3)
load 3249  /  6684
size:  (375, 1242, 3)
load 3250  /  6684
size:  (375, 1242, 3)
load 3251  /  6684
size:  (375, 1242, 3)
load 3252  /  6684
size:  (375, 1242, 3)
load 3253  /  6684
size:  (376, 1241, 3)
load 3254  /  6684
size:  (375, 1242, 3)
load 3255  /  6684
size:  (375, 1242, 3)
load 3256  /  6684
size:  (375, 1242, 3)
load 3257  /  6684
size:  (375, 1242, 3)
load 3258  /  6684
size:  (375, 1242, 3)
load 3259  /  6684
size:  (375, 1242, 3)
load 3260  /  6684
size:  (375, 1242, 3)
load 3261  /  6684
size:  (370, 1224, 3)
load 3262  /  6684
size:  (370, 1224, 3)
load 3263  /  6684
size:  (374, 1238, 3)
load 3264  /  6684
size:  (375, 1242, 3)
load 3265  /  6684
size:  (375, 1242, 3)
load 3266  /  6684
size:  (375, 1242, 3)
load 3267  /  6684
size:  (375, 1242, 3)
load 3268  /  6684
size:  (375, 1242, 3)
load 3269  /  6684
size:  (375, 1242, 3)
load 3270  /  6684
size:  (375, 1242, 3)
load 3271  /  6684
size:  (375, 1242, 3)
load 3272  /  6684
size:  (375, 1242, 3)
load 3273  /  6684
size:  (375, 1242, 3)
load 3274  /  6684
size:  (375, 1242, 3)
load 3275  /  6684
size:  (374, 1238, 3)
load 3276  /  6684
size:  (375, 1242, 3)
load 3277  /  6684
size:  (375, 1242, 3)
load 3278  /  6684
size:  (375, 1242, 3)
load 3279  /  6684
size:  (375, 1242, 3)
load 3280  /  6684
size:  (375, 1242, 3)
load 3281  /  6684
size:  (375, 1242, 3)
load 3282  /  6684
size:  (375, 1242, 3)
load 3283  /  6684
size:  (375, 1242, 3)
load 3284  /  6684
size:  (375, 1242, 3)
load 3285  /  6684
size:  (375, 1242, 3)
load 3286  /  6684
size:  (375, 1242, 3)
load 3287  /  6684
size:  (375, 1242, 3)
load 3288  /  6684
size:  (375, 1242, 3)
load 3289  /  6684
size:  (375, 1242, 3)
load 3290  /  6684
size:  (375, 1242, 3)
load 3291  /  6684
size:  (375, 1242, 3)
load 3292  /  6684
size:  (375, 1242, 3)
load 3293  /  6684
size:  (375, 1242, 3)
load 3294  /  6684
size:  (375, 1242, 3)
load 3295  /  6684
size:  (375, 1242, 3)
load 3296  /  6684
size:  (375, 1242, 3)
load 3297  /  6684
size:  (375, 1242, 3)
load 3298  /  6684
size:  (375, 1242, 3)
load 3299  /  6684
size:  (375, 1242, 3)
load 3300  /  6684
size:  (375, 1242, 3)
load 3301  /  6684
size:  (375, 1242, 3)
load 3302  /  6684
size:  (375, 1242, 3)
load 3303  /  6684
size:  (375, 1242, 3)
load 3304  /  6684
size:  (370, 1224, 3)
load 3305  /  6684
size:  (374, 1238, 3)
load 3306  /  6684
size:  (375, 1242, 3)
load 3307  /  6684
size:  (375, 1242, 3)
load 3308  /  6684
size:  (375, 1242, 3)
load 3309  /  6684
size:  (375, 1242, 3)
load 3310  /  6684
size:  (375, 1242, 3)
load 3311  /  6684
size:  (375, 1242, 3)
load 3312  /  6684
size:  (375, 1242, 3)
load 3313  /  6684
size:  (375, 1242, 3)
load 3314  /  6684
size:  (374, 1238, 3)
load 3315  /  6684
size:  (375, 1242, 3)
load 3316  /  6684
size:  (375, 1242, 3)
load 3317  /  6684
size:  (375, 1242, 3)
load 3318  /  6684
size:  (374, 1238, 3)
load 3319  /  6684
size:  (375, 1242, 3)
load 3320  /  6684
size:  (375, 1242, 3)
load 3321  /  6684
size:  (376, 1241, 3)
load 3322  /  6684
size:  (375, 1242, 3)
load 3323  /  6684
size:  (375, 1242, 3)
load 3324  /  6684
size:  (374, 1238, 3)
load 3325  /  6684
size:  (375, 1242, 3)
load 3326  /  6684
size:  (374, 1238, 3)
load 3327  /  6684
size:  (375, 1242, 3)
load 3328  /  6684
size:  (375, 1242, 3)
load 3329  /  6684
size:  (375, 1242, 3)
load 3330  /  6684
size:  (375, 1242, 3)
load 3331  /  6684
size:  (375, 1242, 3)
load 3332  /  6684
size:  (375, 1242, 3)
load 3333  /  6684
size:  (375, 1242, 3)
load 3334  /  6684
size:  (375, 1242, 3)
load 3335  /  6684
size:  (375, 1242, 3)
load 3336  /  6684
size:  (375, 1242, 3)
load 3337  /  6684
size:  (374, 1238, 3)
load 3338  /  6684
size:  (375, 1242, 3)
load 3339  /  6684
size:  (375, 1242, 3)
load 3340  /  6684
size:  (375, 1242, 3)
load 3341  /  6684
size:  (375, 1242, 3)
load 3342  /  6684
size:  (375, 1242, 3)
load 3343  /  6684
size:  (375, 1242, 3)
load 3344  /  6684
size:  (375, 1242, 3)
load 3345  /  6684
size:  (374, 1238, 3)
load 3346  /  6684
size:  (375, 1242, 3)
load 3347  /  6684
size:  (375, 1242, 3)
load 3348  /  6684
size:  (375, 1242, 3)
load 3349  /  6684
size:  (375, 1242, 3)
load 3350  /  6684
size:  (375, 1242, 3)
load 3351  /  6684
size:  (375, 1242, 3)
load 3352  /  6684
size:  (375, 1242, 3)
load 3353  /  6684
size:  (375, 1242, 3)
load 3354  /  6684
size:  (375, 1242, 3)
load 3355  /  6684
size:  (375, 1242, 3)
load 3356  /  6684
size:  (375, 1242, 3)
load 3357  /  6684
size:  (374, 1238, 3)
load 3358  /  6684
size:  (376, 1241, 3)
load 3359  /  6684
size:  (375, 1242, 3)
load 3360  /  6684
size:  (375, 1242, 3)
load 3361  /  6684
size:  (375, 1242, 3)
load 3362  /  6684
size:  (375, 1242, 3)
load 3363  /  6684
size:  (375, 1242, 3)
load 3364  /  6684
size:  (375, 1242, 3)
load 3365  /  6684
size:  (375, 1242, 3)
load 3366  /  6684
size:  (375, 1242, 3)
load 3367  /  6684
size:  (375, 1242, 3)
load 3368  /  6684
size:  (370, 1224, 3)
load 3369  /  6684
size:  (375, 1242, 3)
load 3370  /  6684
size:  (375, 1242, 3)
load 3371  /  6684
size:  (375, 1242, 3)
load 3372  /  6684
size:  (375, 1242, 3)
load 3373  /  6684
size:  (375, 1242, 3)
load 3374  /  6684
size:  (375, 1242, 3)
load 3375  /  6684
size:  (375, 1242, 3)
load 3376  /  6684
size:  (375, 1242, 3)
load 3377  /  6684
size:  (375, 1242, 3)
load 3378  /  6684
size:  (376, 1241, 3)
load 3379  /  6684
size:  (374, 1238, 3)
load 3380  /  6684
size:  (375, 1242, 3)
load 3381  /  6684
size:  (376, 1241, 3)
load 3382  /  6684
size:  (375, 1242, 3)
load 3383  /  6684
size:  (375, 1242, 3)
load 3384  /  6684
size:  (375, 1242, 3)
load 3385  /  6684
size:  (375, 1242, 3)
load 3386  /  6684
size:  (376, 1241, 3)
load 3387  /  6684
size:  (375, 1242, 3)
load 3388  /  6684
size:  (375, 1242, 3)
load 3389  /  6684
size:  (375, 1242, 3)
load 3390  /  6684
size:  (375, 1242, 3)
load 3391  /  6684
size:  (375, 1242, 3)
load 3392  /  6684
size:  (375, 1242, 3)
load 3393  /  6684
size:  (375, 1242, 3)
load 3394  /  6684
size:  (375, 1242, 3)
load 3395  /  6684
size:  (375, 1242, 3)
load 3396  /  6684
size:  (375, 1242, 3)
load 3397  /  6684
size:  (375, 1242, 3)
load 3398  /  6684
size:  (374, 1238, 3)
load 3399  /  6684
size:  (375, 1242, 3)
load 3400  /  6684
size:  (375, 1242, 3)
load 3401  /  6684
size:  (374, 1238, 3)
load 3402  /  6684
size:  (375, 1242, 3)
load 3403  /  6684
size:  (375, 1242, 3)
load 3404  /  6684
size:  (375, 1242, 3)
load 3405  /  6684
size:  (375, 1242, 3)
load 3406  /  6684
size:  (375, 1242, 3)
load 3407  /  6684
size:  (375, 1242, 3)
load 3408  /  6684
size:  (375, 1242, 3)
load 3409  /  6684
size:  (375, 1242, 3)
load 3410  /  6684
size:  (375, 1242, 3)
load 3411  /  6684
size:  (375, 1242, 3)
load 3412  /  6684
size:  (375, 1242, 3)
load 3413  /  6684
size:  (370, 1224, 3)
load 3414  /  6684
size:  (375, 1242, 3)
load 3415  /  6684
size:  (375, 1242, 3)
load 3416  /  6684
size:  (375, 1242, 3)
load 3417  /  6684
size:  (375, 1242, 3)
load 3418  /  6684
size:  (375, 1242, 3)
load 3419  /  6684
size:  (375, 1242, 3)
load 3420  /  6684
size:  (375, 1242, 3)
load 3421  /  6684
size:  (375, 1242, 3)
load 3422  /  6684
size:  (375, 1242, 3)
load 3423  /  6684
size:  (374, 1238, 3)
load 3424  /  6684
size:  (375, 1242, 3)
load 3425  /  6684
size:  (375, 1242, 3)
load 3426  /  6684
size:  (370, 1224, 3)
load 3427  /  6684
size:  (375, 1242, 3)
load 3428  /  6684
size:  (374, 1238, 3)
load 3429  /  6684
size:  (375, 1242, 3)
load 3430  /  6684
size:  (375, 1242, 3)
load 3431  /  6684
size:  (375, 1242, 3)
load 3432  /  6684
size:  (375, 1242, 3)
load 3433  /  6684
size:  (375, 1242, 3)
load 3434  /  6684
size:  (375, 1242, 3)
load 3435  /  6684
size:  (375, 1242, 3)
load 3436  /  6684
size:  (375, 1242, 3)
load 3437  /  6684
size:  (375, 1242, 3)
load 3438  /  6684
size:  (375, 1242, 3)
load 3439  /  6684
size:  (375, 1242, 3)
load 3440  /  6684
size:  (375, 1242, 3)
load 3441  /  6684
size:  (376, 1241, 3)
load 3442  /  6684
size:  (375, 1242, 3)
load 3443  /  6684
size:  (375, 1242, 3)
load 3444  /  6684
size:  (375, 1242, 3)
load 3445  /  6684
size:  (375, 1242, 3)
load 3446  /  6684
size:  (375, 1242, 3)
load 3447  /  6684
size:  (375, 1242, 3)
load 3448  /  6684
size:  (375, 1242, 3)
load 3449  /  6684
size:  (374, 1238, 3)
load 3450  /  6684
size:  (374, 1238, 3)
load 3451  /  6684
size:  (370, 1224, 3)
load 3452  /  6684
size:  (374, 1238, 3)
load 3453  /  6684
size:  (375, 1242, 3)
load 3454  /  6684
size:  (375, 1242, 3)
load 3455  /  6684
size:  (375, 1242, 3)
load 3456  /  6684
size:  (375, 1242, 3)
load 3457  /  6684
size:  (375, 1242, 3)
load 3458  /  6684
size:  (375, 1242, 3)
load 3459  /  6684
size:  (375, 1242, 3)
load 3460  /  6684
size:  (375, 1242, 3)
load 3461  /  6684
size:  (375, 1242, 3)
load 3462  /  6684
size:  (375, 1242, 3)
load 3463  /  6684
size:  (375, 1242, 3)
load 3464  /  6684
size:  (375, 1242, 3)
load 3465  /  6684
size:  (375, 1242, 3)
load 3466  /  6684
size:  (375, 1242, 3)
load 3467  /  6684
size:  (375, 1242, 3)
load 3468  /  6684
size:  (375, 1242, 3)
load 3469  /  6684
size:  (375, 1242, 3)
load 3470  /  6684
size:  (375, 1242, 3)
load 3471  /  6684
size:  (375, 1242, 3)
load 3472  /  6684
size:  (375, 1242, 3)
load 3473  /  6684
size:  (375, 1242, 3)
load 3474  /  6684
size:  (375, 1242, 3)
load 3475  /  6684
size:  (375, 1242, 3)
load 3476  /  6684
size:  (375, 1242, 3)
load 3477  /  6684
size:  (375, 1242, 3)
load 3478  /  6684
size:  (375, 1242, 3)
load 3479  /  6684
size:  (375, 1242, 3)
load 3480  /  6684
size:  (375, 1242, 3)
load 3481  /  6684
size:  (375, 1242, 3)
load 3482  /  6684
size:  (375, 1242, 3)
load 3483  /  6684
size:  (375, 1242, 3)
load 3484  /  6684
size:  (375, 1242, 3)
load 3485  /  6684
size:  (375, 1242, 3)
load 3486  /  6684
size:  (375, 1242, 3)
load 3487  /  6684
size:  (375, 1242, 3)
load 3488  /  6684
size:  (374, 1238, 3)
load 3489  /  6684
size:  (375, 1242, 3)
load 3490  /  6684
size:  (374, 1238, 3)
load 3491  /  6684
size:  (375, 1242, 3)
load 3492  /  6684
size:  (375, 1242, 3)
load 3493  /  6684
size:  (375, 1242, 3)
load 3494  /  6684
size:  (375, 1242, 3)
load 3495  /  6684
size:  (375, 1242, 3)
load 3496  /  6684
size:  (375, 1242, 3)
load 3497  /  6684
size:  (375, 1242, 3)
load 3498  /  6684
size:  (375, 1242, 3)
load 3499  /  6684
size:  (375, 1242, 3)
load 3500  /  6684
size:  (375, 1242, 3)
load 3501  /  6684
size:  (375, 1242, 3)
load 3502  /  6684
size:  (375, 1242, 3)
load 3503  /  6684
size:  (375, 1242, 3)
load 3504  /  6684
size:  (375, 1242, 3)
load 3505  /  6684
size:  (375, 1242, 3)
load 3506  /  6684
size:  (375, 1242, 3)
load 3507  /  6684
size:  (375, 1242, 3)
load 3508  /  6684
size:  (375, 1242, 3)
load 3509  /  6684
size:  (375, 1242, 3)
load 3510  /  6684
size:  (375, 1242, 3)
load 3511  /  6684
size:  (375, 1242, 3)
load 3512  /  6684
size:  (375, 1242, 3)
load 3513  /  6684
size:  (375, 1242, 3)
load 3514  /  6684
size:  (375, 1242, 3)
load 3515  /  6684
size:  (370, 1224, 3)
load 3516  /  6684
size:  (375, 1242, 3)
load 3517  /  6684
size:  (375, 1242, 3)
load 3518  /  6684
size:  (375, 1242, 3)
load 3519  /  6684
size:  (375, 1242, 3)
load 3520  /  6684
size:  (375, 1242, 3)
load 3521  /  6684
size:  (375, 1242, 3)
load 3522  /  6684
size:  (375, 1242, 3)
load 3523  /  6684
size:  (375, 1242, 3)
load 3524  /  6684
size:  (375, 1242, 3)
load 3525  /  6684
size:  (375, 1242, 3)
load 3526  /  6684
size:  (375, 1242, 3)
load 3527  /  6684
size:  (375, 1242, 3)
load 3528  /  6684
size:  (375, 1242, 3)
load 3529  /  6684
size:  (375, 1242, 3)
load 3530  /  6684
size:  (375, 1242, 3)
load 3531  /  6684
size:  (375, 1242, 3)
load 3532  /  6684
size:  (375, 1242, 3)
load 3533  /  6684
size:  (375, 1242, 3)
load 3534  /  6684
size:  (375, 1242, 3)
load 3535  /  6684
size:  (375, 1242, 3)
load 3536  /  6684
size:  (375, 1242, 3)
load 3537  /  6684
size:  (375, 1242, 3)
load 3538  /  6684
size:  (375, 1242, 3)
load 3539  /  6684
size:  (375, 1242, 3)
load 3540  /  6684
size:  (370, 1224, 3)
load 3541  /  6684
size:  (375, 1242, 3)
load 3542  /  6684
size:  (375, 1242, 3)
load 3543  /  6684
size:  (375, 1242, 3)
load 3544  /  6684
size:  (375, 1242, 3)
load 3545  /  6684
size:  (375, 1242, 3)
load 3546  /  6684
size:  (375, 1242, 3)
load 3547  /  6684
size:  (375, 1242, 3)
load 3548  /  6684
size:  (375, 1242, 3)
load 3549  /  6684
size:  (375, 1242, 3)
load 3550  /  6684
size:  (375, 1242, 3)
load 3551  /  6684
size:  (376, 1241, 3)
load 3552  /  6684
size:  (375, 1242, 3)
load 3553  /  6684
size:  (375, 1242, 3)
load 3554  /  6684
size:  (375, 1242, 3)
load 3555  /  6684
size:  (375, 1242, 3)
load 3556  /  6684
size:  (375, 1242, 3)
load 3557  /  6684
size:  (375, 1242, 3)
load 3558  /  6684
size:  (375, 1242, 3)
load 3559  /  6684
size:  (375, 1242, 3)
load 3560  /  6684
size:  (375, 1242, 3)
load 3561  /  6684
size:  (375, 1242, 3)
load 3562  /  6684
size:  (375, 1242, 3)
load 3563  /  6684
size:  (376, 1241, 3)
load 3564  /  6684
size:  (375, 1242, 3)
load 3565  /  6684
size:  (375, 1242, 3)
load 3566  /  6684
size:  (375, 1242, 3)
load 3567  /  6684
size:  (375, 1242, 3)
load 3568  /  6684
size:  (376, 1241, 3)
load 3569  /  6684
size:  (375, 1242, 3)
load 3570  /  6684
size:  (375, 1242, 3)
load 3571  /  6684
size:  (375, 1242, 3)
load 3572  /  6684
size:  (375, 1242, 3)
load 3573  /  6684
size:  (375, 1242, 3)
load 3574  /  6684
size:  (370, 1224, 3)
load 3575  /  6684
size:  (374, 1238, 3)
load 3576  /  6684
size:  (375, 1242, 3)
load 3577  /  6684
size:  (374, 1238, 3)
load 3578  /  6684
size:  (375, 1242, 3)
load 3579  /  6684
size:  (375, 1242, 3)
load 3580  /  6684
size:  (375, 1242, 3)
load 3581  /  6684
size:  (375, 1242, 3)
load 3582  /  6684
size:  (375, 1242, 3)
load 3583  /  6684
size:  (375, 1242, 3)
load 3584  /  6684
size:  (375, 1242, 3)
load 3585  /  6684
size:  (375, 1242, 3)
load 3586  /  6684
size:  (375, 1242, 3)
load 3587  /  6684
size:  (375, 1242, 3)
load 3588  /  6684
size:  (375, 1242, 3)
load 3589  /  6684
size:  (375, 1242, 3)
load 3590  /  6684
size:  (375, 1242, 3)
load 3591  /  6684
size:  (375, 1242, 3)
load 3592  /  6684
size:  (375, 1242, 3)
load 3593  /  6684
size:  (375, 1242, 3)
load 3594  /  6684
size:  (375, 1242, 3)
load 3595  /  6684
size:  (375, 1242, 3)
load 3596  /  6684
size:  (375, 1242, 3)
load 3597  /  6684
size:  (375, 1242, 3)
load 3598  /  6684
size:  (375, 1242, 3)
load 3599  /  6684
size:  (375, 1242, 3)
load 3600  /  6684
size:  (375, 1242, 3)
load 3601  /  6684
size:  (375, 1242, 3)
load 3602  /  6684
size:  (375, 1242, 3)
load 3603  /  6684
size:  (375, 1242, 3)
load 3604  /  6684
size:  (375, 1242, 3)
load 3605  /  6684
size:  (375, 1242, 3)
load 3606  /  6684
size:  (376, 1241, 3)
load 3607  /  6684
size:  (375, 1242, 3)
load 3608  /  6684
size:  (375, 1242, 3)
load 3609  /  6684
size:  (375, 1242, 3)
load 3610  /  6684
size:  (370, 1224, 3)
load 3611  /  6684
size:  (375, 1242, 3)
load 3612  /  6684
size:  (375, 1242, 3)
load 3613  /  6684
size:  (375, 1242, 3)
load 3614  /  6684
size:  (375, 1242, 3)
load 3615  /  6684
size:  (375, 1242, 3)
load 3616  /  6684
size:  (375, 1242, 3)
load 3617  /  6684
size:  (375, 1242, 3)
load 3618  /  6684
size:  (370, 1224, 3)
load 3619  /  6684
size:  (375, 1242, 3)
load 3620  /  6684
size:  (375, 1242, 3)
load 3621  /  6684
size:  (375, 1242, 3)
load 3622  /  6684
size:  (370, 1224, 3)
load 3623  /  6684
size:  (375, 1242, 3)
load 3624  /  6684
size:  (375, 1242, 3)
load 3625  /  6684
size:  (375, 1242, 3)
load 3626  /  6684
size:  (376, 1241, 3)
load 3627  /  6684
size:  (375, 1242, 3)
load 3628  /  6684
size:  (375, 1242, 3)
load 3629  /  6684
size:  (370, 1224, 3)
load 3630  /  6684
size:  (375, 1242, 3)
load 3631  /  6684
size:  (375, 1242, 3)
load 3632  /  6684
size:  (375, 1242, 3)
load 3633  /  6684
size:  (375, 1242, 3)
load 3634  /  6684
size:  (375, 1242, 3)
load 3635  /  6684
size:  (375, 1242, 3)
load 3636  /  6684
size:  (375, 1242, 3)
load 3637  /  6684
size:  (375, 1242, 3)
load 3638  /  6684
size:  (375, 1242, 3)
load 3639  /  6684
size:  (375, 1242, 3)
load 3640  /  6684
size:  (375, 1242, 3)
load 3641  /  6684
size:  (375, 1242, 3)
load 3642  /  6684
size:  (375, 1242, 3)
load 3643  /  6684
size:  (376, 1241, 3)
load 3644  /  6684
size:  (375, 1242, 3)
load 3645  /  6684
size:  (375, 1242, 3)
load 3646  /  6684
size:  (375, 1242, 3)
load 3647  /  6684
size:  (375, 1242, 3)
load 3648  /  6684
size:  (375, 1242, 3)
load 3649  /  6684
size:  (376, 1241, 3)
load 3650  /  6684
size:  (375, 1242, 3)
load 3651  /  6684
size:  (370, 1224, 3)
load 3652  /  6684
size:  (375, 1242, 3)
load 3653  /  6684
size:  (375, 1242, 3)
load 3654  /  6684
size:  (375, 1242, 3)
load 3655  /  6684
size:  (375, 1242, 3)
load 3656  /  6684
size:  (375, 1242, 3)
load 3657  /  6684
size:  (375, 1242, 3)
load 3658  /  6684
size:  (375, 1242, 3)
load 3659  /  6684
size:  (375, 1242, 3)
load 3660  /  6684
size:  (375, 1242, 3)
load 3661  /  6684
size:  (375, 1242, 3)
load 3662  /  6684
size:  (375, 1242, 3)
load 3663  /  6684
size:  (375, 1242, 3)
load 3664  /  6684
size:  (374, 1238, 3)
load 3665  /  6684
size:  (375, 1242, 3)
load 3666  /  6684
size:  (375, 1242, 3)
load 3667  /  6684
size:  (375, 1242, 3)
load 3668  /  6684
size:  (375, 1242, 3)
load 3669  /  6684
size:  (375, 1242, 3)
load 3670  /  6684
size:  (375, 1242, 3)
load 3671  /  6684
size:  (375, 1242, 3)
load 3672  /  6684
size:  (375, 1242, 3)
load 3673  /  6684
size:  (375, 1242, 3)
load 3674  /  6684
size:  (375, 1242, 3)
load 3675  /  6684
size:  (375, 1242, 3)
load 3676  /  6684
size:  (375, 1242, 3)
load 3677  /  6684
size:  (376, 1241, 3)
load 3678  /  6684
size:  (370, 1224, 3)
load 3679  /  6684
size:  (375, 1242, 3)
load 3680  /  6684
size:  (375, 1242, 3)
load 3681  /  6684
size:  (375, 1242, 3)
load 3682  /  6684
size:  (375, 1242, 3)
load 3683  /  6684
size:  (375, 1242, 3)
load 3684  /  6684
size:  (375, 1242, 3)
load 3685  /  6684
size:  (375, 1242, 3)
load 3686  /  6684
size:  (376, 1241, 3)
load 3687  /  6684
size:  (375, 1242, 3)
load 3688  /  6684
size:  (375, 1242, 3)
load 3689  /  6684
size:  (375, 1242, 3)
load 3690  /  6684
size:  (375, 1242, 3)
load 3691  /  6684
size:  (375, 1242, 3)
load 3692  /  6684
size:  (375, 1242, 3)
load 3693  /  6684
size:  (375, 1242, 3)
load 3694  /  6684
size:  (375, 1242, 3)
load 3695  /  6684
size:  (375, 1242, 3)
load 3696  /  6684
size:  (375, 1242, 3)
load 3697  /  6684
size:  (375, 1242, 3)
load 3698  /  6684
size:  (375, 1242, 3)
load 3699  /  6684
size:  (375, 1242, 3)
load 3700  /  6684
size:  (375, 1242, 3)
load 3701  /  6684
size:  (375, 1242, 3)
load 3702  /  6684
size:  (375, 1242, 3)
load 3703  /  6684
size:  (375, 1242, 3)
load 3704  /  6684
size:  (375, 1242, 3)
load 3705  /  6684
size:  (370, 1224, 3)
load 3706  /  6684
size:  (375, 1242, 3)
load 3707  /  6684
size:  (375, 1242, 3)
load 3708  /  6684
size:  (375, 1242, 3)
load 3709  /  6684
size:  (375, 1242, 3)
load 3710  /  6684
size:  (375, 1242, 3)
load 3711  /  6684
size:  (375, 1242, 3)
load 3712  /  6684
size:  (375, 1242, 3)
load 3713  /  6684
size:  (375, 1242, 3)
load 3714  /  6684
size:  (375, 1242, 3)
load 3715  /  6684
size:  (375, 1242, 3)
load 3716  /  6684
size:  (375, 1242, 3)
load 3717  /  6684
size:  (375, 1242, 3)
load 3718  /  6684
size:  (375, 1242, 3)
load 3719  /  6684
size:  (370, 1224, 3)
load 3720  /  6684
size:  (375, 1242, 3)
load 3721  /  6684
size:  (375, 1242, 3)
load 3722  /  6684
size:  (375, 1242, 3)
load 3723  /  6684
size:  (375, 1242, 3)
load 3724  /  6684
size:  (376, 1241, 3)
load 3725  /  6684
size:  (375, 1242, 3)
load 3726  /  6684
size:  (375, 1242, 3)
load 3727  /  6684
size:  (375, 1242, 3)
load 3728  /  6684
size:  (376, 1241, 3)
load 3729  /  6684
size:  (375, 1242, 3)
load 3730  /  6684
size:  (375, 1242, 3)
load 3731  /  6684
size:  (375, 1242, 3)
load 3732  /  6684
size:  (375, 1242, 3)
load 3733  /  6684
size:  (375, 1242, 3)
load 3734  /  6684
size:  (375, 1242, 3)
load 3735  /  6684
size:  (375, 1242, 3)
load 3736  /  6684
size:  (375, 1242, 3)
load 3737  /  6684
size:  (375, 1242, 3)
load 3738  /  6684
size:  (375, 1242, 3)
load 3739  /  6684
size:  (375, 1242, 3)
load 3740  /  6684
size:  (375, 1242, 3)
load 3741  /  6684
size:  (375, 1242, 3)
load 3742  /  6684
size:  (376, 1241, 3)
load 3743  /  6684
size:  (375, 1242, 3)
load 3744  /  6684
size:  (375, 1242, 3)
load 3745  /  6684
size:  (375, 1242, 3)
load 3746  /  6684
size:  (375, 1242, 3)
load 3747  /  6684
size:  (376, 1241, 3)
load 3748  /  6684
size:  (375, 1242, 3)
load 3749  /  6684
size:  (375, 1242, 3)
load 3750  /  6684
size:  (375, 1242, 3)
load 3751  /  6684
size:  (375, 1242, 3)
load 3752  /  6684
size:  (375, 1242, 3)
load 3753  /  6684
size:  (375, 1242, 3)
load 3754  /  6684
size:  (375, 1242, 3)
load 3755  /  6684
size:  (374, 1238, 3)
load 3756  /  6684
size:  (375, 1242, 3)
load 3757  /  6684
size:  (375, 1242, 3)
load 3758  /  6684
size:  (375, 1242, 3)
load 3759  /  6684
size:  (375, 1242, 3)
load 3760  /  6684
size:  (375, 1242, 3)
load 3761  /  6684
size:  (375, 1242, 3)
load 3762  /  6684
size:  (375, 1242, 3)
load 3763  /  6684
size:  (375, 1242, 3)
load 3764  /  6684
size:  (375, 1242, 3)
load 3765  /  6684
size:  (375, 1242, 3)
load 3766  /  6684
size:  (375, 1242, 3)
load 3767  /  6684
size:  (375, 1242, 3)
load 3768  /  6684
size:  (375, 1242, 3)
load 3769  /  6684
size:  (375, 1242, 3)
load 3770  /  6684
size:  (375, 1242, 3)
load 3771  /  6684
size:  (375, 1242, 3)
load 3772  /  6684
size:  (376, 1241, 3)
load 3773  /  6684
size:  (375, 1242, 3)
load 3774  /  6684
size:  (375, 1242, 3)
load 3775  /  6684
size:  (375, 1242, 3)
load 3776  /  6684
size:  (376, 1241, 3)
load 3777  /  6684
size:  (375, 1242, 3)
load 3778  /  6684
size:  (370, 1224, 3)
load 3779  /  6684
size:  (375, 1242, 3)
load 3780  /  6684
size:  (375, 1242, 3)
load 3781  /  6684
size:  (376, 1241, 3)
load 3782  /  6684
size:  (375, 1242, 3)
load 3783  /  6684
size:  (375, 1242, 3)
load 3784  /  6684
size:  (375, 1242, 3)
load 3785  /  6684
size:  (375, 1242, 3)
load 3786  /  6684
size:  (375, 1242, 3)
load 3787  /  6684
size:  (375, 1242, 3)
load 3788  /  6684
size:  (370, 1224, 3)
load 3789  /  6684
size:  (375, 1242, 3)
load 3790  /  6684
size:  (375, 1242, 3)
load 3791  /  6684
size:  (375, 1242, 3)
load 3792  /  6684
size:  (375, 1242, 3)
load 3793  /  6684
size:  (375, 1242, 3)
load 3794  /  6684
size:  (375, 1242, 3)
load 3795  /  6684
size:  (376, 1241, 3)
load 3796  /  6684
size:  (374, 1238, 3)
load 3797  /  6684
size:  (375, 1242, 3)
load 3798  /  6684
size:  (375, 1242, 3)
load 3799  /  6684
size:  (375, 1242, 3)
load 3800  /  6684
size:  (376, 1241, 3)
load 3801  /  6684
size:  (374, 1238, 3)
load 3802  /  6684
size:  (376, 1241, 3)
load 3803  /  6684
size:  (375, 1242, 3)
load 3804  /  6684
size:  (375, 1242, 3)
load 3805  /  6684
size:  (375, 1242, 3)
load 3806  /  6684
size:  (375, 1242, 3)
load 3807  /  6684
size:  (375, 1242, 3)
load 3808  /  6684
size:  (370, 1224, 3)
load 3809  /  6684
size:  (375, 1242, 3)
load 3810  /  6684
size:  (375, 1242, 3)
load 3811  /  6684
size:  (375, 1242, 3)
load 3812  /  6684
size:  (375, 1242, 3)
load 3813  /  6684
size:  (376, 1241, 3)
load 3814  /  6684
size:  (375, 1242, 3)
load 3815  /  6684
size:  (375, 1242, 3)
load 3816  /  6684
size:  (370, 1224, 3)
load 3817  /  6684
size:  (375, 1242, 3)
load 3818  /  6684
size:  (375, 1242, 3)
load 3819  /  6684
size:  (375, 1242, 3)
load 3820  /  6684
size:  (376, 1241, 3)
load 3821  /  6684
size:  (375, 1242, 3)
load 3822  /  6684
size:  (375, 1242, 3)
load 3823  /  6684
size:  (374, 1238, 3)
load 3824  /  6684
size:  (375, 1242, 3)
load 3825  /  6684
size:  (375, 1242, 3)
load 3826  /  6684
size:  (375, 1242, 3)
load 3827  /  6684
size:  (375, 1242, 3)
load 3828  /  6684
size:  (375, 1242, 3)
load 3829  /  6684
size:  (375, 1242, 3)
load 3830  /  6684
size:  (375, 1242, 3)
load 3831  /  6684
size:  (375, 1242, 3)
load 3832  /  6684
size:  (375, 1242, 3)
load 3833  /  6684
size:  (374, 1238, 3)
load 3834  /  6684
size:  (375, 1242, 3)
load 3835  /  6684
size:  (375, 1242, 3)
load 3836  /  6684
size:  (375, 1242, 3)
load 3837  /  6684
size:  (375, 1242, 3)
load 3838  /  6684
size:  (375, 1242, 3)
load 3839  /  6684
size:  (375, 1242, 3)
load 3840  /  6684
size:  (375, 1242, 3)
load 3841  /  6684
size:  (376, 1241, 3)
load 3842  /  6684
size:  (375, 1242, 3)
load 3843  /  6684
size:  (374, 1238, 3)
load 3844  /  6684
size:  (374, 1238, 3)
load 3845  /  6684
size:  (375, 1242, 3)
load 3846  /  6684
size:  (375, 1242, 3)
load 3847  /  6684
size:  (375, 1242, 3)
load 3848  /  6684
size:  (375, 1242, 3)
load 3849  /  6684
size:  (374, 1238, 3)
load 3850  /  6684
size:  (375, 1242, 3)
load 3851  /  6684
size:  (375, 1242, 3)
load 3852  /  6684
size:  (370, 1224, 3)
load 3853  /  6684
size:  (375, 1242, 3)
load 3854  /  6684
size:  (375, 1242, 3)
load 3855  /  6684
size:  (375, 1242, 3)
load 3856  /  6684
size:  (375, 1242, 3)
load 3857  /  6684
size:  (375, 1242, 3)
load 3858  /  6684
size:  (375, 1242, 3)
load 3859  /  6684
size:  (375, 1242, 3)
load 3860  /  6684
size:  (370, 1224, 3)
load 3861  /  6684
size:  (375, 1242, 3)
load 3862  /  6684
size:  (375, 1242, 3)
load 3863  /  6684
size:  (375, 1242, 3)
load 3864  /  6684
size:  (376, 1241, 3)
load 3865  /  6684
size:  (375, 1242, 3)
load 3866  /  6684
size:  (375, 1242, 3)
load 3867  /  6684
size:  (375, 1242, 3)
load 3868  /  6684
size:  (375, 1242, 3)
load 3869  /  6684
size:  (374, 1238, 3)
load 3870  /  6684
size:  (375, 1242, 3)
load 3871  /  6684
size:  (375, 1242, 3)
load 3872  /  6684
size:  (375, 1242, 3)
load 3873  /  6684
size:  (375, 1242, 3)
load 3874  /  6684
size:  (375, 1242, 3)
load 3875  /  6684
size:  (375, 1242, 3)
load 3876  /  6684
size:  (375, 1242, 3)
load 3877  /  6684
size:  (375, 1242, 3)
load 3878  /  6684
size:  (375, 1242, 3)
load 3879  /  6684
size:  (375, 1242, 3)
load 3880  /  6684
size:  (375, 1242, 3)
load 3881  /  6684
size:  (370, 1224, 3)
load 3882  /  6684
size:  (375, 1242, 3)
load 3883  /  6684
size:  (375, 1242, 3)
load 3884  /  6684
size:  (375, 1242, 3)
load 3885  /  6684
size:  (375, 1242, 3)
load 3886  /  6684
size:  (370, 1224, 3)
load 3887  /  6684
size:  (375, 1242, 3)
load 3888  /  6684
size:  (375, 1242, 3)
load 3889  /  6684
size:  (375, 1242, 3)
load 3890  /  6684
size:  (375, 1242, 3)
load 3891  /  6684
size:  (375, 1242, 3)
load 3892  /  6684
size:  (375, 1242, 3)
load 3893  /  6684
size:  (375, 1242, 3)
load 3894  /  6684
size:  (374, 1238, 3)
load 3895  /  6684
size:  (375, 1242, 3)
load 3896  /  6684
size:  (375, 1242, 3)
load 3897  /  6684
size:  (375, 1242, 3)
load 3898  /  6684
size:  (375, 1242, 3)
load 3899  /  6684
size:  (375, 1242, 3)
load 3900  /  6684
size:  (375, 1242, 3)
load 3901  /  6684
size:  (375, 1242, 3)
load 3902  /  6684
size:  (370, 1224, 3)
load 3903  /  6684
size:  (374, 1238, 3)
load 3904  /  6684
size:  (375, 1242, 3)
load 3905  /  6684
size:  (375, 1242, 3)
load 3906  /  6684
size:  (375, 1242, 3)
load 3907  /  6684
size:  (375, 1242, 3)
load 3908  /  6684
size:  (375, 1242, 3)
load 3909  /  6684
size:  (375, 1242, 3)
load 3910  /  6684
size:  (375, 1242, 3)
load 3911  /  6684
size:  (375, 1242, 3)
load 3912  /  6684
size:  (375, 1242, 3)
load 3913  /  6684
size:  (375, 1242, 3)
load 3914  /  6684
size:  (375, 1242, 3)
load 3915  /  6684
size:  (375, 1242, 3)
load 3916  /  6684
size:  (375, 1242, 3)
load 3917  /  6684
size:  (375, 1242, 3)
load 3918  /  6684
size:  (375, 1242, 3)
load 3919  /  6684
size:  (375, 1242, 3)
load 3920  /  6684
size:  (370, 1224, 3)
load 3921  /  6684
size:  (375, 1242, 3)
load 3922  /  6684
size:  (375, 1242, 3)
load 3923  /  6684
size:  (375, 1242, 3)
load 3924  /  6684
size:  (375, 1242, 3)
load 3925  /  6684
size:  (375, 1242, 3)
load 3926  /  6684
size:  (375, 1242, 3)
load 3927  /  6684
size:  (374, 1238, 3)
load 3928  /  6684
size:  (375, 1242, 3)
load 3929  /  6684
size:  (370, 1224, 3)
load 3930  /  6684
size:  (375, 1242, 3)
load 3931  /  6684
size:  (375, 1242, 3)
load 3932  /  6684
size:  (370, 1224, 3)
load 3933  /  6684
size:  (375, 1242, 3)
load 3934  /  6684
size:  (375, 1242, 3)
load 3935  /  6684
size:  (375, 1242, 3)
load 3936  /  6684
size:  (375, 1242, 3)
load 3937  /  6684
size:  (370, 1224, 3)
load 3938  /  6684
size:  (374, 1238, 3)
load 3939  /  6684
size:  (375, 1242, 3)
load 3940  /  6684
size:  (374, 1238, 3)
load 3941  /  6684
size:  (375, 1242, 3)
load 3942  /  6684
size:  (375, 1242, 3)
load 3943  /  6684
size:  (375, 1242, 3)
load 3944  /  6684
size:  (375, 1242, 3)
load 3945  /  6684
size:  (375, 1242, 3)
load 3946  /  6684
size:  (375, 1242, 3)
load 3947  /  6684
size:  (375, 1242, 3)
load 3948  /  6684
size:  (375, 1242, 3)
load 3949  /  6684
size:  (375, 1242, 3)
load 3950  /  6684
size:  (375, 1242, 3)
load 3951  /  6684
size:  (375, 1242, 3)
load 3952  /  6684
size:  (375, 1242, 3)
load 3953  /  6684
size:  (375, 1242, 3)
load 3954  /  6684
size:  (375, 1242, 3)
load 3955  /  6684
size:  (375, 1242, 3)
load 3956  /  6684
size:  (375, 1242, 3)
load 3957  /  6684
size:  (375, 1242, 3)
load 3958  /  6684
size:  (374, 1238, 3)
load 3959  /  6684
size:  (375, 1242, 3)
load 3960  /  6684
size:  (375, 1242, 3)
load 3961  /  6684
size:  (375, 1242, 3)
load 3962  /  6684
size:  (376, 1241, 3)
load 3963  /  6684
size:  (375, 1242, 3)
load 3964  /  6684
size:  (375, 1242, 3)
load 3965  /  6684
size:  (375, 1242, 3)
load 3966  /  6684
size:  (375, 1242, 3)
load 3967  /  6684
size:  (375, 1242, 3)
load 3968  /  6684
size:  (376, 1241, 3)
load 3969  /  6684
size:  (375, 1242, 3)
load 3970  /  6684
size:  (375, 1242, 3)
load 3971  /  6684
size:  (375, 1242, 3)
load 3972  /  6684
size:  (375, 1242, 3)
load 3973  /  6684
size:  (375, 1242, 3)
load 3974  /  6684
size:  (375, 1242, 3)
load 3975  /  6684
size:  (375, 1242, 3)
load 3976  /  6684
size:  (375, 1242, 3)
load 3977  /  6684
size:  (374, 1238, 3)
load 3978  /  6684
size:  (375, 1242, 3)
load 3979  /  6684
size:  (375, 1242, 3)
load 3980  /  6684
size:  (375, 1242, 3)
load 3981  /  6684
size:  (375, 1242, 3)
load 3982  /  6684
size:  (375, 1242, 3)
load 3983  /  6684
size:  (375, 1242, 3)
load 3984  /  6684
size:  (375, 1242, 3)
load 3985  /  6684
size:  (375, 1242, 3)
load 3986  /  6684
size:  (374, 1238, 3)
load 3987  /  6684
size:  (376, 1241, 3)
load 3988  /  6684
size:  (375, 1242, 3)
load 3989  /  6684
size:  (375, 1242, 3)
load 3990  /  6684
size:  (375, 1242, 3)
load 3991  /  6684
size:  (375, 1242, 3)
load 3992  /  6684
size:  (375, 1242, 3)
load 3993  /  6684
size:  (376, 1241, 3)
load 3994  /  6684
size:  (375, 1242, 3)
load 3995  /  6684
size:  (375, 1242, 3)
load 3996  /  6684
size:  (375, 1242, 3)
load 3997  /  6684
size:  (375, 1242, 3)
load 3998  /  6684
size:  (375, 1242, 3)
load 3999  /  6684
size:  (375, 1242, 3)
load 4000  /  6684
size:  (375, 1242, 3)
load 4001  /  6684
size:  (375, 1242, 3)
load 4002  /  6684
size:  (375, 1242, 3)
load 4003  /  6684
size:  (375, 1242, 3)
load 4004  /  6684
size:  (374, 1238, 3)
load 4005  /  6684
size:  (375, 1242, 3)
load 4006  /  6684
size:  (375, 1242, 3)
load 4007  /  6684
size:  (375, 1242, 3)
load 4008  /  6684
size:  (375, 1242, 3)
load 4009  /  6684
size:  (375, 1242, 3)
load 4010  /  6684
size:  (375, 1242, 3)
load 4011  /  6684
size:  (375, 1242, 3)
load 4012  /  6684
size:  (375, 1242, 3)
load 4013  /  6684
size:  (370, 1224, 3)
load 4014  /  6684
size:  (375, 1242, 3)
load 4015  /  6684
size:  (375, 1242, 3)
load 4016  /  6684
size:  (375, 1242, 3)
load 4017  /  6684
size:  (375, 1242, 3)
load 4018  /  6684
size:  (375, 1242, 3)
load 4019  /  6684
size:  (376, 1241, 3)
load 4020  /  6684
size:  (375, 1242, 3)
load 4021  /  6684
size:  (375, 1242, 3)
load 4022  /  6684
size:  (375, 1242, 3)
load 4023  /  6684
size:  (376, 1241, 3)
load 4024  /  6684
size:  (375, 1242, 3)
load 4025  /  6684
size:  (376, 1241, 3)
load 4026  /  6684
size:  (375, 1242, 3)
load 4027  /  6684
size:  (375, 1242, 3)
load 4028  /  6684
size:  (375, 1242, 3)
load 4029  /  6684
size:  (375, 1242, 3)
load 4030  /  6684
size:  (375, 1242, 3)
load 4031  /  6684
size:  (375, 1242, 3)
load 4032  /  6684
size:  (375, 1242, 3)
load 4033  /  6684
size:  (375, 1242, 3)
load 4034  /  6684
size:  (375, 1242, 3)
load 4035  /  6684
size:  (375, 1242, 3)
load 4036  /  6684
size:  (375, 1242, 3)
load 4037  /  6684
size:  (375, 1242, 3)
load 4038  /  6684
size:  (375, 1242, 3)
load 4039  /  6684
size:  (375, 1242, 3)
load 4040  /  6684
size:  (375, 1242, 3)
load 4041  /  6684
size:  (375, 1242, 3)
load 4042  /  6684
size:  (375, 1242, 3)
load 4043  /  6684
size:  (375, 1242, 3)
load 4044  /  6684
size:  (375, 1242, 3)
load 4045  /  6684
size:  (374, 1238, 3)
load 4046  /  6684
size:  (375, 1242, 3)
load 4047  /  6684
size:  (375, 1242, 3)
load 4048  /  6684
size:  (375, 1242, 3)
load 4049  /  6684
size:  (375, 1242, 3)
load 4050  /  6684
size:  (375, 1242, 3)
load 4051  /  6684
size:  (375, 1242, 3)
load 4052  /  6684
size:  (375, 1242, 3)
load 4053  /  6684
size:  (375, 1242, 3)
load 4054  /  6684
size:  (375, 1242, 3)
load 4055  /  6684
size:  (375, 1242, 3)
load 4056  /  6684
size:  (375, 1242, 3)
load 4057  /  6684
size:  (375, 1242, 3)
load 4058  /  6684
size:  (375, 1242, 3)
load 4059  /  6684
size:  (375, 1242, 3)
load 4060  /  6684
size:  (375, 1242, 3)
load 4061  /  6684
size:  (375, 1242, 3)
load 4062  /  6684
size:  (375, 1242, 3)
load 4063  /  6684
size:  (375, 1242, 3)
load 4064  /  6684
size:  (375, 1242, 3)
load 4065  /  6684
size:  (370, 1224, 3)
load 4066  /  6684
size:  (375, 1242, 3)
load 4067  /  6684
size:  (370, 1224, 3)
load 4068  /  6684
size:  (375, 1242, 3)
load 4069  /  6684
size:  (374, 1238, 3)
load 4070  /  6684
size:  (375, 1242, 3)
load 4071  /  6684
size:  (375, 1242, 3)
load 4072  /  6684
size:  (375, 1242, 3)
load 4073  /  6684
size:  (375, 1242, 3)
load 4074  /  6684
size:  (375, 1242, 3)
load 4075  /  6684
size:  (375, 1242, 3)
load 4076  /  6684
size:  (375, 1242, 3)
load 4077  /  6684
size:  (375, 1242, 3)
load 4078  /  6684
size:  (375, 1242, 3)
load 4079  /  6684
size:  (375, 1242, 3)
load 4080  /  6684
size:  (370, 1224, 3)
load 4081  /  6684
size:  (375, 1242, 3)
load 4082  /  6684
size:  (375, 1242, 3)
load 4083  /  6684
size:  (375, 1242, 3)
load 4084  /  6684
size:  (375, 1242, 3)
load 4085  /  6684
size:  (375, 1242, 3)
load 4086  /  6684
size:  (375, 1242, 3)
load 4087  /  6684
size:  (375, 1242, 3)
load 4088  /  6684
size:  (375, 1242, 3)
load 4089  /  6684
size:  (375, 1242, 3)
load 4090  /  6684
size:  (375, 1242, 3)
load 4091  /  6684
size:  (375, 1242, 3)
load 4092  /  6684
size:  (375, 1242, 3)
load 4093  /  6684
size:  (375, 1242, 3)
load 4094  /  6684
size:  (375, 1242, 3)
load 4095  /  6684
size:  (375, 1242, 3)
load 4096  /  6684
size:  (375, 1242, 3)
load 4097  /  6684
size:  (375, 1242, 3)
load 4098  /  6684
size:  (375, 1242, 3)
load 4099  /  6684
size:  (375, 1242, 3)
load 4100  /  6684
size:  (375, 1242, 3)
load 4101  /  6684
size:  (375, 1242, 3)
load 4102  /  6684
size:  (375, 1242, 3)
load 4103  /  6684
size:  (375, 1242, 3)
load 4104  /  6684
size:  (375, 1242, 3)
load 4105  /  6684
size:  (375, 1242, 3)
load 4106  /  6684
size:  (375, 1242, 3)
load 4107  /  6684
size:  (375, 1242, 3)
load 4108  /  6684
size:  (375, 1242, 3)
load 4109  /  6684
size:  (375, 1242, 3)
load 4110  /  6684
size:  (375, 1242, 3)
load 4111  /  6684
size:  (375, 1242, 3)
load 4112  /  6684
size:  (375, 1242, 3)
load 4113  /  6684
size:  (375, 1242, 3)
load 4114  /  6684
size:  (375, 1242, 3)
load 4115  /  6684
size:  (375, 1242, 3)
load 4116  /  6684
size:  (375, 1242, 3)
load 4117  /  6684
size:  (375, 1242, 3)
load 4118  /  6684
size:  (375, 1242, 3)
load 4119  /  6684
size:  (375, 1242, 3)
load 4120  /  6684
size:  (375, 1242, 3)
load 4121  /  6684
size:  (375, 1242, 3)
load 4122  /  6684
size:  (375, 1242, 3)
load 4123  /  6684
size:  (375, 1242, 3)
load 4124  /  6684
size:  (375, 1242, 3)
load 4125  /  6684
size:  (375, 1242, 3)
load 4126  /  6684
size:  (375, 1242, 3)
load 4127  /  6684
size:  (375, 1242, 3)
load 4128  /  6684
size:  (375, 1242, 3)
load 4129  /  6684
size:  (375, 1242, 3)
load 4130  /  6684
size:  (375, 1242, 3)
load 4131  /  6684
size:  (375, 1242, 3)
load 4132  /  6684
size:  (375, 1242, 3)
load 4133  /  6684
size:  (376, 1241, 3)
load 4134  /  6684
size:  (375, 1242, 3)
load 4135  /  6684
size:  (375, 1242, 3)
load 4136  /  6684
size:  (375, 1242, 3)
load 4137  /  6684
size:  (375, 1242, 3)
load 4138  /  6684
size:  (375, 1242, 3)
load 4139  /  6684
size:  (375, 1242, 3)
load 4140  /  6684
size:  (375, 1242, 3)
load 4141  /  6684
size:  (375, 1242, 3)
load 4142  /  6684
size:  (374, 1238, 3)
load 4143  /  6684
size:  (375, 1242, 3)
load 4144  /  6684
size:  (375, 1242, 3)
load 4145  /  6684
size:  (375, 1242, 3)
load 4146  /  6684
size:  (375, 1242, 3)
load 4147  /  6684
size:  (375, 1242, 3)
load 4148  /  6684
size:  (375, 1242, 3)
load 4149  /  6684
size:  (375, 1242, 3)
load 4150  /  6684
size:  (374, 1238, 3)
load 4151  /  6684
size:  (375, 1242, 3)
load 4152  /  6684
size:  (375, 1242, 3)
load 4153  /  6684
size:  (375, 1242, 3)
load 4154  /  6684
size:  (375, 1242, 3)
load 4155  /  6684
size:  (375, 1242, 3)
load 4156  /  6684
size:  (375, 1242, 3)
load 4157  /  6684
size:  (375, 1242, 3)
load 4158  /  6684
size:  (375, 1242, 3)
load 4159  /  6684
size:  (375, 1242, 3)
load 4160  /  6684
size:  (375, 1242, 3)
load 4161  /  6684
size:  (375, 1242, 3)
load 4162  /  6684
size:  (375, 1242, 3)
load 4163  /  6684
size:  (375, 1242, 3)
load 4164  /  6684
size:  (375, 1242, 3)
load 4165  /  6684
size:  (376, 1241, 3)
load 4166  /  6684
size:  (375, 1242, 3)
load 4167  /  6684
size:  (375, 1242, 3)
load 4168  /  6684
size:  (375, 1242, 3)
load 4169  /  6684
size:  (376, 1241, 3)
load 4170  /  6684
size:  (375, 1242, 3)
load 4171  /  6684
size:  (375, 1242, 3)
load 4172  /  6684
size:  (375, 1242, 3)
load 4173  /  6684
size:  (375, 1242, 3)
load 4174  /  6684
size:  (375, 1242, 3)
load 4175  /  6684
size:  (370, 1224, 3)
load 4176  /  6684
size:  (375, 1242, 3)
load 4177  /  6684
size:  (376, 1241, 3)
load 4178  /  6684
size:  (375, 1242, 3)
load 4179  /  6684
size:  (375, 1242, 3)
load 4180  /  6684
size:  (375, 1242, 3)
load 4181  /  6684
size:  (375, 1242, 3)
load 4182  /  6684
size:  (375, 1242, 3)
load 4183  /  6684
size:  (375, 1242, 3)
load 4184  /  6684
size:  (375, 1242, 3)
load 4185  /  6684
size:  (375, 1242, 3)
load 4186  /  6684
size:  (370, 1224, 3)
load 4187  /  6684
size:  (375, 1242, 3)
load 4188  /  6684
size:  (375, 1242, 3)
load 4189  /  6684
size:  (375, 1242, 3)
load 4190  /  6684
size:  (375, 1242, 3)
load 4191  /  6684
size:  (375, 1242, 3)
load 4192  /  6684
size:  (375, 1242, 3)
load 4193  /  6684
size:  (375, 1242, 3)
load 4194  /  6684
size:  (375, 1242, 3)
load 4195  /  6684
size:  (375, 1242, 3)
load 4196  /  6684
size:  (375, 1242, 3)
load 4197  /  6684
size:  (376, 1241, 3)
load 4198  /  6684
size:  (375, 1242, 3)
load 4199  /  6684
size:  (375, 1242, 3)
load 4200  /  6684
size:  (375, 1242, 3)
load 4201  /  6684
size:  (374, 1238, 3)
load 4202  /  6684
size:  (370, 1224, 3)
load 4203  /  6684
size:  (375, 1242, 3)
load 4204  /  6684
size:  (375, 1242, 3)
load 4205  /  6684
size:  (375, 1242, 3)
load 4206  /  6684
size:  (375, 1242, 3)
load 4207  /  6684
size:  (375, 1242, 3)
load 4208  /  6684
size:  (375, 1242, 3)
load 4209  /  6684
size:  (375, 1242, 3)
load 4210  /  6684
size:  (375, 1242, 3)
load 4211  /  6684
size:  (375, 1242, 3)
load 4212  /  6684
size:  (375, 1242, 3)
load 4213  /  6684
size:  (375, 1242, 3)
load 4214  /  6684
size:  (375, 1242, 3)
load 4215  /  6684
size:  (375, 1242, 3)
load 4216  /  6684
size:  (374, 1238, 3)
load 4217  /  6684
size:  (375, 1242, 3)
load 4218  /  6684
size:  (376, 1241, 3)
load 4219  /  6684
size:  (376, 1241, 3)
load 4220  /  6684
size:  (375, 1242, 3)
load 4221  /  6684
size:  (374, 1238, 3)
load 4222  /  6684
size:  (375, 1242, 3)
load 4223  /  6684
size:  (370, 1224, 3)
load 4224  /  6684
size:  (375, 1242, 3)
load 4225  /  6684
size:  (375, 1242, 3)
load 4226  /  6684
size:  (375, 1242, 3)
load 4227  /  6684
size:  (375, 1242, 3)
load 4228  /  6684
size:  (375, 1242, 3)
load 4229  /  6684
size:  (375, 1242, 3)
load 4230  /  6684
size:  (375, 1242, 3)
load 4231  /  6684
size:  (375, 1242, 3)
load 4232  /  6684
size:  (376, 1241, 3)
load 4233  /  6684
size:  (375, 1242, 3)
load 4234  /  6684
size:  (375, 1242, 3)
load 4235  /  6684
size:  (375, 1242, 3)
load 4236  /  6684
size:  (375, 1242, 3)
load 4237  /  6684
size:  (375, 1242, 3)
load 4238  /  6684
size:  (375, 1242, 3)
load 4239  /  6684
size:  (375, 1242, 3)
load 4240  /  6684
size:  (375, 1242, 3)
load 4241  /  6684
size:  (375, 1242, 3)
load 4242  /  6684
size:  (375, 1242, 3)
load 4243  /  6684
size:  (376, 1241, 3)
load 4244  /  6684
size:  (375, 1242, 3)
load 4245  /  6684
size:  (375, 1242, 3)
load 4246  /  6684
size:  (375, 1242, 3)
load 4247  /  6684
size:  (375, 1242, 3)
load 4248  /  6684
size:  (375, 1242, 3)
load 4249  /  6684
size:  (375, 1242, 3)
load 4250  /  6684
size:  (374, 1238, 3)
load 4251  /  6684
size:  (375, 1242, 3)
load 4252  /  6684
size:  (375, 1242, 3)
load 4253  /  6684
size:  (375, 1242, 3)
load 4254  /  6684
size:  (375, 1242, 3)
load 4255  /  6684
size:  (375, 1242, 3)
load 4256  /  6684
size:  (375, 1242, 3)
load 4257  /  6684
size:  (375, 1242, 3)
load 4258  /  6684
size:  (375, 1242, 3)
load 4259  /  6684
size:  (370, 1224, 3)
load 4260  /  6684
size:  (374, 1238, 3)
load 4261  /  6684
size:  (375, 1242, 3)
load 4262  /  6684
size:  (375, 1242, 3)
load 4263  /  6684
size:  (375, 1242, 3)
load 4264  /  6684
size:  (375, 1242, 3)
load 4265  /  6684
size:  (374, 1238, 3)
load 4266  /  6684
size:  (375, 1242, 3)
load 4267  /  6684
size:  (375, 1242, 3)
load 4268  /  6684
size:  (375, 1242, 3)
load 4269  /  6684
size:  (375, 1242, 3)
load 4270  /  6684
size:  (375, 1242, 3)
load 4271  /  6684
size:  (375, 1242, 3)
load 4272  /  6684
size:  (375, 1242, 3)
load 4273  /  6684
size:  (375, 1242, 3)
load 4274  /  6684
size:  (370, 1224, 3)
load 4275  /  6684
size:  (374, 1238, 3)
load 4276  /  6684
size:  (375, 1242, 3)
load 4277  /  6684
size:  (375, 1242, 3)
load 4278  /  6684
size:  (375, 1242, 3)
load 4279  /  6684
size:  (375, 1242, 3)
load 4280  /  6684
size:  (375, 1242, 3)
load 4281  /  6684
size:  (375, 1242, 3)
load 4282  /  6684
size:  (375, 1242, 3)
load 4283  /  6684
size:  (375, 1242, 3)
load 4284  /  6684
size:  (375, 1242, 3)
load 4285  /  6684
size:  (375, 1242, 3)
load 4286  /  6684
size:  (374, 1238, 3)
load 4287  /  6684
size:  (375, 1242, 3)
load 4288  /  6684
size:  (375, 1242, 3)
load 4289  /  6684
size:  (375, 1242, 3)
load 4290  /  6684
size:  (375, 1242, 3)
load 4291  /  6684
size:  (375, 1242, 3)
load 4292  /  6684
size:  (375, 1242, 3)
load 4293  /  6684
size:  (375, 1242, 3)
load 4294  /  6684
size:  (375, 1242, 3)
load 4295  /  6684
size:  (375, 1242, 3)
load 4296  /  6684
size:  (375, 1242, 3)
load 4297  /  6684
size:  (375, 1242, 3)
load 4298  /  6684
size:  (375, 1242, 3)
load 4299  /  6684
size:  (375, 1242, 3)
load 4300  /  6684
size:  (376, 1241, 3)
load 4301  /  6684
size:  (375, 1242, 3)
load 4302  /  6684
size:  (375, 1242, 3)
load 4303  /  6684
size:  (375, 1242, 3)
load 4304  /  6684
size:  (375, 1242, 3)
load 4305  /  6684
size:  (375, 1242, 3)
load 4306  /  6684
size:  (375, 1242, 3)
load 4307  /  6684
size:  (375, 1242, 3)
load 4308  /  6684
size:  (375, 1242, 3)
load 4309  /  6684
size:  (375, 1242, 3)
load 4310  /  6684
size:  (376, 1241, 3)
load 4311  /  6684
size:  (375, 1242, 3)
load 4312  /  6684
size:  (375, 1242, 3)
load 4313  /  6684
size:  (375, 1242, 3)
load 4314  /  6684
size:  (375, 1242, 3)
load 4315  /  6684
size:  (375, 1242, 3)
load 4316  /  6684
size:  (375, 1242, 3)
load 4317  /  6684
size:  (375, 1242, 3)
load 4318  /  6684
size:  (375, 1242, 3)
load 4319  /  6684
size:  (375, 1242, 3)
load 4320  /  6684
size:  (375, 1242, 3)
load 4321  /  6684
size:  (375, 1242, 3)
load 4322  /  6684
size:  (375, 1242, 3)
load 4323  /  6684
size:  (375, 1242, 3)
load 4324  /  6684
size:  (375, 1242, 3)
load 4325  /  6684
size:  (375, 1242, 3)
load 4326  /  6684
size:  (375, 1242, 3)
load 4327  /  6684
size:  (375, 1242, 3)
load 4328  /  6684
size:  (375, 1242, 3)
load 4329  /  6684
size:  (375, 1242, 3)
load 4330  /  6684
size:  (375, 1242, 3)
load 4331  /  6684
size:  (375, 1242, 3)
load 4332  /  6684
size:  (375, 1242, 3)
load 4333  /  6684
size:  (375, 1242, 3)
load 4334  /  6684
size:  (375, 1242, 3)
load 4335  /  6684
size:  (375, 1242, 3)
load 4336  /  6684
size:  (375, 1242, 3)
load 4337  /  6684
size:  (375, 1242, 3)
load 4338  /  6684
size:  (375, 1242, 3)
load 4339  /  6684
size:  (375, 1242, 3)
load 4340  /  6684
size:  (375, 1242, 3)
load 4341  /  6684
size:  (375, 1242, 3)
load 4342  /  6684
size:  (375, 1242, 3)
load 4343  /  6684
size:  (375, 1242, 3)
load 4344  /  6684
size:  (375, 1242, 3)
load 4345  /  6684
size:  (375, 1242, 3)
load 4346  /  6684
size:  (375, 1242, 3)
load 4347  /  6684
size:  (375, 1242, 3)
load 4348  /  6684
size:  (375, 1242, 3)
load 4349  /  6684
size:  (376, 1241, 3)
load 4350  /  6684
size:  (375, 1242, 3)
load 4351  /  6684
size:  (375, 1242, 3)
load 4352  /  6684
size:  (375, 1242, 3)
load 4353  /  6684
size:  (375, 1242, 3)
load 4354  /  6684
size:  (375, 1242, 3)
load 4355  /  6684
size:  (375, 1242, 3)
load 4356  /  6684
size:  (375, 1242, 3)
load 4357  /  6684
size:  (375, 1242, 3)
load 4358  /  6684
size:  (375, 1242, 3)
load 4359  /  6684
size:  (375, 1242, 3)
load 4360  /  6684
size:  (375, 1242, 3)
load 4361  /  6684
size:  (375, 1242, 3)
load 4362  /  6684
size:  (375, 1242, 3)
load 4363  /  6684
size:  (375, 1242, 3)
load 4364  /  6684
size:  (370, 1224, 3)
load 4365  /  6684
size:  (375, 1242, 3)
load 4366  /  6684
size:  (375, 1242, 3)
load 4367  /  6684
size:  (375, 1242, 3)
load 4368  /  6684
size:  (375, 1242, 3)
load 4369  /  6684
size:  (375, 1242, 3)
load 4370  /  6684
size:  (375, 1242, 3)
load 4371  /  6684
size:  (375, 1242, 3)
load 4372  /  6684
size:  (375, 1242, 3)
load 4373  /  6684
size:  (375, 1242, 3)
load 4374  /  6684
size:  (375, 1242, 3)
load 4375  /  6684
size:  (375, 1242, 3)
load 4376  /  6684
size:  (375, 1242, 3)
load 4377  /  6684
size:  (375, 1242, 3)
load 4378  /  6684
size:  (375, 1242, 3)
load 4379  /  6684
size:  (375, 1242, 3)
load 4380  /  6684
size:  (375, 1242, 3)
load 4381  /  6684
size:  (375, 1242, 3)
load 4382  /  6684
size:  (375, 1242, 3)
load 4383  /  6684
size:  (375, 1242, 3)
load 4384  /  6684
size:  (375, 1242, 3)
load 4385  /  6684
size:  (375, 1242, 3)
load 4386  /  6684
size:  (375, 1242, 3)
load 4387  /  6684
size:  (376, 1241, 3)
load 4388  /  6684
size:  (375, 1242, 3)
load 4389  /  6684
size:  (375, 1242, 3)
load 4390  /  6684
size:  (374, 1238, 3)
load 4391  /  6684
size:  (375, 1242, 3)
load 4392  /  6684
size:  (375, 1242, 3)
load 4393  /  6684
size:  (375, 1242, 3)
load 4394  /  6684
size:  (375, 1242, 3)
load 4395  /  6684
size:  (375, 1242, 3)
load 4396  /  6684
size:  (375, 1242, 3)
load 4397  /  6684
size:  (375, 1242, 3)
load 4398  /  6684
size:  (375, 1242, 3)
load 4399  /  6684
size:  (375, 1242, 3)
load 4400  /  6684
size:  (370, 1224, 3)
load 4401  /  6684
size:  (375, 1242, 3)
load 4402  /  6684
size:  (375, 1242, 3)
load 4403  /  6684
size:  (375, 1242, 3)
load 4404  /  6684
size:  (375, 1242, 3)
load 4405  /  6684
size:  (375, 1242, 3)
load 4406  /  6684
size:  (375, 1242, 3)
load 4407  /  6684
size:  (375, 1242, 3)
load 4408  /  6684
size:  (374, 1238, 3)
load 4409  /  6684
size:  (375, 1242, 3)
load 4410  /  6684
size:  (375, 1242, 3)
load 4411  /  6684
size:  (374, 1238, 3)
load 4412  /  6684
size:  (375, 1242, 3)
load 4413  /  6684
size:  (370, 1224, 3)
load 4414  /  6684
size:  (375, 1242, 3)
load 4415  /  6684
size:  (375, 1242, 3)
load 4416  /  6684
size:  (374, 1238, 3)
load 4417  /  6684
size:  (375, 1242, 3)
load 4418  /  6684
size:  (375, 1242, 3)
load 4419  /  6684
size:  (375, 1242, 3)
load 4420  /  6684
size:  (375, 1242, 3)
load 4421  /  6684
size:  (375, 1242, 3)
load 4422  /  6684
size:  (375, 1242, 3)
load 4423  /  6684
size:  (375, 1242, 3)
load 4424  /  6684
size:  (370, 1224, 3)
load 4425  /  6684
size:  (375, 1242, 3)
load 4426  /  6684
size:  (375, 1242, 3)
load 4427  /  6684
size:  (375, 1242, 3)
load 4428  /  6684
size:  (375, 1242, 3)
load 4429  /  6684
size:  (375, 1242, 3)
load 4430  /  6684
size:  (375, 1242, 3)
load 4431  /  6684
size:  (376, 1241, 3)
load 4432  /  6684
size:  (375, 1242, 3)
load 4433  /  6684
size:  (374, 1238, 3)
load 4434  /  6684
size:  (374, 1238, 3)
load 4435  /  6684
size:  (375, 1242, 3)
load 4436  /  6684
size:  (375, 1242, 3)
load 4437  /  6684
size:  (375, 1242, 3)
load 4438  /  6684
size:  (375, 1242, 3)
load 4439  /  6684
size:  (375, 1242, 3)
load 4440  /  6684
size:  (375, 1242, 3)
load 4441  /  6684
size:  (376, 1241, 3)
load 4442  /  6684
size:  (375, 1242, 3)
load 4443  /  6684
size:  (375, 1242, 3)
load 4444  /  6684
size:  (375, 1242, 3)
load 4445  /  6684
size:  (375, 1242, 3)
load 4446  /  6684
size:  (370, 1224, 3)
load 4447  /  6684
size:  (375, 1242, 3)
load 4448  /  6684
size:  (375, 1242, 3)
load 4449  /  6684
size:  (375, 1242, 3)
load 4450  /  6684
size:  (375, 1242, 3)
load 4451  /  6684
size:  (375, 1242, 3)
load 4452  /  6684
size:  (376, 1241, 3)
load 4453  /  6684
size:  (375, 1242, 3)
load 4454  /  6684
size:  (375, 1242, 3)
load 4455  /  6684
size:  (375, 1242, 3)
load 4456  /  6684
size:  (375, 1242, 3)
load 4457  /  6684
size:  (375, 1242, 3)
load 4458  /  6684
size:  (375, 1242, 3)
load 4459  /  6684
size:  (375, 1242, 3)
load 4460  /  6684
size:  (375, 1242, 3)
load 4461  /  6684
size:  (375, 1242, 3)
load 4462  /  6684
size:  (376, 1241, 3)
load 4463  /  6684
size:  (375, 1242, 3)
load 4464  /  6684
size:  (375, 1242, 3)
load 4465  /  6684
size:  (375, 1242, 3)
load 4466  /  6684
size:  (375, 1242, 3)
load 4467  /  6684
size:  (375, 1242, 3)
load 4468  /  6684
size:  (375, 1242, 3)
load 4469  /  6684
size:  (375, 1242, 3)
load 4470  /  6684
size:  (370, 1224, 3)
load 4471  /  6684
size:  (375, 1242, 3)
load 4472  /  6684
size:  (375, 1242, 3)
load 4473  /  6684
size:  (375, 1242, 3)
load 4474  /  6684
size:  (375, 1242, 3)
load 4475  /  6684
size:  (375, 1242, 3)
load 4476  /  6684
size:  (375, 1242, 3)
load 4477  /  6684
size:  (375, 1242, 3)
load 4478  /  6684
size:  (370, 1224, 3)
load 4479  /  6684
size:  (375, 1242, 3)
load 4480  /  6684
size:  (375, 1242, 3)
load 4481  /  6684
size:  (375, 1242, 3)
load 4482  /  6684
size:  (375, 1242, 3)
load 4483  /  6684
size:  (375, 1242, 3)
load 4484  /  6684
size:  (375, 1242, 3)
load 4485  /  6684
size:  (375, 1242, 3)
load 4486  /  6684
size:  (375, 1242, 3)
load 4487  /  6684
size:  (375, 1242, 3)
load 4488  /  6684
size:  (375, 1242, 3)
load 4489  /  6684
size:  (375, 1242, 3)
load 4490  /  6684
size:  (375, 1242, 3)
load 4491  /  6684
size:  (375, 1242, 3)
load 4492  /  6684
size:  (375, 1242, 3)
load 4493  /  6684
size:  (376, 1241, 3)
load 4494  /  6684
size:  (375, 1242, 3)
load 4495  /  6684
size:  (375, 1242, 3)
load 4496  /  6684
size:  (375, 1242, 3)
load 4497  /  6684
size:  (375, 1242, 3)
load 4498  /  6684
size:  (376, 1241, 3)
load 4499  /  6684
size:  (375, 1242, 3)
load 4500  /  6684
size:  (375, 1242, 3)
load 4501  /  6684
size:  (375, 1242, 3)
load 4502  /  6684
size:  (375, 1242, 3)
load 4503  /  6684
size:  (370, 1224, 3)
load 4504  /  6684
size:  (374, 1238, 3)
load 4505  /  6684
size:  (375, 1242, 3)
load 4506  /  6684
size:  (376, 1241, 3)
load 4507  /  6684
size:  (375, 1242, 3)
load 4508  /  6684
size:  (375, 1242, 3)
load 4509  /  6684
size:  (370, 1224, 3)
load 4510  /  6684
size:  (375, 1242, 3)
load 4511  /  6684
size:  (375, 1242, 3)
load 4512  /  6684
size:  (376, 1241, 3)
load 4513  /  6684
size:  (375, 1242, 3)
load 4514  /  6684
size:  (370, 1224, 3)
load 4515  /  6684
size:  (375, 1242, 3)
load 4516  /  6684
size:  (375, 1242, 3)
load 4517  /  6684
size:  (370, 1224, 3)
load 4518  /  6684
size:  (375, 1242, 3)
load 4519  /  6684
size:  (375, 1242, 3)
load 4520  /  6684
size:  (375, 1242, 3)
load 4521  /  6684
size:  (374, 1238, 3)
load 4522  /  6684
size:  (375, 1242, 3)
load 4523  /  6684
size:  (375, 1242, 3)
load 4524  /  6684
size:  (375, 1242, 3)
load 4525  /  6684
size:  (374, 1238, 3)
load 4526  /  6684
size:  (375, 1242, 3)
load 4527  /  6684
size:  (375, 1242, 3)
load 4528  /  6684
size:  (374, 1238, 3)
load 4529  /  6684
size:  (375, 1242, 3)
load 4530  /  6684
size:  (375, 1242, 3)
load 4531  /  6684
size:  (375, 1242, 3)
load 4532  /  6684
size:  (375, 1242, 3)
load 4533  /  6684
size:  (376, 1241, 3)
load 4534  /  6684
size:  (375, 1242, 3)
load 4535  /  6684
size:  (375, 1242, 3)
load 4536  /  6684
size:  (375, 1242, 3)
load 4537  /  6684
size:  (375, 1242, 3)
load 4538  /  6684
size:  (375, 1242, 3)
load 4539  /  6684
size:  (375, 1242, 3)
load 4540  /  6684
size:  (375, 1242, 3)
load 4541  /  6684
size:  (375, 1242, 3)
load 4542  /  6684
size:  (375, 1242, 3)
load 4543  /  6684
size:  (375, 1242, 3)
load 4544  /  6684
size:  (375, 1242, 3)
load 4545  /  6684
size:  (376, 1241, 3)
load 4546  /  6684
size:  (375, 1242, 3)
load 4547  /  6684
size:  (370, 1224, 3)
load 4548  /  6684
size:  (375, 1242, 3)
load 4549  /  6684
size:  (370, 1224, 3)
load 4550  /  6684
size:  (375, 1242, 3)
load 4551  /  6684
size:  (375, 1242, 3)
load 4552  /  6684
size:  (370, 1224, 3)
load 4553  /  6684
size:  (375, 1242, 3)
load 4554  /  6684
size:  (375, 1242, 3)
load 4555  /  6684
size:  (375, 1242, 3)
load 4556  /  6684
size:  (375, 1242, 3)
load 4557  /  6684
size:  (375, 1242, 3)
load 4558  /  6684
size:  (375, 1242, 3)
load 4559  /  6684
size:  (375, 1242, 3)
load 4560  /  6684
size:  (375, 1242, 3)
load 4561  /  6684
size:  (375, 1242, 3)
load 4562  /  6684
size:  (375, 1242, 3)
load 4563  /  6684
size:  (375, 1242, 3)
load 4564  /  6684
size:  (375, 1242, 3)
load 4565  /  6684
size:  (375, 1242, 3)
load 4566  /  6684
size:  (375, 1242, 3)
load 4567  /  6684
size:  (375, 1242, 3)
load 4568  /  6684
size:  (375, 1242, 3)
load 4569  /  6684
size:  (375, 1242, 3)
load 4570  /  6684
size:  (375, 1242, 3)
load 4571  /  6684
size:  (375, 1242, 3)
load 4572  /  6684
size:  (375, 1242, 3)
load 4573  /  6684
size:  (376, 1241, 3)
load 4574  /  6684
size:  (375, 1242, 3)
load 4575  /  6684
size:  (375, 1242, 3)
load 4576  /  6684
size:  (375, 1242, 3)
load 4577  /  6684
size:  (375, 1242, 3)
load 4578  /  6684
size:  (375, 1242, 3)
load 4579  /  6684
size:  (375, 1242, 3)
load 4580  /  6684
size:  (375, 1242, 3)
load 4581  /  6684
size:  (375, 1242, 3)
load 4582  /  6684
size:  (375, 1242, 3)
load 4583  /  6684
size:  (370, 1224, 3)
load 4584  /  6684
size:  (375, 1242, 3)
load 4585  /  6684
size:  (375, 1242, 3)
load 4586  /  6684
size:  (375, 1242, 3)
load 4587  /  6684
size:  (375, 1242, 3)
load 4588  /  6684
size:  (375, 1242, 3)
load 4589  /  6684
size:  (375, 1242, 3)
load 4590  /  6684
size:  (375, 1242, 3)
load 4591  /  6684
size:  (375, 1242, 3)
load 4592  /  6684
size:  (375, 1242, 3)
load 4593  /  6684
size:  (375, 1242, 3)
load 4594  /  6684
size:  (375, 1242, 3)
load 4595  /  6684
size:  (375, 1242, 3)
load 4596  /  6684
size:  (375, 1242, 3)
load 4597  /  6684
size:  (376, 1241, 3)
load 4598  /  6684
size:  (375, 1242, 3)
load 4599  /  6684
size:  (375, 1242, 3)
load 4600  /  6684
size:  (370, 1224, 3)
load 4601  /  6684
size:  (375, 1242, 3)
load 4602  /  6684
size:  (374, 1238, 3)
load 4603  /  6684
size:  (375, 1242, 3)
load 4604  /  6684
size:  (375, 1242, 3)
load 4605  /  6684
size:  (375, 1242, 3)
load 4606  /  6684
size:  (375, 1242, 3)
load 4607  /  6684
size:  (374, 1238, 3)
load 4608  /  6684
size:  (375, 1242, 3)
load 4609  /  6684
size:  (375, 1242, 3)
load 4610  /  6684
size:  (375, 1242, 3)
load 4611  /  6684
size:  (375, 1242, 3)
load 4612  /  6684
size:  (375, 1242, 3)
load 4613  /  6684
size:  (375, 1242, 3)
load 4614  /  6684
size:  (375, 1242, 3)
load 4615  /  6684
size:  (375, 1242, 3)
load 4616  /  6684
size:  (375, 1242, 3)
load 4617  /  6684
size:  (375, 1242, 3)
load 4618  /  6684
size:  (375, 1242, 3)
load 4619  /  6684
size:  (375, 1242, 3)
load 4620  /  6684
size:  (375, 1242, 3)
load 4621  /  6684
size:  (375, 1242, 3)
load 4622  /  6684
size:  (375, 1242, 3)
load 4623  /  6684
size:  (376, 1241, 3)
load 4624  /  6684
size:  (375, 1242, 3)
load 4625  /  6684
size:  (375, 1242, 3)
load 4626  /  6684
size:  (375, 1242, 3)
load 4627  /  6684
size:  (375, 1242, 3)
load 4628  /  6684
size:  (375, 1242, 3)
load 4629  /  6684
size:  (375, 1242, 3)
load 4630  /  6684
size:  (375, 1242, 3)
load 4631  /  6684
size:  (375, 1242, 3)
load 4632  /  6684
size:  (375, 1242, 3)
load 4633  /  6684
size:  (375, 1242, 3)
load 4634  /  6684
size:  (375, 1242, 3)
load 4635  /  6684
size:  (375, 1242, 3)
load 4636  /  6684
size:  (375, 1242, 3)
load 4637  /  6684
size:  (375, 1242, 3)
load 4638  /  6684
size:  (375, 1242, 3)
load 4639  /  6684
size:  (375, 1242, 3)
load 4640  /  6684
size:  (375, 1242, 3)
load 4641  /  6684
size:  (375, 1242, 3)
load 4642  /  6684
size:  (375, 1242, 3)
load 4643  /  6684
size:  (375, 1242, 3)
load 4644  /  6684
size:  (375, 1242, 3)
load 4645  /  6684
size:  (375, 1242, 3)
load 4646  /  6684
size:  (376, 1241, 3)
load 4647  /  6684
size:  (375, 1242, 3)
load 4648  /  6684
size:  (375, 1242, 3)
load 4649  /  6684
size:  (375, 1242, 3)
load 4650  /  6684
size:  (375, 1242, 3)
load 4651  /  6684
size:  (375, 1242, 3)
load 4652  /  6684
size:  (375, 1242, 3)
load 4653  /  6684
size:  (375, 1242, 3)
load 4654  /  6684
size:  (375, 1242, 3)
load 4655  /  6684
size:  (375, 1242, 3)
load 4656  /  6684
size:  (375, 1242, 3)
load 4657  /  6684
size:  (375, 1242, 3)
load 4658  /  6684
size:  (375, 1242, 3)
load 4659  /  6684
size:  (376, 1241, 3)
load 4660  /  6684
size:  (375, 1242, 3)
load 4661  /  6684
size:  (375, 1242, 3)
load 4662  /  6684
size:  (375, 1242, 3)
load 4663  /  6684
size:  (375, 1242, 3)
load 4664  /  6684
size:  (375, 1242, 3)
load 4665  /  6684
size:  (375, 1242, 3)
load 4666  /  6684
size:  (375, 1242, 3)
load 4667  /  6684
size:  (375, 1242, 3)
load 4668  /  6684
size:  (370, 1224, 3)
load 4669  /  6684
size:  (375, 1242, 3)
load 4670  /  6684
size:  (375, 1242, 3)
load 4671  /  6684
size:  (375, 1242, 3)
load 4672  /  6684
size:  (375, 1242, 3)
load 4673  /  6684
size:  (375, 1242, 3)
load 4674  /  6684
size:  (375, 1242, 3)
load 4675  /  6684
size:  (370, 1224, 3)
load 4676  /  6684
size:  (375, 1242, 3)
load 4677  /  6684
size:  (375, 1242, 3)
load 4678  /  6684
size:  (375, 1242, 3)
load 4679  /  6684
size:  (375, 1242, 3)
load 4680  /  6684
size:  (375, 1242, 3)
load 4681  /  6684
size:  (375, 1242, 3)
load 4682  /  6684
size:  (375, 1242, 3)
load 4683  /  6684
size:  (375, 1242, 3)
load 4684  /  6684
size:  (375, 1242, 3)
load 4685  /  6684
size:  (375, 1242, 3)
load 4686  /  6684
size:  (370, 1224, 3)
load 4687  /  6684
size:  (376, 1241, 3)
load 4688  /  6684
size:  (375, 1242, 3)
load 4689  /  6684
size:  (375, 1242, 3)
load 4690  /  6684
size:  (375, 1242, 3)
load 4691  /  6684
size:  (375, 1242, 3)
load 4692  /  6684
size:  (375, 1242, 3)
load 4693  /  6684
size:  (375, 1242, 3)
load 4694  /  6684
size:  (375, 1242, 3)
load 4695  /  6684
size:  (375, 1242, 3)
load 4696  /  6684
size:  (375, 1242, 3)
load 4697  /  6684
size:  (375, 1242, 3)
load 4698  /  6684
size:  (375, 1242, 3)
load 4699  /  6684
size:  (375, 1242, 3)
load 4700  /  6684
size:  (370, 1224, 3)
load 4701  /  6684
size:  (375, 1242, 3)
load 4702  /  6684
size:  (375, 1242, 3)
load 4703  /  6684
size:  (375, 1242, 3)
load 4704  /  6684
size:  (375, 1242, 3)
load 4705  /  6684
size:  (375, 1242, 3)
load 4706  /  6684
size:  (375, 1242, 3)
load 4707  /  6684
size:  (375, 1242, 3)
load 4708  /  6684
size:  (375, 1242, 3)
load 4709  /  6684
size:  (375, 1242, 3)
load 4710  /  6684
size:  (375, 1242, 3)
load 4711  /  6684
size:  (375, 1242, 3)
load 4712  /  6684
size:  (375, 1242, 3)
load 4713  /  6684
size:  (375, 1242, 3)
load 4714  /  6684
size:  (375, 1242, 3)
load 4715  /  6684
size:  (375, 1242, 3)
load 4716  /  6684
size:  (375, 1242, 3)
load 4717  /  6684
size:  (370, 1224, 3)
load 4718  /  6684
size:  (375, 1242, 3)
load 4719  /  6684
size:  (375, 1242, 3)
load 4720  /  6684
size:  (375, 1242, 3)
load 4721  /  6684
size:  (375, 1242, 3)
load 4722  /  6684
size:  (375, 1242, 3)
load 4723  /  6684
size:  (375, 1242, 3)
load 4724  /  6684
size:  (375, 1242, 3)
load 4725  /  6684
size:  (375, 1242, 3)
load 4726  /  6684
size:  (375, 1242, 3)
load 4727  /  6684
size:  (375, 1242, 3)
load 4728  /  6684
size:  (375, 1242, 3)
load 4729  /  6684
size:  (375, 1242, 3)
load 4730  /  6684
size:  (374, 1238, 3)
load 4731  /  6684
size:  (375, 1242, 3)
load 4732  /  6684
size:  (375, 1242, 3)
load 4733  /  6684
size:  (375, 1242, 3)
load 4734  /  6684
size:  (375, 1242, 3)
load 4735  /  6684
size:  (375, 1242, 3)
load 4736  /  6684
size:  (375, 1242, 3)
load 4737  /  6684
size:  (375, 1242, 3)
load 4738  /  6684
size:  (375, 1242, 3)
load 4739  /  6684
size:  (375, 1242, 3)
load 4740  /  6684
size:  (375, 1242, 3)
load 4741  /  6684
size:  (375, 1242, 3)
load 4742  /  6684
size:  (376, 1241, 3)
load 4743  /  6684
size:  (375, 1242, 3)
load 4744  /  6684
size:  (375, 1242, 3)
load 4745  /  6684
size:  (376, 1241, 3)
load 4746  /  6684
size:  (375, 1242, 3)
load 4747  /  6684
size:  (375, 1242, 3)
load 4748  /  6684
size:  (375, 1242, 3)
load 4749  /  6684
size:  (375, 1242, 3)
load 4750  /  6684
size:  (375, 1242, 3)
load 4751  /  6684
size:  (375, 1242, 3)
load 4752  /  6684
size:  (375, 1242, 3)
load 4753  /  6684
size:  (375, 1242, 3)
load 4754  /  6684
size:  (375, 1242, 3)
load 4755  /  6684
size:  (375, 1242, 3)
load 4756  /  6684
size:  (375, 1242, 3)
load 4757  /  6684
size:  (375, 1242, 3)
load 4758  /  6684
size:  (374, 1238, 3)
load 4759  /  6684
size:  (375, 1242, 3)
load 4760  /  6684
size:  (375, 1242, 3)
load 4761  /  6684
size:  (375, 1242, 3)
load 4762  /  6684
size:  (375, 1242, 3)
load 4763  /  6684
size:  (375, 1242, 3)
load 4764  /  6684
size:  (375, 1242, 3)
load 4765  /  6684
size:  (375, 1242, 3)
load 4766  /  6684
size:  (375, 1242, 3)
load 4767  /  6684
size:  (375, 1242, 3)
load 4768  /  6684
size:  (375, 1242, 3)
load 4769  /  6684
size:  (375, 1242, 3)
load 4770  /  6684
size:  (375, 1242, 3)
load 4771  /  6684
size:  (375, 1242, 3)
load 4772  /  6684
size:  (375, 1242, 3)
load 4773  /  6684
size:  (375, 1242, 3)
load 4774  /  6684
size:  (375, 1242, 3)
load 4775  /  6684
size:  (375, 1242, 3)
load 4776  /  6684
size:  (375, 1242, 3)
load 4777  /  6684
size:  (375, 1242, 3)
load 4778  /  6684
size:  (375, 1242, 3)
load 4779  /  6684
size:  (375, 1242, 3)
load 4780  /  6684
size:  (375, 1242, 3)
load 4781  /  6684
size:  (374, 1238, 3)
load 4782  /  6684
size:  (375, 1242, 3)
load 4783  /  6684
size:  (375, 1242, 3)
load 4784  /  6684
size:  (375, 1242, 3)
load 4785  /  6684
size:  (375, 1242, 3)
load 4786  /  6684
size:  (376, 1241, 3)
load 4787  /  6684
size:  (375, 1242, 3)
load 4788  /  6684
size:  (375, 1242, 3)
load 4789  /  6684
size:  (374, 1238, 3)
load 4790  /  6684
size:  (375, 1242, 3)
load 4791  /  6684
size:  (375, 1242, 3)
load 4792  /  6684
size:  (375, 1242, 3)
load 4793  /  6684
size:  (375, 1242, 3)
load 4794  /  6684
size:  (375, 1242, 3)
load 4795  /  6684
size:  (375, 1242, 3)
load 4796  /  6684
size:  (375, 1242, 3)
load 4797  /  6684
size:  (375, 1242, 3)
load 4798  /  6684
size:  (375, 1242, 3)
load 4799  /  6684
size:  (375, 1242, 3)
load 4800  /  6684
size:  (375, 1242, 3)
load 4801  /  6684
size:  (375, 1242, 3)
load 4802  /  6684
size:  (375, 1242, 3)
load 4803  /  6684
size:  (375, 1242, 3)
load 4804  /  6684
size:  (375, 1242, 3)
load 4805  /  6684
size:  (375, 1242, 3)
load 4806  /  6684
size:  (375, 1242, 3)
load 4807  /  6684
size:  (375, 1242, 3)
load 4808  /  6684
size:  (375, 1242, 3)
load 4809  /  6684
size:  (375, 1242, 3)
load 4810  /  6684
size:  (370, 1224, 3)
load 4811  /  6684
size:  (370, 1224, 3)
load 4812  /  6684
size:  (375, 1242, 3)
load 4813  /  6684
size:  (375, 1242, 3)
load 4814  /  6684
size:  (375, 1242, 3)
load 4815  /  6684
size:  (375, 1242, 3)
load 4816  /  6684
size:  (375, 1242, 3)
load 4817  /  6684
size:  (375, 1242, 3)
load 4818  /  6684
size:  (375, 1242, 3)
load 4819  /  6684
size:  (375, 1242, 3)
load 4820  /  6684
size:  (374, 1238, 3)
load 4821  /  6684
size:  (375, 1242, 3)
load 4822  /  6684
size:  (375, 1242, 3)
load 4823  /  6684
size:  (375, 1242, 3)
load 4824  /  6684
size:  (375, 1242, 3)
load 4825  /  6684
size:  (375, 1242, 3)
load 4826  /  6684
size:  (375, 1242, 3)
load 4827  /  6684
size:  (375, 1242, 3)
load 4828  /  6684
size:  (375, 1242, 3)
load 4829  /  6684
size:  (375, 1242, 3)
load 4830  /  6684
size:  (375, 1242, 3)
load 4831  /  6684
size:  (375, 1242, 3)
load 4832  /  6684
size:  (375, 1242, 3)
load 4833  /  6684
size:  (375, 1242, 3)
load 4834  /  6684
size:  (375, 1242, 3)
load 4835  /  6684
size:  (375, 1242, 3)
load 4836  /  6684
size:  (375, 1242, 3)
load 4837  /  6684
size:  (374, 1238, 3)
load 4838  /  6684
size:  (375, 1242, 3)
load 4839  /  6684
size:  (375, 1242, 3)
load 4840  /  6684
size:  (375, 1242, 3)
load 4841  /  6684
size:  (375, 1242, 3)
load 4842  /  6684
size:  (375, 1242, 3)
load 4843  /  6684
size:  (375, 1242, 3)
load 4844  /  6684
size:  (375, 1242, 3)
load 4845  /  6684
size:  (375, 1242, 3)
load 4846  /  6684
size:  (376, 1241, 3)
load 4847  /  6684
size:  (375, 1242, 3)
load 4848  /  6684
size:  (375, 1242, 3)
load 4849  /  6684
size:  (375, 1242, 3)
load 4850  /  6684
size:  (375, 1242, 3)
load 4851  /  6684
size:  (375, 1242, 3)
load 4852  /  6684
size:  (375, 1242, 3)
load 4853  /  6684
size:  (375, 1242, 3)
load 4854  /  6684
size:  (375, 1242, 3)
load 4855  /  6684
size:  (375, 1242, 3)
load 4856  /  6684
size:  (376, 1241, 3)
load 4857  /  6684
size:  (375, 1242, 3)
load 4858  /  6684
size:  (375, 1242, 3)
load 4859  /  6684
size:  (375, 1242, 3)
load 4860  /  6684
size:  (375, 1242, 3)
load 4861  /  6684
size:  (375, 1242, 3)
load 4862  /  6684
size:  (375, 1242, 3)
load 4863  /  6684
size:  (375, 1242, 3)
load 4864  /  6684
size:  (375, 1242, 3)
load 4865  /  6684
size:  (375, 1242, 3)
load 4866  /  6684
size:  (375, 1242, 3)
load 4867  /  6684
size:  (375, 1242, 3)
load 4868  /  6684
size:  (375, 1242, 3)
load 4869  /  6684
size:  (375, 1242, 3)
load 4870  /  6684
size:  (375, 1242, 3)
load 4871  /  6684
size:  (374, 1238, 3)
load 4872  /  6684
size:  (375, 1242, 3)
load 4873  /  6684
size:  (375, 1242, 3)
load 4874  /  6684
size:  (375, 1242, 3)
load 4875  /  6684
size:  (375, 1242, 3)
load 4876  /  6684
size:  (375, 1242, 3)
load 4877  /  6684
size:  (375, 1242, 3)
load 4878  /  6684
size:  (375, 1242, 3)
load 4879  /  6684
size:  (374, 1238, 3)
load 4880  /  6684
size:  (375, 1242, 3)
load 4881  /  6684
size:  (375, 1242, 3)
load 4882  /  6684
size:  (375, 1242, 3)
load 4883  /  6684
size:  (375, 1242, 3)
load 4884  /  6684
size:  (374, 1238, 3)
load 4885  /  6684
size:  (375, 1242, 3)
load 4886  /  6684
size:  (375, 1242, 3)
load 4887  /  6684
size:  (375, 1242, 3)
load 4888  /  6684
size:  (375, 1242, 3)
load 4889  /  6684
size:  (375, 1242, 3)
load 4890  /  6684
size:  (375, 1242, 3)
load 4891  /  6684
size:  (375, 1242, 3)
load 4892  /  6684
size:  (370, 1224, 3)
load 4893  /  6684
size:  (375, 1242, 3)
load 4894  /  6684
size:  (370, 1224, 3)
load 4895  /  6684
size:  (375, 1242, 3)
load 4896  /  6684
size:  (375, 1242, 3)
load 4897  /  6684
size:  (375, 1242, 3)
load 4898  /  6684
size:  (375, 1242, 3)
load 4899  /  6684
size:  (375, 1242, 3)
load 4900  /  6684
size:  (375, 1242, 3)
load 4901  /  6684
size:  (375, 1242, 3)
load 4902  /  6684
size:  (375, 1242, 3)
load 4903  /  6684
size:  (375, 1242, 3)
load 4904  /  6684
size:  (370, 1224, 3)
load 4905  /  6684
size:  (375, 1242, 3)
load 4906  /  6684
size:  (375, 1242, 3)
load 4907  /  6684
size:  (370, 1224, 3)
load 4908  /  6684
size:  (375, 1242, 3)
load 4909  /  6684
size:  (375, 1242, 3)
load 4910  /  6684
size:  (376, 1241, 3)
load 4911  /  6684
size:  (370, 1224, 3)
load 4912  /  6684
size:  (375, 1242, 3)
load 4913  /  6684
size:  (375, 1242, 3)
load 4914  /  6684
size:  (375, 1242, 3)
load 4915  /  6684
size:  (375, 1242, 3)
load 4916  /  6684
size:  (370, 1224, 3)
load 4917  /  6684
size:  (375, 1242, 3)
load 4918  /  6684
size:  (375, 1242, 3)
load 4919  /  6684
size:  (375, 1242, 3)
load 4920  /  6684
size:  (375, 1242, 3)
load 4921  /  6684
size:  (375, 1242, 3)
load 4922  /  6684
size:  (374, 1238, 3)
load 4923  /  6684
size:  (370, 1224, 3)
load 4924  /  6684
size:  (375, 1242, 3)
load 4925  /  6684
size:  (375, 1242, 3)
load 4926  /  6684
size:  (375, 1242, 3)
load 4927  /  6684
size:  (375, 1242, 3)
load 4928  /  6684
size:  (375, 1242, 3)
load 4929  /  6684
size:  (375, 1242, 3)
load 4930  /  6684
size:  (375, 1242, 3)
load 4931  /  6684
size:  (375, 1242, 3)
load 4932  /  6684
size:  (375, 1242, 3)
load 4933  /  6684
size:  (375, 1242, 3)
load 4934  /  6684
size:  (375, 1242, 3)
load 4935  /  6684
size:  (375, 1242, 3)
load 4936  /  6684
size:  (375, 1242, 3)
load 4937  /  6684
size:  (375, 1242, 3)
load 4938  /  6684
size:  (375, 1242, 3)
load 4939  /  6684
size:  (375, 1242, 3)
load 4940  /  6684
size:  (375, 1242, 3)
load 4941  /  6684
size:  (375, 1242, 3)
load 4942  /  6684
size:  (375, 1242, 3)
load 4943  /  6684
size:  (375, 1242, 3)
load 4944  /  6684
size:  (375, 1242, 3)
load 4945  /  6684
size:  (375, 1242, 3)
load 4946  /  6684
size:  (375, 1242, 3)
load 4947  /  6684
size:  (375, 1242, 3)
load 4948  /  6684
size:  (375, 1242, 3)
load 4949  /  6684
size:  (376, 1241, 3)
load 4950  /  6684
size:  (375, 1242, 3)
load 4951  /  6684
size:  (375, 1242, 3)
load 4952  /  6684
size:  (374, 1238, 3)
load 4953  /  6684
size:  (375, 1242, 3)
load 4954  /  6684
size:  (375, 1242, 3)
load 4955  /  6684
size:  (375, 1242, 3)
load 4956  /  6684
size:  (375, 1242, 3)
load 4957  /  6684
size:  (375, 1242, 3)
load 4958  /  6684
size:  (375, 1242, 3)
load 4959  /  6684
size:  (375, 1242, 3)
load 4960  /  6684
size:  (375, 1242, 3)
load 4961  /  6684
size:  (375, 1242, 3)
load 4962  /  6684
size:  (375, 1242, 3)
load 4963  /  6684
size:  (375, 1242, 3)
load 4964  /  6684
size:  (376, 1241, 3)
load 4965  /  6684
size:  (376, 1241, 3)
load 4966  /  6684
size:  (375, 1242, 3)
load 4967  /  6684
size:  (375, 1242, 3)
load 4968  /  6684
size:  (375, 1242, 3)
load 4969  /  6684
size:  (375, 1242, 3)
load 4970  /  6684
size:  (370, 1224, 3)
load 4971  /  6684
size:  (375, 1242, 3)
load 4972  /  6684
size:  (375, 1242, 3)
load 4973  /  6684
size:  (370, 1224, 3)
load 4974  /  6684
size:  (375, 1242, 3)
load 4975  /  6684
size:  (375, 1242, 3)
load 4976  /  6684
size:  (375, 1242, 3)
load 4977  /  6684
size:  (375, 1242, 3)
load 4978  /  6684
size:  (376, 1241, 3)
load 4979  /  6684
size:  (374, 1238, 3)
load 4980  /  6684
size:  (375, 1242, 3)
load 4981  /  6684
size:  (375, 1242, 3)
load 4982  /  6684
size:  (375, 1242, 3)
load 4983  /  6684
size:  (375, 1242, 3)
load 4984  /  6684
size:  (375, 1242, 3)
load 4985  /  6684
size:  (375, 1242, 3)
load 4986  /  6684
size:  (375, 1242, 3)
load 4987  /  6684
size:  (375, 1242, 3)
load 4988  /  6684
size:  (375, 1242, 3)
load 4989  /  6684
size:  (375, 1242, 3)
load 4990  /  6684
size:  (375, 1242, 3)
load 4991  /  6684
size:  (375, 1242, 3)
load 4992  /  6684
size:  (375, 1242, 3)
load 4993  /  6684
size:  (375, 1242, 3)
load 4994  /  6684
size:  (375, 1242, 3)
load 4995  /  6684
size:  (375, 1242, 3)
load 4996  /  6684
size:  (375, 1242, 3)
load 4997  /  6684
size:  (375, 1242, 3)
load 4998  /  6684
size:  (375, 1242, 3)
load 4999  /  6684
size:  (375, 1242, 3)
load 5000  /  6684
size:  (374, 1238, 3)
load 5001  /  6684
size:  (375, 1242, 3)
load 5002  /  6684
size:  (375, 1242, 3)
load 5003  /  6684
size:  (374, 1238, 3)
load 5004  /  6684
size:  (375, 1242, 3)
load 5005  /  6684
size:  (375, 1242, 3)
load 5006  /  6684
size:  (375, 1242, 3)
load 5007  /  6684
size:  (375, 1242, 3)
load 5008  /  6684
size:  (375, 1242, 3)
load 5009  /  6684
size:  (375, 1242, 3)
load 5010  /  6684
size:  (370, 1224, 3)
load 5011  /  6684
size:  (375, 1242, 3)
load 5012  /  6684
size:  (375, 1242, 3)
load 5013  /  6684
size:  (375, 1242, 3)
load 5014  /  6684
size:  (375, 1242, 3)
load 5015  /  6684
size:  (375, 1242, 3)
load 5016  /  6684
size:  (375, 1242, 3)
load 5017  /  6684
size:  (375, 1242, 3)
load 5018  /  6684
size:  (375, 1242, 3)
load 5019  /  6684
size:  (374, 1238, 3)
load 5020  /  6684
size:  (375, 1242, 3)
load 5021  /  6684
size:  (375, 1242, 3)
load 5022  /  6684
size:  (375, 1242, 3)
load 5023  /  6684
size:  (375, 1242, 3)
load 5024  /  6684
size:  (375, 1242, 3)
load 5025  /  6684
size:  (375, 1242, 3)
load 5026  /  6684
size:  (374, 1238, 3)
load 5027  /  6684
size:  (375, 1242, 3)
load 5028  /  6684
size:  (375, 1242, 3)
load 5029  /  6684
size:  (375, 1242, 3)
load 5030  /  6684
size:  (375, 1242, 3)
load 5031  /  6684
size:  (375, 1242, 3)
load 5032  /  6684
size:  (375, 1242, 3)
load 5033  /  6684
size:  (375, 1242, 3)
load 5034  /  6684
size:  (375, 1242, 3)
load 5035  /  6684
size:  (370, 1224, 3)
load 5036  /  6684
size:  (375, 1242, 3)
load 5037  /  6684
size:  (376, 1241, 3)
load 5038  /  6684
size:  (375, 1242, 3)
load 5039  /  6684
size:  (375, 1242, 3)
load 5040  /  6684
size:  (375, 1242, 3)
load 5041  /  6684
size:  (375, 1242, 3)
load 5042  /  6684
size:  (375, 1242, 3)
load 5043  /  6684
size:  (375, 1242, 3)
load 5044  /  6684
size:  (375, 1242, 3)
load 5045  /  6684
size:  (375, 1242, 3)
load 5046  /  6684
size:  (375, 1242, 3)
load 5047  /  6684
size:  (375, 1242, 3)
load 5048  /  6684
size:  (375, 1242, 3)
load 5049  /  6684
size:  (375, 1242, 3)
load 5050  /  6684
size:  (375, 1242, 3)
load 5051  /  6684
size:  (375, 1242, 3)
load 5052  /  6684
size:  (376, 1241, 3)
load 5053  /  6684
size:  (375, 1242, 3)
load 5054  /  6684
size:  (375, 1242, 3)
load 5055  /  6684
size:  (375, 1242, 3)
load 5056  /  6684
size:  (375, 1242, 3)
load 5057  /  6684
size:  (375, 1242, 3)
load 5058  /  6684
size:  (375, 1242, 3)
load 5059  /  6684
size:  (375, 1242, 3)
load 5060  /  6684
size:  (375, 1242, 3)
load 5061  /  6684
size:  (375, 1242, 3)
load 5062  /  6684
size:  (375, 1242, 3)
load 5063  /  6684
size:  (370, 1224, 3)
load 5064  /  6684
size:  (375, 1242, 3)
load 5065  /  6684
size:  (375, 1242, 3)
load 5066  /  6684
size:  (375, 1242, 3)
load 5067  /  6684
size:  (375, 1242, 3)
load 5068  /  6684
size:  (375, 1242, 3)
load 5069  /  6684
size:  (375, 1242, 3)
load 5070  /  6684
size:  (375, 1242, 3)
load 5071  /  6684
size:  (375, 1242, 3)
load 5072  /  6684
size:  (375, 1242, 3)
load 5073  /  6684
size:  (375, 1242, 3)
load 5074  /  6684
size:  (375, 1242, 3)
load 5075  /  6684
size:  (375, 1242, 3)
load 5076  /  6684
size:  (375, 1242, 3)
load 5077  /  6684
size:  (376, 1241, 3)
load 5078  /  6684
size:  (375, 1242, 3)
load 5079  /  6684
size:  (375, 1242, 3)
load 5080  /  6684
size:  (375, 1242, 3)
load 5081  /  6684
size:  (376, 1241, 3)
load 5082  /  6684
size:  (375, 1242, 3)
load 5083  /  6684
size:  (375, 1242, 3)
load 5084  /  6684
size:  (375, 1242, 3)
load 5085  /  6684
size:  (375, 1242, 3)
load 5086  /  6684
size:  (375, 1242, 3)
load 5087  /  6684
size:  (375, 1242, 3)
load 5088  /  6684
size:  (375, 1242, 3)
load 5089  /  6684
size:  (375, 1242, 3)
load 5090  /  6684
size:  (375, 1242, 3)
load 5091  /  6684
size:  (375, 1242, 3)
load 5092  /  6684
size:  (375, 1242, 3)
load 5093  /  6684
size:  (376, 1241, 3)
load 5094  /  6684
size:  (375, 1242, 3)
load 5095  /  6684
size:  (375, 1242, 3)
load 5096  /  6684
size:  (375, 1242, 3)
load 5097  /  6684
size:  (375, 1242, 3)
load 5098  /  6684
size:  (375, 1242, 3)
load 5099  /  6684
size:  (376, 1241, 3)
load 5100  /  6684
size:  (375, 1242, 3)
load 5101  /  6684
size:  (375, 1242, 3)
load 5102  /  6684
size:  (375, 1242, 3)
load 5103  /  6684
size:  (375, 1242, 3)
load 5104  /  6684
size:  (375, 1242, 3)
load 5105  /  6684
size:  (375, 1242, 3)
load 5106  /  6684
size:  (374, 1238, 3)
load 5107  /  6684
size:  (375, 1242, 3)
load 5108  /  6684
size:  (375, 1242, 3)
load 5109  /  6684
size:  (375, 1242, 3)
load 5110  /  6684
size:  (375, 1242, 3)
load 5111  /  6684
size:  (375, 1242, 3)
load 5112  /  6684
size:  (375, 1242, 3)
load 5113  /  6684
size:  (375, 1242, 3)
load 5114  /  6684
size:  (374, 1238, 3)
load 5115  /  6684
size:  (375, 1242, 3)
load 5116  /  6684
size:  (375, 1242, 3)
load 5117  /  6684
size:  (375, 1242, 3)
load 5118  /  6684
size:  (375, 1242, 3)
load 5119  /  6684
size:  (376, 1241, 3)
load 5120  /  6684
size:  (375, 1242, 3)
load 5121  /  6684
size:  (375, 1242, 3)
load 5122  /  6684
size:  (375, 1242, 3)
load 5123  /  6684
size:  (375, 1242, 3)
load 5124  /  6684
size:  (375, 1242, 3)
load 5125  /  6684
size:  (375, 1242, 3)
load 5126  /  6684
size:  (375, 1242, 3)
load 5127  /  6684
size:  (375, 1242, 3)
load 5128  /  6684
size:  (375, 1242, 3)
load 5129  /  6684
size:  (375, 1242, 3)
load 5130  /  6684
size:  (375, 1242, 3)
load 5131  /  6684
size:  (375, 1242, 3)
load 5132  /  6684
size:  (375, 1242, 3)
load 5133  /  6684
size:  (375, 1242, 3)
load 5134  /  6684
size:  (375, 1242, 3)
load 5135  /  6684
size:  (375, 1242, 3)
load 5136  /  6684
size:  (375, 1242, 3)
load 5137  /  6684
size:  (375, 1242, 3)
load 5138  /  6684
size:  (375, 1242, 3)
load 5139  /  6684
size:  (375, 1242, 3)
load 5140  /  6684
size:  (375, 1242, 3)
load 5141  /  6684
size:  (376, 1241, 3)
load 5142  /  6684
size:  (374, 1238, 3)
load 5143  /  6684
size:  (375, 1242, 3)
load 5144  /  6684
size:  (375, 1242, 3)
load 5145  /  6684
size:  (375, 1242, 3)
load 5146  /  6684
size:  (375, 1242, 3)
load 5147  /  6684
size:  (375, 1242, 3)
load 5148  /  6684
size:  (375, 1242, 3)
load 5149  /  6684
size:  (370, 1224, 3)
load 5150  /  6684
size:  (375, 1242, 3)
load 5151  /  6684
size:  (374, 1238, 3)
load 5152  /  6684
size:  (375, 1242, 3)
load 5153  /  6684
size:  (375, 1242, 3)
load 5154  /  6684
size:  (375, 1242, 3)
load 5155  /  6684
size:  (375, 1242, 3)
load 5156  /  6684
size:  (375, 1242, 3)
load 5157  /  6684
size:  (375, 1242, 3)
load 5158  /  6684
size:  (375, 1242, 3)
load 5159  /  6684
size:  (375, 1242, 3)
load 5160  /  6684
size:  (375, 1242, 3)
load 5161  /  6684
size:  (375, 1242, 3)
load 5162  /  6684
size:  (375, 1242, 3)
load 5163  /  6684
size:  (375, 1242, 3)
load 5164  /  6684
size:  (375, 1242, 3)
load 5165  /  6684
size:  (375, 1242, 3)
load 5166  /  6684
size:  (375, 1242, 3)
load 5167  /  6684
size:  (375, 1242, 3)
load 5168  /  6684
size:  (375, 1242, 3)
load 5169  /  6684
size:  (375, 1242, 3)
load 5170  /  6684
size:  (375, 1242, 3)
load 5171  /  6684
size:  (375, 1242, 3)
load 5172  /  6684
size:  (375, 1242, 3)
load 5173  /  6684
size:  (375, 1242, 3)
load 5174  /  6684
size:  (375, 1242, 3)
load 5175  /  6684
size:  (370, 1224, 3)
load 5176  /  6684
size:  (375, 1242, 3)
load 5177  /  6684
size:  (375, 1242, 3)
load 5178  /  6684
size:  (375, 1242, 3)
load 5179  /  6684
size:  (375, 1242, 3)
load 5180  /  6684
size:  (375, 1242, 3)
load 5181  /  6684
size:  (370, 1224, 3)
load 5182  /  6684
size:  (375, 1242, 3)
load 5183  /  6684
size:  (375, 1242, 3)
load 5184  /  6684
size:  (375, 1242, 3)
load 5185  /  6684
size:  (375, 1242, 3)
load 5186  /  6684
size:  (375, 1242, 3)
load 5187  /  6684
size:  (375, 1242, 3)
load 5188  /  6684
size:  (375, 1242, 3)
load 5189  /  6684
size:  (375, 1242, 3)
load 5190  /  6684
size:  (375, 1242, 3)
load 5191  /  6684
size:  (375, 1242, 3)
load 5192  /  6684
size:  (376, 1241, 3)
load 5193  /  6684
size:  (375, 1242, 3)
load 5194  /  6684
size:  (375, 1242, 3)
load 5195  /  6684
size:  (375, 1242, 3)
load 5196  /  6684
size:  (375, 1242, 3)
load 5197  /  6684
size:  (375, 1242, 3)
load 5198  /  6684
size:  (375, 1242, 3)
load 5199  /  6684
size:  (375, 1242, 3)
load 5200  /  6684
size:  (375, 1242, 3)
load 5201  /  6684
size:  (375, 1242, 3)
load 5202  /  6684
size:  (375, 1242, 3)
load 5203  /  6684
size:  (375, 1242, 3)
load 5204  /  6684
size:  (375, 1242, 3)
load 5205  /  6684
size:  (375, 1242, 3)
load 5206  /  6684
size:  (375, 1242, 3)
load 5207  /  6684
size:  (375, 1242, 3)
load 5208  /  6684
size:  (375, 1242, 3)
load 5209  /  6684
size:  (376, 1241, 3)
load 5210  /  6684
size:  (370, 1224, 3)
load 5211  /  6684
size:  (370, 1224, 3)
load 5212  /  6684
size:  (376, 1241, 3)
load 5213  /  6684
size:  (370, 1224, 3)
load 5214  /  6684
size:  (375, 1242, 3)
load 5215  /  6684
size:  (375, 1242, 3)
load 5216  /  6684
size:  (375, 1242, 3)
load 5217  /  6684
size:  (375, 1242, 3)
load 5218  /  6684
size:  (375, 1242, 3)
load 5219  /  6684
size:  (375, 1242, 3)
load 5220  /  6684
size:  (375, 1242, 3)
load 5221  /  6684
size:  (375, 1242, 3)
load 5222  /  6684
size:  (375, 1242, 3)
load 5223  /  6684
size:  (375, 1242, 3)
load 5224  /  6684
size:  (375, 1242, 3)
load 5225  /  6684
size:  (375, 1242, 3)
load 5226  /  6684
size:  (375, 1242, 3)
load 5227  /  6684
size:  (375, 1242, 3)
load 5228  /  6684
size:  (376, 1241, 3)
load 5229  /  6684
size:  (375, 1242, 3)
load 5230  /  6684
size:  (375, 1242, 3)
load 5231  /  6684
size:  (375, 1242, 3)
load 5232  /  6684
size:  (375, 1242, 3)
load 5233  /  6684
size:  (375, 1242, 3)
load 5234  /  6684
size:  (375, 1242, 3)
load 5235  /  6684
size:  (375, 1242, 3)
load 5236  /  6684
size:  (375, 1242, 3)
load 5237  /  6684
size:  (375, 1242, 3)
load 5238  /  6684
size:  (375, 1242, 3)
load 5239  /  6684
size:  (375, 1242, 3)
load 5240  /  6684
size:  (375, 1242, 3)
load 5241  /  6684
size:  (375, 1242, 3)
load 5242  /  6684
size:  (375, 1242, 3)
load 5243  /  6684
size:  (375, 1242, 3)
load 5244  /  6684
size:  (375, 1242, 3)
load 5245  /  6684
size:  (375, 1242, 3)
load 5246  /  6684
size:  (375, 1242, 3)
load 5247  /  6684
size:  (374, 1238, 3)
load 5248  /  6684
size:  (375, 1242, 3)
load 5249  /  6684
size:  (374, 1238, 3)
load 5250  /  6684
size:  (375, 1242, 3)
load 5251  /  6684
size:  (375, 1242, 3)
load 5252  /  6684
size:  (375, 1242, 3)
load 5253  /  6684
size:  (375, 1242, 3)
load 5254  /  6684
size:  (375, 1242, 3)
load 5255  /  6684
size:  (375, 1242, 3)
load 5256  /  6684
size:  (375, 1242, 3)
load 5257  /  6684
size:  (375, 1242, 3)
load 5258  /  6684
size:  (375, 1242, 3)
load 5259  /  6684
size:  (375, 1242, 3)
load 5260  /  6684
size:  (375, 1242, 3)
load 5261  /  6684
size:  (375, 1242, 3)
load 5262  /  6684
size:  (375, 1242, 3)
load 5263  /  6684
size:  (375, 1242, 3)
load 5264  /  6684
size:  (376, 1241, 3)
load 5265  /  6684
size:  (375, 1242, 3)
load 5266  /  6684
size:  (375, 1242, 3)
load 5267  /  6684
size:  (375, 1242, 3)
load 5268  /  6684
size:  (375, 1242, 3)
load 5269  /  6684
size:  (375, 1242, 3)
load 5270  /  6684
size:  (375, 1242, 3)
load 5271  /  6684
size:  (375, 1242, 3)
load 5272  /  6684
size:  (370, 1224, 3)
load 5273  /  6684
size:  (375, 1242, 3)
load 5274  /  6684
size:  (375, 1242, 3)
load 5275  /  6684
size:  (375, 1242, 3)
load 5276  /  6684
size:  (375, 1242, 3)
load 5277  /  6684
size:  (375, 1242, 3)
load 5278  /  6684
size:  (375, 1242, 3)
load 5279  /  6684
size:  (375, 1242, 3)
load 5280  /  6684
size:  (375, 1242, 3)
load 5281  /  6684
size:  (376, 1241, 3)
load 5282  /  6684
size:  (375, 1242, 3)
load 5283  /  6684
size:  (375, 1242, 3)
load 5284  /  6684
size:  (375, 1242, 3)
load 5285  /  6684
size:  (375, 1242, 3)
load 5286  /  6684
size:  (375, 1242, 3)
load 5287  /  6684
size:  (375, 1242, 3)
load 5288  /  6684
size:  (375, 1242, 3)
load 5289  /  6684
size:  (375, 1242, 3)
load 5290  /  6684
size:  (375, 1242, 3)
load 5291  /  6684
size:  (375, 1242, 3)
load 5292  /  6684
size:  (375, 1242, 3)
load 5293  /  6684
size:  (375, 1242, 3)
load 5294  /  6684
size:  (375, 1242, 3)
load 5295  /  6684
size:  (375, 1242, 3)
load 5296  /  6684
size:  (375, 1242, 3)
load 5297  /  6684
size:  (375, 1242, 3)
load 5298  /  6684
size:  (375, 1242, 3)
load 5299  /  6684
size:  (375, 1242, 3)
load 5300  /  6684
size:  (370, 1224, 3)
load 5301  /  6684
size:  (376, 1241, 3)
load 5302  /  6684
size:  (375, 1242, 3)
load 5303  /  6684
size:  (375, 1242, 3)
load 5304  /  6684
size:  (375, 1242, 3)
load 5305  /  6684
size:  (375, 1242, 3)
load 5306  /  6684
size:  (375, 1242, 3)
load 5307  /  6684
size:  (374, 1238, 3)
load 5308  /  6684
size:  (375, 1242, 3)
load 5309  /  6684
size:  (375, 1242, 3)
load 5310  /  6684
size:  (375, 1242, 3)
load 5311  /  6684
size:  (375, 1242, 3)
load 5312  /  6684
size:  (375, 1242, 3)
load 5313  /  6684
size:  (375, 1242, 3)
load 5314  /  6684
size:  (375, 1242, 3)
load 5315  /  6684
size:  (375, 1242, 3)
load 5316  /  6684
size:  (376, 1241, 3)
load 5317  /  6684
size:  (375, 1242, 3)
load 5318  /  6684
size:  (375, 1242, 3)
load 5319  /  6684
size:  (375, 1242, 3)
load 5320  /  6684
size:  (375, 1242, 3)
load 5321  /  6684
size:  (375, 1242, 3)
load 5322  /  6684
size:  (375, 1242, 3)
load 5323  /  6684
size:  (375, 1242, 3)
load 5324  /  6684
size:  (375, 1242, 3)
load 5325  /  6684
size:  (375, 1242, 3)
load 5326  /  6684
size:  (375, 1242, 3)
load 5327  /  6684
size:  (370, 1224, 3)
load 5328  /  6684
size:  (375, 1242, 3)
load 5329  /  6684
size:  (375, 1242, 3)
load 5330  /  6684
size:  (375, 1242, 3)
load 5331  /  6684
size:  (375, 1242, 3)
load 5332  /  6684
size:  (375, 1242, 3)
load 5333  /  6684
size:  (375, 1242, 3)
load 5334  /  6684
size:  (374, 1238, 3)
load 5335  /  6684
size:  (375, 1242, 3)
load 5336  /  6684
size:  (375, 1242, 3)
load 5337  /  6684
size:  (375, 1242, 3)
load 5338  /  6684
size:  (375, 1242, 3)
load 5339  /  6684
size:  (375, 1242, 3)
load 5340  /  6684
size:  (375, 1242, 3)
load 5341  /  6684
size:  (375, 1242, 3)
load 5342  /  6684
size:  (375, 1242, 3)
load 5343  /  6684
size:  (376, 1241, 3)
load 5344  /  6684
size:  (375, 1242, 3)
load 5345  /  6684
size:  (375, 1242, 3)
load 5346  /  6684
size:  (375, 1242, 3)
load 5347  /  6684
size:  (376, 1241, 3)
load 5348  /  6684
size:  (375, 1242, 3)
load 5349  /  6684
size:  (375, 1242, 3)
load 5350  /  6684
size:  (375, 1242, 3)
load 5351  /  6684
size:  (375, 1242, 3)
load 5352  /  6684
size:  (375, 1242, 3)
load 5353  /  6684
size:  (375, 1242, 3)
load 5354  /  6684
size:  (370, 1224, 3)
load 5355  /  6684
size:  (375, 1242, 3)
load 5356  /  6684
size:  (375, 1242, 3)
load 5357  /  6684
size:  (375, 1242, 3)
load 5358  /  6684
size:  (375, 1242, 3)
load 5359  /  6684
size:  (375, 1242, 3)
load 5360  /  6684
size:  (375, 1242, 3)
load 5361  /  6684
size:  (375, 1242, 3)
load 5362  /  6684
size:  (375, 1242, 3)
load 5363  /  6684
size:  (375, 1242, 3)
load 5364  /  6684
size:  (375, 1242, 3)
load 5365  /  6684
size:  (375, 1242, 3)
load 5366  /  6684
size:  (375, 1242, 3)
load 5367  /  6684
size:  (376, 1241, 3)
load 5368  /  6684
size:  (375, 1242, 3)
load 5369  /  6684
size:  (375, 1242, 3)
load 5370  /  6684
size:  (375, 1242, 3)
load 5371  /  6684
size:  (375, 1242, 3)
load 5372  /  6684
size:  (375, 1242, 3)
load 5373  /  6684
size:  (375, 1242, 3)
load 5374  /  6684
size:  (374, 1238, 3)
load 5375  /  6684
size:  (375, 1242, 3)
load 5376  /  6684
size:  (375, 1242, 3)
load 5377  /  6684
size:  (375, 1242, 3)
load 5378  /  6684
size:  (375, 1242, 3)
load 5379  /  6684
size:  (375, 1242, 3)
load 5380  /  6684
size:  (375, 1242, 3)
load 5381  /  6684
size:  (375, 1242, 3)
load 5382  /  6684
size:  (375, 1242, 3)
load 5383  /  6684
size:  (370, 1224, 3)
load 5384  /  6684
size:  (375, 1242, 3)
load 5385  /  6684
size:  (375, 1242, 3)
load 5386  /  6684
size:  (375, 1242, 3)
load 5387  /  6684
size:  (375, 1242, 3)
load 5388  /  6684
size:  (375, 1242, 3)
load 5389  /  6684
size:  (375, 1242, 3)
load 5390  /  6684
size:  (375, 1242, 3)
load 5391  /  6684
size:  (375, 1242, 3)
load 5392  /  6684
size:  (375, 1242, 3)
load 5393  /  6684
size:  (375, 1242, 3)
load 5394  /  6684
size:  (375, 1242, 3)
load 5395  /  6684
size:  (375, 1242, 3)
load 5396  /  6684
size:  (375, 1242, 3)
load 5397  /  6684
size:  (375, 1242, 3)
load 5398  /  6684
size:  (376, 1241, 3)
load 5399  /  6684
size:  (375, 1242, 3)
load 5400  /  6684
size:  (375, 1242, 3)
load 5401  /  6684
size:  (375, 1242, 3)
load 5402  /  6684
size:  (376, 1241, 3)
load 5403  /  6684
size:  (375, 1242, 3)
load 5404  /  6684
size:  (375, 1242, 3)
load 5405  /  6684
size:  (376, 1241, 3)
load 5406  /  6684
size:  (375, 1242, 3)
load 5407  /  6684
size:  (375, 1242, 3)
load 5408  /  6684
size:  (370, 1224, 3)
load 5409  /  6684
size:  (375, 1242, 3)
load 5410  /  6684
size:  (375, 1242, 3)
load 5411  /  6684
size:  (375, 1242, 3)
load 5412  /  6684
size:  (375, 1242, 3)
load 5413  /  6684
size:  (375, 1242, 3)
load 5414  /  6684
size:  (375, 1242, 3)
load 5415  /  6684
size:  (375, 1242, 3)
load 5416  /  6684
size:  (375, 1242, 3)
load 5417  /  6684
size:  (375, 1242, 3)
load 5418  /  6684
size:  (375, 1242, 3)
load 5419  /  6684
size:  (376, 1241, 3)
load 5420  /  6684
size:  (375, 1242, 3)
load 5421  /  6684
size:  (370, 1224, 3)
load 5422  /  6684
size:  (375, 1242, 3)
load 5423  /  6684
size:  (375, 1242, 3)
load 5424  /  6684
size:  (375, 1242, 3)
load 5425  /  6684
size:  (375, 1242, 3)
load 5426  /  6684
size:  (374, 1238, 3)
load 5427  /  6684
size:  (375, 1242, 3)
load 5428  /  6684
size:  (370, 1224, 3)
load 5429  /  6684
size:  (375, 1242, 3)
load 5430  /  6684
size:  (370, 1224, 3)
load 5431  /  6684
size:  (375, 1242, 3)
load 5432  /  6684
size:  (375, 1242, 3)
load 5433  /  6684
size:  (375, 1242, 3)
load 5434  /  6684
size:  (375, 1242, 3)
load 5435  /  6684
size:  (375, 1242, 3)
load 5436  /  6684
size:  (375, 1242, 3)
load 5437  /  6684
size:  (375, 1242, 3)
load 5438  /  6684
size:  (375, 1242, 3)
load 5439  /  6684
size:  (375, 1242, 3)
load 5440  /  6684
size:  (370, 1224, 3)
load 5441  /  6684
size:  (374, 1238, 3)
load 5442  /  6684
size:  (375, 1242, 3)
load 5443  /  6684
size:  (375, 1242, 3)
load 5444  /  6684
size:  (375, 1242, 3)
load 5445  /  6684
size:  (375, 1242, 3)
load 5446  /  6684
size:  (375, 1242, 3)
load 5447  /  6684
size:  (375, 1242, 3)
load 5448  /  6684
size:  (375, 1242, 3)
load 5449  /  6684
size:  (375, 1242, 3)
load 5450  /  6684
size:  (375, 1242, 3)
load 5451  /  6684
size:  (375, 1242, 3)
load 5452  /  6684
size:  (375, 1242, 3)
load 5453  /  6684
size:  (375, 1242, 3)
load 5454  /  6684
size:  (375, 1242, 3)
load 5455  /  6684
size:  (375, 1242, 3)
load 5456  /  6684
size:  (375, 1242, 3)
load 5457  /  6684
size:  (375, 1242, 3)
load 5458  /  6684
size:  (375, 1242, 3)
load 5459  /  6684
size:  (375, 1242, 3)
load 5460  /  6684
size:  (375, 1242, 3)
load 5461  /  6684
size:  (375, 1242, 3)
load 5462  /  6684
size:  (375, 1242, 3)
load 5463  /  6684
size:  (375, 1242, 3)
load 5464  /  6684
size:  (375, 1242, 3)
load 5465  /  6684
size:  (375, 1242, 3)
load 5466  /  6684
size:  (375, 1242, 3)
load 5467  /  6684
size:  (375, 1242, 3)
load 5468  /  6684
size:  (375, 1242, 3)
load 5469  /  6684
size:  (375, 1242, 3)
load 5470  /  6684
size:  (370, 1224, 3)
load 5471  /  6684
size:  (375, 1242, 3)
load 5472  /  6684
size:  (375, 1242, 3)
load 5473  /  6684
size:  (375, 1242, 3)
load 5474  /  6684
size:  (375, 1242, 3)
load 5475  /  6684
size:  (375, 1242, 3)
load 5476  /  6684
size:  (375, 1242, 3)
load 5477  /  6684
size:  (376, 1241, 3)
load 5478  /  6684
size:  (375, 1242, 3)
load 5479  /  6684
size:  (370, 1224, 3)
load 5480  /  6684
size:  (375, 1242, 3)
load 5481  /  6684
size:  (375, 1242, 3)
load 5482  /  6684
size:  (375, 1242, 3)
load 5483  /  6684
size:  (375, 1242, 3)
load 5484  /  6684
size:  (375, 1242, 3)
load 5485  /  6684
size:  (375, 1242, 3)
load 5486  /  6684
size:  (375, 1242, 3)
load 5487  /  6684
size:  (375, 1242, 3)
load 5488  /  6684
size:  (375, 1242, 3)
load 5489  /  6684
size:  (375, 1242, 3)
load 5490  /  6684
size:  (375, 1242, 3)
load 5491  /  6684
size:  (375, 1242, 3)
load 5492  /  6684
size:  (376, 1241, 3)
load 5493  /  6684
size:  (375, 1242, 3)
load 5494  /  6684
size:  (375, 1242, 3)
load 5495  /  6684
size:  (375, 1242, 3)
load 5496  /  6684
size:  (370, 1224, 3)
load 5497  /  6684
size:  (375, 1242, 3)
load 5498  /  6684
size:  (375, 1242, 3)
load 5499  /  6684
size:  (375, 1242, 3)
load 5500  /  6684
size:  (376, 1241, 3)
load 5501  /  6684
size:  (375, 1242, 3)
load 5502  /  6684
size:  (375, 1242, 3)
load 5503  /  6684
size:  (375, 1242, 3)
load 5504  /  6684
size:  (375, 1242, 3)
load 5505  /  6684
size:  (375, 1242, 3)
load 5506  /  6684
size:  (375, 1242, 3)
load 5507  /  6684
size:  (375, 1242, 3)
load 5508  /  6684
size:  (375, 1242, 3)
load 5509  /  6684
size:  (375, 1242, 3)
load 5510  /  6684
size:  (375, 1242, 3)
load 5511  /  6684
size:  (375, 1242, 3)
load 5512  /  6684
size:  (375, 1242, 3)
load 5513  /  6684
size:  (375, 1242, 3)
load 5514  /  6684
size:  (375, 1242, 3)
load 5515  /  6684
size:  (375, 1242, 3)
load 5516  /  6684
size:  (375, 1242, 3)
load 5517  /  6684
size:  (375, 1242, 3)
load 5518  /  6684
size:  (375, 1242, 3)
load 5519  /  6684
size:  (375, 1242, 3)
load 5520  /  6684
size:  (374, 1238, 3)
load 5521  /  6684
size:  (375, 1242, 3)
load 5522  /  6684
size:  (375, 1242, 3)
load 5523  /  6684
size:  (375, 1242, 3)
load 5524  /  6684
size:  (375, 1242, 3)
load 5525  /  6684
size:  (375, 1242, 3)
load 5526  /  6684
size:  (374, 1238, 3)
load 5527  /  6684
size:  (375, 1242, 3)
load 5528  /  6684
size:  (375, 1242, 3)
load 5529  /  6684
size:  (375, 1242, 3)
load 5530  /  6684
size:  (375, 1242, 3)
load 5531  /  6684
size:  (375, 1242, 3)
load 5532  /  6684
size:  (375, 1242, 3)
load 5533  /  6684
size:  (375, 1242, 3)
load 5534  /  6684
size:  (375, 1242, 3)
load 5535  /  6684
size:  (375, 1242, 3)
load 5536  /  6684
size:  (375, 1242, 3)
load 5537  /  6684
size:  (375, 1242, 3)
load 5538  /  6684
size:  (370, 1224, 3)
load 5539  /  6684
size:  (375, 1242, 3)
load 5540  /  6684
size:  (375, 1242, 3)
load 5541  /  6684
size:  (375, 1242, 3)
load 5542  /  6684
size:  (375, 1242, 3)
load 5543  /  6684
size:  (376, 1241, 3)
load 5544  /  6684
size:  (375, 1242, 3)
load 5545  /  6684
size:  (375, 1242, 3)
load 5546  /  6684
size:  (375, 1242, 3)
load 5547  /  6684
size:  (375, 1242, 3)
load 5548  /  6684
size:  (375, 1242, 3)
load 5549  /  6684
size:  (375, 1242, 3)
load 5550  /  6684
size:  (375, 1242, 3)
load 5551  /  6684
size:  (374, 1238, 3)
load 5552  /  6684
size:  (375, 1242, 3)
load 5553  /  6684
size:  (375, 1242, 3)
load 5554  /  6684
size:  (375, 1242, 3)
load 5555  /  6684
size:  (375, 1242, 3)
load 5556  /  6684
size:  (375, 1242, 3)
load 5557  /  6684
size:  (375, 1242, 3)
load 5558  /  6684
size:  (374, 1238, 3)
load 5559  /  6684
size:  (375, 1242, 3)
load 5560  /  6684
size:  (375, 1242, 3)
load 5561  /  6684
size:  (375, 1242, 3)
load 5562  /  6684
size:  (375, 1242, 3)
load 5563  /  6684
size:  (375, 1242, 3)
load 5564  /  6684
size:  (375, 1242, 3)
load 5565  /  6684
size:  (375, 1242, 3)
load 5566  /  6684
size:  (375, 1242, 3)
load 5567  /  6684
size:  (375, 1242, 3)
load 5568  /  6684
size:  (375, 1242, 3)
load 5569  /  6684
size:  (375, 1242, 3)
load 5570  /  6684
size:  (375, 1242, 3)
load 5571  /  6684
size:  (375, 1242, 3)
load 5572  /  6684
size:  (375, 1242, 3)
load 5573  /  6684
size:  (375, 1242, 3)
load 5574  /  6684
size:  (375, 1242, 3)
load 5575  /  6684
size:  (376, 1241, 3)
load 5576  /  6684
size:  (375, 1242, 3)
load 5577  /  6684
size:  (375, 1242, 3)
load 5578  /  6684
size:  (375, 1242, 3)
load 5579  /  6684
size:  (375, 1242, 3)
load 5580  /  6684
size:  (375, 1242, 3)
load 5581  /  6684
size:  (375, 1242, 3)
load 5582  /  6684
size:  (375, 1242, 3)
load 5583  /  6684
size:  (375, 1242, 3)
load 5584  /  6684
size:  (375, 1242, 3)
load 5585  /  6684
size:  (375, 1242, 3)
load 5586  /  6684
size:  (375, 1242, 3)
load 5587  /  6684
size:  (375, 1242, 3)
load 5588  /  6684
size:  (375, 1242, 3)
load 5589  /  6684
size:  (375, 1242, 3)
load 5590  /  6684
size:  (375, 1242, 3)
load 5591  /  6684
size:  (375, 1242, 3)
load 5592  /  6684
size:  (375, 1242, 3)
load 5593  /  6684
size:  (375, 1242, 3)
load 5594  /  6684
size:  (375, 1242, 3)
load 5595  /  6684
size:  (375, 1242, 3)
load 5596  /  6684
size:  (375, 1242, 3)
load 5597  /  6684
size:  (375, 1242, 3)
load 5598  /  6684
size:  (375, 1242, 3)
load 5599  /  6684
size:  (375, 1242, 3)
load 5600  /  6684
size:  (375, 1242, 3)
load 5601  /  6684
size:  (375, 1242, 3)
load 5602  /  6684
size:  (375, 1242, 3)
load 5603  /  6684
size:  (375, 1242, 3)
load 5604  /  6684
size:  (375, 1242, 3)
load 5605  /  6684
size:  (375, 1242, 3)
load 5606  /  6684
size:  (375, 1242, 3)
load 5607  /  6684
size:  (375, 1242, 3)
load 5608  /  6684
size:  (375, 1242, 3)
load 5609  /  6684
size:  (375, 1242, 3)
load 5610  /  6684
size:  (370, 1224, 3)
load 5611  /  6684
size:  (375, 1242, 3)
load 5612  /  6684
size:  (375, 1242, 3)
load 5613  /  6684
size:  (375, 1242, 3)
load 5614  /  6684
size:  (375, 1242, 3)
load 5615  /  6684
size:  (375, 1242, 3)
load 5616  /  6684
size:  (375, 1242, 3)
load 5617  /  6684
size:  (375, 1242, 3)
load 5618  /  6684
size:  (375, 1242, 3)
load 5619  /  6684
size:  (375, 1242, 3)
load 5620  /  6684
size:  (375, 1242, 3)
load 5621  /  6684
size:  (375, 1242, 3)
load 5622  /  6684
size:  (375, 1242, 3)
load 5623  /  6684
size:  (375, 1242, 3)
load 5624  /  6684
size:  (375, 1242, 3)
load 5625  /  6684
size:  (375, 1242, 3)
load 5626  /  6684
size:  (375, 1242, 3)
load 5627  /  6684
size:  (375, 1242, 3)
load 5628  /  6684
size:  (375, 1242, 3)
load 5629  /  6684
size:  (375, 1242, 3)
load 5630  /  6684
size:  (375, 1242, 3)
load 5631  /  6684
size:  (375, 1242, 3)
load 5632  /  6684
size:  (375, 1242, 3)
load 5633  /  6684
size:  (375, 1242, 3)
load 5634  /  6684
size:  (375, 1242, 3)
load 5635  /  6684
size:  (375, 1242, 3)
load 5636  /  6684
size:  (375, 1242, 3)
load 5637  /  6684
size:  (375, 1242, 3)
load 5638  /  6684
size:  (375, 1242, 3)
load 5639  /  6684
size:  (375, 1242, 3)
load 5640  /  6684
size:  (376, 1241, 3)
load 5641  /  6684
size:  (375, 1242, 3)
load 5642  /  6684
size:  (375, 1242, 3)
load 5643  /  6684
size:  (375, 1242, 3)
load 5644  /  6684
size:  (375, 1242, 3)
load 5645  /  6684
size:  (375, 1242, 3)
load 5646  /  6684
size:  (375, 1242, 3)
load 5647  /  6684
size:  (375, 1242, 3)
load 5648  /  6684
size:  (375, 1242, 3)
load 5649  /  6684
size:  (375, 1242, 3)
load 5650  /  6684
size:  (375, 1242, 3)
load 5651  /  6684
size:  (375, 1242, 3)
load 5652  /  6684
size:  (375, 1242, 3)
load 5653  /  6684
size:  (375, 1242, 3)
load 5654  /  6684
size:  (375, 1242, 3)
load 5655  /  6684
size:  (375, 1242, 3)
load 5656  /  6684
size:  (375, 1242, 3)
load 5657  /  6684
size:  (375, 1242, 3)
load 5658  /  6684
size:  (375, 1242, 3)
load 5659  /  6684
size:  (375, 1242, 3)
load 5660  /  6684
size:  (375, 1242, 3)
load 5661  /  6684
size:  (375, 1242, 3)
load 5662  /  6684
size:  (375, 1242, 3)
load 5663  /  6684
size:  (375, 1242, 3)
load 5664  /  6684
size:  (375, 1242, 3)
load 5665  /  6684
size:  (375, 1242, 3)
load 5666  /  6684
size:  (375, 1242, 3)
load 5667  /  6684
size:  (375, 1242, 3)
load 5668  /  6684
size:  (375, 1242, 3)
load 5669  /  6684
size:  (375, 1242, 3)
load 5670  /  6684
size:  (376, 1241, 3)
load 5671  /  6684
size:  (376, 1241, 3)
load 5672  /  6684
size:  (375, 1242, 3)
load 5673  /  6684
size:  (375, 1242, 3)
load 5674  /  6684
size:  (375, 1242, 3)
load 5675  /  6684
size:  (375, 1242, 3)
load 5676  /  6684
size:  (375, 1242, 3)
load 5677  /  6684
size:  (375, 1242, 3)
load 5678  /  6684
size:  (375, 1242, 3)
load 5679  /  6684
size:  (375, 1242, 3)
load 5680  /  6684
size:  (375, 1242, 3)
load 5681  /  6684
size:  (375, 1242, 3)
load 5682  /  6684
size:  (375, 1242, 3)
load 5683  /  6684
size:  (375, 1242, 3)
load 5684  /  6684
size:  (375, 1242, 3)
load 5685  /  6684
size:  (375, 1242, 3)
load 5686  /  6684
size:  (375, 1242, 3)
load 5687  /  6684
size:  (375, 1242, 3)
load 5688  /  6684
size:  (375, 1242, 3)
load 5689  /  6684
size:  (375, 1242, 3)
load 5690  /  6684
size:  (375, 1242, 3)
load 5691  /  6684
size:  (375, 1242, 3)
load 5692  /  6684
size:  (375, 1242, 3)
load 5693  /  6684
size:  (375, 1242, 3)
load 5694  /  6684
size:  (375, 1242, 3)
load 5695  /  6684
size:  (375, 1242, 3)
load 5696  /  6684
size:  (375, 1242, 3)
load 5697  /  6684
size:  (375, 1242, 3)
load 5698  /  6684
size:  (375, 1242, 3)
load 5699  /  6684
size:  (375, 1242, 3)
load 5700  /  6684
size:  (375, 1242, 3)
load 5701  /  6684
size:  (375, 1242, 3)
load 5702  /  6684
size:  (375, 1242, 3)
load 5703  /  6684
size:  (375, 1242, 3)
load 5704  /  6684
size:  (375, 1242, 3)
load 5705  /  6684
size:  (375, 1242, 3)
load 5706  /  6684
size:  (375, 1242, 3)
load 5707  /  6684
size:  (375, 1242, 3)
load 5708  /  6684
size:  (375, 1242, 3)
load 5709  /  6684
size:  (375, 1242, 3)
load 5710  /  6684
size:  (375, 1242, 3)
load 5711  /  6684
size:  (375, 1242, 3)
load 5712  /  6684
size:  (375, 1242, 3)
load 5713  /  6684
size:  (375, 1242, 3)
load 5714  /  6684
size:  (375, 1242, 3)
load 5715  /  6684
size:  (375, 1242, 3)
load 5716  /  6684
size:  (375, 1242, 3)
load 5717  /  6684
size:  (375, 1242, 3)
load 5718  /  6684
size:  (375, 1242, 3)
load 5719  /  6684
size:  (376, 1241, 3)
load 5720  /  6684
size:  (370, 1224, 3)
load 5721  /  6684
size:  (375, 1242, 3)
load 5722  /  6684
size:  (375, 1242, 3)
load 5723  /  6684
size:  (375, 1242, 3)
load 5724  /  6684
size:  (375, 1242, 3)
load 5725  /  6684
size:  (375, 1242, 3)
load 5726  /  6684
size:  (375, 1242, 3)
load 5727  /  6684
size:  (375, 1242, 3)
load 5728  /  6684
size:  (375, 1242, 3)
load 5729  /  6684
size:  (375, 1242, 3)
load 5730  /  6684
size:  (370, 1224, 3)
load 5731  /  6684
size:  (375, 1242, 3)
load 5732  /  6684
size:  (375, 1242, 3)
load 5733  /  6684
size:  (375, 1242, 3)
load 5734  /  6684
size:  (375, 1242, 3)
load 5735  /  6684
size:  (375, 1242, 3)
load 5736  /  6684
size:  (375, 1242, 3)
load 5737  /  6684
size:  (375, 1242, 3)
load 5738  /  6684
size:  (375, 1242, 3)
load 5739  /  6684
size:  (375, 1242, 3)
load 5740  /  6684
size:  (375, 1242, 3)
load 5741  /  6684
size:  (376, 1241, 3)
load 5742  /  6684
size:  (375, 1242, 3)
load 5743  /  6684
size:  (370, 1224, 3)
load 5744  /  6684
size:  (376, 1241, 3)
load 5745  /  6684
size:  (374, 1238, 3)
load 5746  /  6684
size:  (375, 1242, 3)
load 5747  /  6684
size:  (375, 1242, 3)
load 5748  /  6684
size:  (374, 1238, 3)
load 5749  /  6684
size:  (375, 1242, 3)
load 5750  /  6684
size:  (375, 1242, 3)
load 5751  /  6684
size:  (374, 1238, 3)
load 5752  /  6684
size:  (375, 1242, 3)
load 5753  /  6684
size:  (375, 1242, 3)
load 5754  /  6684
size:  (370, 1224, 3)
load 5755  /  6684
size:  (375, 1242, 3)
load 5756  /  6684
size:  (375, 1242, 3)
load 5757  /  6684
size:  (375, 1242, 3)
load 5758  /  6684
size:  (375, 1242, 3)
load 5759  /  6684
size:  (375, 1242, 3)
load 5760  /  6684
size:  (375, 1242, 3)
load 5761  /  6684
size:  (374, 1238, 3)
load 5762  /  6684
size:  (375, 1242, 3)
load 5763  /  6684
size:  (375, 1242, 3)
load 5764  /  6684
size:  (374, 1238, 3)
load 5765  /  6684
size:  (375, 1242, 3)
load 5766  /  6684
size:  (375, 1242, 3)
load 5767  /  6684
size:  (375, 1242, 3)
load 5768  /  6684
size:  (375, 1242, 3)
load 5769  /  6684
size:  (375, 1242, 3)
load 5770  /  6684
size:  (375, 1242, 3)
load 5771  /  6684
size:  (375, 1242, 3)
load 5772  /  6684
size:  (375, 1242, 3)
load 5773  /  6684
size:  (374, 1238, 3)
load 5774  /  6684
size:  (375, 1242, 3)
load 5775  /  6684
size:  (375, 1242, 3)
load 5776  /  6684
size:  (375, 1242, 3)
load 5777  /  6684
size:  (375, 1242, 3)
load 5778  /  6684
size:  (375, 1242, 3)
load 5779  /  6684
size:  (375, 1242, 3)
load 5780  /  6684
size:  (375, 1242, 3)
load 5781  /  6684
size:  (375, 1242, 3)
load 5782  /  6684
size:  (375, 1242, 3)
load 5783  /  6684
size:  (375, 1242, 3)
load 5784  /  6684
size:  (375, 1242, 3)
load 5785  /  6684
size:  (376, 1241, 3)
load 5786  /  6684
size:  (375, 1242, 3)
load 5787  /  6684
size:  (375, 1242, 3)
load 5788  /  6684
size:  (375, 1242, 3)
load 5789  /  6684
size:  (374, 1238, 3)
load 5790  /  6684
size:  (375, 1242, 3)
load 5791  /  6684
size:  (375, 1242, 3)
load 5792  /  6684
size:  (374, 1238, 3)
load 5793  /  6684
size:  (375, 1242, 3)
load 5794  /  6684
size:  (375, 1242, 3)
load 5795  /  6684
size:  (375, 1242, 3)
load 5796  /  6684
size:  (375, 1242, 3)
load 5797  /  6684
size:  (375, 1242, 3)
load 5798  /  6684
size:  (375, 1242, 3)
load 5799  /  6684
size:  (375, 1242, 3)
load 5800  /  6684
size:  (374, 1238, 3)
load 5801  /  6684
size:  (375, 1242, 3)
load 5802  /  6684
size:  (375, 1242, 3)
load 5803  /  6684
size:  (375, 1242, 3)
load 5804  /  6684
size:  (375, 1242, 3)
load 5805  /  6684
size:  (375, 1242, 3)
load 5806  /  6684
size:  (375, 1242, 3)
load 5807  /  6684
size:  (375, 1242, 3)
load 5808  /  6684
size:  (370, 1224, 3)
load 5809  /  6684
size:  (376, 1241, 3)
load 5810  /  6684
size:  (375, 1242, 3)
load 5811  /  6684
size:  (375, 1242, 3)
load 5812  /  6684
size:  (375, 1242, 3)
load 5813  /  6684
size:  (375, 1242, 3)
load 5814  /  6684
size:  (370, 1224, 3)
load 5815  /  6684
size:  (375, 1242, 3)
load 5816  /  6684
size:  (375, 1242, 3)
load 5817  /  6684
size:  (374, 1238, 3)
load 5818  /  6684
size:  (375, 1242, 3)
load 5819  /  6684
size:  (375, 1242, 3)
load 5820  /  6684
size:  (375, 1242, 3)
load 5821  /  6684
size:  (374, 1238, 3)
load 5822  /  6684
size:  (375, 1242, 3)
load 5823  /  6684
size:  (375, 1242, 3)
load 5824  /  6684
size:  (375, 1242, 3)
load 5825  /  6684
size:  (375, 1242, 3)
load 5826  /  6684
size:  (375, 1242, 3)
load 5827  /  6684
size:  (375, 1242, 3)
load 5828  /  6684
size:  (375, 1242, 3)
load 5829  /  6684
size:  (375, 1242, 3)
load 5830  /  6684
size:  (375, 1242, 3)
load 5831  /  6684
size:  (375, 1242, 3)
load 5832  /  6684
size:  (370, 1224, 3)
load 5833  /  6684
size:  (375, 1242, 3)
load 5834  /  6684
size:  (375, 1242, 3)
load 5835  /  6684
size:  (375, 1242, 3)
load 5836  /  6684
size:  (370, 1224, 3)
load 5837  /  6684
size:  (375, 1242, 3)
load 5838  /  6684
size:  (375, 1242, 3)
load 5839  /  6684
size:  (375, 1242, 3)
load 5840  /  6684
size:  (375, 1242, 3)
load 5841  /  6684
size:  (375, 1242, 3)
load 5842  /  6684
size:  (375, 1242, 3)
load 5843  /  6684
size:  (375, 1242, 3)
load 5844  /  6684
size:  (375, 1242, 3)
load 5845  /  6684
size:  (375, 1242, 3)
load 5846  /  6684
size:  (375, 1242, 3)
load 5847  /  6684
size:  (375, 1242, 3)
load 5848  /  6684
size:  (375, 1242, 3)
load 5849  /  6684
size:  (375, 1242, 3)
load 5850  /  6684
size:  (375, 1242, 3)
load 5851  /  6684
size:  (375, 1242, 3)
load 5852  /  6684
size:  (375, 1242, 3)
load 5853  /  6684
size:  (375, 1242, 3)
load 5854  /  6684
size:  (375, 1242, 3)
load 5855  /  6684
size:  (375, 1242, 3)
load 5856  /  6684
size:  (375, 1242, 3)
load 5857  /  6684
size:  (375, 1242, 3)
load 5858  /  6684
size:  (375, 1242, 3)
load 5859  /  6684
size:  (375, 1242, 3)
load 5860  /  6684
size:  (375, 1242, 3)
load 5861  /  6684
size:  (375, 1242, 3)
load 5862  /  6684
size:  (375, 1242, 3)
load 5863  /  6684
size:  (375, 1242, 3)
load 5864  /  6684
size:  (375, 1242, 3)
load 5865  /  6684
size:  (375, 1242, 3)
load 5866  /  6684
size:  (375, 1242, 3)
load 5867  /  6684
size:  (375, 1242, 3)
load 5868  /  6684
size:  (375, 1242, 3)
load 5869  /  6684
size:  (375, 1242, 3)
load 5870  /  6684
size:  (375, 1242, 3)
load 5871  /  6684
size:  (375, 1242, 3)
load 5872  /  6684
size:  (375, 1242, 3)
load 5873  /  6684
size:  (375, 1242, 3)
load 5874  /  6684
size:  (375, 1242, 3)
load 5875  /  6684
size:  (375, 1242, 3)
load 5876  /  6684
size:  (375, 1242, 3)
load 5877  /  6684
size:  (375, 1242, 3)
load 5878  /  6684
size:  (375, 1242, 3)
load 5879  /  6684
size:  (375, 1242, 3)
load 5880  /  6684
size:  (375, 1242, 3)
load 5881  /  6684
size:  (375, 1242, 3)
load 5882  /  6684
size:  (375, 1242, 3)
load 5883  /  6684
size:  (375, 1242, 3)
load 5884  /  6684
size:  (375, 1242, 3)
load 5885  /  6684
size:  (375, 1242, 3)
load 5886  /  6684
size:  (375, 1242, 3)
load 5887  /  6684
size:  (375, 1242, 3)
load 5888  /  6684
size:  (375, 1242, 3)
load 5889  /  6684
size:  (375, 1242, 3)
load 5890  /  6684
size:  (375, 1242, 3)
load 5891  /  6684
size:  (375, 1242, 3)
load 5892  /  6684
size:  (375, 1242, 3)
load 5893  /  6684
size:  (375, 1242, 3)
load 5894  /  6684
size:  (375, 1242, 3)
load 5895  /  6684
size:  (375, 1242, 3)
load 5896  /  6684
size:  (375, 1242, 3)
load 5897  /  6684
size:  (375, 1242, 3)
load 5898  /  6684
size:  (375, 1242, 3)
load 5899  /  6684
size:  (375, 1242, 3)
load 5900  /  6684
size:  (375, 1242, 3)
load 5901  /  6684
size:  (375, 1242, 3)
load 5902  /  6684
size:  (375, 1242, 3)
load 5903  /  6684
size:  (375, 1242, 3)
load 5904  /  6684
size:  (375, 1242, 3)
load 5905  /  6684
size:  (375, 1242, 3)
load 5906  /  6684
size:  (375, 1242, 3)
load 5907  /  6684
size:  (374, 1238, 3)
load 5908  /  6684
size:  (375, 1242, 3)
load 5909  /  6684
size:  (375, 1242, 3)
load 5910  /  6684
size:  (375, 1242, 3)
load 5911  /  6684
size:  (375, 1242, 3)
load 5912  /  6684
size:  (375, 1242, 3)
load 5913  /  6684
size:  (375, 1242, 3)
load 5914  /  6684
size:  (375, 1242, 3)
load 5915  /  6684
size:  (375, 1242, 3)
load 5916  /  6684
size:  (375, 1242, 3)
load 5917  /  6684
size:  (370, 1224, 3)
load 5918  /  6684
size:  (375, 1242, 3)
load 5919  /  6684
size:  (375, 1242, 3)
load 5920  /  6684
size:  (375, 1242, 3)
load 5921  /  6684
size:  (375, 1242, 3)
load 5922  /  6684
size:  (375, 1242, 3)
load 5923  /  6684
size:  (375, 1242, 3)
load 5924  /  6684
size:  (376, 1241, 3)
load 5925  /  6684
size:  (375, 1242, 3)
load 5926  /  6684
size:  (375, 1242, 3)
load 5927  /  6684
size:  (375, 1242, 3)
load 5928  /  6684
size:  (375, 1242, 3)
load 5929  /  6684
size:  (375, 1242, 3)
load 5930  /  6684
size:  (375, 1242, 3)
load 5931  /  6684
size:  (375, 1242, 3)
load 5932  /  6684
size:  (375, 1242, 3)
load 5933  /  6684
size:  (375, 1242, 3)
load 5934  /  6684
size:  (375, 1242, 3)
load 5935  /  6684
size:  (375, 1242, 3)
load 5936  /  6684
size:  (375, 1242, 3)
load 5937  /  6684
size:  (376, 1241, 3)
load 5938  /  6684
size:  (375, 1242, 3)
load 5939  /  6684
size:  (375, 1242, 3)
load 5940  /  6684
size:  (375, 1242, 3)
load 5941  /  6684
size:  (375, 1242, 3)
load 5942  /  6684
size:  (375, 1242, 3)
load 5943  /  6684
size:  (375, 1242, 3)
load 5944  /  6684
size:  (375, 1242, 3)
load 5945  /  6684
size:  (375, 1242, 3)
load 5946  /  6684
size:  (375, 1242, 3)
load 5947  /  6684
size:  (375, 1242, 3)
load 5948  /  6684
size:  (375, 1242, 3)
load 5949  /  6684
size:  (375, 1242, 3)
load 5950  /  6684
size:  (375, 1242, 3)
load 5951  /  6684
size:  (375, 1242, 3)
load 5952  /  6684
size:  (375, 1242, 3)
load 5953  /  6684
size:  (376, 1241, 3)
load 5954  /  6684
size:  (375, 1242, 3)
load 5955  /  6684
size:  (375, 1242, 3)
load 5956  /  6684
size:  (375, 1242, 3)
load 5957  /  6684
size:  (375, 1242, 3)
load 5958  /  6684
size:  (374, 1238, 3)
load 5959  /  6684
size:  (374, 1238, 3)
load 5960  /  6684
size:  (375, 1242, 3)
load 5961  /  6684
size:  (375, 1242, 3)
load 5962  /  6684
size:  (375, 1242, 3)
load 5963  /  6684
size:  (376, 1241, 3)
load 5964  /  6684
size:  (374, 1238, 3)
load 5965  /  6684
size:  (370, 1224, 3)
load 5966  /  6684
size:  (375, 1242, 3)
load 5967  /  6684
size:  (375, 1242, 3)
load 5968  /  6684
size:  (375, 1242, 3)
load 5969  /  6684
size:  (375, 1242, 3)
load 5970  /  6684
size:  (375, 1242, 3)
load 5971  /  6684
size:  (375, 1242, 3)
load 5972  /  6684
size:  (375, 1242, 3)
load 5973  /  6684
size:  (375, 1242, 3)
load 5974  /  6684
size:  (370, 1224, 3)
load 5975  /  6684
size:  (375, 1242, 3)
load 5976  /  6684
size:  (375, 1242, 3)
load 5977  /  6684
size:  (375, 1242, 3)
load 5978  /  6684
size:  (375, 1242, 3)
load 5979  /  6684
size:  (375, 1242, 3)
load 5980  /  6684
size:  (375, 1242, 3)
load 5981  /  6684
size:  (375, 1242, 3)
load 5982  /  6684
size:  (375, 1242, 3)
load 5983  /  6684
size:  (375, 1242, 3)
load 5984  /  6684
size:  (375, 1242, 3)
load 5985  /  6684
size:  (375, 1242, 3)
load 5986  /  6684
size:  (375, 1242, 3)
load 5987  /  6684
size:  (375, 1242, 3)
load 5988  /  6684
size:  (374, 1238, 3)
load 5989  /  6684
size:  (375, 1242, 3)
load 5990  /  6684
size:  (370, 1224, 3)
load 5991  /  6684
size:  (375, 1242, 3)
load 5992  /  6684
size:  (375, 1242, 3)
load 5993  /  6684
size:  (375, 1242, 3)
load 5994  /  6684
size:  (375, 1242, 3)
load 5995  /  6684
size:  (375, 1242, 3)
load 5996  /  6684
size:  (375, 1242, 3)
load 5997  /  6684
size:  (375, 1242, 3)
load 5998  /  6684
size:  (375, 1242, 3)
load 5999  /  6684
size:  (375, 1242, 3)
load 6000  /  6684
size:  (375, 1242, 3)
load 6001  /  6684
size:  (375, 1242, 3)
load 6002  /  6684
size:  (375, 1242, 3)
load 6003  /  6684
size:  (375, 1242, 3)
load 6004  /  6684
size:  (375, 1242, 3)
load 6005  /  6684
size:  (375, 1242, 3)
load 6006  /  6684
size:  (375, 1242, 3)
load 6007  /  6684
size:  (375, 1242, 3)
load 6008  /  6684
size:  (375, 1242, 3)
load 6009  /  6684
size:  (375, 1242, 3)
load 6010  /  6684
size:  (375, 1242, 3)
load 6011  /  6684
size:  (375, 1242, 3)
load 6012  /  6684
size:  (375, 1242, 3)
load 6013  /  6684
size:  (375, 1242, 3)
load 6014  /  6684
size:  (376, 1241, 3)
load 6015  /  6684
size:  (375, 1242, 3)
load 6016  /  6684
size:  (375, 1242, 3)
load 6017  /  6684
size:  (375, 1242, 3)
load 6018  /  6684
size:  (375, 1242, 3)
load 6019  /  6684
size:  (375, 1242, 3)
load 6020  /  6684
size:  (375, 1242, 3)
load 6021  /  6684
size:  (375, 1242, 3)
load 6022  /  6684
size:  (375, 1242, 3)
load 6023  /  6684
size:  (375, 1242, 3)
load 6024  /  6684
size:  (375, 1242, 3)
load 6025  /  6684
size:  (375, 1242, 3)
load 6026  /  6684
size:  (375, 1242, 3)
load 6027  /  6684
size:  (375, 1242, 3)
load 6028  /  6684
size:  (375, 1242, 3)
load 6029  /  6684
size:  (375, 1242, 3)
load 6030  /  6684
size:  (375, 1242, 3)
load 6031  /  6684
size:  (375, 1242, 3)
load 6032  /  6684
size:  (370, 1224, 3)
load 6033  /  6684
size:  (374, 1238, 3)
load 6034  /  6684
size:  (375, 1242, 3)
load 6035  /  6684
size:  (375, 1242, 3)
load 6036  /  6684
size:  (375, 1242, 3)
load 6037  /  6684
size:  (370, 1224, 3)
load 6038  /  6684
size:  (375, 1242, 3)
load 6039  /  6684
size:  (375, 1242, 3)
load 6040  /  6684
size:  (375, 1242, 3)
load 6041  /  6684
size:  (375, 1242, 3)
load 6042  /  6684
size:  (375, 1242, 3)
load 6043  /  6684
size:  (375, 1242, 3)
load 6044  /  6684
size:  (375, 1242, 3)
load 6045  /  6684
size:  (375, 1242, 3)
load 6046  /  6684
size:  (375, 1242, 3)
load 6047  /  6684
size:  (375, 1242, 3)
load 6048  /  6684
size:  (375, 1242, 3)
load 6049  /  6684
size:  (375, 1242, 3)
load 6050  /  6684
size:  (375, 1242, 3)
load 6051  /  6684
size:  (375, 1242, 3)
load 6052  /  6684
size:  (375, 1242, 3)
load 6053  /  6684
size:  (375, 1242, 3)
load 6054  /  6684
size:  (375, 1242, 3)
load 6055  /  6684
size:  (374, 1238, 3)
load 6056  /  6684
size:  (375, 1242, 3)
load 6057  /  6684
size:  (375, 1242, 3)
load 6058  /  6684
size:  (375, 1242, 3)
load 6059  /  6684
size:  (375, 1242, 3)
load 6060  /  6684
size:  (376, 1241, 3)
load 6061  /  6684
size:  (375, 1242, 3)
load 6062  /  6684
size:  (375, 1242, 3)
load 6063  /  6684
size:  (375, 1242, 3)
load 6064  /  6684
size:  (375, 1242, 3)
load 6065  /  6684
size:  (375, 1242, 3)
load 6066  /  6684
size:  (375, 1242, 3)
load 6067  /  6684
size:  (376, 1241, 3)
load 6068  /  6684
size:  (376, 1241, 3)
load 6069  /  6684
size:  (375, 1242, 3)
load 6070  /  6684
size:  (375, 1242, 3)
load 6071  /  6684
size:  (375, 1242, 3)
load 6072  /  6684
size:  (375, 1242, 3)
load 6073  /  6684
size:  (375, 1242, 3)
load 6074  /  6684
size:  (375, 1242, 3)
load 6075  /  6684
size:  (375, 1242, 3)
load 6076  /  6684
size:  (376, 1241, 3)
load 6077  /  6684
size:  (375, 1242, 3)
load 6078  /  6684
size:  (375, 1242, 3)
load 6079  /  6684
size:  (375, 1242, 3)
load 6080  /  6684
size:  (375, 1242, 3)
load 6081  /  6684
size:  (375, 1242, 3)
load 6082  /  6684
size:  (375, 1242, 3)
load 6083  /  6684
size:  (375, 1242, 3)
load 6084  /  6684
size:  (375, 1242, 3)
load 6085  /  6684
size:  (374, 1238, 3)
load 6086  /  6684
size:  (370, 1224, 3)
load 6087  /  6684
size:  (375, 1242, 3)
load 6088  /  6684
size:  (375, 1242, 3)
load 6089  /  6684
size:  (375, 1242, 3)
load 6090  /  6684
size:  (375, 1242, 3)
load 6091  /  6684
size:  (375, 1242, 3)
load 6092  /  6684
size:  (375, 1242, 3)
load 6093  /  6684
size:  (375, 1242, 3)
load 6094  /  6684
size:  (375, 1242, 3)
load 6095  /  6684
size:  (375, 1242, 3)
load 6096  /  6684
size:  (370, 1224, 3)
load 6097  /  6684
size:  (375, 1242, 3)
load 6098  /  6684
size:  (375, 1242, 3)
load 6099  /  6684
size:  (375, 1242, 3)
load 6100  /  6684
size:  (375, 1242, 3)
load 6101  /  6684
size:  (374, 1238, 3)
load 6102  /  6684
size:  (375, 1242, 3)
load 6103  /  6684
size:  (375, 1242, 3)
load 6104  /  6684
size:  (375, 1242, 3)
load 6105  /  6684
size:  (375, 1242, 3)
load 6106  /  6684
size:  (375, 1242, 3)
load 6107  /  6684
size:  (375, 1242, 3)
load 6108  /  6684
size:  (375, 1242, 3)
load 6109  /  6684
size:  (375, 1242, 3)
load 6110  /  6684
size:  (375, 1242, 3)
load 6111  /  6684
size:  (375, 1242, 3)
load 6112  /  6684
size:  (375, 1242, 3)
load 6113  /  6684
size:  (375, 1242, 3)
load 6114  /  6684
size:  (375, 1242, 3)
load 6115  /  6684
size:  (375, 1242, 3)
load 6116  /  6684
size:  (375, 1242, 3)
load 6117  /  6684
size:  (375, 1242, 3)
load 6118  /  6684
size:  (375, 1242, 3)
load 6119  /  6684
size:  (375, 1242, 3)
load 6120  /  6684
size:  (375, 1242, 3)
load 6121  /  6684
size:  (375, 1242, 3)
load 6122  /  6684
size:  (375, 1242, 3)
load 6123  /  6684
size:  (375, 1242, 3)
load 6124  /  6684
size:  (375, 1242, 3)
load 6125  /  6684
size:  (375, 1242, 3)
load 6126  /  6684
size:  (375, 1242, 3)
load 6127  /  6684
size:  (375, 1242, 3)
load 6128  /  6684
size:  (375, 1242, 3)
load 6129  /  6684
size:  (375, 1242, 3)
load 6130  /  6684
size:  (376, 1241, 3)
load 6131  /  6684
size:  (376, 1241, 3)
load 6132  /  6684
size:  (375, 1242, 3)
load 6133  /  6684
size:  (375, 1242, 3)
load 6134  /  6684
size:  (376, 1241, 3)
load 6135  /  6684
size:  (375, 1242, 3)
load 6136  /  6684
size:  (375, 1242, 3)
load 6137  /  6684
size:  (375, 1242, 3)
load 6138  /  6684
size:  (375, 1242, 3)
load 6139  /  6684
size:  (376, 1241, 3)
load 6140  /  6684
size:  (375, 1242, 3)
load 6141  /  6684
size:  (375, 1242, 3)
load 6142  /  6684
size:  (375, 1242, 3)
load 6143  /  6684
size:  (375, 1242, 3)
load 6144  /  6684
size:  (375, 1242, 3)
load 6145  /  6684
size:  (375, 1242, 3)
load 6146  /  6684
size:  (375, 1242, 3)
load 6147  /  6684
size:  (375, 1242, 3)
load 6148  /  6684
size:  (375, 1242, 3)
load 6149  /  6684
size:  (375, 1242, 3)
load 6150  /  6684
size:  (375, 1242, 3)
load 6151  /  6684
size:  (375, 1242, 3)
load 6152  /  6684
size:  (375, 1242, 3)
load 6153  /  6684
size:  (375, 1242, 3)
load 6154  /  6684
size:  (375, 1242, 3)
load 6155  /  6684
size:  (375, 1242, 3)
load 6156  /  6684
size:  (375, 1242, 3)
load 6157  /  6684
size:  (375, 1242, 3)
load 6158  /  6684
size:  (375, 1242, 3)
load 6159  /  6684
size:  (375, 1242, 3)
load 6160  /  6684
size:  (375, 1242, 3)
load 6161  /  6684
size:  (375, 1242, 3)
load 6162  /  6684
size:  (375, 1242, 3)
load 6163  /  6684
size:  (376, 1241, 3)
load 6164  /  6684
size:  (375, 1242, 3)
load 6165  /  6684
size:  (375, 1242, 3)
load 6166  /  6684
size:  (375, 1242, 3)
load 6167  /  6684
size:  (375, 1242, 3)
load 6168  /  6684
size:  (375, 1242, 3)
load 6169  /  6684
size:  (375, 1242, 3)
load 6170  /  6684
size:  (375, 1242, 3)
load 6171  /  6684
size:  (375, 1242, 3)
load 6172  /  6684
size:  (375, 1242, 3)
load 6173  /  6684
size:  (375, 1242, 3)
load 6174  /  6684
size:  (375, 1242, 3)
load 6175  /  6684
size:  (375, 1242, 3)
load 6176  /  6684
size:  (375, 1242, 3)
load 6177  /  6684
size:  (375, 1242, 3)
load 6178  /  6684
size:  (376, 1241, 3)
load 6179  /  6684
size:  (374, 1238, 3)
load 6180  /  6684
size:  (375, 1242, 3)
load 6181  /  6684
size:  (375, 1242, 3)
load 6182  /  6684
size:  (375, 1242, 3)
load 6183  /  6684
size:  (375, 1242, 3)
load 6184  /  6684
size:  (375, 1242, 3)
load 6185  /  6684
size:  (375, 1242, 3)
load 6186  /  6684
size:  (375, 1242, 3)
load 6187  /  6684
size:  (375, 1242, 3)
load 6188  /  6684
size:  (375, 1242, 3)
load 6189  /  6684
size:  (375, 1242, 3)
load 6190  /  6684
size:  (375, 1242, 3)
load 6191  /  6684
size:  (375, 1242, 3)
load 6192  /  6684
size:  (374, 1238, 3)
load 6193  /  6684
size:  (375, 1242, 3)
load 6194  /  6684
size:  (375, 1242, 3)
load 6195  /  6684
size:  (375, 1242, 3)
load 6196  /  6684
size:  (375, 1242, 3)
load 6197  /  6684
size:  (375, 1242, 3)
load 6198  /  6684
size:  (376, 1241, 3)
load 6199  /  6684
size:  (375, 1242, 3)
load 6200  /  6684
size:  (375, 1242, 3)
load 6201  /  6684
size:  (375, 1242, 3)
load 6202  /  6684
size:  (375, 1242, 3)
load 6203  /  6684
size:  (375, 1242, 3)
load 6204  /  6684
size:  (375, 1242, 3)
load 6205  /  6684
size:  (375, 1242, 3)
load 6206  /  6684
size:  (374, 1238, 3)
load 6207  /  6684
size:  (375, 1242, 3)
load 6208  /  6684
size:  (375, 1242, 3)
load 6209  /  6684
size:  (375, 1242, 3)
load 6210  /  6684
size:  (375, 1242, 3)
load 6211  /  6684
size:  (376, 1241, 3)
load 6212  /  6684
size:  (375, 1242, 3)
load 6213  /  6684
size:  (375, 1242, 3)
load 6214  /  6684
size:  (375, 1242, 3)
load 6215  /  6684
size:  (375, 1242, 3)
load 6216  /  6684
size:  (375, 1242, 3)
load 6217  /  6684
size:  (375, 1242, 3)
load 6218  /  6684
size:  (375, 1242, 3)
load 6219  /  6684
size:  (375, 1242, 3)
load 6220  /  6684
size:  (376, 1241, 3)
load 6221  /  6684
size:  (375, 1242, 3)
load 6222  /  6684
size:  (375, 1242, 3)
load 6223  /  6684
size:  (375, 1242, 3)
load 6224  /  6684
size:  (375, 1242, 3)
load 6225  /  6684
size:  (375, 1242, 3)
load 6226  /  6684
size:  (375, 1242, 3)
load 6227  /  6684
size:  (375, 1242, 3)
load 6228  /  6684
size:  (375, 1242, 3)
load 6229  /  6684
size:  (375, 1242, 3)
load 6230  /  6684
size:  (375, 1242, 3)
load 6231  /  6684
size:  (375, 1242, 3)
load 6232  /  6684
size:  (374, 1238, 3)
load 6233  /  6684
size:  (375, 1242, 3)
load 6234  /  6684
size:  (375, 1242, 3)
load 6235  /  6684
size:  (375, 1242, 3)
load 6236  /  6684
size:  (375, 1242, 3)
load 6237  /  6684
size:  (375, 1242, 3)
load 6238  /  6684
size:  (375, 1242, 3)
load 6239  /  6684
size:  (375, 1242, 3)
load 6240  /  6684
size:  (375, 1242, 3)
load 6241  /  6684
size:  (375, 1242, 3)
load 6242  /  6684
size:  (376, 1241, 3)
load 6243  /  6684
size:  (370, 1224, 3)
load 6244  /  6684
size:  (375, 1242, 3)
load 6245  /  6684
size:  (375, 1242, 3)
load 6246  /  6684
size:  (375, 1242, 3)
load 6247  /  6684
size:  (375, 1242, 3)
load 6248  /  6684
size:  (375, 1242, 3)
load 6249  /  6684
size:  (375, 1242, 3)
load 6250  /  6684
size:  (375, 1242, 3)
load 6251  /  6684
size:  (375, 1242, 3)
load 6252  /  6684
size:  (375, 1242, 3)
load 6253  /  6684
size:  (375, 1242, 3)
load 6254  /  6684
size:  (375, 1242, 3)
load 6255  /  6684
size:  (375, 1242, 3)
load 6256  /  6684
size:  (375, 1242, 3)
load 6257  /  6684
size:  (370, 1224, 3)
load 6258  /  6684
size:  (375, 1242, 3)
load 6259  /  6684
size:  (375, 1242, 3)
load 6260  /  6684
size:  (375, 1242, 3)
load 6261  /  6684
size:  (375, 1242, 3)
load 6262  /  6684
size:  (375, 1242, 3)
load 6263  /  6684
size:  (375, 1242, 3)
load 6264  /  6684
size:  (375, 1242, 3)
load 6265  /  6684
size:  (375, 1242, 3)
load 6266  /  6684
size:  (375, 1242, 3)
load 6267  /  6684
size:  (370, 1224, 3)
load 6268  /  6684
size:  (375, 1242, 3)
load 6269  /  6684
size:  (375, 1242, 3)
load 6270  /  6684
size:  (375, 1242, 3)
load 6271  /  6684
size:  (376, 1241, 3)
load 6272  /  6684
size:  (375, 1242, 3)
load 6273  /  6684
size:  (375, 1242, 3)
load 6274  /  6684
size:  (375, 1242, 3)
load 6275  /  6684
size:  (375, 1242, 3)
load 6276  /  6684
size:  (375, 1242, 3)
load 6277  /  6684
size:  (375, 1242, 3)
load 6278  /  6684
size:  (376, 1241, 3)
load 6279  /  6684
size:  (375, 1242, 3)
load 6280  /  6684
size:  (375, 1242, 3)
load 6281  /  6684
size:  (375, 1242, 3)
load 6282  /  6684
size:  (375, 1242, 3)
load 6283  /  6684
size:  (375, 1242, 3)
load 6284  /  6684
size:  (375, 1242, 3)
load 6285  /  6684
size:  (375, 1242, 3)
load 6286  /  6684
size:  (375, 1242, 3)
load 6287  /  6684
size:  (375, 1242, 3)
load 6288  /  6684
size:  (375, 1242, 3)
load 6289  /  6684
size:  (375, 1242, 3)
load 6290  /  6684
size:  (375, 1242, 3)
load 6291  /  6684
size:  (375, 1242, 3)
load 6292  /  6684
size:  (375, 1242, 3)
load 6293  /  6684
size:  (375, 1242, 3)
load 6294  /  6684
size:  (375, 1242, 3)
load 6295  /  6684
size:  (375, 1242, 3)
load 6296  /  6684
size:  (375, 1242, 3)
load 6297  /  6684
size:  (375, 1242, 3)
load 6298  /  6684
size:  (375, 1242, 3)
load 6299  /  6684
size:  (375, 1242, 3)
load 6300  /  6684
size:  (375, 1242, 3)
load 6301  /  6684
size:  (375, 1242, 3)
load 6302  /  6684
size:  (375, 1242, 3)
load 6303  /  6684
size:  (375, 1242, 3)
load 6304  /  6684
size:  (375, 1242, 3)
load 6305  /  6684
size:  (375, 1242, 3)
load 6306  /  6684
size:  (375, 1242, 3)
load 6307  /  6684
size:  (375, 1242, 3)
load 6308  /  6684
size:  (375, 1242, 3)
load 6309  /  6684
size:  (375, 1242, 3)
load 6310  /  6684
size:  (375, 1242, 3)
load 6311  /  6684
size:  (375, 1242, 3)
load 6312  /  6684
size:  (375, 1242, 3)
load 6313  /  6684
size:  (375, 1242, 3)
load 6314  /  6684
size:  (375, 1242, 3)
load 6315  /  6684
size:  (375, 1242, 3)
load 6316  /  6684
size:  (375, 1242, 3)
load 6317  /  6684
size:  (375, 1242, 3)
load 6318  /  6684
size:  (375, 1242, 3)
load 6319  /  6684
size:  (375, 1242, 3)
load 6320  /  6684
size:  (375, 1242, 3)
load 6321  /  6684
size:  (375, 1242, 3)
load 6322  /  6684
size:  (375, 1242, 3)
load 6323  /  6684
size:  (375, 1242, 3)
load 6324  /  6684
size:  (375, 1242, 3)
load 6325  /  6684
size:  (375, 1242, 3)
load 6326  /  6684
size:  (375, 1242, 3)
load 6327  /  6684
size:  (375, 1242, 3)
load 6328  /  6684
size:  (375, 1242, 3)
load 6329  /  6684
size:  (375, 1242, 3)
load 6330  /  6684
size:  (375, 1242, 3)
load 6331  /  6684
size:  (375, 1242, 3)
load 6332  /  6684
size:  (375, 1242, 3)
load 6333  /  6684
size:  (370, 1224, 3)
load 6334  /  6684
size:  (375, 1242, 3)
load 6335  /  6684
size:  (375, 1242, 3)
load 6336  /  6684
size:  (375, 1242, 3)
load 6337  /  6684
size:  (375, 1242, 3)
load 6338  /  6684
size:  (375, 1242, 3)
load 6339  /  6684
size:  (375, 1242, 3)
load 6340  /  6684
size:  (375, 1242, 3)
load 6341  /  6684
size:  (375, 1242, 3)
load 6342  /  6684
size:  (375, 1242, 3)
load 6343  /  6684
size:  (375, 1242, 3)
load 6344  /  6684
size:  (375, 1242, 3)
load 6345  /  6684
size:  (375, 1242, 3)
load 6346  /  6684
size:  (375, 1242, 3)
load 6347  /  6684
size:  (375, 1242, 3)
load 6348  /  6684
size:  (375, 1242, 3)
load 6349  /  6684
size:  (374, 1238, 3)
load 6350  /  6684
size:  (375, 1242, 3)
load 6351  /  6684
size:  (375, 1242, 3)
load 6352  /  6684
size:  (375, 1242, 3)
load 6353  /  6684
size:  (375, 1242, 3)
load 6354  /  6684
size:  (375, 1242, 3)
load 6355  /  6684
size:  (375, 1242, 3)
load 6356  /  6684
size:  (375, 1242, 3)
load 6357  /  6684
size:  (375, 1242, 3)
load 6358  /  6684
size:  (375, 1242, 3)
load 6359  /  6684
size:  (375, 1242, 3)
load 6360  /  6684
size:  (375, 1242, 3)
load 6361  /  6684
size:  (374, 1238, 3)
load 6362  /  6684
size:  (375, 1242, 3)
load 6363  /  6684
size:  (375, 1242, 3)
load 6364  /  6684
size:  (375, 1242, 3)
load 6365  /  6684
size:  (375, 1242, 3)
load 6366  /  6684
size:  (375, 1242, 3)
load 6367  /  6684
size:  (375, 1242, 3)
load 6368  /  6684
size:  (375, 1242, 3)
load 6369  /  6684
size:  (375, 1242, 3)
load 6370  /  6684
size:  (375, 1242, 3)
load 6371  /  6684
size:  (375, 1242, 3)
load 6372  /  6684
size:  (375, 1242, 3)
load 6373  /  6684
size:  (375, 1242, 3)
load 6374  /  6684
size:  (375, 1242, 3)
load 6375  /  6684
size:  (375, 1242, 3)
load 6376  /  6684
size:  (375, 1242, 3)
load 6377  /  6684
size:  (375, 1242, 3)
load 6378  /  6684
size:  (375, 1242, 3)
load 6379  /  6684
size:  (375, 1242, 3)
load 6380  /  6684
size:  (375, 1242, 3)
load 6381  /  6684
size:  (375, 1242, 3)
load 6382  /  6684
size:  (375, 1242, 3)
load 6383  /  6684
size:  (375, 1242, 3)
load 6384  /  6684
size:  (375, 1242, 3)
load 6385  /  6684
size:  (375, 1242, 3)
load 6386  /  6684
size:  (375, 1242, 3)
load 6387  /  6684
size:  (375, 1242, 3)
load 6388  /  6684
size:  (375, 1242, 3)
load 6389  /  6684
size:  (375, 1242, 3)
load 6390  /  6684
size:  (375, 1242, 3)
load 6391  /  6684
size:  (375, 1242, 3)
load 6392  /  6684
size:  (375, 1242, 3)
load 6393  /  6684
size:  (370, 1224, 3)
load 6394  /  6684
size:  (374, 1238, 3)
load 6395  /  6684
size:  (375, 1242, 3)
load 6396  /  6684
size:  (375, 1242, 3)
load 6397  /  6684
size:  (375, 1242, 3)
load 6398  /  6684
size:  (375, 1242, 3)
load 6399  /  6684
size:  (375, 1242, 3)
load 6400  /  6684
size:  (375, 1242, 3)
load 6401  /  6684
size:  (375, 1242, 3)
load 6402  /  6684
size:  (375, 1242, 3)
load 6403  /  6684
size:  (375, 1242, 3)
load 6404  /  6684
size:  (374, 1238, 3)
load 6405  /  6684
size:  (376, 1241, 3)
load 6406  /  6684
size:  (375, 1242, 3)
load 6407  /  6684
size:  (375, 1242, 3)
load 6408  /  6684
size:  (375, 1242, 3)
load 6409  /  6684
size:  (375, 1242, 3)
load 6410  /  6684
size:  (375, 1242, 3)
load 6411  /  6684
size:  (375, 1242, 3)
load 6412  /  6684
size:  (375, 1242, 3)
load 6413  /  6684
size:  (374, 1238, 3)
load 6414  /  6684
size:  (375, 1242, 3)
load 6415  /  6684
size:  (374, 1238, 3)
load 6416  /  6684
size:  (375, 1242, 3)
load 6417  /  6684
size:  (375, 1242, 3)
load 6418  /  6684
size:  (375, 1242, 3)
load 6419  /  6684
size:  (375, 1242, 3)
load 6420  /  6684
size:  (375, 1242, 3)
load 6421  /  6684
size:  (375, 1242, 3)
load 6422  /  6684
size:  (375, 1242, 3)
load 6423  /  6684
size:  (375, 1242, 3)
load 6424  /  6684
size:  (375, 1242, 3)
load 6425  /  6684
size:  (375, 1242, 3)
load 6426  /  6684
size:  (375, 1242, 3)
load 6427  /  6684
size:  (375, 1242, 3)
load 6428  /  6684
size:  (375, 1242, 3)
load 6429  /  6684
size:  (375, 1242, 3)
load 6430  /  6684
size:  (375, 1242, 3)
load 6431  /  6684
size:  (375, 1242, 3)
load 6432  /  6684
size:  (375, 1242, 3)
load 6433  /  6684
size:  (375, 1242, 3)
load 6434  /  6684
size:  (375, 1242, 3)
load 6435  /  6684
size:  (375, 1242, 3)
load 6436  /  6684
size:  (375, 1242, 3)
load 6437  /  6684
size:  (375, 1242, 3)
load 6438  /  6684
size:  (375, 1242, 3)
load 6439  /  6684
size:  (375, 1242, 3)
load 6440  /  6684
size:  (375, 1242, 3)
load 6441  /  6684
size:  (375, 1242, 3)
load 6442  /  6684
size:  (375, 1242, 3)
load 6443  /  6684
size:  (375, 1242, 3)
load 6444  /  6684
size:  (375, 1242, 3)
load 6445  /  6684
size:  (375, 1242, 3)
load 6446  /  6684
size:  (375, 1242, 3)
load 6447  /  6684
size:  (375, 1242, 3)
load 6448  /  6684
size:  (375, 1242, 3)
load 6449  /  6684
size:  (375, 1242, 3)
load 6450  /  6684
size:  (375, 1242, 3)
load 6451  /  6684
size:  (375, 1242, 3)
load 6452  /  6684
size:  (375, 1242, 3)
load 6453  /  6684
size:  (370, 1224, 3)
load 6454  /  6684
size:  (375, 1242, 3)
load 6455  /  6684
size:  (375, 1242, 3)
load 6456  /  6684
size:  (374, 1238, 3)
load 6457  /  6684
size:  (375, 1242, 3)
load 6458  /  6684
size:  (375, 1242, 3)
load 6459  /  6684
size:  (375, 1242, 3)
load 6460  /  6684
size:  (375, 1242, 3)
load 6461  /  6684
size:  (375, 1242, 3)
load 6462  /  6684
size:  (375, 1242, 3)
load 6463  /  6684
size:  (375, 1242, 3)
load 6464  /  6684
size:  (375, 1242, 3)
load 6465  /  6684
size:  (375, 1242, 3)
load 6466  /  6684
size:  (375, 1242, 3)
load 6467  /  6684
size:  (375, 1242, 3)
load 6468  /  6684
size:  (375, 1242, 3)
load 6469  /  6684
size:  (375, 1242, 3)
load 6470  /  6684
size:  (375, 1242, 3)
load 6471  /  6684
size:  (375, 1242, 3)
load 6472  /  6684
size:  (375, 1242, 3)
load 6473  /  6684
size:  (375, 1242, 3)
load 6474  /  6684
size:  (375, 1242, 3)
load 6475  /  6684
size:  (374, 1238, 3)
load 6476  /  6684
size:  (375, 1242, 3)
load 6477  /  6684
size:  (375, 1242, 3)
load 6478  /  6684
size:  (374, 1238, 3)
load 6479  /  6684
size:  (375, 1242, 3)
load 6480  /  6684
size:  (375, 1242, 3)
load 6481  /  6684
size:  (375, 1242, 3)
load 6482  /  6684
size:  (375, 1242, 3)
load 6483  /  6684
size:  (375, 1242, 3)
load 6484  /  6684
size:  (375, 1242, 3)
load 6485  /  6684
size:  (375, 1242, 3)
load 6486  /  6684
size:  (375, 1242, 3)
load 6487  /  6684
size:  (370, 1224, 3)
load 6488  /  6684
size:  (375, 1242, 3)
load 6489  /  6684
size:  (375, 1242, 3)
load 6490  /  6684
size:  (375, 1242, 3)
load 6491  /  6684
size:  (375, 1242, 3)
load 6492  /  6684
size:  (375, 1242, 3)
load 6493  /  6684
size:  (375, 1242, 3)
load 6494  /  6684
size:  (375, 1242, 3)
load 6495  /  6684
size:  (375, 1242, 3)
load 6496  /  6684
size:  (375, 1242, 3)
load 6497  /  6684
size:  (375, 1242, 3)
load 6498  /  6684
size:  (375, 1242, 3)
load 6499  /  6684
size:  (375, 1242, 3)
load 6500  /  6684
size:  (375, 1242, 3)
load 6501  /  6684
size:  (375, 1242, 3)
load 6502  /  6684
size:  (376, 1241, 3)
load 6503  /  6684
size:  (376, 1241, 3)
load 6504  /  6684
size:  (375, 1242, 3)
load 6505  /  6684
size:  (375, 1242, 3)
load 6506  /  6684
size:  (375, 1242, 3)
load 6507  /  6684
size:  (375, 1242, 3)
load 6508  /  6684
size:  (375, 1242, 3)
load 6509  /  6684
size:  (375, 1242, 3)
load 6510  /  6684
size:  (375, 1242, 3)
load 6511  /  6684
size:  (375, 1242, 3)
load 6512  /  6684
size:  (375, 1242, 3)
load 6513  /  6684
size:  (375, 1242, 3)
load 6514  /  6684
size:  (375, 1242, 3)
load 6515  /  6684
size:  (375, 1242, 3)
load 6516  /  6684
size:  (375, 1242, 3)
load 6517  /  6684
size:  (370, 1224, 3)
load 6518  /  6684
size:  (375, 1242, 3)
load 6519  /  6684
size:  (375, 1242, 3)
load 6520  /  6684
size:  (375, 1242, 3)
load 6521  /  6684
size:  (375, 1242, 3)
load 6522  /  6684
size:  (375, 1242, 3)
load 6523  /  6684
size:  (375, 1242, 3)
load 6524  /  6684
size:  (375, 1242, 3)
load 6525  /  6684
size:  (375, 1242, 3)
load 6526  /  6684
size:  (375, 1242, 3)
load 6527  /  6684
size:  (375, 1242, 3)
load 6528  /  6684
size:  (375, 1242, 3)
load 6529  /  6684
size:  (375, 1242, 3)
load 6530  /  6684
size:  (375, 1242, 3)
load 6531  /  6684
size:  (375, 1242, 3)
load 6532  /  6684
size:  (375, 1242, 3)
load 6533  /  6684
size:  (375, 1242, 3)
load 6534  /  6684
size:  (375, 1242, 3)
load 6535  /  6684
size:  (375, 1242, 3)
load 6536  /  6684
size:  (375, 1242, 3)
load 6537  /  6684
size:  (375, 1242, 3)
load 6538  /  6684
size:  (375, 1242, 3)
load 6539  /  6684
size:  (375, 1242, 3)
load 6540  /  6684
size:  (375, 1242, 3)
load 6541  /  6684
size:  (375, 1242, 3)
load 6542  /  6684
size:  (374, 1238, 3)
load 6543  /  6684
size:  (375, 1242, 3)
load 6544  /  6684
size:  (375, 1242, 3)
load 6545  /  6684
size:  (375, 1242, 3)
load 6546  /  6684
size:  (375, 1242, 3)
load 6547  /  6684
size:  (370, 1224, 3)
load 6548  /  6684
size:  (375, 1242, 3)
load 6549  /  6684
size:  (376, 1241, 3)
load 6550  /  6684
size:  (375, 1242, 3)
load 6551  /  6684
size:  (375, 1242, 3)
load 6552  /  6684
size:  (375, 1242, 3)
load 6553  /  6684
size:  (375, 1242, 3)
load 6554  /  6684
size:  (375, 1242, 3)
load 6555  /  6684
size:  (375, 1242, 3)
load 6556  /  6684
size:  (375, 1242, 3)
load 6557  /  6684
size:  (376, 1241, 3)
load 6558  /  6684
size:  (375, 1242, 3)
load 6559  /  6684
size:  (375, 1242, 3)
load 6560  /  6684
size:  (375, 1242, 3)
load 6561  /  6684
size:  (375, 1242, 3)
load 6562  /  6684
size:  (375, 1242, 3)
load 6563  /  6684
size:  (374, 1238, 3)
load 6564  /  6684
size:  (370, 1224, 3)
load 6565  /  6684
size:  (375, 1242, 3)
load 6566  /  6684
size:  (375, 1242, 3)
load 6567  /  6684
size:  (375, 1242, 3)
load 6568  /  6684
size:  (376, 1241, 3)
load 6569  /  6684
size:  (375, 1242, 3)
load 6570  /  6684
size:  (375, 1242, 3)
load 6571  /  6684
size:  (375, 1242, 3)
load 6572  /  6684
size:  (375, 1242, 3)
load 6573  /  6684
size:  (375, 1242, 3)
load 6574  /  6684
size:  (375, 1242, 3)
load 6575  /  6684
size:  (370, 1224, 3)
load 6576  /  6684
size:  (376, 1241, 3)
load 6577  /  6684
size:  (375, 1242, 3)
load 6578  /  6684
size:  (375, 1242, 3)
load 6579  /  6684
size:  (376, 1241, 3)
load 6580  /  6684
size:  (375, 1242, 3)
load 6581  /  6684
size:  (375, 1242, 3)
load 6582  /  6684
size:  (375, 1242, 3)
load 6583  /  6684
size:  (375, 1242, 3)
load 6584  /  6684
size:  (375, 1242, 3)
load 6585  /  6684
size:  (375, 1242, 3)
load 6586  /  6684
size:  (375, 1242, 3)
load 6587  /  6684
size:  (375, 1242, 3)
load 6588  /  6684
size:  (375, 1242, 3)
load 6589  /  6684
size:  (375, 1242, 3)
load 6590  /  6684
size:  (375, 1242, 3)
load 6591  /  6684
size:  (375, 1242, 3)
load 6592  /  6684
size:  (375, 1242, 3)
load 6593  /  6684
size:  (374, 1238, 3)
load 6594  /  6684
size:  (375, 1242, 3)
load 6595  /  6684
size:  (375, 1242, 3)
load 6596  /  6684
size:  (375, 1242, 3)
load 6597  /  6684
size:  (375, 1242, 3)
load 6598  /  6684
size:  (375, 1242, 3)
load 6599  /  6684
size:  (376, 1241, 3)
load 6600  /  6684
size:  (375, 1242, 3)
load 6601  /  6684
size:  (375, 1242, 3)
load 6602  /  6684
size:  (375, 1242, 3)
load 6603  /  6684
size:  (375, 1242, 3)
load 6604  /  6684
size:  (375, 1242, 3)
load 6605  /  6684
size:  (375, 1242, 3)
load 6606  /  6684
size:  (376, 1241, 3)
load 6607  /  6684
size:  (375, 1242, 3)
load 6608  /  6684
size:  (375, 1242, 3)
load 6609  /  6684
size:  (374, 1238, 3)
load 6610  /  6684
size:  (375, 1242, 3)
load 6611  /  6684
size:  (375, 1242, 3)
load 6612  /  6684
size:  (375, 1242, 3)
load 6613  /  6684
size:  (375, 1242, 3)
load 6614  /  6684
size:  (375, 1242, 3)
load 6615  /  6684
size:  (374, 1238, 3)
load 6616  /  6684
size:  (375, 1242, 3)
load 6617  /  6684
size:  (375, 1242, 3)
load 6618  /  6684
size:  (375, 1242, 3)
load 6619  /  6684
size:  (374, 1238, 3)
load 6620  /  6684
size:  (375, 1242, 3)
load 6621  /  6684
size:  (375, 1242, 3)
load 6622  /  6684
size:  (375, 1242, 3)
load 6623  /  6684
size:  (375, 1242, 3)
load 6624  /  6684
size:  (375, 1242, 3)
load 6625  /  6684
size:  (375, 1242, 3)
load 6626  /  6684
size:  (375, 1242, 3)
load 6627  /  6684
size:  (375, 1242, 3)
load 6628  /  6684
size:  (374, 1238, 3)
load 6629  /  6684
size:  (375, 1242, 3)
load 6630  /  6684
size:  (375, 1242, 3)
load 6631  /  6684
size:  (375, 1242, 3)
load 6632  /  6684
size:  (375, 1242, 3)
load 6633  /  6684
size:  (375, 1242, 3)
load 6634  /  6684
size:  (374, 1238, 3)
load 6635  /  6684
size:  (375, 1242, 3)
load 6636  /  6684
size:  (375, 1242, 3)
load 6637  /  6684
size:  (375, 1242, 3)
load 6638  /  6684
size:  (375, 1242, 3)
load 6639  /  6684
size:  (374, 1238, 3)
load 6640  /  6684
size:  (375, 1242, 3)
load 6641  /  6684
size:  (375, 1242, 3)
load 6642  /  6684
size:  (375, 1242, 3)
load 6643  /  6684
size:  (375, 1242, 3)
load 6644  /  6684
size:  (375, 1242, 3)
load 6645  /  6684
size:  (375, 1242, 3)
load 6646  /  6684
size:  (375, 1242, 3)
load 6647  /  6684
size:  (375, 1242, 3)
load 6648  /  6684
size:  (375, 1242, 3)
load 6649  /  6684
size:  (374, 1238, 3)
load 6650  /  6684
size:  (375, 1242, 3)
load 6651  /  6684
size:  (375, 1242, 3)
load 6652  /  6684
size:  (375, 1242, 3)
load 6653  /  6684
size:  (376, 1241, 3)
load 6654  /  6684
size:  (375, 1242, 3)
load 6655  /  6684
size:  (375, 1242, 3)
load 6656  /  6684
size:  (370, 1224, 3)
load 6657  /  6684
size:  (375, 1242, 3)
load 6658  /  6684
size:  (374, 1238, 3)
load 6659  /  6684
size:  (375, 1242, 3)
load 6660  /  6684
size:  (375, 1242, 3)
load 6661  /  6684
size:  (375, 1242, 3)
load 6662  /  6684
size:  (375, 1242, 3)
load 6663  /  6684
size:  (375, 1242, 3)
load 6664  /  6684
size:  (375, 1242, 3)
load 6665  /  6684
size:  (375, 1242, 3)
load 6666  /  6684
size:  (375, 1242, 3)
load 6667  /  6684
size:  (375, 1242, 3)
load 6668  /  6684
size:  (374, 1238, 3)
load 6669  /  6684
size:  (375, 1242, 3)
load 6670  /  6684
size:  (374, 1238, 3)
load 6671  /  6684
size:  (375, 1242, 3)
load 6672  /  6684
size:  (376, 1241, 3)
load 6673  /  6684
size:  (374, 1238, 3)
load 6674  /  6684
size:  (375, 1242, 3)
load 6675  /  6684
size:  (375, 1242, 3)
load 6676  /  6684
size:  (375, 1242, 3)
load 6677  /  6684
size:  (370, 1224, 3)
load 6678  /  6684
size:  (375, 1242, 3)
load 6679  /  6684
size:  (376, 1241, 3)
load 6680  /  6684
size:  (375, 1242, 3)
load 6681  /  6684
size:  (375, 1242, 3)
load 6682  /  6684
size:  (375, 1242, 3)
load 6683  /  6684
size:  (375, 1242, 3)
append flipped images to roidb
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 6684
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
[18:18:14] include/dmlc/logging.h:300: [18:18:14] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0020.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7fe1b22a6969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7fe1b229ed6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7fe1b1f31213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe25ac7fadc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe25ac7f40c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe25ae965fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe25ae97f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe25c20df45]
[bt] (20) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 63, in train_net
    arg_params, aux_params = load_param(pretrained, epoch, convert=True)
  File "/home/hustxly/pre3D/rcnn/utils/load_model.py", line 49, in load_param
    arg_params, aux_params = load_checkpoint(prefix, epoch)
  File "/home/hustxly/pre3D/rcnn/utils/load_model.py", line 15, in load_checkpoint
    save_dict = mx.nd.load('%s-%04d.params' % (prefix, epoch))
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 1247, in load
    ctypes.byref(names)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [18:18:14] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0020.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7fe1b22a6969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7fe1b229ed6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7fe1b1f31213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe25ac7fadc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe25ac7f40c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe25ae965fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe25ae97f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe25c20df45]
[bt] (20) python() [0x578c4e]

enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 6684
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
[18:18:21] include/dmlc/logging.h:300: [18:18:21] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0020.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7f99aa8c8969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7f99aa8c0d6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7f99aa553213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f9a532a1adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f9a532a140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f9a534b85fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f9a534b9f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f9a5482ff45]
[bt] (20) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 63, in train_net
    arg_params, aux_params = load_param(pretrained, epoch, convert=True)
  File "/home/hustxly/pre3D/rcnn/utils/load_model.py", line 49, in load_param
    arg_params, aux_params = load_checkpoint(prefix, epoch)
  File "/home/hustxly/pre3D/rcnn/utils/load_model.py", line 15, in load_checkpoint
    save_dict = mx.nd.load('%s-%04d.params' % (prefix, epoch))
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 1247, in load
    ctypes.byref(names)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [18:18:21] src/io/local_filesys.cc:154: Check failed: allow_null  LocalFileSystem: fail to open "/data01/hustxly/model/faster_rcnn/kitti_ry_cls_input_up_2/ry_alpha_car_only_reg-0020.params"

Stack trace returned 21 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc2io15LocalFileSystem4OpenERKNS0_3URIEPKcb+0x459) [0x7f99aa8c8969]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc6Stream6CreateEPKcS2_b+0x3a) [0x7f99aa8c0d6a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXNDArrayLoad+0x203) [0x7f99aa553213]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f9a532a1adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f9a532a140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f9a534b85fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f9a534b9f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (11) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (12) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python() [0x4a1634]
[bt] (16) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (17) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (18) python(Py_Main+0xb5e) [0x44f904]
[bt] (19) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f9a5482ff45]
[bt] (20) python() [0x578c4e]

