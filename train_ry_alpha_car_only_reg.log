{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:44:00] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
python: can't open file 'example/env/train_3dbox.py': [Errno 2] No such file or directory
  File "example/env/train_3dbox.py", line 91
    '''
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 187, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 32, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 142
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss])
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 144
    return rcnn
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                           ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    im_info = mx.symbol.Variable(name="im_info")
                                               ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 246
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 245
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 10, in <module>
    from rcnn.processing.generate_anchor import generator_anchors
ImportError: cannot import name generator_anchors
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189, in <module>
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS):
AttributeError: 'EasyDict' object has no attribute 'NUM_CLASSES'
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 83, in get_vgg_rpn_roi
    rpn_cls_prob = mx.symbol.SoftmaxOutput(data=rpn_cls_score_reshape, label=rpn_label, multi_output=True,
NameError: global name 'rpn_label' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 95, in get_vgg_rpn_roi
    cls_prob=rpn_cls_act_reshape, bbox_pred=rpn_bbox_pred, im_info=im_info, name='rois',
NameError: global name 'im_info' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 141, in get_3dbox_loss
    loss_dim = mx.symbol.square(data=(target_dim-dim_pred), name="loss_dim")
NameError: global name 'target_dim' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 199, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 153, in get_3dbox_loss
    rot_loss = RotLoss()
NameError: global name 'RotLoss' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 166
    loss_total = loss_dim * alpha / 64 + loss_conf
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 207, in get_vgg_3dbox_train
    cls_prob = mx.symbol.SoftmaxOutput(name='cls_prob', data=cls_score, label=label, normalization='batch')
UnboundLocalError: local variable 'label' referenced before assignment
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 212, in get_vgg_3dbox_train
    bbox_loss_ = bbox_outside_weight * \
NameError: global name 'bbox_outside_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 214, in get_vgg_3dbox_train
    data=rpn_bbox_inside_weight * (bbox_pred - bbox_target))
NameError: global name 'bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 194, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(im_info, relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 124, in get_vgg_rpn_roi
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss, label, bbox_targt, bbox_weight])
NameError: global name 'bbox_targt' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 51, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 346, in get_batch
    self.anchor_ratios, self.allowed_border)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 417, in assign_anchor
    bbox_weights[labels == 1, :] = np.array(config.TRAIN.RPN_BBOX_WEIGHTS)
AttributeError: 'EasyDict' object has no attribute 'RPN_BBOX_WEIGHTS'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 2L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 8L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 200, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 49, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
NameError: global name 'data_shape_dict' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2488L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 191, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 61, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2488L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
  File "example/env/train_3dbox.py", line 114
    print 'ok'
    ^
IndentationError: unexpected indent
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2489L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
ok
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:13:52] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Error in CustomOp.forward: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 724, in forward_entry
    aux=tensors[4])
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 42, in forward
    sample_rois(all_rois, fg_rois_per_image, rois_per_image, self._num_classes, gt_boxes=gt_boxes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 283, in sample_rois
    expand_bbox_regression_targets(bbox_target_data, num_classes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/processing/bbox_regression.py", line 139, in expand_bbox_regression_targets
    bbox_weights[index, start:end] = config.TRAIN.BBOX_WEIGHTS
AttributeError: 'EasyDict' object has no attribute 'BBOX_WEIGHTS'

[11:14:08] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:16:51] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.49 samples/sec	Train-RPNAcc=0.580171,	RPNLogLoss=0.689842,	RPNL1Loss=0.111169,	RCNNAcc=0.207961,	RCNNLogLoss=2.817367,	RCNNL1Loss=0.212329,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.55 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.689458,	RPNL1Loss=0.126438,	RCNNAcc=0.487614,	RCNNLogLoss=2.268237,	RCNNL1Loss=0.265416,	
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 8, in <module>
    from rcnn.config import config
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/config.py", line 78
    config.TRAIN.RPN_NMS_THRESH = 0.7ls
                                      ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 97, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc8_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:38:10] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
[11:38:26] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:38:26] src/executor/graph_executor.cc:44: Check failed: i < head_grads.size() && !head_grads[i].is_none() Because the last operator is not Loss function, head_gradient is required in calling backward.

Stack trace returned 27 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f4db7a3271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor8BackwardERKSt6vectorINS_7NDArrayESaIS3_EE+0x15d) [0x7f4db8275add]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXExecutorBackward+0xb8) [0x7f4db8219778]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f4e60f61adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f4e60f6140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f4e611785fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f4e61179f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (17) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (18) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (19) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (20) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (21) python() [0x4a1634]
[bt] (22) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (23) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (24) python(Py_Main+0xb5e) [0x44f904]
[bt] (25) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f4e624eff45]
[bt] (26) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 196, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 410, in fit
    self.forward_backward(data_batch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 144, in forward_backward
    self.backward()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 179, in backward
    self._curr_module.backward(out_grads=out_grads)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 465, in backward
    self._exec_group.backward(out_grads=out_grads)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 411, in backward
    exec_.backward(out_grads=out_grads_slice)
  File "/home/hustxly/mxnet/python/mxnet/executor.py", line 147, in backward
    ndarray))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [11:38:26] src/executor/graph_executor.cc:44: Check failed: i < head_grads.size() && !head_grads[i].is_none() Because the last operator is not Loss function, head_gradient is required in calling backward.

Stack trace returned 27 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f4db7a3271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor8BackwardERKSt6vectorINS_7NDArrayESaIS3_EE+0x15d) [0x7f4db8275add]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXExecutorBackward+0xb8) [0x7f4db8219778]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f4e60f61adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f4e60f6140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f4e611785fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f4e61179f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (17) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (18) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (19) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (20) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (21) python() [0x4a1634]
[bt] (22) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (23) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (24) python(Py_Main+0xb5e) [0x44f904]
[bt] (25) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f4e624eff45]
[bt] (26) python() [0x578c4e]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:59:24] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 196, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[12:43:49] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 203, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[12:45:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.54 samples/sec	Train-RPNAcc=0.588356,	RPNLogLoss=0.688438,	RPNL1Loss=0.115115,	RCNNAcc=0.194940,	RCNNLogLoss=2.837928,	RCNNL1Loss=0.272949,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.50 samples/sec	Train-RPNAcc=0.592702,	RPNLogLoss=0.687396,	RPNL1Loss=0.132219,	RCNNAcc=0.472370,	RCNNLogLoss=2.298971,	RCNNL1Loss=0.329313,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.69 samples/sec	Train-RPNAcc=0.600218,	RPNLogLoss=0.686898,	RPNL1Loss=0.136774,	RCNNAcc=0.594647,	RCNNLogLoss=1.909852,	RCNNL1Loss=0.335864,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[20:28:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.61 samples/sec	Train-RPNAcc=0.563616,	RPNLogLoss=0.691758,	RPNL1Loss=0.118104,	RCNNAcc=0.191592,	RCNNLogLoss=2.841586,	RCNNL1Loss=0.258174,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[20:54:15] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 105, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc8_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 12L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 105, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc9_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 12L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[21:00:17] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:43:21] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.60 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.688932,	RPNL1Loss=0.162465,	RCNNAcc=0.177455,	RCNNLogLoss=2.885032,	RCNNL1Loss=0.336327,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.86 samples/sec	Train-RPNAcc=0.593274,	RPNLogLoss=0.688133,	RPNL1Loss=0.129164,	RCNNAcc=0.470655,	RCNNLogLoss=2.306914,	RCNNL1Loss=0.329383,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.82 samples/sec	Train-RPNAcc=0.601178,	RPNLogLoss=0.687275,	RPNL1Loss=0.120215,	RCNNAcc=0.608222,	RCNNLogLoss=1.880212,	RCNNL1Loss=0.306126,	
INFO:root:Epoch[1] Batch [80]	Speed: 0.97 samples/sec	Train-RPNAcc=0.608314,	RPNLogLoss=0.686595,	RPNL1Loss=0.119597,	RCNNAcc=0.675540,	RCNNLogLoss=1.607514,	RCNNL1Loss=0.297878,	
INFO:root:Epoch[1] Batch [100]	Speed: 0.79 samples/sec	Train-RPNAcc=0.616607,	RPNLogLoss=0.685581,	RPNL1Loss=0.130103,	RCNNAcc=0.703899,	RCNNLogLoss=1.459083,	RCNNL1Loss=0.321868,	
INFO:root:Epoch[1] Batch [120]	Speed: 0.87 samples/sec	Train-RPNAcc=0.625678,	RPNLogLoss=0.684273,	RPNL1Loss=0.127825,	RCNNAcc=0.728177,	RCNNLogLoss=1.320564,	RCNNL1Loss=0.324794,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.95 samples/sec	Train-RPNAcc=0.633283,	RPNLogLoss=0.682898,	RPNL1Loss=0.132785,	RCNNAcc=0.748781,	RCNNLogLoss=1.202359,	RCNNL1Loss=0.323892,	
INFO:root:Epoch[1] Batch [160]	Speed: 0.83 samples/sec	Train-RPNAcc=0.640115,	RPNLogLoss=0.681510,	RPNL1Loss=0.134434,	RCNNAcc=0.762277,	RCNNLogLoss=1.113592,	RCNNL1Loss=0.326054,	
INFO:root:Epoch[1] Batch [180]	Speed: 0.79 samples/sec	Train-RPNAcc=0.647402,	RPNLogLoss=0.680011,	RPNL1Loss=0.135963,	RCNNAcc=0.776934,	RCNNLogLoss=1.031368,	RCNNL1Loss=0.319910,	
INFO:root:Epoch[1] Batch [200]	Speed: 0.98 samples/sec	Train-RPNAcc=0.653898,	RPNLogLoss=0.678374,	RPNL1Loss=0.137699,	RCNNAcc=0.786303,	RCNNLogLoss=0.968132,	RCNNL1Loss=0.321844,	
INFO:root:Epoch[1] Batch [220]	Speed: 0.88 samples/sec	Train-RPNAcc=0.661093,	RPNLogLoss=0.676715,	RPNL1Loss=0.134511,	RCNNAcc=0.796663,	RCNNLogLoss=0.910511,	RCNNL1Loss=0.315775,	
INFO:root:Epoch[1] Batch [240]	Speed: 1.05 samples/sec	Train-RPNAcc=0.667012,	RPNLogLoss=0.674963,	RPNL1Loss=0.133910,	RCNNAcc=0.804785,	RCNNLogLoss=0.859739,	RCNNL1Loss=0.314300,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.95 samples/sec	Train-RPNAcc=0.673746,	RPNLogLoss=0.673179,	RPNL1Loss=0.133964,	RCNNAcc=0.810973,	RCNNLogLoss=0.818879,	RCNNL1Loss=0.315344,	
INFO:root:Epoch[1] Batch [280]	Speed: 0.94 samples/sec	Train-RPNAcc=0.681425,	RPNLogLoss=0.671202,	RPNL1Loss=0.133793,	RCNNAcc=0.817977,	RCNNLogLoss=0.779751,	RCNNL1Loss=0.311582,	
INFO:root:Epoch[1] Batch [300]	Speed: 1.08 samples/sec	Train-RPNAcc=0.689083,	RPNLogLoss=0.669286,	RPNL1Loss=0.132383,	RCNNAcc=0.821455,	RCNNLogLoss=0.750870,	RCNNL1Loss=0.314483,	
INFO:root:Epoch[1] Batch [320]	Speed: 0.96 samples/sec	Train-RPNAcc=0.695848,	RPNLogLoss=0.667271,	RPNL1Loss=0.133914,	RCNNAcc=0.825131,	RCNNLogLoss=0.724867,	RCNNL1Loss=0.316649,	
INFO:root:Epoch[1] Batch [340]	Speed: 1.08 samples/sec	Train-RPNAcc=0.703996,	RPNLogLoss=0.664977,	RPNL1Loss=0.133020,	RCNNAcc=0.828789,	RCNNLogLoss=0.700400,	RCNNL1Loss=0.318892,	
INFO:root:Epoch[1] Batch [360]	Speed: 0.92 samples/sec	Train-RPNAcc=0.710981,	RPNLogLoss=0.662672,	RPNL1Loss=0.133019,	RCNNAcc=0.829856,	RCNNLogLoss=0.681870,	RCNNL1Loss=0.329944,	
INFO:root:Epoch[1] Batch [380]	Speed: 1.13 samples/sec	Train-RPNAcc=0.718688,	RPNLogLoss=0.660018,	RPNL1Loss=0.132743,	RCNNAcc=0.833661,	RCNNLogLoss=0.659349,	RCNNL1Loss=0.328331,	
INFO:root:Epoch[1] Batch [400]	Speed: 1.02 samples/sec	Train-RPNAcc=0.724614,	RPNLogLoss=0.657702,	RPNL1Loss=0.133130,	RCNNAcc=0.835178,	RCNNLogLoss=0.643083,	RCNNL1Loss=0.330612,	
INFO:root:Epoch[1] Batch [420]	Speed: 1.01 samples/sec	Train-RPNAcc=0.730942,	RPNLogLoss=0.655227,	RPNL1Loss=0.133190,	RCNNAcc=0.837162,	RCNNLogLoss=0.627163,	RCNNL1Loss=0.332483,	
INFO:root:Epoch[1] Batch [440]	Speed: 1.17 samples/sec	Train-RPNAcc=0.736899,	RPNLogLoss=0.652507,	RPNL1Loss=0.133504,	RCNNAcc=0.839675,	RCNNLogLoss=0.611529,	RCNNL1Loss=0.333065,	
INFO:root:Epoch[1] Batch [460]	Speed: 1.04 samples/sec	Train-RPNAcc=0.742365,	RPNLogLoss=0.649930,	RPNL1Loss=0.132935,	RCNNAcc=0.840530,	RCNNLogLoss=0.599674,	RCNNL1Loss=0.336655,	
INFO:root:Epoch[1] Batch [480]	Speed: 1.08 samples/sec	Train-RPNAcc=0.747466,	RPNLogLoss=0.647449,	RPNL1Loss=0.134214,	RCNNAcc=0.841768,	RCNNLogLoss=0.587771,	RCNNL1Loss=0.337567,	
INFO:root:Epoch[1] Batch [500]	Speed: 1.02 samples/sec	Train-RPNAcc=0.751770,	RPNLogLoss=0.644765,	RPNL1Loss=0.134417,	RCNNAcc=0.842970,	RCNNLogLoss=0.576698,	RCNNL1Loss=0.340340,	
INFO:root:Epoch[1] Batch [520]	Speed: 0.99 samples/sec	Train-RPNAcc=0.756425,	RPNLogLoss=0.642058,	RPNL1Loss=0.134187,	RCNNAcc=0.844200,	RCNNLogLoss=0.566322,	RCNNL1Loss=0.340579,	
INFO:root:Epoch[1] Batch [540]	Speed: 1.03 samples/sec	Train-RPNAcc=0.760116,	RPNLogLoss=0.639343,	RPNL1Loss=0.134406,	RCNNAcc=0.844154,	RCNNLogLoss=0.558783,	RCNNL1Loss=0.345100,	
INFO:root:Epoch[1] Batch [560]	Speed: 1.06 samples/sec	Train-RPNAcc=0.764706,	RPNLogLoss=0.636167,	RPNL1Loss=0.133693,	RCNNAcc=0.844962,	RCNNLogLoss=0.550100,	RCNNL1Loss=0.347409,	
INFO:root:Epoch[1] Batch [580]	Speed: 1.20 samples/sec	Train-RPNAcc=0.768684,	RPNLogLoss=0.632904,	RPNL1Loss=0.133879,	RCNNAcc=0.846130,	RCNNLogLoss=0.540802,	RCNNL1Loss=0.347832,	
INFO:root:Epoch[1] Batch [600]	Speed: 1.06 samples/sec	Train-RPNAcc=0.772697,	RPNLogLoss=0.629603,	RPNL1Loss=0.133035,	RCNNAcc=0.847364,	RCNNLogLoss=0.532077,	RCNNL1Loss=0.348467,	
INFO:root:Epoch[1] Batch [620]	Speed: 1.05 samples/sec	Train-RPNAcc=0.775042,	RPNLogLoss=0.626668,	RPNL1Loss=0.133769,	RCNNAcc=0.847675,	RCNNLogLoss=0.526164,	RCNNL1Loss=0.350132,	
INFO:root:Epoch[1] Batch [640]	Speed: 1.11 samples/sec	Train-RPNAcc=0.778014,	RPNLogLoss=0.623491,	RPNL1Loss=0.132403,	RCNNAcc=0.848162,	RCNNLogLoss=0.520149,	RCNNL1Loss=0.352079,	
INFO:root:Epoch[1] Batch [660]	Speed: 1.24 samples/sec	Train-RPNAcc=0.781746,	RPNLogLoss=0.619570,	RPNL1Loss=0.131171,	RCNNAcc=0.848986,	RCNNLogLoss=0.513084,	RCNNL1Loss=0.351516,	
INFO:root:Epoch[1] Batch [680]	Speed: 0.96 samples/sec	Train-RPNAcc=0.783688,	RPNLogLoss=0.616576,	RPNL1Loss=0.132369,	RCNNAcc=0.849062,	RCNNLogLoss=0.507960,	RCNNL1Loss=0.353803,	
INFO:root:Epoch[1] Batch [700]	Speed: 1.07 samples/sec	Train-RPNAcc=0.786482,	RPNLogLoss=0.613146,	RPNL1Loss=0.131892,	RCNNAcc=0.849601,	RCNNLogLoss=0.502239,	RCNNL1Loss=0.355016,	
INFO:root:Epoch[1] Batch [720]	Speed: 1.18 samples/sec	Train-RPNAcc=0.788900,	RPNLogLoss=0.609293,	RPNL1Loss=0.132436,	RCNNAcc=0.850046,	RCNNLogLoss=0.497134,	RCNNL1Loss=0.353960,	
INFO:root:Epoch[1] Batch [740]	Speed: 0.99 samples/sec	Train-RPNAcc=0.790776,	RPNLogLoss=0.606082,	RPNL1Loss=0.132961,	RCNNAcc=0.849749,	RCNNLogLoss=0.493672,	RCNNL1Loss=0.355475,	
INFO:root:Epoch[1] Batch [760]	Speed: 1.27 samples/sec	Train-RPNAcc=0.793497,	RPNLogLoss=0.602047,	RPNL1Loss=0.132501,	RCNNAcc=0.850741,	RCNNLogLoss=0.488898,	RCNNL1Loss=0.352915,	
INFO:root:Epoch[1] Batch [780]	Speed: 1.07 samples/sec	Train-RPNAcc=0.795304,	RPNLogLoss=0.598195,	RPNL1Loss=0.132957,	RCNNAcc=0.851132,	RCNNLogLoss=0.484880,	RCNNL1Loss=0.352076,	
INFO:root:Epoch[1] Batch [800]	Speed: 1.17 samples/sec	Train-RPNAcc=0.797509,	RPNLogLoss=0.594006,	RPNL1Loss=0.132641,	RCNNAcc=0.851562,	RCNNLogLoss=0.480475,	RCNNL1Loss=0.351652,	
INFO:root:Epoch[1] Batch [820]	Speed: 0.99 samples/sec	Train-RPNAcc=0.799259,	RPNLogLoss=0.589931,	RPNL1Loss=0.132236,	RCNNAcc=0.851667,	RCNNLogLoss=0.477351,	RCNNL1Loss=0.351855,	
INFO:root:Epoch[1] Batch [840]	Speed: 1.16 samples/sec	Train-RPNAcc=0.801515,	RPNLogLoss=0.585073,	RPNL1Loss=0.131305,	RCNNAcc=0.852046,	RCNNLogLoss=0.473784,	RCNNL1Loss=0.351850,	
INFO:root:Epoch[1] Batch [860]	Speed: 1.09 samples/sec	Train-RPNAcc=0.803136,	RPNLogLoss=0.580394,	RPNL1Loss=0.131323,	RCNNAcc=0.853323,	RCNNLogLoss=0.468089,	RCNNL1Loss=0.349920,	
INFO:root:Epoch[1] Batch [880]	Speed: 1.14 samples/sec	Train-RPNAcc=0.804976,	RPNLogLoss=0.575774,	RPNL1Loss=0.130716,	RCNNAcc=0.853212,	RCNNLogLoss=0.465926,	RCNNL1Loss=0.350124,	
INFO:root:Epoch[1] Batch [900]	Speed: 1.08 samples/sec	Train-RPNAcc=0.806638,	RPNLogLoss=0.571388,	RPNL1Loss=0.130127,	RCNNAcc=0.853331,	RCNNLogLoss=0.462832,	RCNNL1Loss=0.349852,	
INFO:root:Epoch[1] Batch [920]	Speed: 1.09 samples/sec	Train-RPNAcc=0.807818,	RPNLogLoss=0.567060,	RPNL1Loss=0.129675,	RCNNAcc=0.852589,	RCNNLogLoss=0.461446,	RCNNL1Loss=0.351843,	
INFO:root:Epoch[1] Batch [940]	Speed: 1.18 samples/sec	Train-RPNAcc=0.809810,	RPNLogLoss=0.562262,	RPNL1Loss=0.128891,	RCNNAcc=0.852658,	RCNNLogLoss=0.459461,	RCNNL1Loss=0.353024,	
INFO:root:Epoch[1] Batch [960]	Speed: 1.05 samples/sec	Train-RPNAcc=0.811459,	RPNLogLoss=0.557935,	RPNL1Loss=0.128235,	RCNNAcc=0.851725,	RCNNLogLoss=0.459469,	RCNNL1Loss=0.356156,	
INFO:root:Epoch[1] Batch [980]	Speed: 1.15 samples/sec	Train-RPNAcc=0.813026,	RPNLogLoss=0.553008,	RPNL1Loss=0.127361,	RCNNAcc=0.852024,	RCNNLogLoss=0.456953,	RCNNL1Loss=0.355789,	
INFO:root:Epoch[1] Batch [1000]	Speed: 1.00 samples/sec	Train-RPNAcc=0.814397,	RPNLogLoss=0.548546,	RPNL1Loss=0.126685,	RCNNAcc=0.851890,	RCNNLogLoss=0.455288,	RCNNL1Loss=0.355424,	
INFO:root:Epoch[1] Batch [1020]	Speed: 1.02 samples/sec	Train-RPNAcc=0.814937,	RPNLogLoss=0.544657,	RPNL1Loss=0.126519,	RCNNAcc=0.851892,	RCNNLogLoss=0.453571,	RCNNL1Loss=0.355157,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [1040]	Speed: 1.07 samples/sec	Train-RPNAcc=0.816875,	RPNLogLoss=0.539735,	RPNL1Loss=0.125172,	RCNNAcc=0.852178,	RCNNLogLoss=0.451253,	RCNNL1Loss=0.354670,	
INFO:root:Epoch[1] Batch [1060]	Speed: 1.12 samples/sec	Train-RPNAcc=0.818619,	RPNLogLoss=0.535017,	RPNL1Loss=0.124124,	RCNNAcc=0.852233,	RCNNLogLoss=0.449141,	RCNNL1Loss=0.354627,	
INFO:root:Epoch[1] Batch [1080]	Speed: 1.11 samples/sec	Train-RPNAcc=0.820247,	RPNLogLoss=0.530131,	RPNL1Loss=0.123006,	RCNNAcc=0.852336,	RCNNLogLoss=0.447343,	RCNNL1Loss=0.354002,	
INFO:root:Epoch[1] Batch [1100]	Speed: 1.05 samples/sec	Train-RPNAcc=0.821249,	RPNLogLoss=0.526050,	RPNL1Loss=0.122464,	RCNNAcc=0.852194,	RCNNLogLoss=0.446310,	RCNNL1Loss=0.354471,	
INFO:root:Epoch[1] Batch [1120]	Speed: 1.08 samples/sec	Train-RPNAcc=0.822187,	RPNLogLoss=0.521730,	RPNL1Loss=0.121908,	RCNNAcc=0.852622,	RCNNLogLoss=0.444003,	RCNNL1Loss=0.354099,	
INFO:root:Epoch[1] Batch [1140]	Speed: 1.04 samples/sec	Train-RPNAcc=0.822740,	RPNLogLoss=0.518268,	RPNL1Loss=0.121691,	RCNNAcc=0.852637,	RCNNLogLoss=0.442641,	RCNNL1Loss=0.354184,	
INFO:root:Epoch[1] Batch [1160]	Speed: 1.05 samples/sec	Train-RPNAcc=0.824027,	RPNLogLoss=0.513836,	RPNL1Loss=0.121004,	RCNNAcc=0.853090,	RCNNLogLoss=0.440523,	RCNNL1Loss=0.353089,	
INFO:root:Epoch[1] Batch [1180]	Speed: 0.99 samples/sec	Train-RPNAcc=0.824837,	RPNLogLoss=0.510054,	RPNL1Loss=0.120765,	RCNNAcc=0.853296,	RCNNLogLoss=0.439043,	RCNNL1Loss=0.352558,	
INFO:root:Epoch[1] Batch [1200]	Speed: 1.16 samples/sec	Train-RPNAcc=0.826359,	RPNLogLoss=0.505413,	RPNL1Loss=0.119724,	RCNNAcc=0.854119,	RCNNLogLoss=0.436003,	RCNNL1Loss=0.350563,	
INFO:root:Epoch[1] Batch [1220]	Speed: 1.04 samples/sec	Train-RPNAcc=0.827450,	RPNLogLoss=0.501343,	RPNL1Loss=0.119174,	RCNNAcc=0.854666,	RCNNLogLoss=0.433401,	RCNNL1Loss=0.349877,	
INFO:root:Epoch[1] Batch [1240]	Speed: 1.06 samples/sec	Train-RPNAcc=0.828468,	RPNLogLoss=0.497260,	RPNL1Loss=0.118499,	RCNNAcc=0.854861,	RCNNLogLoss=0.431979,	RCNNL1Loss=0.349589,	
INFO:root:Epoch[1] Batch [1260]	Speed: 1.06 samples/sec	Train-RPNAcc=0.829534,	RPNLogLoss=0.493290,	RPNL1Loss=0.117782,	RCNNAcc=0.855032,	RCNNLogLoss=0.430573,	RCNNL1Loss=0.350005,	
INFO:root:Epoch[1] Batch [1280]	Speed: 1.07 samples/sec	Train-RPNAcc=0.830839,	RPNLogLoss=0.488974,	RPNL1Loss=0.116837,	RCNNAcc=0.855856,	RCNNLogLoss=0.427962,	RCNNL1Loss=0.348670,	
INFO:root:Epoch[1] Batch [1300]	Speed: 0.98 samples/sec	Train-RPNAcc=0.831392,	RPNLogLoss=0.485824,	RPNL1Loss=0.116581,	RCNNAcc=0.856132,	RCNNLogLoss=0.426386,	RCNNL1Loss=0.348556,	
INFO:root:Epoch[1] Batch [1320]	Speed: 0.88 samples/sec	Train-RPNAcc=0.832339,	RPNLogLoss=0.482435,	RPNL1Loss=0.115929,	RCNNAcc=0.856495,	RCNNLogLoss=0.424572,	RCNNL1Loss=0.347671,	
INFO:root:Epoch[1] Batch [1340]	Speed: 0.92 samples/sec	Train-RPNAcc=0.832867,	RPNLogLoss=0.479282,	RPNL1Loss=0.115635,	RCNNAcc=0.856503,	RCNNLogLoss=0.423538,	RCNNL1Loss=0.348206,	
INFO:root:Epoch[1] Batch [1360]	Speed: 1.05 samples/sec	Train-RPNAcc=0.833486,	RPNLogLoss=0.476126,	RPNL1Loss=0.115235,	RCNNAcc=0.856953,	RCNNLogLoss=0.421439,	RCNNL1Loss=0.347231,	
INFO:root:Epoch[1] Batch [1380]	Speed: 0.93 samples/sec	Train-RPNAcc=0.834320,	RPNLogLoss=0.472979,	RPNL1Loss=0.114770,	RCNNAcc=0.857078,	RCNNLogLoss=0.420568,	RCNNL1Loss=0.347059,	
INFO:root:Epoch[1] Batch [1400]	Speed: 0.95 samples/sec	Train-RPNAcc=0.834630,	RPNLogLoss=0.470317,	RPNL1Loss=0.114736,	RCNNAcc=0.857373,	RCNNLogLoss=0.418936,	RCNNL1Loss=0.346159,	
INFO:root:Epoch[1] Batch [1420]	Speed: 1.00 samples/sec	Train-RPNAcc=0.835432,	RPNLogLoss=0.466944,	RPNL1Loss=0.114319,	RCNNAcc=0.857902,	RCNNLogLoss=0.417026,	RCNNL1Loss=0.345495,	
INFO:root:Epoch[1] Batch [1440]	Speed: 0.96 samples/sec	Train-RPNAcc=0.836314,	RPNLogLoss=0.463818,	RPNL1Loss=0.113788,	RCNNAcc=0.858063,	RCNNLogLoss=0.415863,	RCNNL1Loss=0.345305,	
INFO:root:Epoch[1] Batch [1460]	Speed: 0.99 samples/sec	Train-RPNAcc=0.837191,	RPNLogLoss=0.460567,	RPNL1Loss=0.113247,	RCNNAcc=0.858498,	RCNNLogLoss=0.414457,	RCNNL1Loss=0.344589,	
INFO:root:Epoch[1] Batch [1480]	Speed: 1.01 samples/sec	Train-RPNAcc=0.838158,	RPNLogLoss=0.457168,	RPNL1Loss=0.112627,	RCNNAcc=0.859349,	RCNNLogLoss=0.411654,	RCNNL1Loss=0.343083,	
INFO:root:Epoch[1] Batch [1500]	Speed: 0.96 samples/sec	Train-RPNAcc=0.838761,	RPNLogLoss=0.454152,	RPNL1Loss=0.112245,	RCNNAcc=0.859932,	RCNNLogLoss=0.409602,	RCNNL1Loss=0.342678,	
INFO:root:Epoch[1] Batch [1520]	Speed: 0.95 samples/sec	Train-RPNAcc=0.839199,	RPNLogLoss=0.451570,	RPNL1Loss=0.112015,	RCNNAcc=0.860305,	RCNNLogLoss=0.407903,	RCNNL1Loss=0.342089,	
INFO:root:Epoch[1] Batch [1540]	Speed: 0.99 samples/sec	Train-RPNAcc=0.840135,	RPNLogLoss=0.448353,	RPNL1Loss=0.111471,	RCNNAcc=0.861149,	RCNNLogLoss=0.405247,	RCNNL1Loss=0.340469,	
INFO:root:Epoch[1] Batch [1560]	Speed: 0.92 samples/sec	Train-RPNAcc=0.840980,	RPNLogLoss=0.445351,	RPNL1Loss=0.110940,	RCNNAcc=0.861757,	RCNNLogLoss=0.403333,	RCNNL1Loss=0.339179,	
INFO:root:Epoch[1] Batch [1580]	Speed: 0.95 samples/sec	Train-RPNAcc=0.841198,	RPNLogLoss=0.442907,	RPNL1Loss=0.110687,	RCNNAcc=0.862221,	RCNNLogLoss=0.401616,	RCNNL1Loss=0.338461,	
INFO:root:Epoch[1] Batch [1600]	Speed: 0.91 samples/sec	Train-RPNAcc=0.841932,	RPNLogLoss=0.440233,	RPNL1Loss=0.110348,	RCNNAcc=0.862552,	RCNNLogLoss=0.400357,	RCNNL1Loss=0.337958,	
INFO:root:Epoch[1] Batch [1620]	Speed: 1.01 samples/sec	Train-RPNAcc=0.842605,	RPNLogLoss=0.437301,	RPNL1Loss=0.109857,	RCNNAcc=0.863279,	RCNNLogLoss=0.397903,	RCNNL1Loss=0.336401,	
INFO:root:Epoch[1] Batch [1640]	Speed: 0.96 samples/sec	Train-RPNAcc=0.843476,	RPNLogLoss=0.434480,	RPNL1Loss=0.109200,	RCNNAcc=0.863750,	RCNNLogLoss=0.396246,	RCNNL1Loss=0.335754,	
INFO:root:Epoch[1] Batch [1660]	Speed: 0.98 samples/sec	Train-RPNAcc=0.843825,	RPNLogLoss=0.432425,	RPNL1Loss=0.108899,	RCNNAcc=0.864314,	RCNNLogLoss=0.394565,	RCNNL1Loss=0.334447,	
INFO:root:Epoch[1] Batch [1680]	Speed: 0.93 samples/sec	Train-RPNAcc=0.844459,	RPNLogLoss=0.430120,	RPNL1Loss=0.108693,	RCNNAcc=0.864552,	RCNNLogLoss=0.393331,	RCNNL1Loss=0.334202,	
INFO:root:Epoch[1] Batch [1700]	Speed: 0.89 samples/sec	Train-RPNAcc=0.845029,	RPNLogLoss=0.427665,	RPNL1Loss=0.108301,	RCNNAcc=0.864813,	RCNNLogLoss=0.392536,	RCNNL1Loss=0.333634,	
INFO:root:Epoch[1] Batch [1720]	Speed: 0.88 samples/sec	Train-RPNAcc=0.845625,	RPNLogLoss=0.425311,	RPNL1Loss=0.107978,	RCNNAcc=0.865322,	RCNNLogLoss=0.390896,	RCNNL1Loss=0.332790,	
INFO:root:Epoch[1] Batch [1740]	Speed: 1.01 samples/sec	Train-RPNAcc=0.846478,	RPNLogLoss=0.422680,	RPNL1Loss=0.107412,	RCNNAcc=0.865971,	RCNNLogLoss=0.388914,	RCNNL1Loss=0.332261,	
INFO:root:Epoch[1] Batch [1760]	Speed: 0.93 samples/sec	Train-RPNAcc=0.847199,	RPNLogLoss=0.420201,	RPNL1Loss=0.106928,	RCNNAcc=0.866708,	RCNNLogLoss=0.386591,	RCNNL1Loss=0.331131,	
INFO:root:Epoch[1] Batch [1780]	Speed: 0.83 samples/sec	Train-RPNAcc=0.847917,	RPNLogLoss=0.417796,	RPNL1Loss=0.106519,	RCNNAcc=0.867038,	RCNNLogLoss=0.385380,	RCNNL1Loss=0.330498,	
INFO:root:Epoch[1] Batch [1800]	Speed: 0.92 samples/sec	Train-RPNAcc=0.848513,	RPNLogLoss=0.415443,	RPNL1Loss=0.106213,	RCNNAcc=0.867600,	RCNNLogLoss=0.383498,	RCNNL1Loss=0.329358,	
INFO:root:Epoch[1] Batch [1820]	Speed: 0.93 samples/sec	Train-RPNAcc=0.849111,	RPNLogLoss=0.413136,	RPNL1Loss=0.105776,	RCNNAcc=0.868131,	RCNNLogLoss=0.381828,	RCNNL1Loss=0.328459,	
INFO:root:Epoch[1] Batch [1840]	Speed: 0.80 samples/sec	Train-RPNAcc=0.849430,	RPNLogLoss=0.411209,	RPNL1Loss=0.105585,	RCNNAcc=0.868401,	RCNNLogLoss=0.380722,	RCNNL1Loss=0.328127,	
INFO:root:Epoch[1] Batch [1860]	Speed: 0.87 samples/sec	Train-RPNAcc=0.849890,	RPNLogLoss=0.409092,	RPNL1Loss=0.105389,	RCNNAcc=0.868716,	RCNNLogLoss=0.379563,	RCNNL1Loss=0.327404,	
INFO:root:Epoch[1] Batch [1880]	Speed: 0.83 samples/sec	Train-RPNAcc=0.850262,	RPNLogLoss=0.407280,	RPNL1Loss=0.105237,	RCNNAcc=0.869052,	RCNNLogLoss=0.378324,	RCNNL1Loss=0.326779,	
INFO:root:Epoch[1] Batch [1900]	Speed: 0.83 samples/sec	Train-RPNAcc=0.850849,	RPNLogLoss=0.405081,	RPNL1Loss=0.104827,	RCNNAcc=0.869616,	RCNNLogLoss=0.376586,	RCNNL1Loss=0.326059,	
INFO:root:Epoch[1] Batch [1920]	Speed: 0.95 samples/sec	Train-RPNAcc=0.851532,	RPNLogLoss=0.402839,	RPNL1Loss=0.104314,	RCNNAcc=0.870238,	RCNNLogLoss=0.374799,	RCNNL1Loss=0.324857,	
INFO:root:Epoch[1] Batch [1940]	Speed: 0.84 samples/sec	Train-RPNAcc=0.851657,	RPNLogLoss=0.401223,	RPNL1Loss=0.104239,	RCNNAcc=0.870766,	RCNNLogLoss=0.373113,	RCNNL1Loss=0.323880,	
INFO:root:Epoch[1] Batch [1960]	Speed: 0.90 samples/sec	Train-RPNAcc=0.852351,	RPNLogLoss=0.399245,	RPNL1Loss=0.103919,	RCNNAcc=0.870976,	RCNNLogLoss=0.372378,	RCNNL1Loss=0.323489,	
INFO:root:Epoch[1] Batch [1980]	Speed: 0.90 samples/sec	Train-RPNAcc=0.852970,	RPNLogLoss=0.397362,	RPNL1Loss=0.103675,	RCNNAcc=0.871344,	RCNNLogLoss=0.371173,	RCNNL1Loss=0.323022,	
INFO:root:Epoch[1] Batch [2000]	Speed: 0.85 samples/sec	Train-RPNAcc=0.853530,	RPNLogLoss=0.395380,	RPNL1Loss=0.103362,	RCNNAcc=0.871744,	RCNNLogLoss=0.369963,	RCNNL1Loss=0.322354,	
INFO:root:Epoch[1] Batch [2020]	Speed: 0.85 samples/sec	Train-RPNAcc=0.854075,	RPNLogLoss=0.393485,	RPNL1Loss=0.103038,	RCNNAcc=0.872035,	RCNNLogLoss=0.368766,	RCNNL1Loss=0.322073,	
INFO:root:Epoch[1] Batch [2040]	Speed: 0.92 samples/sec	Train-RPNAcc=0.854529,	RPNLogLoss=0.391560,	RPNL1Loss=0.102764,	RCNNAcc=0.872588,	RCNNLogLoss=0.366963,	RCNNL1Loss=0.321183,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [2060]	Speed: 0.90 samples/sec	Train-RPNAcc=0.855219,	RPNLogLoss=0.389481,	RPNL1Loss=0.102409,	RCNNAcc=0.873230,	RCNNLogLoss=0.365144,	RCNNL1Loss=0.319860,	
INFO:root:Epoch[1] Batch [2080]	Speed: 0.88 samples/sec	Train-RPNAcc=0.856030,	RPNLogLoss=0.387163,	RPNL1Loss=0.101906,	RCNNAcc=0.873787,	RCNNLogLoss=0.363700,	RCNNL1Loss=0.318832,	
INFO:root:Epoch[1] Batch [2100]	Speed: 0.80 samples/sec	Train-RPNAcc=0.856502,	RPNLogLoss=0.385392,	RPNL1Loss=0.101687,	RCNNAcc=0.874018,	RCNNLogLoss=0.362625,	RCNNL1Loss=0.318381,	
INFO:root:Epoch[1] Batch [2120]	Speed: 0.89 samples/sec	Train-RPNAcc=0.857252,	RPNLogLoss=0.383350,	RPNL1Loss=0.101195,	RCNNAcc=0.874599,	RCNNLogLoss=0.360952,	RCNNL1Loss=0.317366,	
INFO:root:Epoch[1] Batch [2140]	Speed: 0.83 samples/sec	Train-RPNAcc=0.857658,	RPNLogLoss=0.381711,	RPNL1Loss=0.101094,	RCNNAcc=0.875113,	RCNNLogLoss=0.359405,	RCNNL1Loss=0.316549,	
INFO:root:Epoch[1] Batch [2160]	Speed: 0.90 samples/sec	Train-RPNAcc=0.858370,	RPNLogLoss=0.379575,	RPNL1Loss=0.100591,	RCNNAcc=0.875622,	RCNNLogLoss=0.357947,	RCNNL1Loss=0.315718,	
INFO:root:Epoch[1] Batch [2180]	Speed: 0.81 samples/sec	Train-RPNAcc=0.858976,	RPNLogLoss=0.377806,	RPNL1Loss=0.100302,	RCNNAcc=0.876003,	RCNNLogLoss=0.356597,	RCNNL1Loss=0.314991,	
INFO:root:Epoch[1] Batch [2200]	Speed: 0.86 samples/sec	Train-RPNAcc=0.859687,	RPNLogLoss=0.375743,	RPNL1Loss=0.099743,	RCNNAcc=0.876548,	RCNNLogLoss=0.354912,	RCNNL1Loss=0.313974,	
INFO:root:Epoch[1] Batch [2220]	Speed: 0.82 samples/sec	Train-RPNAcc=0.860165,	RPNLogLoss=0.374027,	RPNL1Loss=0.099471,	RCNNAcc=0.876833,	RCNNLogLoss=0.354012,	RCNNL1Loss=0.313638,	
INFO:root:Epoch[1] Batch [2240]	Speed: 0.85 samples/sec	Train-RPNAcc=0.860475,	RPNLogLoss=0.372665,	RPNL1Loss=0.099325,	RCNNAcc=0.877221,	RCNNLogLoss=0.352803,	RCNNL1Loss=0.313252,	
INFO:root:Epoch[1] Batch [2260]	Speed: 0.81 samples/sec	Train-RPNAcc=0.860971,	RPNLogLoss=0.371062,	RPNL1Loss=0.099041,	RCNNAcc=0.877505,	RCNNLogLoss=0.351964,	RCNNL1Loss=0.312908,	
INFO:root:Epoch[1] Batch [2280]	Speed: 0.85 samples/sec	Train-RPNAcc=0.861350,	RPNLogLoss=0.369532,	RPNL1Loss=0.098839,	RCNNAcc=0.877891,	RCNNLogLoss=0.350823,	RCNNL1Loss=0.312481,	
INFO:root:Epoch[1] Batch [2300]	Speed: 0.85 samples/sec	Train-RPNAcc=0.861983,	RPNLogLoss=0.367731,	RPNL1Loss=0.098447,	RCNNAcc=0.878283,	RCNNLogLoss=0.349503,	RCNNL1Loss=0.311819,	
INFO:root:Epoch[1] Batch [2320]	Speed: 0.80 samples/sec	Train-RPNAcc=0.862500,	RPNLogLoss=0.366047,	RPNL1Loss=0.098150,	RCNNAcc=0.878514,	RCNNLogLoss=0.348630,	RCNNL1Loss=0.311647,	
INFO:root:Epoch[1] Batch [2340]	Speed: 0.82 samples/sec	Train-RPNAcc=0.862757,	RPNLogLoss=0.364759,	RPNL1Loss=0.098071,	RCNNAcc=0.878674,	RCNNLogLoss=0.348093,	RCNNL1Loss=0.311368,	
INFO:root:Epoch[1] Batch [2360]	Speed: 0.80 samples/sec	Train-RPNAcc=0.863233,	RPNLogLoss=0.363512,	RPNL1Loss=0.097934,	RCNNAcc=0.878941,	RCNNLogLoss=0.347285,	RCNNL1Loss=0.310773,	
INFO:root:Epoch[1] Batch [2380]	Speed: 0.81 samples/sec	Train-RPNAcc=0.863578,	RPNLogLoss=0.362260,	RPNL1Loss=0.097664,	RCNNAcc=0.879187,	RCNNLogLoss=0.346573,	RCNNL1Loss=0.310616,	
INFO:root:Epoch[1] Batch [2400]	Speed: 0.86 samples/sec	Train-RPNAcc=0.864077,	RPNLogLoss=0.360688,	RPNL1Loss=0.097365,	RCNNAcc=0.879721,	RCNNLogLoss=0.345060,	RCNNL1Loss=0.309721,	
INFO:root:Epoch[1] Batch [2420]	Speed: 0.81 samples/sec	Train-RPNAcc=0.864507,	RPNLogLoss=0.359195,	RPNL1Loss=0.097014,	RCNNAcc=0.879924,	RCNNLogLoss=0.344369,	RCNNL1Loss=0.309600,	
INFO:root:Epoch[1] Batch [2440]	Speed: 0.85 samples/sec	Train-RPNAcc=0.865043,	RPNLogLoss=0.357729,	RPNL1Loss=0.096715,	RCNNAcc=0.880188,	RCNNLogLoss=0.343552,	RCNNL1Loss=0.309412,	
INFO:root:Epoch[1] Batch [2460]	Speed: 0.86 samples/sec	Train-RPNAcc=0.865592,	RPNLogLoss=0.356121,	RPNL1Loss=0.096385,	RCNNAcc=0.880600,	RCNNLogLoss=0.342278,	RCNNL1Loss=0.308501,	
INFO:root:Epoch[1] Batch [2480]	Speed: 0.84 samples/sec	Train-RPNAcc=0.865915,	RPNLogLoss=0.354900,	RPNL1Loss=0.096300,	RCNNAcc=0.880885,	RCNNLogLoss=0.341440,	RCNNL1Loss=0.308160,	
INFO:root:Epoch[1] Batch [2500]	Speed: 0.77 samples/sec	Train-RPNAcc=0.866503,	RPNLogLoss=0.353377,	RPNL1Loss=0.096017,	RCNNAcc=0.881198,	RCNNLogLoss=0.340451,	RCNNL1Loss=0.307925,	
INFO:root:Epoch[1] Batch [2520]	Speed: 0.85 samples/sec	Train-RPNAcc=0.866978,	RPNLogLoss=0.352023,	RPNL1Loss=0.095836,	RCNNAcc=0.881468,	RCNNLogLoss=0.339454,	RCNNL1Loss=0.307576,	
INFO:root:Epoch[1] Batch [2540]	Speed: 0.78 samples/sec	Train-RPNAcc=0.867393,	RPNLogLoss=0.350769,	RPNL1Loss=0.095712,	RCNNAcc=0.881773,	RCNNLogLoss=0.338405,	RCNNL1Loss=0.307129,	
INFO:root:Epoch[1] Batch [2560]	Speed: 0.88 samples/sec	Train-RPNAcc=0.867976,	RPNLogLoss=0.349246,	RPNL1Loss=0.095394,	RCNNAcc=0.882154,	RCNNLogLoss=0.337287,	RCNNL1Loss=0.306302,	
INFO:root:Epoch[1] Batch [2580]	Speed: 0.76 samples/sec	Train-RPNAcc=0.868224,	RPNLogLoss=0.348230,	RPNL1Loss=0.095425,	RCNNAcc=0.882228,	RCNNLogLoss=0.336893,	RCNNL1Loss=0.306407,	
INFO:root:Epoch[1] Batch [2600]	Speed: 0.77 samples/sec	Train-RPNAcc=0.868763,	RPNLogLoss=0.346880,	RPNL1Loss=0.095226,	RCNNAcc=0.882539,	RCNNLogLoss=0.336105,	RCNNL1Loss=0.306320,	
INFO:root:Epoch[1] Batch [2620]	Speed: 0.78 samples/sec	Train-RPNAcc=0.869076,	RPNLogLoss=0.345934,	RPNL1Loss=0.095203,	RCNNAcc=0.882672,	RCNNLogLoss=0.335624,	RCNNL1Loss=0.306459,	
INFO:root:Epoch[1] Batch [2640]	Speed: 0.79 samples/sec	Train-RPNAcc=0.869564,	RPNLogLoss=0.344696,	RPNL1Loss=0.094978,	RCNNAcc=0.882966,	RCNNLogLoss=0.334689,	RCNNL1Loss=0.306015,	
INFO:root:Epoch[1] Batch [2660]	Speed: 0.80 samples/sec	Train-RPNAcc=0.869997,	RPNLogLoss=0.343478,	RPNL1Loss=0.094815,	RCNNAcc=0.883182,	RCNNLogLoss=0.333949,	RCNNL1Loss=0.305626,	
INFO:root:Epoch[1] Batch [2680]	Speed: 0.75 samples/sec	Train-RPNAcc=0.870244,	RPNLogLoss=0.342589,	RPNL1Loss=0.094792,	RCNNAcc=0.883145,	RCNNLogLoss=0.333905,	RCNNL1Loss=0.305916,	
INFO:root:Epoch[1] Batch [2700]	Speed: 0.83 samples/sec	Train-RPNAcc=0.870861,	RPNLogLoss=0.341033,	RPNL1Loss=0.094362,	RCNNAcc=0.883550,	RCNNLogLoss=0.332634,	RCNNL1Loss=0.305160,	
INFO:root:Epoch[1] Batch [2720]	Speed: 0.78 samples/sec	Train-RPNAcc=0.871280,	RPNLogLoss=0.339874,	RPNL1Loss=0.094282,	RCNNAcc=0.883869,	RCNNLogLoss=0.331607,	RCNNL1Loss=0.304597,	
INFO:root:Epoch[1] Batch [2740]	Speed: 0.79 samples/sec	Train-RPNAcc=0.871836,	RPNLogLoss=0.338558,	RPNL1Loss=0.094042,	RCNNAcc=0.884135,	RCNNLogLoss=0.330815,	RCNNL1Loss=0.304116,	
INFO:root:Epoch[1] Batch [2760]	Speed: 0.75 samples/sec	Train-RPNAcc=0.872173,	RPNLogLoss=0.337499,	RPNL1Loss=0.093953,	RCNNAcc=0.884369,	RCNNLogLoss=0.330101,	RCNNL1Loss=0.303963,	
INFO:root:Epoch[1] Batch [2780]	Speed: 0.89 samples/sec	Train-RPNAcc=0.872786,	RPNLogLoss=0.336105,	RPNL1Loss=0.093614,	RCNNAcc=0.884745,	RCNNLogLoss=0.328845,	RCNNL1Loss=0.303127,	
INFO:root:Epoch[1] Batch [2800]	Speed: 0.83 samples/sec	Train-RPNAcc=0.873272,	RPNLogLoss=0.334800,	RPNL1Loss=0.093364,	RCNNAcc=0.885005,	RCNNLogLoss=0.327897,	RCNNL1Loss=0.302808,	
INFO:root:Epoch[1] Batch [2820]	Speed: 0.84 samples/sec	Train-RPNAcc=0.873694,	RPNLogLoss=0.333542,	RPNL1Loss=0.093155,	RCNNAcc=0.885302,	RCNNLogLoss=0.326976,	RCNNL1Loss=0.302299,	
INFO:root:Epoch[1] Batch [2840]	Speed: 0.82 samples/sec	Train-RPNAcc=0.874215,	RPNLogLoss=0.332263,	RPNL1Loss=0.092859,	RCNNAcc=0.885667,	RCNNLogLoss=0.326070,	RCNNL1Loss=0.301765,	
INFO:root:Epoch[1] Batch [2860]	Speed: 0.76 samples/sec	Train-RPNAcc=0.874590,	RPNLogLoss=0.331169,	RPNL1Loss=0.092796,	RCNNAcc=0.885964,	RCNNLogLoss=0.325104,	RCNNL1Loss=0.301385,	
INFO:root:Epoch[1] Batch [2880]	Speed: 0.81 samples/sec	Train-RPNAcc=0.875062,	RPNLogLoss=0.329917,	RPNL1Loss=0.092560,	RCNNAcc=0.886243,	RCNNLogLoss=0.324285,	RCNNL1Loss=0.300833,	
INFO:root:Epoch[1] Batch [2900]	Speed: 0.78 samples/sec	Train-RPNAcc=0.875470,	RPNLogLoss=0.328748,	RPNL1Loss=0.092372,	RCNNAcc=0.886470,	RCNNLogLoss=0.323418,	RCNNL1Loss=0.300475,	
INFO:root:Epoch[1] Batch [2920]	Speed: 0.75 samples/sec	Train-RPNAcc=0.875895,	RPNLogLoss=0.327618,	RPNL1Loss=0.092282,	RCNNAcc=0.886669,	RCNNLogLoss=0.322733,	RCNNL1Loss=0.300041,	
INFO:root:Epoch[1] Batch [2940]	Speed: 0.75 samples/sec	Train-RPNAcc=0.876250,	RPNLogLoss=0.326665,	RPNL1Loss=0.092158,	RCNNAcc=0.886725,	RCNNLogLoss=0.322477,	RCNNL1Loss=0.300266,	
INFO:root:Epoch[1] Batch [2960]	Speed: 0.76 samples/sec	Train-RPNAcc=0.876689,	RPNLogLoss=0.325513,	RPNL1Loss=0.091947,	RCNNAcc=0.887016,	RCNNLogLoss=0.321724,	RCNNL1Loss=0.300075,	
INFO:root:Epoch[1] Batch [2980]	Speed: 0.78 samples/sec	Train-RPNAcc=0.877068,	RPNLogLoss=0.324529,	RPNL1Loss=0.091807,	RCNNAcc=0.887121,	RCNNLogLoss=0.321303,	RCNNL1Loss=0.300163,	
INFO:root:Epoch[1] Batch [3000]	Speed: 0.68 samples/sec	Train-RPNAcc=0.877355,	RPNLogLoss=0.323731,	RPNL1Loss=0.091801,	RCNNAcc=0.887186,	RCNNLogLoss=0.320999,	RCNNL1Loss=0.300308,	
INFO:root:Epoch[1] Batch [3020]	Speed: 0.74 samples/sec	Train-RPNAcc=0.877728,	RPNLogLoss=0.322710,	RPNL1Loss=0.091593,	RCNNAcc=0.887317,	RCNNLogLoss=0.320447,	RCNNL1Loss=0.300151,	
INFO:root:Epoch[1] Batch [3040]	Speed: 0.78 samples/sec	Train-RPNAcc=0.878118,	RPNLogLoss=0.321665,	RPNL1Loss=0.091380,	RCNNAcc=0.887506,	RCNNLogLoss=0.319877,	RCNNL1Loss=0.299999,	
INFO:root:Epoch[1] Batch [3060]	Speed: 0.80 samples/sec	Train-RPNAcc=0.878530,	RPNLogLoss=0.320569,	RPNL1Loss=0.091227,	RCNNAcc=0.887879,	RCNNLogLoss=0.318745,	RCNNL1Loss=0.299309,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [3080]	Speed: 0.85 samples/sec	Train-RPNAcc=0.878962,	RPNLogLoss=0.319501,	RPNL1Loss=0.090994,	RCNNAcc=0.888221,	RCNNLogLoss=0.317726,	RCNNL1Loss=0.298720,	
INFO:root:Epoch[1] Batch [3100]	Speed: 0.73 samples/sec	Train-RPNAcc=0.879255,	RPNLogLoss=0.318536,	RPNL1Loss=0.090907,	RCNNAcc=0.888479,	RCNNLogLoss=0.316958,	RCNNL1Loss=0.298433,	
INFO:root:Epoch[1] Batch [3120]	Speed: 0.77 samples/sec	Train-RPNAcc=0.879737,	RPNLogLoss=0.317332,	RPNL1Loss=0.090663,	RCNNAcc=0.888710,	RCNNLogLoss=0.316287,	RCNNL1Loss=0.298104,	
INFO:root:Epoch[1] Batch [3140]	Speed: 0.82 samples/sec	Train-RPNAcc=0.880104,	RPNLogLoss=0.316404,	RPNL1Loss=0.090415,	RCNNAcc=0.888906,	RCNNLogLoss=0.315656,	RCNNL1Loss=0.297855,	
INFO:root:Epoch[1] Batch [3160]	Speed: 0.74 samples/sec	Train-RPNAcc=0.880350,	RPNLogLoss=0.315526,	RPNL1Loss=0.090253,	RCNNAcc=0.889172,	RCNNLogLoss=0.314879,	RCNNL1Loss=0.297455,	
INFO:root:Epoch[1] Batch [3180]	Speed: 0.81 samples/sec	Train-RPNAcc=0.880799,	RPNLogLoss=0.314427,	RPNL1Loss=0.090053,	RCNNAcc=0.889444,	RCNNLogLoss=0.314085,	RCNNL1Loss=0.297004,	
INFO:root:Epoch[1] Batch [3200]	Speed: 0.73 samples/sec	Train-RPNAcc=0.881271,	RPNLogLoss=0.313309,	RPNL1Loss=0.089866,	RCNNAcc=0.889685,	RCNNLogLoss=0.313411,	RCNNL1Loss=0.296764,	
INFO:root:Epoch[1] Batch [3220]	Speed: 0.75 samples/sec	Train-RPNAcc=0.881772,	RPNLogLoss=0.312162,	RPNL1Loss=0.089596,	RCNNAcc=0.889859,	RCNNLogLoss=0.312799,	RCNNL1Loss=0.296392,	
INFO:root:Epoch[1] Batch [3240]	Speed: 0.76 samples/sec	Train-RPNAcc=0.882195,	RPNLogLoss=0.311205,	RPNL1Loss=0.089553,	RCNNAcc=0.890027,	RCNNLogLoss=0.312225,	RCNNL1Loss=0.296088,	
INFO:root:Epoch[1] Batch [3260]	Speed: 0.82 samples/sec	Train-RPNAcc=0.882612,	RPNLogLoss=0.310177,	RPNL1Loss=0.089306,	RCNNAcc=0.890335,	RCNNLogLoss=0.311239,	RCNNL1Loss=0.295620,	
INFO:root:Epoch[1] Batch [3280]	Speed: 0.78 samples/sec	Train-RPNAcc=0.882961,	RPNLogLoss=0.309295,	RPNL1Loss=0.089213,	RCNNAcc=0.890508,	RCNNLogLoss=0.310685,	RCNNL1Loss=0.295442,	
INFO:root:Epoch[1] Batch [3300]	Speed: 0.73 samples/sec	Train-RPNAcc=0.883343,	RPNLogLoss=0.308459,	RPNL1Loss=0.089042,	RCNNAcc=0.890606,	RCNNLogLoss=0.310287,	RCNNL1Loss=0.295175,	
INFO:root:Epoch[1] Batch [3320]	Speed: 0.76 samples/sec	Train-RPNAcc=0.883836,	RPNLogLoss=0.307340,	RPNL1Loss=0.088750,	RCNNAcc=0.890903,	RCNNLogLoss=0.309439,	RCNNL1Loss=0.294700,	
INFO:root:Epoch[1] Batch [3340]	Speed: 0.77 samples/sec	Train-RPNAcc=0.884183,	RPNLogLoss=0.306505,	RPNL1Loss=0.088563,	RCNNAcc=0.891027,	RCNNLogLoss=0.309030,	RCNNL1Loss=0.294633,	
INFO:root:Epoch[1] Batch [3360]	Speed: 0.73 samples/sec	Train-RPNAcc=0.884549,	RPNLogLoss=0.305537,	RPNL1Loss=0.088361,	RCNNAcc=0.891190,	RCNNLogLoss=0.308435,	RCNNL1Loss=0.294278,	
INFO:root:Epoch[1] Batch [3380]	Speed: 0.73 samples/sec	Train-RPNAcc=0.884922,	RPNLogLoss=0.304614,	RPNL1Loss=0.088266,	RCNNAcc=0.891390,	RCNNLogLoss=0.307786,	RCNNL1Loss=0.294002,	
INFO:root:Epoch[1] Batch [3400]	Speed: 0.77 samples/sec	Train-RPNAcc=0.885211,	RPNLogLoss=0.303823,	RPNL1Loss=0.088167,	RCNNAcc=0.891463,	RCNNLogLoss=0.307527,	RCNNL1Loss=0.294042,	
INFO:root:Epoch[1] Batch [3420]	Speed: 0.75 samples/sec	Train-RPNAcc=0.885608,	RPNLogLoss=0.302873,	RPNL1Loss=0.087930,	RCNNAcc=0.891744,	RCNNLogLoss=0.306744,	RCNNL1Loss=0.293725,	
INFO:root:Epoch[1] Batch [3440]	Speed: 0.79 samples/sec	Train-RPNAcc=0.885994,	RPNLogLoss=0.301923,	RPNL1Loss=0.087752,	RCNNAcc=0.891955,	RCNNLogLoss=0.306182,	RCNNL1Loss=0.293499,	
INFO:root:Epoch[1] Batch [3460]	Speed: 0.76 samples/sec	Train-RPNAcc=0.886320,	RPNLogLoss=0.301185,	RPNL1Loss=0.087696,	RCNNAcc=0.892131,	RCNNLogLoss=0.305670,	RCNNL1Loss=0.293321,	
INFO:root:Epoch[1] Batch [3480]	Speed: 0.79 samples/sec	Train-RPNAcc=0.886690,	RPNLogLoss=0.300291,	RPNL1Loss=0.087597,	RCNNAcc=0.892429,	RCNNLogLoss=0.304746,	RCNNL1Loss=0.292909,	
INFO:root:Epoch[1] Batch [3500]	Speed: 0.80 samples/sec	Train-RPNAcc=0.887093,	RPNLogLoss=0.299409,	RPNL1Loss=0.087419,	RCNNAcc=0.892694,	RCNNLogLoss=0.303968,	RCNNL1Loss=0.292452,	
INFO:root:Epoch[1] Batch [3520]	Speed: 0.72 samples/sec	Train-RPNAcc=0.887481,	RPNLogLoss=0.298568,	RPNL1Loss=0.087351,	RCNNAcc=0.892722,	RCNNLogLoss=0.303750,	RCNNL1Loss=0.292397,	
INFO:root:Epoch[1] Batch [3540]	Speed: 0.70 samples/sec	Train-RPNAcc=0.887812,	RPNLogLoss=0.297797,	RPNL1Loss=0.087285,	RCNNAcc=0.892798,	RCNNLogLoss=0.303351,	RCNNL1Loss=0.292350,	
INFO:root:Epoch[1] Batch [3560]	Speed: 0.80 samples/sec	Train-RPNAcc=0.888141,	RPNLogLoss=0.296934,	RPNL1Loss=0.087136,	RCNNAcc=0.893005,	RCNNLogLoss=0.302687,	RCNNL1Loss=0.292005,	
INFO:root:Epoch[1] Batch [3580]	Speed: 0.79 samples/sec	Train-RPNAcc=0.888484,	RPNLogLoss=0.296042,	RPNL1Loss=0.086949,	RCNNAcc=0.893204,	RCNNLogLoss=0.302060,	RCNNL1Loss=0.291705,	
INFO:root:Epoch[1] Batch [3600]	Speed: 0.79 samples/sec	Train-RPNAcc=0.888887,	RPNLogLoss=0.295138,	RPNL1Loss=0.086757,	RCNNAcc=0.893389,	RCNNLogLoss=0.301446,	RCNNL1Loss=0.291451,	
INFO:root:Epoch[1] Batch [3620]	Speed: 0.80 samples/sec	Train-RPNAcc=0.889241,	RPNLogLoss=0.294307,	RPNL1Loss=0.086597,	RCNNAcc=0.893553,	RCNNLogLoss=0.300891,	RCNNL1Loss=0.291383,	
INFO:root:Epoch[1] Batch [3640]	Speed: 0.72 samples/sec	Train-RPNAcc=0.889564,	RPNLogLoss=0.293580,	RPNL1Loss=0.086513,	RCNNAcc=0.893642,	RCNNLogLoss=0.300624,	RCNNL1Loss=0.291307,	
INFO:root:Epoch[1] Batch [3660]	Speed: 0.78 samples/sec	Train-RPNAcc=0.889923,	RPNLogLoss=0.292662,	RPNL1Loss=0.086292,	RCNNAcc=0.893839,	RCNNLogLoss=0.300041,	RCNNL1Loss=0.291076,	
INFO:root:Epoch[1] Batch [3680]	Speed: 0.75 samples/sec	Train-RPNAcc=0.890303,	RPNLogLoss=0.291776,	RPNL1Loss=0.086176,	RCNNAcc=0.893944,	RCNNLogLoss=0.299564,	RCNNL1Loss=0.291087,	
INFO:root:Epoch[1] Batch [3700]	Speed: 0.75 samples/sec	Train-RPNAcc=0.890678,	RPNLogLoss=0.290852,	RPNL1Loss=0.086016,	RCNNAcc=0.894125,	RCNNLogLoss=0.298946,	RCNNL1Loss=0.290833,	
INFO:root:Epoch[1] Batch [3720]	Speed: 0.81 samples/sec	Train-RPNAcc=0.891035,	RPNLogLoss=0.289928,	RPNL1Loss=0.085789,	RCNNAcc=0.894310,	RCNNLogLoss=0.298283,	RCNNL1Loss=0.290378,	
INFO:root:Epoch[1] Batch [3740]	Speed: 0.72 samples/sec	Train-RPNAcc=0.891315,	RPNLogLoss=0.289160,	RPNL1Loss=0.085662,	RCNNAcc=0.894522,	RCNNLogLoss=0.297681,	RCNNL1Loss=0.290024,	
INFO:root:Epoch[1] Batch [3760]	Speed: 0.74 samples/sec	Train-RPNAcc=0.891652,	RPNLogLoss=0.288380,	RPNL1Loss=0.085599,	RCNNAcc=0.894626,	RCNNLogLoss=0.297383,	RCNNL1Loss=0.289930,	
INFO:root:Epoch[1] Batch [3780]	Speed: 0.77 samples/sec	Train-RPNAcc=0.892011,	RPNLogLoss=0.287519,	RPNL1Loss=0.085421,	RCNNAcc=0.894859,	RCNNLogLoss=0.296681,	RCNNL1Loss=0.289586,	
INFO:root:Epoch[1] Batch [3800]	Speed: 0.73 samples/sec	Train-RPNAcc=0.892275,	RPNLogLoss=0.286899,	RPNL1Loss=0.085363,	RCNNAcc=0.895015,	RCNNLogLoss=0.296178,	RCNNL1Loss=0.289428,	
INFO:root:Epoch[1] Batch [3820]	Speed: 0.79 samples/sec	Train-RPNAcc=0.892568,	RPNLogLoss=0.286173,	RPNL1Loss=0.085222,	RCNNAcc=0.895164,	RCNNLogLoss=0.295763,	RCNNL1Loss=0.289301,	
INFO:root:Epoch[1] Batch [3840]	Speed: 0.72 samples/sec	Train-RPNAcc=0.892874,	RPNLogLoss=0.285401,	RPNL1Loss=0.085071,	RCNNAcc=0.895313,	RCNNLogLoss=0.295307,	RCNNL1Loss=0.289266,	
INFO:root:Epoch[1] Batch [3860]	Speed: 0.75 samples/sec	Train-RPNAcc=0.893122,	RPNLogLoss=0.284730,	RPNL1Loss=0.084993,	RCNNAcc=0.895354,	RCNNLogLoss=0.295009,	RCNNL1Loss=0.289338,	
INFO:root:Epoch[1] Batch [3880]	Speed: 0.73 samples/sec	Train-RPNAcc=0.893479,	RPNLogLoss=0.283902,	RPNL1Loss=0.084802,	RCNNAcc=0.895515,	RCNNLogLoss=0.294501,	RCNNL1Loss=0.289172,	
INFO:root:Epoch[1] Batch [3900]	Speed: 0.74 samples/sec	Train-RPNAcc=0.893734,	RPNLogLoss=0.283224,	RPNL1Loss=0.084746,	RCNNAcc=0.895692,	RCNNLogLoss=0.293985,	RCNNL1Loss=0.289008,	
INFO:root:Epoch[1] Batch [3920]	Speed: 0.77 samples/sec	Train-RPNAcc=0.894068,	RPNLogLoss=0.282454,	RPNL1Loss=0.084545,	RCNNAcc=0.895778,	RCNNLogLoss=0.293700,	RCNNL1Loss=0.288941,	
INFO:root:Epoch[1] Batch [3940]	Speed: 0.80 samples/sec	Train-RPNAcc=0.894430,	RPNLogLoss=0.281573,	RPNL1Loss=0.084358,	RCNNAcc=0.896013,	RCNNLogLoss=0.292983,	RCNNL1Loss=0.288560,	
INFO:root:Epoch[1] Batch [3960]	Speed: 0.73 samples/sec	Train-RPNAcc=0.894672,	RPNLogLoss=0.280852,	RPNL1Loss=0.084197,	RCNNAcc=0.896201,	RCNNLogLoss=0.292472,	RCNNL1Loss=0.288173,	
INFO:root:Epoch[1] Batch [3980]	Speed: 0.74 samples/sec	Train-RPNAcc=0.894941,	RPNLogLoss=0.280201,	RPNL1Loss=0.084106,	RCNNAcc=0.896300,	RCNNLogLoss=0.292150,	RCNNL1Loss=0.288053,	
INFO:root:Epoch[1] Batch [4000]	Speed: 0.79 samples/sec	Train-RPNAcc=0.895286,	RPNLogLoss=0.279377,	RPNL1Loss=0.083921,	RCNNAcc=0.896522,	RCNNLogLoss=0.291513,	RCNNL1Loss=0.287612,	
INFO:root:Epoch[1] Batch [4020]	Speed: 0.70 samples/sec	Train-RPNAcc=0.895602,	RPNLogLoss=0.278600,	RPNL1Loss=0.083741,	RCNNAcc=0.896681,	RCNNLogLoss=0.290987,	RCNNL1Loss=0.287542,	
INFO:root:Epoch[1] Batch [4040]	Speed: 0.78 samples/sec	Train-RPNAcc=0.895944,	RPNLogLoss=0.277805,	RPNL1Loss=0.083567,	RCNNAcc=0.896821,	RCNNLogLoss=0.290634,	RCNNL1Loss=0.287396,	
INFO:root:Epoch[1] Batch [4060]	Speed: 0.77 samples/sec	Train-RPNAcc=0.896282,	RPNLogLoss=0.276975,	RPNL1Loss=0.083359,	RCNNAcc=0.897025,	RCNNLogLoss=0.290139,	RCNNL1Loss=0.287045,	
INFO:root:Epoch[1] Batch [4080]	Speed: 0.74 samples/sec	Train-RPNAcc=0.896521,	RPNLogLoss=0.276407,	RPNL1Loss=0.083295,	RCNNAcc=0.897065,	RCNNLogLoss=0.290016,	RCNNL1Loss=0.287057,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [4100]	Speed: 0.75 samples/sec	Train-RPNAcc=0.896871,	RPNLogLoss=0.275656,	RPNL1Loss=0.083153,	RCNNAcc=0.897268,	RCNNLogLoss=0.289440,	RCNNL1Loss=0.286815,	
INFO:root:Epoch[1] Batch [4120]	Speed: 0.69 samples/sec	Train-RPNAcc=0.897061,	RPNLogLoss=0.275153,	RPNL1Loss=0.083099,	RCNNAcc=0.897321,	RCNNLogLoss=0.289194,	RCNNL1Loss=0.286739,	
INFO:root:Epoch[1] Batch [4140]	Speed: 0.71 samples/sec	Train-RPNAcc=0.897314,	RPNLogLoss=0.274557,	RPNL1Loss=0.083002,	RCNNAcc=0.897455,	RCNNLogLoss=0.288763,	RCNNL1Loss=0.286609,	
INFO:root:Epoch[1] Batch [4160]	Speed: 0.73 samples/sec	Train-RPNAcc=0.897598,	RPNLogLoss=0.273902,	RPNL1Loss=0.082931,	RCNNAcc=0.897583,	RCNNLogLoss=0.288372,	RCNNL1Loss=0.286402,	
INFO:root:Epoch[1] Batch [4180]	Speed: 0.78 samples/sec	Train-RPNAcc=0.897907,	RPNLogLoss=0.273249,	RPNL1Loss=0.082765,	RCNNAcc=0.897684,	RCNNLogLoss=0.288060,	RCNNL1Loss=0.286367,	
INFO:root:Epoch[1] Batch [4200]	Speed: 0.77 samples/sec	Train-RPNAcc=0.898248,	RPNLogLoss=0.272505,	RPNL1Loss=0.082614,	RCNNAcc=0.897835,	RCNNLogLoss=0.287686,	RCNNL1Loss=0.286128,	
INFO:root:Epoch[1] Batch [4220]	Speed: 0.73 samples/sec	Train-RPNAcc=0.898549,	RPNLogLoss=0.271786,	RPNL1Loss=0.082484,	RCNNAcc=0.897990,	RCNNLogLoss=0.287123,	RCNNL1Loss=0.285880,	
INFO:root:Epoch[1] Batch [4240]	Speed: 0.71 samples/sec	Train-RPNAcc=0.898770,	RPNLogLoss=0.271244,	RPNL1Loss=0.082399,	RCNNAcc=0.898062,	RCNNLogLoss=0.286885,	RCNNL1Loss=0.285890,	
INFO:root:Epoch[1] Batch [4260]	Speed: 0.79 samples/sec	Train-RPNAcc=0.899113,	RPNLogLoss=0.270510,	RPNL1Loss=0.082218,	RCNNAcc=0.898142,	RCNNLogLoss=0.286614,	RCNNL1Loss=0.285887,	
INFO:root:Epoch[1] Batch [4280]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899429,	RPNLogLoss=0.269785,	RPNL1Loss=0.082040,	RCNNAcc=0.898312,	RCNNLogLoss=0.286102,	RCNNL1Loss=0.285601,	
INFO:root:Epoch[1] Batch [4300]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899713,	RPNLogLoss=0.269159,	RPNL1Loss=0.081905,	RCNNAcc=0.898438,	RCNNLogLoss=0.285752,	RCNNL1Loss=0.285412,	
INFO:root:Epoch[1] Batch [4320]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899994,	RPNLogLoss=0.268486,	RPNL1Loss=0.081750,	RCNNAcc=0.898606,	RCNNLogLoss=0.285243,	RCNNL1Loss=0.285165,	
INFO:root:Epoch[1] Batch [4340]	Speed: 0.73 samples/sec	Train-RPNAcc=0.900334,	RPNLogLoss=0.267694,	RPNL1Loss=0.081541,	RCNNAcc=0.898740,	RCNNLogLoss=0.284824,	RCNNL1Loss=0.284869,	
INFO:root:Epoch[1] Batch [4360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.900544,	RPNLogLoss=0.267180,	RPNL1Loss=0.081472,	RCNNAcc=0.898824,	RCNNLogLoss=0.284539,	RCNNL1Loss=0.284874,	
INFO:root:Epoch[1] Batch [4380]	Speed: 0.79 samples/sec	Train-RPNAcc=0.900877,	RPNLogLoss=0.266395,	RPNL1Loss=0.081273,	RCNNAcc=0.899013,	RCNNLogLoss=0.283994,	RCNNL1Loss=0.284553,	
INFO:root:Epoch[1] Batch [4400]	Speed: 0.78 samples/sec	Train-RPNAcc=0.901175,	RPNLogLoss=0.265675,	RPNL1Loss=0.081113,	RCNNAcc=0.899162,	RCNNLogLoss=0.283540,	RCNNL1Loss=0.284336,	
INFO:root:Epoch[1] Batch [4420]	Speed: 0.72 samples/sec	Train-RPNAcc=0.901360,	RPNLogLoss=0.265206,	RPNL1Loss=0.081075,	RCNNAcc=0.899238,	RCNNLogLoss=0.283356,	RCNNL1Loss=0.284324,	
INFO:root:Epoch[1] Batch [4440]	Speed: 0.70 samples/sec	Train-RPNAcc=0.901578,	RPNLogLoss=0.264669,	RPNL1Loss=0.080992,	RCNNAcc=0.899375,	RCNNLogLoss=0.282898,	RCNNL1Loss=0.284250,	
INFO:root:Epoch[1] Batch [4460]	Speed: 0.71 samples/sec	Train-RPNAcc=0.901822,	RPNLogLoss=0.264137,	RPNL1Loss=0.080950,	RCNNAcc=0.899434,	RCNNLogLoss=0.282657,	RCNNL1Loss=0.284284,	
INFO:root:Epoch[1] Batch [4480]	Speed: 0.77 samples/sec	Train-RPNAcc=0.902077,	RPNLogLoss=0.263537,	RPNL1Loss=0.080781,	RCNNAcc=0.899546,	RCNNLogLoss=0.282264,	RCNNL1Loss=0.284127,	
INFO:root:Epoch[1] Batch [4500]	Speed: 0.74 samples/sec	Train-RPNAcc=0.902329,	RPNLogLoss=0.262906,	RPNL1Loss=0.080689,	RCNNAcc=0.899734,	RCNNLogLoss=0.281757,	RCNNL1Loss=0.283886,	
INFO:root:Epoch[1] Batch [4520]	Speed: 0.74 samples/sec	Train-RPNAcc=0.902549,	RPNLogLoss=0.262388,	RPNL1Loss=0.080676,	RCNNAcc=0.899865,	RCNNLogLoss=0.281387,	RCNNL1Loss=0.283761,	
INFO:root:Epoch[1] Batch [4540]	Speed: 0.73 samples/sec	Train-RPNAcc=0.902834,	RPNLogLoss=0.261710,	RPNL1Loss=0.080554,	RCNNAcc=0.900053,	RCNNLogLoss=0.280903,	RCNNL1Loss=0.283533,	
INFO:root:Epoch[1] Batch [4560]	Speed: 0.69 samples/sec	Train-RPNAcc=0.903026,	RPNLogLoss=0.261240,	RPNL1Loss=0.080481,	RCNNAcc=0.900116,	RCNNLogLoss=0.280688,	RCNNL1Loss=0.283652,	
INFO:root:Epoch[1] Batch [4580]	Speed: 0.66 samples/sec	Train-RPNAcc=0.903251,	RPNLogLoss=0.260753,	RPNL1Loss=0.080409,	RCNNAcc=0.900174,	RCNNLogLoss=0.280480,	RCNNL1Loss=0.283566,	
INFO:root:Epoch[1] Batch [4600]	Speed: 0.74 samples/sec	Train-RPNAcc=0.903517,	RPNLogLoss=0.260240,	RPNL1Loss=0.080371,	RCNNAcc=0.900271,	RCNNLogLoss=0.280162,	RCNNL1Loss=0.283449,	
INFO:root:Epoch[1] Batch [4620]	Speed: 0.78 samples/sec	Train-RPNAcc=0.903788,	RPNLogLoss=0.259644,	RPNL1Loss=0.080241,	RCNNAcc=0.900426,	RCNNLogLoss=0.279678,	RCNNL1Loss=0.283259,	
INFO:root:Epoch[1] Batch [4640]	Speed: 0.73 samples/sec	Train-RPNAcc=0.904017,	RPNLogLoss=0.259068,	RPNL1Loss=0.080089,	RCNNAcc=0.900540,	RCNNLogLoss=0.279335,	RCNNL1Loss=0.282956,	
INFO:root:Epoch[1] Batch [4660]	Speed: 0.78 samples/sec	Train-RPNAcc=0.904263,	RPNLogLoss=0.258475,	RPNL1Loss=0.079964,	RCNNAcc=0.900665,	RCNNLogLoss=0.278925,	RCNNL1Loss=0.282718,	
INFO:root:Epoch[1] Batch [4680]	Speed: 0.74 samples/sec	Train-RPNAcc=0.904521,	RPNLogLoss=0.257890,	RPNL1Loss=0.079857,	RCNNAcc=0.900751,	RCNNLogLoss=0.278668,	RCNNL1Loss=0.282745,	
INFO:root:Epoch[1] Batch [4700]	Speed: 0.80 samples/sec	Train-RPNAcc=0.904804,	RPNLogLoss=0.257231,	RPNL1Loss=0.079689,	RCNNAcc=0.900875,	RCNNLogLoss=0.278281,	RCNNL1Loss=0.282483,	
INFO:root:Epoch[1] Batch [4720]	Speed: 0.71 samples/sec	Train-RPNAcc=0.905028,	RPNLogLoss=0.256661,	RPNL1Loss=0.079593,	RCNNAcc=0.900946,	RCNNLogLoss=0.277976,	RCNNL1Loss=0.282334,	
INFO:root:Epoch[1] Batch [4740]	Speed: 0.77 samples/sec	Train-RPNAcc=0.905306,	RPNLogLoss=0.256017,	RPNL1Loss=0.079454,	RCNNAcc=0.901087,	RCNNLogLoss=0.277564,	RCNNL1Loss=0.282172,	
INFO:root:Epoch[1] Batch [4760]	Speed: 0.73 samples/sec	Train-RPNAcc=0.905526,	RPNLogLoss=0.255477,	RPNL1Loss=0.079378,	RCNNAcc=0.901170,	RCNNLogLoss=0.277305,	RCNNL1Loss=0.282113,	
INFO:root:Epoch[1] Batch [4780]	Speed: 0.71 samples/sec	Train-RPNAcc=0.905726,	RPNLogLoss=0.255010,	RPNL1Loss=0.079347,	RCNNAcc=0.901184,	RCNNLogLoss=0.277140,	RCNNL1Loss=0.282194,	
INFO:root:Epoch[1] Batch [4800]	Speed: 0.80 samples/sec	Train-RPNAcc=0.906025,	RPNLogLoss=0.254307,	RPNL1Loss=0.079162,	RCNNAcc=0.901425,	RCNNLogLoss=0.276460,	RCNNL1Loss=0.281712,	
INFO:root:Epoch[1] Batch [4820]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906253,	RPNLogLoss=0.253766,	RPNL1Loss=0.079084,	RCNNAcc=0.901518,	RCNNLogLoss=0.276129,	RCNNL1Loss=0.281576,	
INFO:root:Epoch[1] Batch [4840]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906539,	RPNLogLoss=0.253150,	RPNL1Loss=0.078924,	RCNNAcc=0.901715,	RCNNLogLoss=0.275593,	RCNNL1Loss=0.281237,	
INFO:root:Epoch[1] Batch [4860]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906838,	RPNLogLoss=0.252472,	RPNL1Loss=0.078776,	RCNNAcc=0.901816,	RCNNLogLoss=0.275262,	RCNNL1Loss=0.281074,	
INFO:root:Epoch[1] Batch [4880]	Speed: 0.73 samples/sec	Train-RPNAcc=0.907020,	RPNLogLoss=0.252081,	RPNL1Loss=0.078806,	RCNNAcc=0.901876,	RCNNLogLoss=0.275095,	RCNNL1Loss=0.280980,	
INFO:root:Epoch[1] Batch [4900]	Speed: 0.80 samples/sec	Train-RPNAcc=0.907308,	RPNLogLoss=0.251394,	RPNL1Loss=0.078645,	RCNNAcc=0.902067,	RCNNLogLoss=0.274503,	RCNNL1Loss=0.280646,	
INFO:root:Epoch[1] Batch [4920]	Speed: 0.72 samples/sec	Train-RPNAcc=0.907545,	RPNLogLoss=0.250798,	RPNL1Loss=0.078515,	RCNNAcc=0.902162,	RCNNLogLoss=0.274184,	RCNNL1Loss=0.280613,	
INFO:root:Epoch[1] Batch [4940]	Speed: 0.75 samples/sec	Train-RPNAcc=0.907778,	RPNLogLoss=0.250253,	RPNL1Loss=0.078414,	RCNNAcc=0.902324,	RCNNLogLoss=0.273814,	RCNNL1Loss=0.280308,	
INFO:root:Epoch[1] Batch [4960]	Speed: 0.73 samples/sec	Train-RPNAcc=0.908055,	RPNLogLoss=0.249642,	RPNL1Loss=0.078238,	RCNNAcc=0.902434,	RCNNLogLoss=0.273491,	RCNNL1Loss=0.280126,	
INFO:root:Epoch[1] Batch [4980]	Speed: 0.71 samples/sec	Train-RPNAcc=0.908252,	RPNLogLoss=0.249143,	RPNL1Loss=0.078156,	RCNNAcc=0.902445,	RCNNLogLoss=0.273346,	RCNNL1Loss=0.280018,	
INFO:root:Epoch[1] Batch [5000]	Speed: 0.77 samples/sec	Train-RPNAcc=0.908489,	RPNLogLoss=0.248578,	RPNL1Loss=0.078025,	RCNNAcc=0.902573,	RCNNLogLoss=0.272951,	RCNNL1Loss=0.279818,	
INFO:root:Epoch[1] Batch [5020]	Speed: 0.75 samples/sec	Train-RPNAcc=0.908760,	RPNLogLoss=0.247965,	RPNL1Loss=0.077843,	RCNNAcc=0.902737,	RCNNLogLoss=0.272524,	RCNNL1Loss=0.279552,	
INFO:root:Epoch[1] Batch [5040]	Speed: 0.74 samples/sec	Train-RPNAcc=0.908936,	RPNLogLoss=0.247545,	RPNL1Loss=0.077784,	RCNNAcc=0.902858,	RCNNLogLoss=0.272181,	RCNNL1Loss=0.279498,	
INFO:root:Epoch[1] Batch [5060]	Speed: 0.72 samples/sec	Train-RPNAcc=0.909163,	RPNLogLoss=0.247003,	RPNL1Loss=0.077716,	RCNNAcc=0.902996,	RCNNLogLoss=0.271752,	RCNNL1Loss=0.279341,	
INFO:root:Epoch[1] Batch [5080]	Speed: 0.78 samples/sec	Train-RPNAcc=0.909435,	RPNLogLoss=0.246408,	RPNL1Loss=0.077546,	RCNNAcc=0.903124,	RCNNLogLoss=0.271336,	RCNNL1Loss=0.279091,	
INFO:root:Epoch[1] Batch [5100]	Speed: 0.70 samples/sec	Train-RPNAcc=0.909692,	RPNLogLoss=0.245802,	RPNL1Loss=0.077445,	RCNNAcc=0.903208,	RCNNLogLoss=0.271054,	RCNNL1Loss=0.278974,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [5120]	Speed: 0.70 samples/sec	Train-RPNAcc=0.909963,	RPNLogLoss=0.245170,	RPNL1Loss=0.077298,	RCNNAcc=0.903351,	RCNNLogLoss=0.270594,	RCNNL1Loss=0.278668,	
INFO:root:Epoch[1] Batch [5140]	Speed: 0.75 samples/sec	Train-RPNAcc=0.910224,	RPNLogLoss=0.244568,	RPNL1Loss=0.077164,	RCNNAcc=0.903474,	RCNNLogLoss=0.270211,	RCNNL1Loss=0.278516,	
INFO:root:Epoch[1] Batch [5160]	Speed: 0.74 samples/sec	Train-RPNAcc=0.910466,	RPNLogLoss=0.243956,	RPNL1Loss=0.077031,	RCNNAcc=0.903613,	RCNNLogLoss=0.269810,	RCNNL1Loss=0.278249,	
INFO:root:Epoch[1] Batch [5180]	Speed: 0.77 samples/sec	Train-RPNAcc=0.910690,	RPNLogLoss=0.243444,	RPNL1Loss=0.076918,	RCNNAcc=0.903803,	RCNNLogLoss=0.269320,	RCNNL1Loss=0.277901,	
INFO:root:Epoch[1] Batch [5200]	Speed: 0.71 samples/sec	Train-RPNAcc=0.910879,	RPNLogLoss=0.243013,	RPNL1Loss=0.076818,	RCNNAcc=0.903937,	RCNNLogLoss=0.268872,	RCNNL1Loss=0.277825,	
INFO:root:Epoch[1] Batch [5220]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911058,	RPNLogLoss=0.242564,	RPNL1Loss=0.076743,	RCNNAcc=0.904028,	RCNNLogLoss=0.268582,	RCNNL1Loss=0.277632,	
INFO:root:Epoch[1] Batch [5240]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911271,	RPNLogLoss=0.242094,	RPNL1Loss=0.076677,	RCNNAcc=0.904160,	RCNNLogLoss=0.268168,	RCNNL1Loss=0.277501,	
INFO:root:Epoch[1] Batch [5260]	Speed: 0.76 samples/sec	Train-RPNAcc=0.911492,	RPNLogLoss=0.241602,	RPNL1Loss=0.076578,	RCNNAcc=0.904259,	RCNNLogLoss=0.267887,	RCNNL1Loss=0.277402,	
INFO:root:Epoch[1] Batch [5280]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911745,	RPNLogLoss=0.241048,	RPNL1Loss=0.076472,	RCNNAcc=0.904358,	RCNNLogLoss=0.267521,	RCNNL1Loss=0.277258,	
INFO:root:Epoch[1] Batch [5300]	Speed: 0.70 samples/sec	Train-RPNAcc=0.911932,	RPNLogLoss=0.240665,	RPNL1Loss=0.076497,	RCNNAcc=0.904405,	RCNNLogLoss=0.267390,	RCNNL1Loss=0.277314,	
INFO:root:Epoch[1] Batch [5320]	Speed: 0.75 samples/sec	Train-RPNAcc=0.912115,	RPNLogLoss=0.240178,	RPNL1Loss=0.076399,	RCNNAcc=0.904534,	RCNNLogLoss=0.267043,	RCNNL1Loss=0.277159,	
INFO:root:Epoch[1] Batch [5340]	Speed: 0.75 samples/sec	Train-RPNAcc=0.912335,	RPNLogLoss=0.239681,	RPNL1Loss=0.076302,	RCNNAcc=0.904632,	RCNNLogLoss=0.266712,	RCNNL1Loss=0.277067,	
INFO:root:Epoch[1] Batch [5360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.912546,	RPNLogLoss=0.239202,	RPNL1Loss=0.076228,	RCNNAcc=0.904707,	RCNNLogLoss=0.266483,	RCNNL1Loss=0.276950,	
INFO:root:Epoch[1] Batch [5380]	Speed: 0.73 samples/sec	Train-RPNAcc=0.912774,	RPNLogLoss=0.238676,	RPNL1Loss=0.076123,	RCNNAcc=0.904893,	RCNNLogLoss=0.265949,	RCNNL1Loss=0.276662,	
INFO:root:Epoch[1] Batch [5400]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913004,	RPNLogLoss=0.238117,	RPNL1Loss=0.075997,	RCNNAcc=0.904990,	RCNNLogLoss=0.265616,	RCNNL1Loss=0.276434,	
INFO:root:Epoch[1] Batch [5420]	Speed: 0.69 samples/sec	Train-RPNAcc=0.913177,	RPNLogLoss=0.237754,	RPNL1Loss=0.075970,	RCNNAcc=0.905035,	RCNNLogLoss=0.265429,	RCNNL1Loss=0.276429,	
INFO:root:Epoch[1] Batch [5440]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913411,	RPNLogLoss=0.237215,	RPNL1Loss=0.075830,	RCNNAcc=0.905153,	RCNNLogLoss=0.265066,	RCNNL1Loss=0.276254,	
INFO:root:Epoch[1] Batch [5460]	Speed: 0.72 samples/sec	Train-RPNAcc=0.913592,	RPNLogLoss=0.236801,	RPNL1Loss=0.075742,	RCNNAcc=0.905177,	RCNNLogLoss=0.264962,	RCNNL1Loss=0.276302,	
INFO:root:Epoch[1] Batch [5480]	Speed: 0.70 samples/sec	Train-RPNAcc=0.913738,	RPNLogLoss=0.236452,	RPNL1Loss=0.075719,	RCNNAcc=0.905229,	RCNNLogLoss=0.264747,	RCNNL1Loss=0.276287,	
INFO:root:Epoch[1] Batch [5500]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913955,	RPNLogLoss=0.235980,	RPNL1Loss=0.075598,	RCNNAcc=0.905313,	RCNNLogLoss=0.264466,	RCNNL1Loss=0.276218,	
INFO:root:Epoch[1] Batch [5520]	Speed: 0.74 samples/sec	Train-RPNAcc=0.914161,	RPNLogLoss=0.235513,	RPNL1Loss=0.075502,	RCNNAcc=0.905414,	RCNNLogLoss=0.264185,	RCNNL1Loss=0.276074,	
INFO:root:Epoch[1] Batch [5540]	Speed: 0.69 samples/sec	Train-RPNAcc=0.914352,	RPNLogLoss=0.235120,	RPNL1Loss=0.075437,	RCNNAcc=0.905459,	RCNNLogLoss=0.264035,	RCNNL1Loss=0.276114,	
INFO:root:Epoch[1] Batch [5560]	Speed: 0.74 samples/sec	Train-RPNAcc=0.914546,	RPNLogLoss=0.234689,	RPNL1Loss=0.075365,	RCNNAcc=0.905543,	RCNNLogLoss=0.263714,	RCNNL1Loss=0.276001,	
INFO:root:Epoch[1] Batch [5580]	Speed: 0.72 samples/sec	Train-RPNAcc=0.914749,	RPNLogLoss=0.234252,	RPNL1Loss=0.075319,	RCNNAcc=0.905593,	RCNNLogLoss=0.263549,	RCNNL1Loss=0.275978,	
INFO:root:Epoch[1] Batch [5600]	Speed: 0.75 samples/sec	Train-RPNAcc=0.914948,	RPNLogLoss=0.233796,	RPNL1Loss=0.075211,	RCNNAcc=0.905666,	RCNNLogLoss=0.263305,	RCNNL1Loss=0.275851,	
INFO:root:Epoch[1] Batch [5620]	Speed: 0.71 samples/sec	Train-RPNAcc=0.915075,	RPNLogLoss=0.233499,	RPNL1Loss=0.075147,	RCNNAcc=0.905708,	RCNNLogLoss=0.263132,	RCNNL1Loss=0.275739,	
INFO:root:Epoch[1] Batch [5640]	Speed: 0.74 samples/sec	Train-RPNAcc=0.915270,	RPNLogLoss=0.233055,	RPNL1Loss=0.075075,	RCNNAcc=0.905781,	RCNNLogLoss=0.262898,	RCNNL1Loss=0.275707,	
INFO:root:Epoch[1] Batch [5660]	Speed: 0.75 samples/sec	Train-RPNAcc=0.915443,	RPNLogLoss=0.232677,	RPNL1Loss=0.075037,	RCNNAcc=0.905865,	RCNNLogLoss=0.262610,	RCNNL1Loss=0.275551,	
INFO:root:Epoch[1] Batch [5680]	Speed: 0.76 samples/sec	Train-RPNAcc=0.915650,	RPNLogLoss=0.232207,	RPNL1Loss=0.074952,	RCNNAcc=0.905953,	RCNNLogLoss=0.262314,	RCNNL1Loss=0.275368,	
INFO:root:Epoch[1] Batch [5700]	Speed: 0.74 samples/sec	Train-RPNAcc=0.915873,	RPNLogLoss=0.231669,	RPNL1Loss=0.074855,	RCNNAcc=0.906128,	RCNNLogLoss=0.261821,	RCNNL1Loss=0.274966,	
INFO:root:Epoch[1] Batch [5720]	Speed: 0.77 samples/sec	Train-RPNAcc=0.916065,	RPNLogLoss=0.231197,	RPNL1Loss=0.074731,	RCNNAcc=0.906224,	RCNNLogLoss=0.261472,	RCNNL1Loss=0.274897,	
INFO:root:Epoch[1] Batch [5740]	Speed: 0.70 samples/sec	Train-RPNAcc=0.916239,	RPNLogLoss=0.230762,	RPNL1Loss=0.074640,	RCNNAcc=0.906264,	RCNNLogLoss=0.261274,	RCNNL1Loss=0.274790,	
INFO:root:Epoch[1] Batch [5760]	Speed: 0.71 samples/sec	Train-RPNAcc=0.916416,	RPNLogLoss=0.230374,	RPNL1Loss=0.074609,	RCNNAcc=0.906321,	RCNNLogLoss=0.261136,	RCNNL1Loss=0.274685,	
INFO:root:Epoch[1] Batch [5780]	Speed: 0.75 samples/sec	Train-RPNAcc=0.916576,	RPNLogLoss=0.230022,	RPNL1Loss=0.074523,	RCNNAcc=0.906385,	RCNNLogLoss=0.260929,	RCNNL1Loss=0.274483,	
INFO:root:Epoch[1] Batch [5800]	Speed: 0.76 samples/sec	Train-RPNAcc=0.916786,	RPNLogLoss=0.229533,	RPNL1Loss=0.074439,	RCNNAcc=0.906522,	RCNNLogLoss=0.260504,	RCNNL1Loss=0.274300,	
INFO:root:Epoch[1] Batch [5820]	Speed: 0.68 samples/sec	Train-RPNAcc=0.916913,	RPNLogLoss=0.229241,	RPNL1Loss=0.074432,	RCNNAcc=0.906524,	RCNNLogLoss=0.260447,	RCNNL1Loss=0.274352,	
INFO:root:Epoch[1] Batch [5840]	Speed: 0.75 samples/sec	Train-RPNAcc=0.917094,	RPNLogLoss=0.228819,	RPNL1Loss=0.074358,	RCNNAcc=0.906622,	RCNNLogLoss=0.260130,	RCNNL1Loss=0.274158,	
INFO:root:Epoch[1] Batch [5860]	Speed: 0.76 samples/sec	Train-RPNAcc=0.917269,	RPNLogLoss=0.228397,	RPNL1Loss=0.074241,	RCNNAcc=0.906741,	RCNNLogLoss=0.259755,	RCNNL1Loss=0.273905,	
INFO:root:Epoch[1] Batch [5880]	Speed: 0.74 samples/sec	Train-RPNAcc=0.917462,	RPNLogLoss=0.227935,	RPNL1Loss=0.074188,	RCNNAcc=0.906811,	RCNNLogLoss=0.259518,	RCNNL1Loss=0.273790,	
INFO:root:Epoch[1] Batch [5900]	Speed: 0.72 samples/sec	Train-RPNAcc=0.917636,	RPNLogLoss=0.227541,	RPNL1Loss=0.074108,	RCNNAcc=0.906876,	RCNNLogLoss=0.259261,	RCNNL1Loss=0.273655,	
INFO:root:Epoch[1] Batch [5920]	Speed: 0.72 samples/sec	Train-RPNAcc=0.917810,	RPNLogLoss=0.227157,	RPNL1Loss=0.074032,	RCNNAcc=0.906963,	RCNNLogLoss=0.258973,	RCNNL1Loss=0.273480,	
INFO:root:Epoch[1] Batch [5940]	Speed: 0.68 samples/sec	Train-RPNAcc=0.918016,	RPNLogLoss=0.226708,	RPNL1Loss=0.073941,	RCNNAcc=0.907050,	RCNNLogLoss=0.258704,	RCNNL1Loss=0.273414,	
INFO:root:Epoch[1] Batch [5960]	Speed: 0.71 samples/sec	Train-RPNAcc=0.918188,	RPNLogLoss=0.226282,	RPNL1Loss=0.073829,	RCNNAcc=0.907116,	RCNNLogLoss=0.258518,	RCNNL1Loss=0.273364,	
INFO:root:Epoch[1] Batch [5980]	Speed: 0.76 samples/sec	Train-RPNAcc=0.918367,	RPNLogLoss=0.225872,	RPNL1Loss=0.073724,	RCNNAcc=0.907201,	RCNNLogLoss=0.258268,	RCNNL1Loss=0.273211,	
INFO:root:Epoch[1] Batch [6000]	Speed: 0.72 samples/sec	Train-RPNAcc=0.918533,	RPNLogLoss=0.225446,	RPNL1Loss=0.073605,	RCNNAcc=0.907267,	RCNNLogLoss=0.258066,	RCNNL1Loss=0.273150,	
INFO:root:Epoch[1] Batch [6020]	Speed: 0.74 samples/sec	Train-RPNAcc=0.918716,	RPNLogLoss=0.225025,	RPNL1Loss=0.073491,	RCNNAcc=0.907324,	RCNNLogLoss=0.257840,	RCNNL1Loss=0.272991,	
INFO:root:Epoch[1] Batch [6040]	Speed: 0.73 samples/sec	Train-RPNAcc=0.918891,	RPNLogLoss=0.224585,	RPNL1Loss=0.073414,	RCNNAcc=0.907415,	RCNNLogLoss=0.257573,	RCNNL1Loss=0.272863,	
INFO:root:Epoch[1] Batch [6060]	Speed: 0.71 samples/sec	Train-RPNAcc=0.919074,	RPNLogLoss=0.224132,	RPNL1Loss=0.073337,	RCNNAcc=0.907513,	RCNNLogLoss=0.257244,	RCNNL1Loss=0.272696,	
INFO:root:Epoch[1] Batch [6080]	Speed: 0.73 samples/sec	Train-RPNAcc=0.919239,	RPNLogLoss=0.223751,	RPNL1Loss=0.073258,	RCNNAcc=0.907604,	RCNNLogLoss=0.256945,	RCNNL1Loss=0.272629,	
INFO:root:Epoch[1] Batch [6100]	Speed: 0.71 samples/sec	Train-RPNAcc=0.919393,	RPNLogLoss=0.223468,	RPNL1Loss=0.073195,	RCNNAcc=0.907670,	RCNNLogLoss=0.256713,	RCNNL1Loss=0.272679,	
INFO:root:Epoch[1] Batch [6120]	Speed: 0.72 samples/sec	Train-RPNAcc=0.919560,	RPNLogLoss=0.223062,	RPNL1Loss=0.073111,	RCNNAcc=0.907777,	RCNNLogLoss=0.256368,	RCNNL1Loss=0.272506,	
INFO:root:Epoch[1] Batch [6140]	Speed: 0.69 samples/sec	Train-RPNAcc=0.919707,	RPNLogLoss=0.222685,	RPNL1Loss=0.073026,	RCNNAcc=0.907824,	RCNNLogLoss=0.256183,	RCNNL1Loss=0.272461,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [6160]	Speed: 0.73 samples/sec	Train-RPNAcc=0.919890,	RPNLogLoss=0.222243,	RPNL1Loss=0.072896,	RCNNAcc=0.907886,	RCNNLogLoss=0.255935,	RCNNL1Loss=0.272342,	
INFO:root:Epoch[1] Batch [6180]	Speed: 0.78 samples/sec	Train-RPNAcc=0.920087,	RPNLogLoss=0.221745,	RPNL1Loss=0.072751,	RCNNAcc=0.908035,	RCNNLogLoss=0.255503,	RCNNL1Loss=0.272036,	
INFO:root:Epoch[1] Batch [6200]	Speed: 0.71 samples/sec	Train-RPNAcc=0.920246,	RPNLogLoss=0.221390,	RPNL1Loss=0.072714,	RCNNAcc=0.908067,	RCNNLogLoss=0.255362,	RCNNL1Loss=0.272016,	
INFO:root:Epoch[1] Batch [6220]	Speed: 0.74 samples/sec	Train-RPNAcc=0.920407,	RPNLogLoss=0.221017,	RPNL1Loss=0.072605,	RCNNAcc=0.908151,	RCNNLogLoss=0.255081,	RCNNL1Loss=0.271831,	
INFO:root:Epoch[1] Batch [6240]	Speed: 0.70 samples/sec	Train-RPNAcc=0.920575,	RPNLogLoss=0.220620,	RPNL1Loss=0.072575,	RCNNAcc=0.908213,	RCNNLogLoss=0.254873,	RCNNL1Loss=0.271763,	
INFO:root:Epoch[1] Batch [6260]	Speed: 0.72 samples/sec	Train-RPNAcc=0.920707,	RPNLogLoss=0.220303,	RPNL1Loss=0.072522,	RCNNAcc=0.908234,	RCNNLogLoss=0.254789,	RCNNL1Loss=0.271840,	
INFO:root:Epoch[1] Batch [6280]	Speed: 0.74 samples/sec	Train-RPNAcc=0.920877,	RPNLogLoss=0.219907,	RPNL1Loss=0.072442,	RCNNAcc=0.908335,	RCNNLogLoss=0.254518,	RCNNL1Loss=0.271698,	
INFO:root:Epoch[1] Batch [6300]	Speed: 0.70 samples/sec	Train-RPNAcc=0.921063,	RPNLogLoss=0.219472,	RPNL1Loss=0.072360,	RCNNAcc=0.908428,	RCNNLogLoss=0.254286,	RCNNL1Loss=0.271578,	
INFO:root:Epoch[1] Batch [6320]	Speed: 0.73 samples/sec	Train-RPNAcc=0.921225,	RPNLogLoss=0.219083,	RPNL1Loss=0.072266,	RCNNAcc=0.908538,	RCNNLogLoss=0.253996,	RCNNL1Loss=0.271370,	
INFO:root:Epoch[1] Batch [6340]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921383,	RPNLogLoss=0.218714,	RPNL1Loss=0.072193,	RCNNAcc=0.908613,	RCNNLogLoss=0.253787,	RCNNL1Loss=0.271310,	
INFO:root:Epoch[1] Batch [6360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921558,	RPNLogLoss=0.218363,	RPNL1Loss=0.072154,	RCNNAcc=0.908671,	RCNNLogLoss=0.253604,	RCNNL1Loss=0.271341,	
INFO:root:Epoch[1] Batch [6380]	Speed: 0.75 samples/sec	Train-RPNAcc=0.921720,	RPNLogLoss=0.217990,	RPNL1Loss=0.072061,	RCNNAcc=0.908757,	RCNNLogLoss=0.253311,	RCNNL1Loss=0.271175,	
INFO:root:Epoch[1] Batch [6400]	Speed: 0.72 samples/sec	Train-RPNAcc=0.921866,	RPNLogLoss=0.217653,	RPNL1Loss=0.071990,	RCNNAcc=0.908778,	RCNNLogLoss=0.253197,	RCNNL1Loss=0.271105,	
INFO:root:Epoch[1] Batch [6420]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921986,	RPNLogLoss=0.217403,	RPNL1Loss=0.071991,	RCNNAcc=0.908775,	RCNNLogLoss=0.253155,	RCNNL1Loss=0.271151,	
INFO:root:Epoch[1] Batch [6440]	Speed: 0.70 samples/sec	Train-RPNAcc=0.922125,	RPNLogLoss=0.217050,	RPNL1Loss=0.071926,	RCNNAcc=0.908817,	RCNNLogLoss=0.252955,	RCNNL1Loss=0.271171,	
INFO:root:Epoch[1] Batch [6460]	Speed: 0.73 samples/sec	Train-RPNAcc=0.922285,	RPNLogLoss=0.216678,	RPNL1Loss=0.071838,	RCNNAcc=0.908850,	RCNNLogLoss=0.252828,	RCNNL1Loss=0.271139,	
INFO:root:Epoch[1] Batch [6480]	Speed: 0.74 samples/sec	Train-RPNAcc=0.922449,	RPNLogLoss=0.216274,	RPNL1Loss=0.071729,	RCNNAcc=0.908936,	RCNNLogLoss=0.252551,	RCNNL1Loss=0.270984,	
INFO:root:Epoch[1] Batch [6500]	Speed: 0.69 samples/sec	Train-RPNAcc=0.922580,	RPNLogLoss=0.215951,	RPNL1Loss=0.071688,	RCNNAcc=0.908967,	RCNNLogLoss=0.252402,	RCNNL1Loss=0.271004,	
INFO:root:Epoch[1] Batch [6520]	Speed: 0.75 samples/sec	Train-RPNAcc=0.922739,	RPNLogLoss=0.215572,	RPNL1Loss=0.071603,	RCNNAcc=0.909047,	RCNNLogLoss=0.252140,	RCNNL1Loss=0.270894,	
INFO:root:Epoch[1] Batch [6540]	Speed: 0.72 samples/sec	Train-RPNAcc=0.922905,	RPNLogLoss=0.215178,	RPNL1Loss=0.071499,	RCNNAcc=0.909120,	RCNNLogLoss=0.251894,	RCNNL1Loss=0.270804,	
INFO:root:Epoch[1] Batch [6560]	Speed: 0.75 samples/sec	Train-RPNAcc=0.923050,	RPNLogLoss=0.214833,	RPNL1Loss=0.071420,	RCNNAcc=0.909174,	RCNNLogLoss=0.251704,	RCNNL1Loss=0.270731,	
INFO:root:Epoch[1] Batch [6580]	Speed: 0.74 samples/sec	Train-RPNAcc=0.923169,	RPNLogLoss=0.214526,	RPNL1Loss=0.071377,	RCNNAcc=0.909232,	RCNNLogLoss=0.251507,	RCNNL1Loss=0.270643,	
INFO:root:Epoch[1] Batch [6600]	Speed: 0.73 samples/sec	Train-RPNAcc=0.923320,	RPNLogLoss=0.214177,	RPNL1Loss=0.071335,	RCNNAcc=0.909318,	RCNNLogLoss=0.251246,	RCNNL1Loss=0.270514,	
INFO:root:Epoch[1] Batch [6620]	Speed: 0.71 samples/sec	Train-RPNAcc=0.923453,	RPNLogLoss=0.213872,	RPNL1Loss=0.071273,	RCNNAcc=0.909360,	RCNNLogLoss=0.251106,	RCNNL1Loss=0.270503,	
INFO:root:Epoch[1] Batch [6640]	Speed: 0.67 samples/sec	Train-RPNAcc=0.923560,	RPNLogLoss=0.213606,	RPNL1Loss=0.071256,	RCNNAcc=0.909413,	RCNNLogLoss=0.250900,	RCNNL1Loss=0.270498,	
INFO:root:Epoch[1] Batch [6660]	Speed: 0.74 samples/sec	Train-RPNAcc=0.923694,	RPNLogLoss=0.213276,	RPNL1Loss=0.071197,	RCNNAcc=0.909516,	RCNNLogLoss=0.250608,	RCNNL1Loss=0.270439,	
INFO:root:Epoch[1] Batch [6680]	Speed: 0.72 samples/sec	Train-RPNAcc=0.923813,	RPNLogLoss=0.212986,	RPNL1Loss=0.071154,	RCNNAcc=0.909600,	RCNNLogLoss=0.250380,	RCNNL1Loss=0.270286,	
INFO:root:Epoch[1] Batch [6700]	Speed: 0.72 samples/sec	Train-RPNAcc=0.923990,	RPNLogLoss=0.212577,	RPNL1Loss=0.071047,	RCNNAcc=0.909714,	RCNNLogLoss=0.250062,	RCNNL1Loss=0.270077,	
INFO:root:Epoch[1] Batch [6720]	Speed: 0.74 samples/sec	Train-RPNAcc=0.924134,	RPNLogLoss=0.212233,	RPNL1Loss=0.071016,	RCNNAcc=0.909795,	RCNNLogLoss=0.249844,	RCNNL1Loss=0.270049,	
INFO:root:Epoch[1] Batch [6740]	Speed: 0.69 samples/sec	Train-RPNAcc=0.924264,	RPNLogLoss=0.211950,	RPNL1Loss=0.070987,	RCNNAcc=0.909844,	RCNNLogLoss=0.249689,	RCNNL1Loss=0.270040,	
INFO:root:Epoch[1] Batch [6760]	Speed: 0.74 samples/sec	Train-RPNAcc=0.924400,	RPNLogLoss=0.211590,	RPNL1Loss=0.070882,	RCNNAcc=0.909927,	RCNNLogLoss=0.249435,	RCNNL1Loss=0.269953,	
INFO:root:Epoch[1] Batch [6780]	Speed: 0.71 samples/sec	Train-RPNAcc=0.924562,	RPNLogLoss=0.211205,	RPNL1Loss=0.070804,	RCNNAcc=0.909996,	RCNNLogLoss=0.249206,	RCNNL1Loss=0.269791,	
INFO:root:Epoch[1] Batch [6800]	Speed: 0.70 samples/sec	Train-RPNAcc=0.924675,	RPNLogLoss=0.210946,	RPNL1Loss=0.070781,	RCNNAcc=0.909991,	RCNNLogLoss=0.249189,	RCNNL1Loss=0.269869,	
INFO:root:Epoch[1] Batch [6820]	Speed: 0.70 samples/sec	Train-RPNAcc=0.924771,	RPNLogLoss=0.210679,	RPNL1Loss=0.070780,	RCNNAcc=0.910039,	RCNNLogLoss=0.249048,	RCNNL1Loss=0.269827,	
INFO:root:Epoch[1] Batch [6840]	Speed: 0.72 samples/sec	Train-RPNAcc=0.924908,	RPNLogLoss=0.210382,	RPNL1Loss=0.070718,	RCNNAcc=0.910064,	RCNNLogLoss=0.248947,	RCNNL1Loss=0.269828,	
INFO:root:Epoch[1] Train-RPNAcc=0.924962
INFO:root:Epoch[1] Train-RPNLogLoss=0.210268
INFO:root:Epoch[1] Train-RPNL1Loss=0.070704
INFO:root:Epoch[1] Train-RCNNAcc=0.910088
INFO:root:Epoch[1] Train-RCNNLogLoss=0.248865
INFO:root:Epoch[1] Train-RCNNL1Loss=0.269769
INFO:root:Epoch[1] Time cost=8478.565
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
[12:04:44] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [12:04:44] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f471823771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f4718352ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f4718a263da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f47c1766adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f47c176640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f47c197d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f47c197ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47c2cf4f45]
[bt] (32) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 139, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 436, in fit
    callback(epoch, self.symbol, arg_params, aux_params)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/callback.py", line 41, in _callback
    arg['bbox_pred_weight_test'] = (arg['bbox_pred_weight'].T * mx.nd.array(stds)).T
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 141, in __mul__
    return multiply(self, other)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 763, in multiply
    None)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 683, in _ufunc_helper
    return fn_array(lhs, rhs)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/ndarray.py", line 131, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [12:04:44] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f471823771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f4718352ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f4718a263da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f47c1766adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f47c176640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f47c197d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f47c197ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47c2cf4f45]
[bt] (32) python() [0x578c4e]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[15:31:36] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.32 samples/sec	Train-RPNAcc=0.568266,	RPNLogLoss=0.690575,	RPNL1Loss=0.205601,	RCNNAcc=0.167039,	RCNNLogLoss=2.897209,	RCNNL1Loss=0.392915,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.35 samples/sec	Train-RPNAcc=0.574028,	RPNLogLoss=0.690181,	RPNL1Loss=0.176274,	RCNNAcc=0.455602,	RCNNLogLoss=2.330655,	RCNNL1Loss=0.368696,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.35 samples/sec	Train-RPNAcc=0.590100,	RPNLogLoss=0.688450,	RPNL1Loss=0.173849,	RCNNAcc=0.580943,	RCNNLogLoss=1.935022,	RCNNL1Loss=0.367200,	
INFO:root:Epoch[1] Batch [80]	Speed: 0.39 samples/sec	Train-RPNAcc=0.598139,	RPNLogLoss=0.687671,	RPNL1Loss=0.181154,	RCNNAcc=0.653646,	RCNNLogLoss=1.654464,	RCNNL1Loss=0.346961,	
INFO:root:Epoch[1] Batch [100]	Speed: 0.37 samples/sec	Train-RPNAcc=0.608640,	RPNLogLoss=0.686473,	RPNL1Loss=0.170385,	RCNNAcc=0.696782,	RCNNLogLoss=1.454009,	RCNNL1Loss=0.333254,	
INFO:root:Epoch[1] Batch [120]	Speed: 0.35 samples/sec	Train-RPNAcc=0.615928,	RPNLogLoss=0.685261,	RPNL1Loss=0.160919,	RCNNAcc=0.728435,	RCNNLogLoss=1.300138,	RCNNL1Loss=0.320475,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.31 samples/sec	Train-RPNAcc=0.624197,	RPNLogLoss=0.683894,	RPNL1Loss=0.158642,	RCNNAcc=0.747396,	RCNNLogLoss=1.190032,	RCNNL1Loss=0.320617,	
INFO:root:Epoch[1] Batch [160]	Speed: 0.34 samples/sec	Train-RPNAcc=0.632570,	RPNLogLoss=0.682278,	RPNL1Loss=0.155862,	RCNNAcc=0.760530,	RCNNLogLoss=1.101494,	RCNNL1Loss=0.323855,	
INFO:root:Epoch[1] Batch [180]	Speed: 0.39 samples/sec	Train-RPNAcc=0.638014,	RPNLogLoss=0.680976,	RPNL1Loss=0.157402,	RCNNAcc=0.771193,	RCNNLogLoss=1.028079,	RCNNL1Loss=0.327429,	
INFO:root:Epoch[1] Batch [200]	Speed: 0.36 samples/sec	Train-RPNAcc=0.647699,	RPNLogLoss=0.679157,	RPNL1Loss=0.151758,	RCNNAcc=0.783582,	RCNNLogLoss=0.958333,	RCNNL1Loss=0.322216,	
INFO:root:Epoch[1] Batch [220]	Speed: 0.31 samples/sec	Train-RPNAcc=0.655419,	RPNLogLoss=0.677278,	RPNL1Loss=0.147366,	RCNNAcc=0.791077,	RCNNLogLoss=0.905604,	RCNNL1Loss=0.326945,	
INFO:root:Epoch[1] Batch [240]	Speed: 0.40 samples/sec	Train-RPNAcc=0.663236,	RPNLogLoss=0.675329,	RPNL1Loss=0.144618,	RCNNAcc=0.799630,	RCNNLogLoss=0.857097,	RCNNL1Loss=0.326116,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.39 samples/sec	Train-RPNAcc=0.669630,	RPNLogLoss=0.673505,	RPNL1Loss=0.146396,	RCNNAcc=0.808459,	RCNNLogLoss=0.811099,	RCNNL1Loss=0.318188,	
INFO:root:Epoch[1] Batch [280]	Speed: 0.34 samples/sec	Train-RPNAcc=0.677352,	RPNLogLoss=0.671438,	RPNL1Loss=0.145468,	RCNNAcc=0.812111,	RCNNLogLoss=0.778790,	RCNNL1Loss=0.323562,	
INFO:root:Epoch[1] Batch [300]	Speed: 0.34 samples/sec	Train-RPNAcc=0.683360,	RPNLogLoss=0.669611,	RPNL1Loss=0.145939,	RCNNAcc=0.815070,	RCNNLogLoss=0.749703,	RCNNL1Loss=0.325645,	
INFO:root:Epoch[1] Batch [320]	Speed: 0.37 samples/sec	Train-RPNAcc=0.690664,	RPNLogLoss=0.667664,	RPNL1Loss=0.145182,	RCNNAcc=0.818146,	RCNNLogLoss=0.723253,	RCNNL1Loss=0.328968,	
INFO:root:Epoch[1] Batch [340]	Speed: 0.36 samples/sec	Train-RPNAcc=0.697684,	RPNLogLoss=0.665629,	RPNL1Loss=0.145408,	RCNNAcc=0.821687,	RCNNLogLoss=0.699003,	RCNNL1Loss=0.329717,	
INFO:root:Epoch[1] Batch [360]	Speed: 0.62 samples/sec	Train-RPNAcc=0.705094,	RPNLogLoss=0.663366,	RPNL1Loss=0.144495,	RCNNAcc=0.826091,	RCNNLogLoss=0.674604,	RCNNL1Loss=0.328032,	
INFO:root:Epoch[1] Batch [380]	Speed: 0.54 samples/sec	Train-RPNAcc=0.712475,	RPNLogLoss=0.661046,	RPNL1Loss=0.145015,	RCNNAcc=0.830832,	RCNNLogLoss=0.651164,	RCNNL1Loss=0.324276,	
INFO:root:Epoch[1] Batch [400]	Speed: 0.45 samples/sec	Train-RPNAcc=0.720591,	RPNLogLoss=0.658437,	RPNL1Loss=0.142943,	RCNNAcc=0.833502,	RCNNLogLoss=0.633454,	RCNNL1Loss=0.326085,	
INFO:root:Epoch[1] Batch [420]	Speed: 0.37 samples/sec	Train-RPNAcc=0.726674,	RPNLogLoss=0.656164,	RPNL1Loss=0.142754,	RCNNAcc=0.834806,	RCNNLogLoss=0.619199,	RCNNL1Loss=0.329407,	
INFO:root:Epoch[1] Batch [440]	Speed: 0.39 samples/sec	Train-RPNAcc=0.732276,	RPNLogLoss=0.653843,	RPNL1Loss=0.142357,	RCNNAcc=0.834485,	RCNNLogLoss=0.609091,	RCNNL1Loss=0.338099,	
INFO:root:Epoch[1] Batch [460]	Speed: 0.35 samples/sec	Train-RPNAcc=0.737925,	RPNLogLoss=0.651189,	RPNL1Loss=0.142825,	RCNNAcc=0.837497,	RCNNLogLoss=0.593639,	RCNNL1Loss=0.335519,	
INFO:root:Epoch[1] Batch [480]	Speed: 0.26 samples/sec	Train-RPNAcc=0.742821,	RPNLogLoss=0.648629,	RPNL1Loss=0.142762,	RCNNAcc=0.836977,	RCNNLogLoss=0.585568,	RCNNL1Loss=0.341680,	
INFO:root:Epoch[1] Batch [500]	Speed: 0.38 samples/sec	Train-RPNAcc=0.748503,	RPNLogLoss=0.645714,	RPNL1Loss=0.141457,	RCNNAcc=0.838994,	RCNNLogLoss=0.573152,	RCNNL1Loss=0.341064,	
INFO:root:Epoch[1] Batch [520]	Speed: 0.33 samples/sec	Train-RPNAcc=0.752849,	RPNLogLoss=0.642961,	RPNL1Loss=0.140702,	RCNNAcc=0.840481,	RCNNLogLoss=0.561523,	RCNNL1Loss=0.342540,	
INFO:root:Epoch[1] Batch [540]	Speed: 0.27 samples/sec	Train-RPNAcc=0.757690,	RPNLogLoss=0.639817,	RPNL1Loss=0.139826,	RCNNAcc=0.842291,	RCNNLogLoss=0.551162,	RCNNL1Loss=0.341942,	
INFO:root:Epoch[1] Batch [560]	Speed: 0.34 samples/sec	Train-RPNAcc=0.762248,	RPNLogLoss=0.636640,	RPNL1Loss=0.140053,	RCNNAcc=0.844056,	RCNNLogLoss=0.541311,	RCNNL1Loss=0.341765,	
INFO:root:Epoch[1] Batch [580]	Speed: 0.36 samples/sec	Train-RPNAcc=0.764704,	RPNLogLoss=0.634265,	RPNL1Loss=0.141005,	RCNNAcc=0.844449,	RCNNLogLoss=0.534302,	RCNNL1Loss=0.345216,	
INFO:root:Epoch[1] Batch [600]	Speed: 0.37 samples/sec	Train-RPNAcc=0.768680,	RPNLogLoss=0.630831,	RPNL1Loss=0.140021,	RCNNAcc=0.845700,	RCNNLogLoss=0.525432,	RCNNL1Loss=0.344658,	
INFO:root:Epoch[1] Batch [620]	Speed: 0.40 samples/sec	Train-RPNAcc=0.771412,	RPNLogLoss=0.627968,	RPNL1Loss=0.139923,	RCNNAcc=0.846681,	RCNNLogLoss=0.518945,	RCNNL1Loss=0.345208,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2482L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 9L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[04:47:16] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2482L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 752L, 2482L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.57 samples/sec	Train-RPNAcc=0.584077,	RPNLogLoss=0.690725,	RPNL1Loss=0.163435,	RCNNAcc=0.160714,	RCNNLogLoss=2.895509,	RCNNL1Loss=0.342722,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:02:39] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
  File "example/env/train_end2end.py", line 153
    else
       ^
SyntaxError: invalid syntax
  File "example/env/train_end2end.py", line 153
    else
       ^
SyntaxError: invalid syntax
Error in proposal_target.list_arguments: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 656, in list_arguments_entry
    ret = op_prop.list_arguments()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 88, in list_arguments
    if config.TRAIN.BBOX_3D:
NameError: global name 'config' is not defined

[15:29:38] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:29:38] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe87bb3771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7fe87c4ec13a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7fe87c4ecd49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7fe87c457893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7fe87c44d9ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7fe87d11a558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7fe87c33bfe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe925066adc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe92506640c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe92527d5fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe92527ef9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe9265f4f45]
[bt] (23) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 184, in get_vgg_train
    batch_rois=config.TRAIN.BATCH_ROIS, fg_fraction=config.TRAIN.FG_FRACTION)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/symbol.py", line 181, in creator
    ctypes.byref(sym_handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:29:38] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe87bb3771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7fe87c4ec13a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7fe87c4ecd49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7fe87c457893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7fe87c44d9ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7fe87d11a558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7fe87c33bfe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe925066adc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe92506640c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe92527d5fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe92527ef9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe9265f4f45]
[bt] (23) python() [0x578c4e]

Error in proposal_target.list_arguments: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 656, in list_arguments_entry
    ret = op_prop.list_arguments()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 88, in list_arguments
    if config.TRAIN.BBOX_3D:
NameError: global name 'config' is not defined

[15:29:47] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:29:47] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f008fd7c71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7f009073113a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7f0090731d49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7f009069c893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7f00906929ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7f009135f558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7f0090580fe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f01312abadc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f01312ab40c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f01314c25fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f01314c3f9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0132839f45]
[bt] (23) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 184, in get_vgg_train
    batch_rois=config.TRAIN.BATCH_ROIS, fg_fraction=config.TRAIN.FG_FRACTION)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/symbol.py", line 181, in creator
    ctypes.byref(sym_handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:29:47] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f008fd7c71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7f009073113a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7f0090731d49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7f009069c893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7f00906929ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7f009135f558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7f0090580fe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f01312abadc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f01312ab40c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f01314c25fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f01314c3f9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0132839f45]
[bt] (23) python() [0x578c4e]

[15:31:30] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:31:30] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1800ed271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f18024b4204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f180249361b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f18aa401adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f18aa40140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f18aa6185fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f18aa619f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f18ab98ff45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:31:30] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1800ed271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f18024b4204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f180249361b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f18aa401adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f18aa40140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f18aa6185fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f18aa619f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f18ab98ff45]
[bt] (22) python() [0x578c4e]

[15:35:46] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:35:46] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0d9374471c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f0d94d26204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f0d94d0561b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0e3cc73adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0e3cc7340c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f0e3ce8a5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f0e3ce8bf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0e3e201f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:35:46] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0d9374471c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f0d94d26204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f0d94d0561b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0e3cc73adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0e3cc7340c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f0e3ce8a5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f0e3ce8bf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0e3e201f45]
[bt] (22) python() [0x578c4e]

[15:37:09] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:37:09] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fc2a55e571c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7fc2a6bc7204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7fc2a6ba661b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc34eb14adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fc34eb1440c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fc34ed2b5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fc34ed2cf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fc3500a2f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:37:09] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fc2a55e571c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7fc2a6bc7204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7fc2a6ba661b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc34eb14adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fc34eb1440c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fc34ed2b5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fc34ed2cf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fc3500a2f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
