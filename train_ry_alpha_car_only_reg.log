{'EPS': 1e-14,
 'IMAGE_STRIDE': 0,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'SCALES': [(600, 1000)],
 'TEST': {'BATCH_IMAGES': 1,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 6000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
600
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 18L, 62L),
 'rpn_cls_prob_output': (1L, 2L, 162L, 62L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 18L, 62L),
 'bbox_weight': (1L, 36L, 18L, 62L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 302L, 1000L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 10044L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:44:00] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
python: can't open file 'example/env/train_3dbox.py': [Errno 2] No such file or directory
  File "example/env/train_3dbox.py", line 91
    '''
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 187, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 32, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 142
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss])
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 144
    return rcnn
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                           ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    im_info = mx.symbol.Variable(name="im_info")
                                               ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 196
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 197
    data = mx.symbol.Variable(name="data")
                                         ^
IndentationError: unindent does not match any outer indentation level
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 246
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 245
    def get_vgg_3dbox_test(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS)):
                                                                                          ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 18
    super(Proposal3DBOX, self).__init__()
        ^
IndentationError: expected an indented block
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 3, in <module>
    import proposal_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_3dbox.py", line 10, in <module>
    from rcnn.processing.generate_anchor import generator_anchors
ImportError: cannot import name generator_anchors
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol import symbol_3dbox
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 189, in <module>
    def get_vgg_3dbox_train(num_classes=config.NUM_CLASSES, num_anchors=config.NUM_ANCHORS):
AttributeError: 'EasyDict' object has no attribute 'NUM_CLASSES'
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "<string>", line 1, in <module>
NameError: name 'get_vgg_3dbox_train' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 208, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
TypeError: get_vgg_rpn_roi() takes exactly 6 arguments (5 given)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 83, in get_vgg_rpn_roi
    rpn_cls_prob = mx.symbol.SoftmaxOutput(data=rpn_cls_score_reshape, label=rpn_label, multi_output=True,
NameError: global name 'rpn_label' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 190, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 86, in get_vgg_rpn_roi
    rpn_bbox_loss_ = rpn_bbox_weight * mx.symbol.smooth_l1(name='rpn_bbox_loss_', scalar=3.0, data=(rpn_bbox_pred - rpn_bbox_target))
NameError: global name 'rpn_bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 192, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 95, in get_vgg_rpn_roi
    cls_prob=rpn_cls_act_reshape, bbox_pred=rpn_bbox_pred, im_info=im_info, name='rois',
NameError: global name 'im_info' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(rcnn)
NameError: global name 'rcnn' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 198, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 141, in get_3dbox_loss
    loss_dim = mx.symbol.square(data=(target_dim-dim_pred), name="loss_dim")
NameError: global name 'target_dim' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 199, in get_vgg_3dbox_train
    group = get_3dbox_loss(drop7)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 153, in get_3dbox_loss
    rot_loss = RotLoss()
NameError: global name 'RotLoss' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 166
    loss_total = loss_dim * alpha / 64 + loss_conf
    ^
IndentationError: unexpected indent
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 207, in get_vgg_3dbox_train
    cls_prob = mx.symbol.SoftmaxOutput(name='cls_prob', data=cls_score, label=label, normalization='batch')
UnboundLocalError: local variable 'label' referenced before assignment
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 212, in get_vgg_3dbox_train
    bbox_loss_ = bbox_outside_weight * \
NameError: global name 'bbox_outside_weight' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 214, in get_vgg_3dbox_train
    data=rpn_bbox_inside_weight * (bbox_pred - bbox_target))
NameError: global name 'bbox_target' is not defined
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 33, in train_net
    sym = eval('get_' + args.network + '_3dbox_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 194, in get_vgg_3dbox_train
    group = get_vgg_rpn_roi(im_info, relu5_3, gt_boxes, rpn_label, rpn_bbox_target, rpn_bbox_weight, num_classes, num_anchors, config)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 124, in get_vgg_rpn_roi
    rcnn = mx.symbol.Group([drop7, rpn_cls_prob, rpn_bbox_loss, label, bbox_targt, bbox_weight])
NameError: global name 'bbox_targt' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 51, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 346, in get_batch
    self.anchor_ratios, self.allowed_border)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 417, in assign_anchor
    bbox_weights[labels == 1, :] = np.array(config.TRAIN.RPN_BBOX_WEIGHTS)
AttributeError: 'EasyDict' object has no attribute 'RPN_BBOX_WEIGHTS'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 2L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 8L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2491L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 64, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 200, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 49, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
NameError: global name 'data_shape_dict' is not defined
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  data: (1L, 3L, 752L, 2488L)
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 191, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 61, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator rpn_cls_prob: Expecting (1,87420) or (1,564,155). But got (1,65565)
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2488L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
  File "example/env/train_3dbox.py", line 114
    print 'ok'
    ^
IndentationError: unexpected indent
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2489L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
ok
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:13:52] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Error in CustomOp.forward: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 724, in forward_entry
    aux=tensors[4])
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 42, in forward
    sample_rois(all_rois, fg_rois_per_image, rois_per_image, self._num_classes, gt_boxes=gt_boxes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 283, in sample_rois
    expand_bbox_regression_targets(bbox_target_data, num_classes)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/processing/bbox_regression.py", line 139, in expand_bbox_regression_targets
    bbox_weights[index, start:end] = config.TRAIN.BBOX_WEIGHTS
AttributeError: 'EasyDict' object has no attribute 'BBOX_WEIGHTS'

[11:14:08] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

terminate called after throwing an instance of 'dmlc::Error'
  what():  [11:14:08] src/operator/custom.cc:80: Check failed: op_info_->forward(ptrs.size(), ptrs.data(), tags.data(), reqs.data(), ctx.is_train, op_info_->p_forward) 

Stack trace returned 6 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe6e158271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZZN5mxnet2op8CustomOpIN7mshadow3gpuEE7ForwardERKNS_9OpContextERKSt6vectorINS_5TBlobESaIS9_EERKS8_INS_9OpReqTypeESaISE_EESD_SD_ENUlvE_clEv+0xa7) [0x7fe6e1f3cc07]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNSt6thread5_ImplISt12_Bind_simpleIFZN5mxnet2op8CustomOpIN7mshadow3gpuEEC1EP12CustomOpInfoEUlvE0_vEEE6_M_runEv+0xde) [0x7fe6e1f373de]
[bt] (3) /usr/lib/x86_64-linux-gnu/libstdc++.so.6(+0xb1a60) [0x7fe6d72c9a60]
[bt] (4) /lib/x86_64-linux-gnu/libpthread.so.0(+0x8184) [0x7fe7883eb184]
[bt] (5) /lib/x86_64-linux-gnu/libc.so.6(clone+0x6d) [0x7fe78811837d]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 2L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:16:51] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.49 samples/sec	Train-RPNAcc=0.580171,	RPNLogLoss=0.689842,	RPNL1Loss=0.111169,	RCNNAcc=0.207961,	RCNNLogLoss=2.817367,	RCNNL1Loss=0.212329,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.55 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.689458,	RPNL1Loss=0.126438,	RCNNAcc=0.487614,	RCNNLogLoss=2.268237,	RCNNL1Loss=0.265416,	
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 8, in <module>
    from rcnn.config import config
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/config.py", line 78
    config.TRAIN.RPN_NMS_THRESH = 0.7ls
                                      ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 10, in <module>
    from rcnn.symbol.symbol_3dbox import *
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_3dbox.py", line 400
    3dbox_loss = dim_loss * alpha / 64 + conf_loss
             ^
SyntaxError: invalid syntax
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 188, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 97, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc8_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:38:10] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
[11:38:26] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [11:38:26] src/executor/graph_executor.cc:44: Check failed: i < head_grads.size() && !head_grads[i].is_none() Because the last operator is not Loss function, head_gradient is required in calling backward.

Stack trace returned 27 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f4db7a3271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor8BackwardERKSt6vectorINS_7NDArrayESaIS3_EE+0x15d) [0x7f4db8275add]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXExecutorBackward+0xb8) [0x7f4db8219778]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f4e60f61adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f4e60f6140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f4e611785fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f4e61179f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (17) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (18) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (19) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (20) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (21) python() [0x4a1634]
[bt] (22) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (23) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (24) python(Py_Main+0xb5e) [0x44f904]
[bt] (25) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f4e624eff45]
[bt] (26) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 196, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 410, in fit
    self.forward_backward(data_batch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 144, in forward_backward
    self.backward()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 179, in backward
    self._curr_module.backward(out_grads=out_grads)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 465, in backward
    self._exec_group.backward(out_grads=out_grads)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 411, in backward
    exec_.backward(out_grads=out_grads_slice)
  File "/home/hustxly/mxnet/python/mxnet/executor.py", line 147, in backward
    ndarray))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [11:38:26] src/executor/graph_executor.cc:44: Check failed: i < head_grads.size() && !head_grads[i].is_none() Because the last operator is not Loss function, head_gradient is required in calling backward.

Stack trace returned 27 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f4db7a3271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet4exec13GraphExecutor8BackwardERKSt6vectorINS_7NDArrayESaIS3_EE+0x15d) [0x7f4db8275add]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXExecutorBackward+0xb8) [0x7f4db8219778]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f4e60f61adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f4e60f6140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f4e611785fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f4e61179f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalFrameEx+0xc72) [0x499ef2]
[bt] (17) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (18) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (19) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (20) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (21) python() [0x4a1634]
[bt] (22) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (23) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (24) python(Py_Main+0xb5e) [0x44f904]
[bt] (25) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f4e624eff45]
[bt] (26) python() [0x578c4e]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[11:59:24] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 196, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_output': (128L, 64L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc8_3_bias': (256L,),
 'fc8_3_weight': (256L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'fc9_3_bias': (64L,),
 'fc9_3_weight': (64L, 256L),
 'gt_boxes': (1L, 11L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[12:43:49] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 203, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[12:45:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.54 samples/sec	Train-RPNAcc=0.588356,	RPNLogLoss=0.688438,	RPNL1Loss=0.115115,	RCNNAcc=0.194940,	RCNNLogLoss=2.837928,	RCNNL1Loss=0.272949,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.50 samples/sec	Train-RPNAcc=0.592702,	RPNLogLoss=0.687396,	RPNL1Loss=0.132219,	RCNNAcc=0.472370,	RCNNLogLoss=2.298971,	RCNNL1Loss=0.329313,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.69 samples/sec	Train-RPNAcc=0.600218,	RPNLogLoss=0.686898,	RPNL1Loss=0.136774,	RCNNAcc=0.594647,	RCNNLogLoss=1.909852,	RCNNL1Loss=0.335864,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 1L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[20:28:22] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.61 samples/sec	Train-RPNAcc=0.563616,	RPNLogLoss=0.691758,	RPNL1Loss=0.118104,	RCNNAcc=0.191592,	RCNNLogLoss=2.841586,	RCNNL1Loss=0.258174,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[20:54:15] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 105, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc8_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 12L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 5L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 4L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 105, in train_net
    assert k in arg_params, k + ' not initialized'
AssertionError: fc9_1_weight not initialized
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 7L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 83, in train_net
    arg_params['fc8_3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc8_3_weight'])
KeyError: 'fc8_3_weight'
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 12L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[21:00:17] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 6L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[09:43:21] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.60 samples/sec	Train-RPNAcc=0.585938,	RPNLogLoss=0.688932,	RPNL1Loss=0.162465,	RCNNAcc=0.177455,	RCNNLogLoss=2.885032,	RCNNL1Loss=0.336327,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.86 samples/sec	Train-RPNAcc=0.593274,	RPNLogLoss=0.688133,	RPNL1Loss=0.129164,	RCNNAcc=0.470655,	RCNNLogLoss=2.306914,	RCNNL1Loss=0.329383,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.82 samples/sec	Train-RPNAcc=0.601178,	RPNLogLoss=0.687275,	RPNL1Loss=0.120215,	RCNNAcc=0.608222,	RCNNLogLoss=1.880212,	RCNNL1Loss=0.306126,	
INFO:root:Epoch[1] Batch [80]	Speed: 0.97 samples/sec	Train-RPNAcc=0.608314,	RPNLogLoss=0.686595,	RPNL1Loss=0.119597,	RCNNAcc=0.675540,	RCNNLogLoss=1.607514,	RCNNL1Loss=0.297878,	
INFO:root:Epoch[1] Batch [100]	Speed: 0.79 samples/sec	Train-RPNAcc=0.616607,	RPNLogLoss=0.685581,	RPNL1Loss=0.130103,	RCNNAcc=0.703899,	RCNNLogLoss=1.459083,	RCNNL1Loss=0.321868,	
INFO:root:Epoch[1] Batch [120]	Speed: 0.87 samples/sec	Train-RPNAcc=0.625678,	RPNLogLoss=0.684273,	RPNL1Loss=0.127825,	RCNNAcc=0.728177,	RCNNLogLoss=1.320564,	RCNNL1Loss=0.324794,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.95 samples/sec	Train-RPNAcc=0.633283,	RPNLogLoss=0.682898,	RPNL1Loss=0.132785,	RCNNAcc=0.748781,	RCNNLogLoss=1.202359,	RCNNL1Loss=0.323892,	
INFO:root:Epoch[1] Batch [160]	Speed: 0.83 samples/sec	Train-RPNAcc=0.640115,	RPNLogLoss=0.681510,	RPNL1Loss=0.134434,	RCNNAcc=0.762277,	RCNNLogLoss=1.113592,	RCNNL1Loss=0.326054,	
INFO:root:Epoch[1] Batch [180]	Speed: 0.79 samples/sec	Train-RPNAcc=0.647402,	RPNLogLoss=0.680011,	RPNL1Loss=0.135963,	RCNNAcc=0.776934,	RCNNLogLoss=1.031368,	RCNNL1Loss=0.319910,	
INFO:root:Epoch[1] Batch [200]	Speed: 0.98 samples/sec	Train-RPNAcc=0.653898,	RPNLogLoss=0.678374,	RPNL1Loss=0.137699,	RCNNAcc=0.786303,	RCNNLogLoss=0.968132,	RCNNL1Loss=0.321844,	
INFO:root:Epoch[1] Batch [220]	Speed: 0.88 samples/sec	Train-RPNAcc=0.661093,	RPNLogLoss=0.676715,	RPNL1Loss=0.134511,	RCNNAcc=0.796663,	RCNNLogLoss=0.910511,	RCNNL1Loss=0.315775,	
INFO:root:Epoch[1] Batch [240]	Speed: 1.05 samples/sec	Train-RPNAcc=0.667012,	RPNLogLoss=0.674963,	RPNL1Loss=0.133910,	RCNNAcc=0.804785,	RCNNLogLoss=0.859739,	RCNNL1Loss=0.314300,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.95 samples/sec	Train-RPNAcc=0.673746,	RPNLogLoss=0.673179,	RPNL1Loss=0.133964,	RCNNAcc=0.810973,	RCNNLogLoss=0.818879,	RCNNL1Loss=0.315344,	
INFO:root:Epoch[1] Batch [280]	Speed: 0.94 samples/sec	Train-RPNAcc=0.681425,	RPNLogLoss=0.671202,	RPNL1Loss=0.133793,	RCNNAcc=0.817977,	RCNNLogLoss=0.779751,	RCNNL1Loss=0.311582,	
INFO:root:Epoch[1] Batch [300]	Speed: 1.08 samples/sec	Train-RPNAcc=0.689083,	RPNLogLoss=0.669286,	RPNL1Loss=0.132383,	RCNNAcc=0.821455,	RCNNLogLoss=0.750870,	RCNNL1Loss=0.314483,	
INFO:root:Epoch[1] Batch [320]	Speed: 0.96 samples/sec	Train-RPNAcc=0.695848,	RPNLogLoss=0.667271,	RPNL1Loss=0.133914,	RCNNAcc=0.825131,	RCNNLogLoss=0.724867,	RCNNL1Loss=0.316649,	
INFO:root:Epoch[1] Batch [340]	Speed: 1.08 samples/sec	Train-RPNAcc=0.703996,	RPNLogLoss=0.664977,	RPNL1Loss=0.133020,	RCNNAcc=0.828789,	RCNNLogLoss=0.700400,	RCNNL1Loss=0.318892,	
INFO:root:Epoch[1] Batch [360]	Speed: 0.92 samples/sec	Train-RPNAcc=0.710981,	RPNLogLoss=0.662672,	RPNL1Loss=0.133019,	RCNNAcc=0.829856,	RCNNLogLoss=0.681870,	RCNNL1Loss=0.329944,	
INFO:root:Epoch[1] Batch [380]	Speed: 1.13 samples/sec	Train-RPNAcc=0.718688,	RPNLogLoss=0.660018,	RPNL1Loss=0.132743,	RCNNAcc=0.833661,	RCNNLogLoss=0.659349,	RCNNL1Loss=0.328331,	
INFO:root:Epoch[1] Batch [400]	Speed: 1.02 samples/sec	Train-RPNAcc=0.724614,	RPNLogLoss=0.657702,	RPNL1Loss=0.133130,	RCNNAcc=0.835178,	RCNNLogLoss=0.643083,	RCNNL1Loss=0.330612,	
INFO:root:Epoch[1] Batch [420]	Speed: 1.01 samples/sec	Train-RPNAcc=0.730942,	RPNLogLoss=0.655227,	RPNL1Loss=0.133190,	RCNNAcc=0.837162,	RCNNLogLoss=0.627163,	RCNNL1Loss=0.332483,	
INFO:root:Epoch[1] Batch [440]	Speed: 1.17 samples/sec	Train-RPNAcc=0.736899,	RPNLogLoss=0.652507,	RPNL1Loss=0.133504,	RCNNAcc=0.839675,	RCNNLogLoss=0.611529,	RCNNL1Loss=0.333065,	
INFO:root:Epoch[1] Batch [460]	Speed: 1.04 samples/sec	Train-RPNAcc=0.742365,	RPNLogLoss=0.649930,	RPNL1Loss=0.132935,	RCNNAcc=0.840530,	RCNNLogLoss=0.599674,	RCNNL1Loss=0.336655,	
INFO:root:Epoch[1] Batch [480]	Speed: 1.08 samples/sec	Train-RPNAcc=0.747466,	RPNLogLoss=0.647449,	RPNL1Loss=0.134214,	RCNNAcc=0.841768,	RCNNLogLoss=0.587771,	RCNNL1Loss=0.337567,	
INFO:root:Epoch[1] Batch [500]	Speed: 1.02 samples/sec	Train-RPNAcc=0.751770,	RPNLogLoss=0.644765,	RPNL1Loss=0.134417,	RCNNAcc=0.842970,	RCNNLogLoss=0.576698,	RCNNL1Loss=0.340340,	
INFO:root:Epoch[1] Batch [520]	Speed: 0.99 samples/sec	Train-RPNAcc=0.756425,	RPNLogLoss=0.642058,	RPNL1Loss=0.134187,	RCNNAcc=0.844200,	RCNNLogLoss=0.566322,	RCNNL1Loss=0.340579,	
INFO:root:Epoch[1] Batch [540]	Speed: 1.03 samples/sec	Train-RPNAcc=0.760116,	RPNLogLoss=0.639343,	RPNL1Loss=0.134406,	RCNNAcc=0.844154,	RCNNLogLoss=0.558783,	RCNNL1Loss=0.345100,	
INFO:root:Epoch[1] Batch [560]	Speed: 1.06 samples/sec	Train-RPNAcc=0.764706,	RPNLogLoss=0.636167,	RPNL1Loss=0.133693,	RCNNAcc=0.844962,	RCNNLogLoss=0.550100,	RCNNL1Loss=0.347409,	
INFO:root:Epoch[1] Batch [580]	Speed: 1.20 samples/sec	Train-RPNAcc=0.768684,	RPNLogLoss=0.632904,	RPNL1Loss=0.133879,	RCNNAcc=0.846130,	RCNNLogLoss=0.540802,	RCNNL1Loss=0.347832,	
INFO:root:Epoch[1] Batch [600]	Speed: 1.06 samples/sec	Train-RPNAcc=0.772697,	RPNLogLoss=0.629603,	RPNL1Loss=0.133035,	RCNNAcc=0.847364,	RCNNLogLoss=0.532077,	RCNNL1Loss=0.348467,	
INFO:root:Epoch[1] Batch [620]	Speed: 1.05 samples/sec	Train-RPNAcc=0.775042,	RPNLogLoss=0.626668,	RPNL1Loss=0.133769,	RCNNAcc=0.847675,	RCNNLogLoss=0.526164,	RCNNL1Loss=0.350132,	
INFO:root:Epoch[1] Batch [640]	Speed: 1.11 samples/sec	Train-RPNAcc=0.778014,	RPNLogLoss=0.623491,	RPNL1Loss=0.132403,	RCNNAcc=0.848162,	RCNNLogLoss=0.520149,	RCNNL1Loss=0.352079,	
INFO:root:Epoch[1] Batch [660]	Speed: 1.24 samples/sec	Train-RPNAcc=0.781746,	RPNLogLoss=0.619570,	RPNL1Loss=0.131171,	RCNNAcc=0.848986,	RCNNLogLoss=0.513084,	RCNNL1Loss=0.351516,	
INFO:root:Epoch[1] Batch [680]	Speed: 0.96 samples/sec	Train-RPNAcc=0.783688,	RPNLogLoss=0.616576,	RPNL1Loss=0.132369,	RCNNAcc=0.849062,	RCNNLogLoss=0.507960,	RCNNL1Loss=0.353803,	
INFO:root:Epoch[1] Batch [700]	Speed: 1.07 samples/sec	Train-RPNAcc=0.786482,	RPNLogLoss=0.613146,	RPNL1Loss=0.131892,	RCNNAcc=0.849601,	RCNNLogLoss=0.502239,	RCNNL1Loss=0.355016,	
INFO:root:Epoch[1] Batch [720]	Speed: 1.18 samples/sec	Train-RPNAcc=0.788900,	RPNLogLoss=0.609293,	RPNL1Loss=0.132436,	RCNNAcc=0.850046,	RCNNLogLoss=0.497134,	RCNNL1Loss=0.353960,	
INFO:root:Epoch[1] Batch [740]	Speed: 0.99 samples/sec	Train-RPNAcc=0.790776,	RPNLogLoss=0.606082,	RPNL1Loss=0.132961,	RCNNAcc=0.849749,	RCNNLogLoss=0.493672,	RCNNL1Loss=0.355475,	
INFO:root:Epoch[1] Batch [760]	Speed: 1.27 samples/sec	Train-RPNAcc=0.793497,	RPNLogLoss=0.602047,	RPNL1Loss=0.132501,	RCNNAcc=0.850741,	RCNNLogLoss=0.488898,	RCNNL1Loss=0.352915,	
INFO:root:Epoch[1] Batch [780]	Speed: 1.07 samples/sec	Train-RPNAcc=0.795304,	RPNLogLoss=0.598195,	RPNL1Loss=0.132957,	RCNNAcc=0.851132,	RCNNLogLoss=0.484880,	RCNNL1Loss=0.352076,	
INFO:root:Epoch[1] Batch [800]	Speed: 1.17 samples/sec	Train-RPNAcc=0.797509,	RPNLogLoss=0.594006,	RPNL1Loss=0.132641,	RCNNAcc=0.851562,	RCNNLogLoss=0.480475,	RCNNL1Loss=0.351652,	
INFO:root:Epoch[1] Batch [820]	Speed: 0.99 samples/sec	Train-RPNAcc=0.799259,	RPNLogLoss=0.589931,	RPNL1Loss=0.132236,	RCNNAcc=0.851667,	RCNNLogLoss=0.477351,	RCNNL1Loss=0.351855,	
INFO:root:Epoch[1] Batch [840]	Speed: 1.16 samples/sec	Train-RPNAcc=0.801515,	RPNLogLoss=0.585073,	RPNL1Loss=0.131305,	RCNNAcc=0.852046,	RCNNLogLoss=0.473784,	RCNNL1Loss=0.351850,	
INFO:root:Epoch[1] Batch [860]	Speed: 1.09 samples/sec	Train-RPNAcc=0.803136,	RPNLogLoss=0.580394,	RPNL1Loss=0.131323,	RCNNAcc=0.853323,	RCNNLogLoss=0.468089,	RCNNL1Loss=0.349920,	
INFO:root:Epoch[1] Batch [880]	Speed: 1.14 samples/sec	Train-RPNAcc=0.804976,	RPNLogLoss=0.575774,	RPNL1Loss=0.130716,	RCNNAcc=0.853212,	RCNNLogLoss=0.465926,	RCNNL1Loss=0.350124,	
INFO:root:Epoch[1] Batch [900]	Speed: 1.08 samples/sec	Train-RPNAcc=0.806638,	RPNLogLoss=0.571388,	RPNL1Loss=0.130127,	RCNNAcc=0.853331,	RCNNLogLoss=0.462832,	RCNNL1Loss=0.349852,	
INFO:root:Epoch[1] Batch [920]	Speed: 1.09 samples/sec	Train-RPNAcc=0.807818,	RPNLogLoss=0.567060,	RPNL1Loss=0.129675,	RCNNAcc=0.852589,	RCNNLogLoss=0.461446,	RCNNL1Loss=0.351843,	
INFO:root:Epoch[1] Batch [940]	Speed: 1.18 samples/sec	Train-RPNAcc=0.809810,	RPNLogLoss=0.562262,	RPNL1Loss=0.128891,	RCNNAcc=0.852658,	RCNNLogLoss=0.459461,	RCNNL1Loss=0.353024,	
INFO:root:Epoch[1] Batch [960]	Speed: 1.05 samples/sec	Train-RPNAcc=0.811459,	RPNLogLoss=0.557935,	RPNL1Loss=0.128235,	RCNNAcc=0.851725,	RCNNLogLoss=0.459469,	RCNNL1Loss=0.356156,	
INFO:root:Epoch[1] Batch [980]	Speed: 1.15 samples/sec	Train-RPNAcc=0.813026,	RPNLogLoss=0.553008,	RPNL1Loss=0.127361,	RCNNAcc=0.852024,	RCNNLogLoss=0.456953,	RCNNL1Loss=0.355789,	
INFO:root:Epoch[1] Batch [1000]	Speed: 1.00 samples/sec	Train-RPNAcc=0.814397,	RPNLogLoss=0.548546,	RPNL1Loss=0.126685,	RCNNAcc=0.851890,	RCNNLogLoss=0.455288,	RCNNL1Loss=0.355424,	
INFO:root:Epoch[1] Batch [1020]	Speed: 1.02 samples/sec	Train-RPNAcc=0.814937,	RPNLogLoss=0.544657,	RPNL1Loss=0.126519,	RCNNAcc=0.851892,	RCNNLogLoss=0.453571,	RCNNL1Loss=0.355157,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [1040]	Speed: 1.07 samples/sec	Train-RPNAcc=0.816875,	RPNLogLoss=0.539735,	RPNL1Loss=0.125172,	RCNNAcc=0.852178,	RCNNLogLoss=0.451253,	RCNNL1Loss=0.354670,	
INFO:root:Epoch[1] Batch [1060]	Speed: 1.12 samples/sec	Train-RPNAcc=0.818619,	RPNLogLoss=0.535017,	RPNL1Loss=0.124124,	RCNNAcc=0.852233,	RCNNLogLoss=0.449141,	RCNNL1Loss=0.354627,	
INFO:root:Epoch[1] Batch [1080]	Speed: 1.11 samples/sec	Train-RPNAcc=0.820247,	RPNLogLoss=0.530131,	RPNL1Loss=0.123006,	RCNNAcc=0.852336,	RCNNLogLoss=0.447343,	RCNNL1Loss=0.354002,	
INFO:root:Epoch[1] Batch [1100]	Speed: 1.05 samples/sec	Train-RPNAcc=0.821249,	RPNLogLoss=0.526050,	RPNL1Loss=0.122464,	RCNNAcc=0.852194,	RCNNLogLoss=0.446310,	RCNNL1Loss=0.354471,	
INFO:root:Epoch[1] Batch [1120]	Speed: 1.08 samples/sec	Train-RPNAcc=0.822187,	RPNLogLoss=0.521730,	RPNL1Loss=0.121908,	RCNNAcc=0.852622,	RCNNLogLoss=0.444003,	RCNNL1Loss=0.354099,	
INFO:root:Epoch[1] Batch [1140]	Speed: 1.04 samples/sec	Train-RPNAcc=0.822740,	RPNLogLoss=0.518268,	RPNL1Loss=0.121691,	RCNNAcc=0.852637,	RCNNLogLoss=0.442641,	RCNNL1Loss=0.354184,	
INFO:root:Epoch[1] Batch [1160]	Speed: 1.05 samples/sec	Train-RPNAcc=0.824027,	RPNLogLoss=0.513836,	RPNL1Loss=0.121004,	RCNNAcc=0.853090,	RCNNLogLoss=0.440523,	RCNNL1Loss=0.353089,	
INFO:root:Epoch[1] Batch [1180]	Speed: 0.99 samples/sec	Train-RPNAcc=0.824837,	RPNLogLoss=0.510054,	RPNL1Loss=0.120765,	RCNNAcc=0.853296,	RCNNLogLoss=0.439043,	RCNNL1Loss=0.352558,	
INFO:root:Epoch[1] Batch [1200]	Speed: 1.16 samples/sec	Train-RPNAcc=0.826359,	RPNLogLoss=0.505413,	RPNL1Loss=0.119724,	RCNNAcc=0.854119,	RCNNLogLoss=0.436003,	RCNNL1Loss=0.350563,	
INFO:root:Epoch[1] Batch [1220]	Speed: 1.04 samples/sec	Train-RPNAcc=0.827450,	RPNLogLoss=0.501343,	RPNL1Loss=0.119174,	RCNNAcc=0.854666,	RCNNLogLoss=0.433401,	RCNNL1Loss=0.349877,	
INFO:root:Epoch[1] Batch [1240]	Speed: 1.06 samples/sec	Train-RPNAcc=0.828468,	RPNLogLoss=0.497260,	RPNL1Loss=0.118499,	RCNNAcc=0.854861,	RCNNLogLoss=0.431979,	RCNNL1Loss=0.349589,	
INFO:root:Epoch[1] Batch [1260]	Speed: 1.06 samples/sec	Train-RPNAcc=0.829534,	RPNLogLoss=0.493290,	RPNL1Loss=0.117782,	RCNNAcc=0.855032,	RCNNLogLoss=0.430573,	RCNNL1Loss=0.350005,	
INFO:root:Epoch[1] Batch [1280]	Speed: 1.07 samples/sec	Train-RPNAcc=0.830839,	RPNLogLoss=0.488974,	RPNL1Loss=0.116837,	RCNNAcc=0.855856,	RCNNLogLoss=0.427962,	RCNNL1Loss=0.348670,	
INFO:root:Epoch[1] Batch [1300]	Speed: 0.98 samples/sec	Train-RPNAcc=0.831392,	RPNLogLoss=0.485824,	RPNL1Loss=0.116581,	RCNNAcc=0.856132,	RCNNLogLoss=0.426386,	RCNNL1Loss=0.348556,	
INFO:root:Epoch[1] Batch [1320]	Speed: 0.88 samples/sec	Train-RPNAcc=0.832339,	RPNLogLoss=0.482435,	RPNL1Loss=0.115929,	RCNNAcc=0.856495,	RCNNLogLoss=0.424572,	RCNNL1Loss=0.347671,	
INFO:root:Epoch[1] Batch [1340]	Speed: 0.92 samples/sec	Train-RPNAcc=0.832867,	RPNLogLoss=0.479282,	RPNL1Loss=0.115635,	RCNNAcc=0.856503,	RCNNLogLoss=0.423538,	RCNNL1Loss=0.348206,	
INFO:root:Epoch[1] Batch [1360]	Speed: 1.05 samples/sec	Train-RPNAcc=0.833486,	RPNLogLoss=0.476126,	RPNL1Loss=0.115235,	RCNNAcc=0.856953,	RCNNLogLoss=0.421439,	RCNNL1Loss=0.347231,	
INFO:root:Epoch[1] Batch [1380]	Speed: 0.93 samples/sec	Train-RPNAcc=0.834320,	RPNLogLoss=0.472979,	RPNL1Loss=0.114770,	RCNNAcc=0.857078,	RCNNLogLoss=0.420568,	RCNNL1Loss=0.347059,	
INFO:root:Epoch[1] Batch [1400]	Speed: 0.95 samples/sec	Train-RPNAcc=0.834630,	RPNLogLoss=0.470317,	RPNL1Loss=0.114736,	RCNNAcc=0.857373,	RCNNLogLoss=0.418936,	RCNNL1Loss=0.346159,	
INFO:root:Epoch[1] Batch [1420]	Speed: 1.00 samples/sec	Train-RPNAcc=0.835432,	RPNLogLoss=0.466944,	RPNL1Loss=0.114319,	RCNNAcc=0.857902,	RCNNLogLoss=0.417026,	RCNNL1Loss=0.345495,	
INFO:root:Epoch[1] Batch [1440]	Speed: 0.96 samples/sec	Train-RPNAcc=0.836314,	RPNLogLoss=0.463818,	RPNL1Loss=0.113788,	RCNNAcc=0.858063,	RCNNLogLoss=0.415863,	RCNNL1Loss=0.345305,	
INFO:root:Epoch[1] Batch [1460]	Speed: 0.99 samples/sec	Train-RPNAcc=0.837191,	RPNLogLoss=0.460567,	RPNL1Loss=0.113247,	RCNNAcc=0.858498,	RCNNLogLoss=0.414457,	RCNNL1Loss=0.344589,	
INFO:root:Epoch[1] Batch [1480]	Speed: 1.01 samples/sec	Train-RPNAcc=0.838158,	RPNLogLoss=0.457168,	RPNL1Loss=0.112627,	RCNNAcc=0.859349,	RCNNLogLoss=0.411654,	RCNNL1Loss=0.343083,	
INFO:root:Epoch[1] Batch [1500]	Speed: 0.96 samples/sec	Train-RPNAcc=0.838761,	RPNLogLoss=0.454152,	RPNL1Loss=0.112245,	RCNNAcc=0.859932,	RCNNLogLoss=0.409602,	RCNNL1Loss=0.342678,	
INFO:root:Epoch[1] Batch [1520]	Speed: 0.95 samples/sec	Train-RPNAcc=0.839199,	RPNLogLoss=0.451570,	RPNL1Loss=0.112015,	RCNNAcc=0.860305,	RCNNLogLoss=0.407903,	RCNNL1Loss=0.342089,	
INFO:root:Epoch[1] Batch [1540]	Speed: 0.99 samples/sec	Train-RPNAcc=0.840135,	RPNLogLoss=0.448353,	RPNL1Loss=0.111471,	RCNNAcc=0.861149,	RCNNLogLoss=0.405247,	RCNNL1Loss=0.340469,	
INFO:root:Epoch[1] Batch [1560]	Speed: 0.92 samples/sec	Train-RPNAcc=0.840980,	RPNLogLoss=0.445351,	RPNL1Loss=0.110940,	RCNNAcc=0.861757,	RCNNLogLoss=0.403333,	RCNNL1Loss=0.339179,	
INFO:root:Epoch[1] Batch [1580]	Speed: 0.95 samples/sec	Train-RPNAcc=0.841198,	RPNLogLoss=0.442907,	RPNL1Loss=0.110687,	RCNNAcc=0.862221,	RCNNLogLoss=0.401616,	RCNNL1Loss=0.338461,	
INFO:root:Epoch[1] Batch [1600]	Speed: 0.91 samples/sec	Train-RPNAcc=0.841932,	RPNLogLoss=0.440233,	RPNL1Loss=0.110348,	RCNNAcc=0.862552,	RCNNLogLoss=0.400357,	RCNNL1Loss=0.337958,	
INFO:root:Epoch[1] Batch [1620]	Speed: 1.01 samples/sec	Train-RPNAcc=0.842605,	RPNLogLoss=0.437301,	RPNL1Loss=0.109857,	RCNNAcc=0.863279,	RCNNLogLoss=0.397903,	RCNNL1Loss=0.336401,	
INFO:root:Epoch[1] Batch [1640]	Speed: 0.96 samples/sec	Train-RPNAcc=0.843476,	RPNLogLoss=0.434480,	RPNL1Loss=0.109200,	RCNNAcc=0.863750,	RCNNLogLoss=0.396246,	RCNNL1Loss=0.335754,	
INFO:root:Epoch[1] Batch [1660]	Speed: 0.98 samples/sec	Train-RPNAcc=0.843825,	RPNLogLoss=0.432425,	RPNL1Loss=0.108899,	RCNNAcc=0.864314,	RCNNLogLoss=0.394565,	RCNNL1Loss=0.334447,	
INFO:root:Epoch[1] Batch [1680]	Speed: 0.93 samples/sec	Train-RPNAcc=0.844459,	RPNLogLoss=0.430120,	RPNL1Loss=0.108693,	RCNNAcc=0.864552,	RCNNLogLoss=0.393331,	RCNNL1Loss=0.334202,	
INFO:root:Epoch[1] Batch [1700]	Speed: 0.89 samples/sec	Train-RPNAcc=0.845029,	RPNLogLoss=0.427665,	RPNL1Loss=0.108301,	RCNNAcc=0.864813,	RCNNLogLoss=0.392536,	RCNNL1Loss=0.333634,	
INFO:root:Epoch[1] Batch [1720]	Speed: 0.88 samples/sec	Train-RPNAcc=0.845625,	RPNLogLoss=0.425311,	RPNL1Loss=0.107978,	RCNNAcc=0.865322,	RCNNLogLoss=0.390896,	RCNNL1Loss=0.332790,	
INFO:root:Epoch[1] Batch [1740]	Speed: 1.01 samples/sec	Train-RPNAcc=0.846478,	RPNLogLoss=0.422680,	RPNL1Loss=0.107412,	RCNNAcc=0.865971,	RCNNLogLoss=0.388914,	RCNNL1Loss=0.332261,	
INFO:root:Epoch[1] Batch [1760]	Speed: 0.93 samples/sec	Train-RPNAcc=0.847199,	RPNLogLoss=0.420201,	RPNL1Loss=0.106928,	RCNNAcc=0.866708,	RCNNLogLoss=0.386591,	RCNNL1Loss=0.331131,	
INFO:root:Epoch[1] Batch [1780]	Speed: 0.83 samples/sec	Train-RPNAcc=0.847917,	RPNLogLoss=0.417796,	RPNL1Loss=0.106519,	RCNNAcc=0.867038,	RCNNLogLoss=0.385380,	RCNNL1Loss=0.330498,	
INFO:root:Epoch[1] Batch [1800]	Speed: 0.92 samples/sec	Train-RPNAcc=0.848513,	RPNLogLoss=0.415443,	RPNL1Loss=0.106213,	RCNNAcc=0.867600,	RCNNLogLoss=0.383498,	RCNNL1Loss=0.329358,	
INFO:root:Epoch[1] Batch [1820]	Speed: 0.93 samples/sec	Train-RPNAcc=0.849111,	RPNLogLoss=0.413136,	RPNL1Loss=0.105776,	RCNNAcc=0.868131,	RCNNLogLoss=0.381828,	RCNNL1Loss=0.328459,	
INFO:root:Epoch[1] Batch [1840]	Speed: 0.80 samples/sec	Train-RPNAcc=0.849430,	RPNLogLoss=0.411209,	RPNL1Loss=0.105585,	RCNNAcc=0.868401,	RCNNLogLoss=0.380722,	RCNNL1Loss=0.328127,	
INFO:root:Epoch[1] Batch [1860]	Speed: 0.87 samples/sec	Train-RPNAcc=0.849890,	RPNLogLoss=0.409092,	RPNL1Loss=0.105389,	RCNNAcc=0.868716,	RCNNLogLoss=0.379563,	RCNNL1Loss=0.327404,	
INFO:root:Epoch[1] Batch [1880]	Speed: 0.83 samples/sec	Train-RPNAcc=0.850262,	RPNLogLoss=0.407280,	RPNL1Loss=0.105237,	RCNNAcc=0.869052,	RCNNLogLoss=0.378324,	RCNNL1Loss=0.326779,	
INFO:root:Epoch[1] Batch [1900]	Speed: 0.83 samples/sec	Train-RPNAcc=0.850849,	RPNLogLoss=0.405081,	RPNL1Loss=0.104827,	RCNNAcc=0.869616,	RCNNLogLoss=0.376586,	RCNNL1Loss=0.326059,	
INFO:root:Epoch[1] Batch [1920]	Speed: 0.95 samples/sec	Train-RPNAcc=0.851532,	RPNLogLoss=0.402839,	RPNL1Loss=0.104314,	RCNNAcc=0.870238,	RCNNLogLoss=0.374799,	RCNNL1Loss=0.324857,	
INFO:root:Epoch[1] Batch [1940]	Speed: 0.84 samples/sec	Train-RPNAcc=0.851657,	RPNLogLoss=0.401223,	RPNL1Loss=0.104239,	RCNNAcc=0.870766,	RCNNLogLoss=0.373113,	RCNNL1Loss=0.323880,	
INFO:root:Epoch[1] Batch [1960]	Speed: 0.90 samples/sec	Train-RPNAcc=0.852351,	RPNLogLoss=0.399245,	RPNL1Loss=0.103919,	RCNNAcc=0.870976,	RCNNLogLoss=0.372378,	RCNNL1Loss=0.323489,	
INFO:root:Epoch[1] Batch [1980]	Speed: 0.90 samples/sec	Train-RPNAcc=0.852970,	RPNLogLoss=0.397362,	RPNL1Loss=0.103675,	RCNNAcc=0.871344,	RCNNLogLoss=0.371173,	RCNNL1Loss=0.323022,	
INFO:root:Epoch[1] Batch [2000]	Speed: 0.85 samples/sec	Train-RPNAcc=0.853530,	RPNLogLoss=0.395380,	RPNL1Loss=0.103362,	RCNNAcc=0.871744,	RCNNLogLoss=0.369963,	RCNNL1Loss=0.322354,	
INFO:root:Epoch[1] Batch [2020]	Speed: 0.85 samples/sec	Train-RPNAcc=0.854075,	RPNLogLoss=0.393485,	RPNL1Loss=0.103038,	RCNNAcc=0.872035,	RCNNLogLoss=0.368766,	RCNNL1Loss=0.322073,	
INFO:root:Epoch[1] Batch [2040]	Speed: 0.92 samples/sec	Train-RPNAcc=0.854529,	RPNLogLoss=0.391560,	RPNL1Loss=0.102764,	RCNNAcc=0.872588,	RCNNLogLoss=0.366963,	RCNNL1Loss=0.321183,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [2060]	Speed: 0.90 samples/sec	Train-RPNAcc=0.855219,	RPNLogLoss=0.389481,	RPNL1Loss=0.102409,	RCNNAcc=0.873230,	RCNNLogLoss=0.365144,	RCNNL1Loss=0.319860,	
INFO:root:Epoch[1] Batch [2080]	Speed: 0.88 samples/sec	Train-RPNAcc=0.856030,	RPNLogLoss=0.387163,	RPNL1Loss=0.101906,	RCNNAcc=0.873787,	RCNNLogLoss=0.363700,	RCNNL1Loss=0.318832,	
INFO:root:Epoch[1] Batch [2100]	Speed: 0.80 samples/sec	Train-RPNAcc=0.856502,	RPNLogLoss=0.385392,	RPNL1Loss=0.101687,	RCNNAcc=0.874018,	RCNNLogLoss=0.362625,	RCNNL1Loss=0.318381,	
INFO:root:Epoch[1] Batch [2120]	Speed: 0.89 samples/sec	Train-RPNAcc=0.857252,	RPNLogLoss=0.383350,	RPNL1Loss=0.101195,	RCNNAcc=0.874599,	RCNNLogLoss=0.360952,	RCNNL1Loss=0.317366,	
INFO:root:Epoch[1] Batch [2140]	Speed: 0.83 samples/sec	Train-RPNAcc=0.857658,	RPNLogLoss=0.381711,	RPNL1Loss=0.101094,	RCNNAcc=0.875113,	RCNNLogLoss=0.359405,	RCNNL1Loss=0.316549,	
INFO:root:Epoch[1] Batch [2160]	Speed: 0.90 samples/sec	Train-RPNAcc=0.858370,	RPNLogLoss=0.379575,	RPNL1Loss=0.100591,	RCNNAcc=0.875622,	RCNNLogLoss=0.357947,	RCNNL1Loss=0.315718,	
INFO:root:Epoch[1] Batch [2180]	Speed: 0.81 samples/sec	Train-RPNAcc=0.858976,	RPNLogLoss=0.377806,	RPNL1Loss=0.100302,	RCNNAcc=0.876003,	RCNNLogLoss=0.356597,	RCNNL1Loss=0.314991,	
INFO:root:Epoch[1] Batch [2200]	Speed: 0.86 samples/sec	Train-RPNAcc=0.859687,	RPNLogLoss=0.375743,	RPNL1Loss=0.099743,	RCNNAcc=0.876548,	RCNNLogLoss=0.354912,	RCNNL1Loss=0.313974,	
INFO:root:Epoch[1] Batch [2220]	Speed: 0.82 samples/sec	Train-RPNAcc=0.860165,	RPNLogLoss=0.374027,	RPNL1Loss=0.099471,	RCNNAcc=0.876833,	RCNNLogLoss=0.354012,	RCNNL1Loss=0.313638,	
INFO:root:Epoch[1] Batch [2240]	Speed: 0.85 samples/sec	Train-RPNAcc=0.860475,	RPNLogLoss=0.372665,	RPNL1Loss=0.099325,	RCNNAcc=0.877221,	RCNNLogLoss=0.352803,	RCNNL1Loss=0.313252,	
INFO:root:Epoch[1] Batch [2260]	Speed: 0.81 samples/sec	Train-RPNAcc=0.860971,	RPNLogLoss=0.371062,	RPNL1Loss=0.099041,	RCNNAcc=0.877505,	RCNNLogLoss=0.351964,	RCNNL1Loss=0.312908,	
INFO:root:Epoch[1] Batch [2280]	Speed: 0.85 samples/sec	Train-RPNAcc=0.861350,	RPNLogLoss=0.369532,	RPNL1Loss=0.098839,	RCNNAcc=0.877891,	RCNNLogLoss=0.350823,	RCNNL1Loss=0.312481,	
INFO:root:Epoch[1] Batch [2300]	Speed: 0.85 samples/sec	Train-RPNAcc=0.861983,	RPNLogLoss=0.367731,	RPNL1Loss=0.098447,	RCNNAcc=0.878283,	RCNNLogLoss=0.349503,	RCNNL1Loss=0.311819,	
INFO:root:Epoch[1] Batch [2320]	Speed: 0.80 samples/sec	Train-RPNAcc=0.862500,	RPNLogLoss=0.366047,	RPNL1Loss=0.098150,	RCNNAcc=0.878514,	RCNNLogLoss=0.348630,	RCNNL1Loss=0.311647,	
INFO:root:Epoch[1] Batch [2340]	Speed: 0.82 samples/sec	Train-RPNAcc=0.862757,	RPNLogLoss=0.364759,	RPNL1Loss=0.098071,	RCNNAcc=0.878674,	RCNNLogLoss=0.348093,	RCNNL1Loss=0.311368,	
INFO:root:Epoch[1] Batch [2360]	Speed: 0.80 samples/sec	Train-RPNAcc=0.863233,	RPNLogLoss=0.363512,	RPNL1Loss=0.097934,	RCNNAcc=0.878941,	RCNNLogLoss=0.347285,	RCNNL1Loss=0.310773,	
INFO:root:Epoch[1] Batch [2380]	Speed: 0.81 samples/sec	Train-RPNAcc=0.863578,	RPNLogLoss=0.362260,	RPNL1Loss=0.097664,	RCNNAcc=0.879187,	RCNNLogLoss=0.346573,	RCNNL1Loss=0.310616,	
INFO:root:Epoch[1] Batch [2400]	Speed: 0.86 samples/sec	Train-RPNAcc=0.864077,	RPNLogLoss=0.360688,	RPNL1Loss=0.097365,	RCNNAcc=0.879721,	RCNNLogLoss=0.345060,	RCNNL1Loss=0.309721,	
INFO:root:Epoch[1] Batch [2420]	Speed: 0.81 samples/sec	Train-RPNAcc=0.864507,	RPNLogLoss=0.359195,	RPNL1Loss=0.097014,	RCNNAcc=0.879924,	RCNNLogLoss=0.344369,	RCNNL1Loss=0.309600,	
INFO:root:Epoch[1] Batch [2440]	Speed: 0.85 samples/sec	Train-RPNAcc=0.865043,	RPNLogLoss=0.357729,	RPNL1Loss=0.096715,	RCNNAcc=0.880188,	RCNNLogLoss=0.343552,	RCNNL1Loss=0.309412,	
INFO:root:Epoch[1] Batch [2460]	Speed: 0.86 samples/sec	Train-RPNAcc=0.865592,	RPNLogLoss=0.356121,	RPNL1Loss=0.096385,	RCNNAcc=0.880600,	RCNNLogLoss=0.342278,	RCNNL1Loss=0.308501,	
INFO:root:Epoch[1] Batch [2480]	Speed: 0.84 samples/sec	Train-RPNAcc=0.865915,	RPNLogLoss=0.354900,	RPNL1Loss=0.096300,	RCNNAcc=0.880885,	RCNNLogLoss=0.341440,	RCNNL1Loss=0.308160,	
INFO:root:Epoch[1] Batch [2500]	Speed: 0.77 samples/sec	Train-RPNAcc=0.866503,	RPNLogLoss=0.353377,	RPNL1Loss=0.096017,	RCNNAcc=0.881198,	RCNNLogLoss=0.340451,	RCNNL1Loss=0.307925,	
INFO:root:Epoch[1] Batch [2520]	Speed: 0.85 samples/sec	Train-RPNAcc=0.866978,	RPNLogLoss=0.352023,	RPNL1Loss=0.095836,	RCNNAcc=0.881468,	RCNNLogLoss=0.339454,	RCNNL1Loss=0.307576,	
INFO:root:Epoch[1] Batch [2540]	Speed: 0.78 samples/sec	Train-RPNAcc=0.867393,	RPNLogLoss=0.350769,	RPNL1Loss=0.095712,	RCNNAcc=0.881773,	RCNNLogLoss=0.338405,	RCNNL1Loss=0.307129,	
INFO:root:Epoch[1] Batch [2560]	Speed: 0.88 samples/sec	Train-RPNAcc=0.867976,	RPNLogLoss=0.349246,	RPNL1Loss=0.095394,	RCNNAcc=0.882154,	RCNNLogLoss=0.337287,	RCNNL1Loss=0.306302,	
INFO:root:Epoch[1] Batch [2580]	Speed: 0.76 samples/sec	Train-RPNAcc=0.868224,	RPNLogLoss=0.348230,	RPNL1Loss=0.095425,	RCNNAcc=0.882228,	RCNNLogLoss=0.336893,	RCNNL1Loss=0.306407,	
INFO:root:Epoch[1] Batch [2600]	Speed: 0.77 samples/sec	Train-RPNAcc=0.868763,	RPNLogLoss=0.346880,	RPNL1Loss=0.095226,	RCNNAcc=0.882539,	RCNNLogLoss=0.336105,	RCNNL1Loss=0.306320,	
INFO:root:Epoch[1] Batch [2620]	Speed: 0.78 samples/sec	Train-RPNAcc=0.869076,	RPNLogLoss=0.345934,	RPNL1Loss=0.095203,	RCNNAcc=0.882672,	RCNNLogLoss=0.335624,	RCNNL1Loss=0.306459,	
INFO:root:Epoch[1] Batch [2640]	Speed: 0.79 samples/sec	Train-RPNAcc=0.869564,	RPNLogLoss=0.344696,	RPNL1Loss=0.094978,	RCNNAcc=0.882966,	RCNNLogLoss=0.334689,	RCNNL1Loss=0.306015,	
INFO:root:Epoch[1] Batch [2660]	Speed: 0.80 samples/sec	Train-RPNAcc=0.869997,	RPNLogLoss=0.343478,	RPNL1Loss=0.094815,	RCNNAcc=0.883182,	RCNNLogLoss=0.333949,	RCNNL1Loss=0.305626,	
INFO:root:Epoch[1] Batch [2680]	Speed: 0.75 samples/sec	Train-RPNAcc=0.870244,	RPNLogLoss=0.342589,	RPNL1Loss=0.094792,	RCNNAcc=0.883145,	RCNNLogLoss=0.333905,	RCNNL1Loss=0.305916,	
INFO:root:Epoch[1] Batch [2700]	Speed: 0.83 samples/sec	Train-RPNAcc=0.870861,	RPNLogLoss=0.341033,	RPNL1Loss=0.094362,	RCNNAcc=0.883550,	RCNNLogLoss=0.332634,	RCNNL1Loss=0.305160,	
INFO:root:Epoch[1] Batch [2720]	Speed: 0.78 samples/sec	Train-RPNAcc=0.871280,	RPNLogLoss=0.339874,	RPNL1Loss=0.094282,	RCNNAcc=0.883869,	RCNNLogLoss=0.331607,	RCNNL1Loss=0.304597,	
INFO:root:Epoch[1] Batch [2740]	Speed: 0.79 samples/sec	Train-RPNAcc=0.871836,	RPNLogLoss=0.338558,	RPNL1Loss=0.094042,	RCNNAcc=0.884135,	RCNNLogLoss=0.330815,	RCNNL1Loss=0.304116,	
INFO:root:Epoch[1] Batch [2760]	Speed: 0.75 samples/sec	Train-RPNAcc=0.872173,	RPNLogLoss=0.337499,	RPNL1Loss=0.093953,	RCNNAcc=0.884369,	RCNNLogLoss=0.330101,	RCNNL1Loss=0.303963,	
INFO:root:Epoch[1] Batch [2780]	Speed: 0.89 samples/sec	Train-RPNAcc=0.872786,	RPNLogLoss=0.336105,	RPNL1Loss=0.093614,	RCNNAcc=0.884745,	RCNNLogLoss=0.328845,	RCNNL1Loss=0.303127,	
INFO:root:Epoch[1] Batch [2800]	Speed: 0.83 samples/sec	Train-RPNAcc=0.873272,	RPNLogLoss=0.334800,	RPNL1Loss=0.093364,	RCNNAcc=0.885005,	RCNNLogLoss=0.327897,	RCNNL1Loss=0.302808,	
INFO:root:Epoch[1] Batch [2820]	Speed: 0.84 samples/sec	Train-RPNAcc=0.873694,	RPNLogLoss=0.333542,	RPNL1Loss=0.093155,	RCNNAcc=0.885302,	RCNNLogLoss=0.326976,	RCNNL1Loss=0.302299,	
INFO:root:Epoch[1] Batch [2840]	Speed: 0.82 samples/sec	Train-RPNAcc=0.874215,	RPNLogLoss=0.332263,	RPNL1Loss=0.092859,	RCNNAcc=0.885667,	RCNNLogLoss=0.326070,	RCNNL1Loss=0.301765,	
INFO:root:Epoch[1] Batch [2860]	Speed: 0.76 samples/sec	Train-RPNAcc=0.874590,	RPNLogLoss=0.331169,	RPNL1Loss=0.092796,	RCNNAcc=0.885964,	RCNNLogLoss=0.325104,	RCNNL1Loss=0.301385,	
INFO:root:Epoch[1] Batch [2880]	Speed: 0.81 samples/sec	Train-RPNAcc=0.875062,	RPNLogLoss=0.329917,	RPNL1Loss=0.092560,	RCNNAcc=0.886243,	RCNNLogLoss=0.324285,	RCNNL1Loss=0.300833,	
INFO:root:Epoch[1] Batch [2900]	Speed: 0.78 samples/sec	Train-RPNAcc=0.875470,	RPNLogLoss=0.328748,	RPNL1Loss=0.092372,	RCNNAcc=0.886470,	RCNNLogLoss=0.323418,	RCNNL1Loss=0.300475,	
INFO:root:Epoch[1] Batch [2920]	Speed: 0.75 samples/sec	Train-RPNAcc=0.875895,	RPNLogLoss=0.327618,	RPNL1Loss=0.092282,	RCNNAcc=0.886669,	RCNNLogLoss=0.322733,	RCNNL1Loss=0.300041,	
INFO:root:Epoch[1] Batch [2940]	Speed: 0.75 samples/sec	Train-RPNAcc=0.876250,	RPNLogLoss=0.326665,	RPNL1Loss=0.092158,	RCNNAcc=0.886725,	RCNNLogLoss=0.322477,	RCNNL1Loss=0.300266,	
INFO:root:Epoch[1] Batch [2960]	Speed: 0.76 samples/sec	Train-RPNAcc=0.876689,	RPNLogLoss=0.325513,	RPNL1Loss=0.091947,	RCNNAcc=0.887016,	RCNNLogLoss=0.321724,	RCNNL1Loss=0.300075,	
INFO:root:Epoch[1] Batch [2980]	Speed: 0.78 samples/sec	Train-RPNAcc=0.877068,	RPNLogLoss=0.324529,	RPNL1Loss=0.091807,	RCNNAcc=0.887121,	RCNNLogLoss=0.321303,	RCNNL1Loss=0.300163,	
INFO:root:Epoch[1] Batch [3000]	Speed: 0.68 samples/sec	Train-RPNAcc=0.877355,	RPNLogLoss=0.323731,	RPNL1Loss=0.091801,	RCNNAcc=0.887186,	RCNNLogLoss=0.320999,	RCNNL1Loss=0.300308,	
INFO:root:Epoch[1] Batch [3020]	Speed: 0.74 samples/sec	Train-RPNAcc=0.877728,	RPNLogLoss=0.322710,	RPNL1Loss=0.091593,	RCNNAcc=0.887317,	RCNNLogLoss=0.320447,	RCNNL1Loss=0.300151,	
INFO:root:Epoch[1] Batch [3040]	Speed: 0.78 samples/sec	Train-RPNAcc=0.878118,	RPNLogLoss=0.321665,	RPNL1Loss=0.091380,	RCNNAcc=0.887506,	RCNNLogLoss=0.319877,	RCNNL1Loss=0.299999,	
INFO:root:Epoch[1] Batch [3060]	Speed: 0.80 samples/sec	Train-RPNAcc=0.878530,	RPNLogLoss=0.320569,	RPNL1Loss=0.091227,	RCNNAcc=0.887879,	RCNNLogLoss=0.318745,	RCNNL1Loss=0.299309,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [3080]	Speed: 0.85 samples/sec	Train-RPNAcc=0.878962,	RPNLogLoss=0.319501,	RPNL1Loss=0.090994,	RCNNAcc=0.888221,	RCNNLogLoss=0.317726,	RCNNL1Loss=0.298720,	
INFO:root:Epoch[1] Batch [3100]	Speed: 0.73 samples/sec	Train-RPNAcc=0.879255,	RPNLogLoss=0.318536,	RPNL1Loss=0.090907,	RCNNAcc=0.888479,	RCNNLogLoss=0.316958,	RCNNL1Loss=0.298433,	
INFO:root:Epoch[1] Batch [3120]	Speed: 0.77 samples/sec	Train-RPNAcc=0.879737,	RPNLogLoss=0.317332,	RPNL1Loss=0.090663,	RCNNAcc=0.888710,	RCNNLogLoss=0.316287,	RCNNL1Loss=0.298104,	
INFO:root:Epoch[1] Batch [3140]	Speed: 0.82 samples/sec	Train-RPNAcc=0.880104,	RPNLogLoss=0.316404,	RPNL1Loss=0.090415,	RCNNAcc=0.888906,	RCNNLogLoss=0.315656,	RCNNL1Loss=0.297855,	
INFO:root:Epoch[1] Batch [3160]	Speed: 0.74 samples/sec	Train-RPNAcc=0.880350,	RPNLogLoss=0.315526,	RPNL1Loss=0.090253,	RCNNAcc=0.889172,	RCNNLogLoss=0.314879,	RCNNL1Loss=0.297455,	
INFO:root:Epoch[1] Batch [3180]	Speed: 0.81 samples/sec	Train-RPNAcc=0.880799,	RPNLogLoss=0.314427,	RPNL1Loss=0.090053,	RCNNAcc=0.889444,	RCNNLogLoss=0.314085,	RCNNL1Loss=0.297004,	
INFO:root:Epoch[1] Batch [3200]	Speed: 0.73 samples/sec	Train-RPNAcc=0.881271,	RPNLogLoss=0.313309,	RPNL1Loss=0.089866,	RCNNAcc=0.889685,	RCNNLogLoss=0.313411,	RCNNL1Loss=0.296764,	
INFO:root:Epoch[1] Batch [3220]	Speed: 0.75 samples/sec	Train-RPNAcc=0.881772,	RPNLogLoss=0.312162,	RPNL1Loss=0.089596,	RCNNAcc=0.889859,	RCNNLogLoss=0.312799,	RCNNL1Loss=0.296392,	
INFO:root:Epoch[1] Batch [3240]	Speed: 0.76 samples/sec	Train-RPNAcc=0.882195,	RPNLogLoss=0.311205,	RPNL1Loss=0.089553,	RCNNAcc=0.890027,	RCNNLogLoss=0.312225,	RCNNL1Loss=0.296088,	
INFO:root:Epoch[1] Batch [3260]	Speed: 0.82 samples/sec	Train-RPNAcc=0.882612,	RPNLogLoss=0.310177,	RPNL1Loss=0.089306,	RCNNAcc=0.890335,	RCNNLogLoss=0.311239,	RCNNL1Loss=0.295620,	
INFO:root:Epoch[1] Batch [3280]	Speed: 0.78 samples/sec	Train-RPNAcc=0.882961,	RPNLogLoss=0.309295,	RPNL1Loss=0.089213,	RCNNAcc=0.890508,	RCNNLogLoss=0.310685,	RCNNL1Loss=0.295442,	
INFO:root:Epoch[1] Batch [3300]	Speed: 0.73 samples/sec	Train-RPNAcc=0.883343,	RPNLogLoss=0.308459,	RPNL1Loss=0.089042,	RCNNAcc=0.890606,	RCNNLogLoss=0.310287,	RCNNL1Loss=0.295175,	
INFO:root:Epoch[1] Batch [3320]	Speed: 0.76 samples/sec	Train-RPNAcc=0.883836,	RPNLogLoss=0.307340,	RPNL1Loss=0.088750,	RCNNAcc=0.890903,	RCNNLogLoss=0.309439,	RCNNL1Loss=0.294700,	
INFO:root:Epoch[1] Batch [3340]	Speed: 0.77 samples/sec	Train-RPNAcc=0.884183,	RPNLogLoss=0.306505,	RPNL1Loss=0.088563,	RCNNAcc=0.891027,	RCNNLogLoss=0.309030,	RCNNL1Loss=0.294633,	
INFO:root:Epoch[1] Batch [3360]	Speed: 0.73 samples/sec	Train-RPNAcc=0.884549,	RPNLogLoss=0.305537,	RPNL1Loss=0.088361,	RCNNAcc=0.891190,	RCNNLogLoss=0.308435,	RCNNL1Loss=0.294278,	
INFO:root:Epoch[1] Batch [3380]	Speed: 0.73 samples/sec	Train-RPNAcc=0.884922,	RPNLogLoss=0.304614,	RPNL1Loss=0.088266,	RCNNAcc=0.891390,	RCNNLogLoss=0.307786,	RCNNL1Loss=0.294002,	
INFO:root:Epoch[1] Batch [3400]	Speed: 0.77 samples/sec	Train-RPNAcc=0.885211,	RPNLogLoss=0.303823,	RPNL1Loss=0.088167,	RCNNAcc=0.891463,	RCNNLogLoss=0.307527,	RCNNL1Loss=0.294042,	
INFO:root:Epoch[1] Batch [3420]	Speed: 0.75 samples/sec	Train-RPNAcc=0.885608,	RPNLogLoss=0.302873,	RPNL1Loss=0.087930,	RCNNAcc=0.891744,	RCNNLogLoss=0.306744,	RCNNL1Loss=0.293725,	
INFO:root:Epoch[1] Batch [3440]	Speed: 0.79 samples/sec	Train-RPNAcc=0.885994,	RPNLogLoss=0.301923,	RPNL1Loss=0.087752,	RCNNAcc=0.891955,	RCNNLogLoss=0.306182,	RCNNL1Loss=0.293499,	
INFO:root:Epoch[1] Batch [3460]	Speed: 0.76 samples/sec	Train-RPNAcc=0.886320,	RPNLogLoss=0.301185,	RPNL1Loss=0.087696,	RCNNAcc=0.892131,	RCNNLogLoss=0.305670,	RCNNL1Loss=0.293321,	
INFO:root:Epoch[1] Batch [3480]	Speed: 0.79 samples/sec	Train-RPNAcc=0.886690,	RPNLogLoss=0.300291,	RPNL1Loss=0.087597,	RCNNAcc=0.892429,	RCNNLogLoss=0.304746,	RCNNL1Loss=0.292909,	
INFO:root:Epoch[1] Batch [3500]	Speed: 0.80 samples/sec	Train-RPNAcc=0.887093,	RPNLogLoss=0.299409,	RPNL1Loss=0.087419,	RCNNAcc=0.892694,	RCNNLogLoss=0.303968,	RCNNL1Loss=0.292452,	
INFO:root:Epoch[1] Batch [3520]	Speed: 0.72 samples/sec	Train-RPNAcc=0.887481,	RPNLogLoss=0.298568,	RPNL1Loss=0.087351,	RCNNAcc=0.892722,	RCNNLogLoss=0.303750,	RCNNL1Loss=0.292397,	
INFO:root:Epoch[1] Batch [3540]	Speed: 0.70 samples/sec	Train-RPNAcc=0.887812,	RPNLogLoss=0.297797,	RPNL1Loss=0.087285,	RCNNAcc=0.892798,	RCNNLogLoss=0.303351,	RCNNL1Loss=0.292350,	
INFO:root:Epoch[1] Batch [3560]	Speed: 0.80 samples/sec	Train-RPNAcc=0.888141,	RPNLogLoss=0.296934,	RPNL1Loss=0.087136,	RCNNAcc=0.893005,	RCNNLogLoss=0.302687,	RCNNL1Loss=0.292005,	
INFO:root:Epoch[1] Batch [3580]	Speed: 0.79 samples/sec	Train-RPNAcc=0.888484,	RPNLogLoss=0.296042,	RPNL1Loss=0.086949,	RCNNAcc=0.893204,	RCNNLogLoss=0.302060,	RCNNL1Loss=0.291705,	
INFO:root:Epoch[1] Batch [3600]	Speed: 0.79 samples/sec	Train-RPNAcc=0.888887,	RPNLogLoss=0.295138,	RPNL1Loss=0.086757,	RCNNAcc=0.893389,	RCNNLogLoss=0.301446,	RCNNL1Loss=0.291451,	
INFO:root:Epoch[1] Batch [3620]	Speed: 0.80 samples/sec	Train-RPNAcc=0.889241,	RPNLogLoss=0.294307,	RPNL1Loss=0.086597,	RCNNAcc=0.893553,	RCNNLogLoss=0.300891,	RCNNL1Loss=0.291383,	
INFO:root:Epoch[1] Batch [3640]	Speed: 0.72 samples/sec	Train-RPNAcc=0.889564,	RPNLogLoss=0.293580,	RPNL1Loss=0.086513,	RCNNAcc=0.893642,	RCNNLogLoss=0.300624,	RCNNL1Loss=0.291307,	
INFO:root:Epoch[1] Batch [3660]	Speed: 0.78 samples/sec	Train-RPNAcc=0.889923,	RPNLogLoss=0.292662,	RPNL1Loss=0.086292,	RCNNAcc=0.893839,	RCNNLogLoss=0.300041,	RCNNL1Loss=0.291076,	
INFO:root:Epoch[1] Batch [3680]	Speed: 0.75 samples/sec	Train-RPNAcc=0.890303,	RPNLogLoss=0.291776,	RPNL1Loss=0.086176,	RCNNAcc=0.893944,	RCNNLogLoss=0.299564,	RCNNL1Loss=0.291087,	
INFO:root:Epoch[1] Batch [3700]	Speed: 0.75 samples/sec	Train-RPNAcc=0.890678,	RPNLogLoss=0.290852,	RPNL1Loss=0.086016,	RCNNAcc=0.894125,	RCNNLogLoss=0.298946,	RCNNL1Loss=0.290833,	
INFO:root:Epoch[1] Batch [3720]	Speed: 0.81 samples/sec	Train-RPNAcc=0.891035,	RPNLogLoss=0.289928,	RPNL1Loss=0.085789,	RCNNAcc=0.894310,	RCNNLogLoss=0.298283,	RCNNL1Loss=0.290378,	
INFO:root:Epoch[1] Batch [3740]	Speed: 0.72 samples/sec	Train-RPNAcc=0.891315,	RPNLogLoss=0.289160,	RPNL1Loss=0.085662,	RCNNAcc=0.894522,	RCNNLogLoss=0.297681,	RCNNL1Loss=0.290024,	
INFO:root:Epoch[1] Batch [3760]	Speed: 0.74 samples/sec	Train-RPNAcc=0.891652,	RPNLogLoss=0.288380,	RPNL1Loss=0.085599,	RCNNAcc=0.894626,	RCNNLogLoss=0.297383,	RCNNL1Loss=0.289930,	
INFO:root:Epoch[1] Batch [3780]	Speed: 0.77 samples/sec	Train-RPNAcc=0.892011,	RPNLogLoss=0.287519,	RPNL1Loss=0.085421,	RCNNAcc=0.894859,	RCNNLogLoss=0.296681,	RCNNL1Loss=0.289586,	
INFO:root:Epoch[1] Batch [3800]	Speed: 0.73 samples/sec	Train-RPNAcc=0.892275,	RPNLogLoss=0.286899,	RPNL1Loss=0.085363,	RCNNAcc=0.895015,	RCNNLogLoss=0.296178,	RCNNL1Loss=0.289428,	
INFO:root:Epoch[1] Batch [3820]	Speed: 0.79 samples/sec	Train-RPNAcc=0.892568,	RPNLogLoss=0.286173,	RPNL1Loss=0.085222,	RCNNAcc=0.895164,	RCNNLogLoss=0.295763,	RCNNL1Loss=0.289301,	
INFO:root:Epoch[1] Batch [3840]	Speed: 0.72 samples/sec	Train-RPNAcc=0.892874,	RPNLogLoss=0.285401,	RPNL1Loss=0.085071,	RCNNAcc=0.895313,	RCNNLogLoss=0.295307,	RCNNL1Loss=0.289266,	
INFO:root:Epoch[1] Batch [3860]	Speed: 0.75 samples/sec	Train-RPNAcc=0.893122,	RPNLogLoss=0.284730,	RPNL1Loss=0.084993,	RCNNAcc=0.895354,	RCNNLogLoss=0.295009,	RCNNL1Loss=0.289338,	
INFO:root:Epoch[1] Batch [3880]	Speed: 0.73 samples/sec	Train-RPNAcc=0.893479,	RPNLogLoss=0.283902,	RPNL1Loss=0.084802,	RCNNAcc=0.895515,	RCNNLogLoss=0.294501,	RCNNL1Loss=0.289172,	
INFO:root:Epoch[1] Batch [3900]	Speed: 0.74 samples/sec	Train-RPNAcc=0.893734,	RPNLogLoss=0.283224,	RPNL1Loss=0.084746,	RCNNAcc=0.895692,	RCNNLogLoss=0.293985,	RCNNL1Loss=0.289008,	
INFO:root:Epoch[1] Batch [3920]	Speed: 0.77 samples/sec	Train-RPNAcc=0.894068,	RPNLogLoss=0.282454,	RPNL1Loss=0.084545,	RCNNAcc=0.895778,	RCNNLogLoss=0.293700,	RCNNL1Loss=0.288941,	
INFO:root:Epoch[1] Batch [3940]	Speed: 0.80 samples/sec	Train-RPNAcc=0.894430,	RPNLogLoss=0.281573,	RPNL1Loss=0.084358,	RCNNAcc=0.896013,	RCNNLogLoss=0.292983,	RCNNL1Loss=0.288560,	
INFO:root:Epoch[1] Batch [3960]	Speed: 0.73 samples/sec	Train-RPNAcc=0.894672,	RPNLogLoss=0.280852,	RPNL1Loss=0.084197,	RCNNAcc=0.896201,	RCNNLogLoss=0.292472,	RCNNL1Loss=0.288173,	
INFO:root:Epoch[1] Batch [3980]	Speed: 0.74 samples/sec	Train-RPNAcc=0.894941,	RPNLogLoss=0.280201,	RPNL1Loss=0.084106,	RCNNAcc=0.896300,	RCNNLogLoss=0.292150,	RCNNL1Loss=0.288053,	
INFO:root:Epoch[1] Batch [4000]	Speed: 0.79 samples/sec	Train-RPNAcc=0.895286,	RPNLogLoss=0.279377,	RPNL1Loss=0.083921,	RCNNAcc=0.896522,	RCNNLogLoss=0.291513,	RCNNL1Loss=0.287612,	
INFO:root:Epoch[1] Batch [4020]	Speed: 0.70 samples/sec	Train-RPNAcc=0.895602,	RPNLogLoss=0.278600,	RPNL1Loss=0.083741,	RCNNAcc=0.896681,	RCNNLogLoss=0.290987,	RCNNL1Loss=0.287542,	
INFO:root:Epoch[1] Batch [4040]	Speed: 0.78 samples/sec	Train-RPNAcc=0.895944,	RPNLogLoss=0.277805,	RPNL1Loss=0.083567,	RCNNAcc=0.896821,	RCNNLogLoss=0.290634,	RCNNL1Loss=0.287396,	
INFO:root:Epoch[1] Batch [4060]	Speed: 0.77 samples/sec	Train-RPNAcc=0.896282,	RPNLogLoss=0.276975,	RPNL1Loss=0.083359,	RCNNAcc=0.897025,	RCNNLogLoss=0.290139,	RCNNL1Loss=0.287045,	
INFO:root:Epoch[1] Batch [4080]	Speed: 0.74 samples/sec	Train-RPNAcc=0.896521,	RPNLogLoss=0.276407,	RPNL1Loss=0.083295,	RCNNAcc=0.897065,	RCNNLogLoss=0.290016,	RCNNL1Loss=0.287057,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [4100]	Speed: 0.75 samples/sec	Train-RPNAcc=0.896871,	RPNLogLoss=0.275656,	RPNL1Loss=0.083153,	RCNNAcc=0.897268,	RCNNLogLoss=0.289440,	RCNNL1Loss=0.286815,	
INFO:root:Epoch[1] Batch [4120]	Speed: 0.69 samples/sec	Train-RPNAcc=0.897061,	RPNLogLoss=0.275153,	RPNL1Loss=0.083099,	RCNNAcc=0.897321,	RCNNLogLoss=0.289194,	RCNNL1Loss=0.286739,	
INFO:root:Epoch[1] Batch [4140]	Speed: 0.71 samples/sec	Train-RPNAcc=0.897314,	RPNLogLoss=0.274557,	RPNL1Loss=0.083002,	RCNNAcc=0.897455,	RCNNLogLoss=0.288763,	RCNNL1Loss=0.286609,	
INFO:root:Epoch[1] Batch [4160]	Speed: 0.73 samples/sec	Train-RPNAcc=0.897598,	RPNLogLoss=0.273902,	RPNL1Loss=0.082931,	RCNNAcc=0.897583,	RCNNLogLoss=0.288372,	RCNNL1Loss=0.286402,	
INFO:root:Epoch[1] Batch [4180]	Speed: 0.78 samples/sec	Train-RPNAcc=0.897907,	RPNLogLoss=0.273249,	RPNL1Loss=0.082765,	RCNNAcc=0.897684,	RCNNLogLoss=0.288060,	RCNNL1Loss=0.286367,	
INFO:root:Epoch[1] Batch [4200]	Speed: 0.77 samples/sec	Train-RPNAcc=0.898248,	RPNLogLoss=0.272505,	RPNL1Loss=0.082614,	RCNNAcc=0.897835,	RCNNLogLoss=0.287686,	RCNNL1Loss=0.286128,	
INFO:root:Epoch[1] Batch [4220]	Speed: 0.73 samples/sec	Train-RPNAcc=0.898549,	RPNLogLoss=0.271786,	RPNL1Loss=0.082484,	RCNNAcc=0.897990,	RCNNLogLoss=0.287123,	RCNNL1Loss=0.285880,	
INFO:root:Epoch[1] Batch [4240]	Speed: 0.71 samples/sec	Train-RPNAcc=0.898770,	RPNLogLoss=0.271244,	RPNL1Loss=0.082399,	RCNNAcc=0.898062,	RCNNLogLoss=0.286885,	RCNNL1Loss=0.285890,	
INFO:root:Epoch[1] Batch [4260]	Speed: 0.79 samples/sec	Train-RPNAcc=0.899113,	RPNLogLoss=0.270510,	RPNL1Loss=0.082218,	RCNNAcc=0.898142,	RCNNLogLoss=0.286614,	RCNNL1Loss=0.285887,	
INFO:root:Epoch[1] Batch [4280]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899429,	RPNLogLoss=0.269785,	RPNL1Loss=0.082040,	RCNNAcc=0.898312,	RCNNLogLoss=0.286102,	RCNNL1Loss=0.285601,	
INFO:root:Epoch[1] Batch [4300]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899713,	RPNLogLoss=0.269159,	RPNL1Loss=0.081905,	RCNNAcc=0.898438,	RCNNLogLoss=0.285752,	RCNNL1Loss=0.285412,	
INFO:root:Epoch[1] Batch [4320]	Speed: 0.77 samples/sec	Train-RPNAcc=0.899994,	RPNLogLoss=0.268486,	RPNL1Loss=0.081750,	RCNNAcc=0.898606,	RCNNLogLoss=0.285243,	RCNNL1Loss=0.285165,	
INFO:root:Epoch[1] Batch [4340]	Speed: 0.73 samples/sec	Train-RPNAcc=0.900334,	RPNLogLoss=0.267694,	RPNL1Loss=0.081541,	RCNNAcc=0.898740,	RCNNLogLoss=0.284824,	RCNNL1Loss=0.284869,	
INFO:root:Epoch[1] Batch [4360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.900544,	RPNLogLoss=0.267180,	RPNL1Loss=0.081472,	RCNNAcc=0.898824,	RCNNLogLoss=0.284539,	RCNNL1Loss=0.284874,	
INFO:root:Epoch[1] Batch [4380]	Speed: 0.79 samples/sec	Train-RPNAcc=0.900877,	RPNLogLoss=0.266395,	RPNL1Loss=0.081273,	RCNNAcc=0.899013,	RCNNLogLoss=0.283994,	RCNNL1Loss=0.284553,	
INFO:root:Epoch[1] Batch [4400]	Speed: 0.78 samples/sec	Train-RPNAcc=0.901175,	RPNLogLoss=0.265675,	RPNL1Loss=0.081113,	RCNNAcc=0.899162,	RCNNLogLoss=0.283540,	RCNNL1Loss=0.284336,	
INFO:root:Epoch[1] Batch [4420]	Speed: 0.72 samples/sec	Train-RPNAcc=0.901360,	RPNLogLoss=0.265206,	RPNL1Loss=0.081075,	RCNNAcc=0.899238,	RCNNLogLoss=0.283356,	RCNNL1Loss=0.284324,	
INFO:root:Epoch[1] Batch [4440]	Speed: 0.70 samples/sec	Train-RPNAcc=0.901578,	RPNLogLoss=0.264669,	RPNL1Loss=0.080992,	RCNNAcc=0.899375,	RCNNLogLoss=0.282898,	RCNNL1Loss=0.284250,	
INFO:root:Epoch[1] Batch [4460]	Speed: 0.71 samples/sec	Train-RPNAcc=0.901822,	RPNLogLoss=0.264137,	RPNL1Loss=0.080950,	RCNNAcc=0.899434,	RCNNLogLoss=0.282657,	RCNNL1Loss=0.284284,	
INFO:root:Epoch[1] Batch [4480]	Speed: 0.77 samples/sec	Train-RPNAcc=0.902077,	RPNLogLoss=0.263537,	RPNL1Loss=0.080781,	RCNNAcc=0.899546,	RCNNLogLoss=0.282264,	RCNNL1Loss=0.284127,	
INFO:root:Epoch[1] Batch [4500]	Speed: 0.74 samples/sec	Train-RPNAcc=0.902329,	RPNLogLoss=0.262906,	RPNL1Loss=0.080689,	RCNNAcc=0.899734,	RCNNLogLoss=0.281757,	RCNNL1Loss=0.283886,	
INFO:root:Epoch[1] Batch [4520]	Speed: 0.74 samples/sec	Train-RPNAcc=0.902549,	RPNLogLoss=0.262388,	RPNL1Loss=0.080676,	RCNNAcc=0.899865,	RCNNLogLoss=0.281387,	RCNNL1Loss=0.283761,	
INFO:root:Epoch[1] Batch [4540]	Speed: 0.73 samples/sec	Train-RPNAcc=0.902834,	RPNLogLoss=0.261710,	RPNL1Loss=0.080554,	RCNNAcc=0.900053,	RCNNLogLoss=0.280903,	RCNNL1Loss=0.283533,	
INFO:root:Epoch[1] Batch [4560]	Speed: 0.69 samples/sec	Train-RPNAcc=0.903026,	RPNLogLoss=0.261240,	RPNL1Loss=0.080481,	RCNNAcc=0.900116,	RCNNLogLoss=0.280688,	RCNNL1Loss=0.283652,	
INFO:root:Epoch[1] Batch [4580]	Speed: 0.66 samples/sec	Train-RPNAcc=0.903251,	RPNLogLoss=0.260753,	RPNL1Loss=0.080409,	RCNNAcc=0.900174,	RCNNLogLoss=0.280480,	RCNNL1Loss=0.283566,	
INFO:root:Epoch[1] Batch [4600]	Speed: 0.74 samples/sec	Train-RPNAcc=0.903517,	RPNLogLoss=0.260240,	RPNL1Loss=0.080371,	RCNNAcc=0.900271,	RCNNLogLoss=0.280162,	RCNNL1Loss=0.283449,	
INFO:root:Epoch[1] Batch [4620]	Speed: 0.78 samples/sec	Train-RPNAcc=0.903788,	RPNLogLoss=0.259644,	RPNL1Loss=0.080241,	RCNNAcc=0.900426,	RCNNLogLoss=0.279678,	RCNNL1Loss=0.283259,	
INFO:root:Epoch[1] Batch [4640]	Speed: 0.73 samples/sec	Train-RPNAcc=0.904017,	RPNLogLoss=0.259068,	RPNL1Loss=0.080089,	RCNNAcc=0.900540,	RCNNLogLoss=0.279335,	RCNNL1Loss=0.282956,	
INFO:root:Epoch[1] Batch [4660]	Speed: 0.78 samples/sec	Train-RPNAcc=0.904263,	RPNLogLoss=0.258475,	RPNL1Loss=0.079964,	RCNNAcc=0.900665,	RCNNLogLoss=0.278925,	RCNNL1Loss=0.282718,	
INFO:root:Epoch[1] Batch [4680]	Speed: 0.74 samples/sec	Train-RPNAcc=0.904521,	RPNLogLoss=0.257890,	RPNL1Loss=0.079857,	RCNNAcc=0.900751,	RCNNLogLoss=0.278668,	RCNNL1Loss=0.282745,	
INFO:root:Epoch[1] Batch [4700]	Speed: 0.80 samples/sec	Train-RPNAcc=0.904804,	RPNLogLoss=0.257231,	RPNL1Loss=0.079689,	RCNNAcc=0.900875,	RCNNLogLoss=0.278281,	RCNNL1Loss=0.282483,	
INFO:root:Epoch[1] Batch [4720]	Speed: 0.71 samples/sec	Train-RPNAcc=0.905028,	RPNLogLoss=0.256661,	RPNL1Loss=0.079593,	RCNNAcc=0.900946,	RCNNLogLoss=0.277976,	RCNNL1Loss=0.282334,	
INFO:root:Epoch[1] Batch [4740]	Speed: 0.77 samples/sec	Train-RPNAcc=0.905306,	RPNLogLoss=0.256017,	RPNL1Loss=0.079454,	RCNNAcc=0.901087,	RCNNLogLoss=0.277564,	RCNNL1Loss=0.282172,	
INFO:root:Epoch[1] Batch [4760]	Speed: 0.73 samples/sec	Train-RPNAcc=0.905526,	RPNLogLoss=0.255477,	RPNL1Loss=0.079378,	RCNNAcc=0.901170,	RCNNLogLoss=0.277305,	RCNNL1Loss=0.282113,	
INFO:root:Epoch[1] Batch [4780]	Speed: 0.71 samples/sec	Train-RPNAcc=0.905726,	RPNLogLoss=0.255010,	RPNL1Loss=0.079347,	RCNNAcc=0.901184,	RCNNLogLoss=0.277140,	RCNNL1Loss=0.282194,	
INFO:root:Epoch[1] Batch [4800]	Speed: 0.80 samples/sec	Train-RPNAcc=0.906025,	RPNLogLoss=0.254307,	RPNL1Loss=0.079162,	RCNNAcc=0.901425,	RCNNLogLoss=0.276460,	RCNNL1Loss=0.281712,	
INFO:root:Epoch[1] Batch [4820]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906253,	RPNLogLoss=0.253766,	RPNL1Loss=0.079084,	RCNNAcc=0.901518,	RCNNLogLoss=0.276129,	RCNNL1Loss=0.281576,	
INFO:root:Epoch[1] Batch [4840]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906539,	RPNLogLoss=0.253150,	RPNL1Loss=0.078924,	RCNNAcc=0.901715,	RCNNLogLoss=0.275593,	RCNNL1Loss=0.281237,	
INFO:root:Epoch[1] Batch [4860]	Speed: 0.74 samples/sec	Train-RPNAcc=0.906838,	RPNLogLoss=0.252472,	RPNL1Loss=0.078776,	RCNNAcc=0.901816,	RCNNLogLoss=0.275262,	RCNNL1Loss=0.281074,	
INFO:root:Epoch[1] Batch [4880]	Speed: 0.73 samples/sec	Train-RPNAcc=0.907020,	RPNLogLoss=0.252081,	RPNL1Loss=0.078806,	RCNNAcc=0.901876,	RCNNLogLoss=0.275095,	RCNNL1Loss=0.280980,	
INFO:root:Epoch[1] Batch [4900]	Speed: 0.80 samples/sec	Train-RPNAcc=0.907308,	RPNLogLoss=0.251394,	RPNL1Loss=0.078645,	RCNNAcc=0.902067,	RCNNLogLoss=0.274503,	RCNNL1Loss=0.280646,	
INFO:root:Epoch[1] Batch [4920]	Speed: 0.72 samples/sec	Train-RPNAcc=0.907545,	RPNLogLoss=0.250798,	RPNL1Loss=0.078515,	RCNNAcc=0.902162,	RCNNLogLoss=0.274184,	RCNNL1Loss=0.280613,	
INFO:root:Epoch[1] Batch [4940]	Speed: 0.75 samples/sec	Train-RPNAcc=0.907778,	RPNLogLoss=0.250253,	RPNL1Loss=0.078414,	RCNNAcc=0.902324,	RCNNLogLoss=0.273814,	RCNNL1Loss=0.280308,	
INFO:root:Epoch[1] Batch [4960]	Speed: 0.73 samples/sec	Train-RPNAcc=0.908055,	RPNLogLoss=0.249642,	RPNL1Loss=0.078238,	RCNNAcc=0.902434,	RCNNLogLoss=0.273491,	RCNNL1Loss=0.280126,	
INFO:root:Epoch[1] Batch [4980]	Speed: 0.71 samples/sec	Train-RPNAcc=0.908252,	RPNLogLoss=0.249143,	RPNL1Loss=0.078156,	RCNNAcc=0.902445,	RCNNLogLoss=0.273346,	RCNNL1Loss=0.280018,	
INFO:root:Epoch[1] Batch [5000]	Speed: 0.77 samples/sec	Train-RPNAcc=0.908489,	RPNLogLoss=0.248578,	RPNL1Loss=0.078025,	RCNNAcc=0.902573,	RCNNLogLoss=0.272951,	RCNNL1Loss=0.279818,	
INFO:root:Epoch[1] Batch [5020]	Speed: 0.75 samples/sec	Train-RPNAcc=0.908760,	RPNLogLoss=0.247965,	RPNL1Loss=0.077843,	RCNNAcc=0.902737,	RCNNLogLoss=0.272524,	RCNNL1Loss=0.279552,	
INFO:root:Epoch[1] Batch [5040]	Speed: 0.74 samples/sec	Train-RPNAcc=0.908936,	RPNLogLoss=0.247545,	RPNL1Loss=0.077784,	RCNNAcc=0.902858,	RCNNLogLoss=0.272181,	RCNNL1Loss=0.279498,	
INFO:root:Epoch[1] Batch [5060]	Speed: 0.72 samples/sec	Train-RPNAcc=0.909163,	RPNLogLoss=0.247003,	RPNL1Loss=0.077716,	RCNNAcc=0.902996,	RCNNLogLoss=0.271752,	RCNNL1Loss=0.279341,	
INFO:root:Epoch[1] Batch [5080]	Speed: 0.78 samples/sec	Train-RPNAcc=0.909435,	RPNLogLoss=0.246408,	RPNL1Loss=0.077546,	RCNNAcc=0.903124,	RCNNLogLoss=0.271336,	RCNNL1Loss=0.279091,	
INFO:root:Epoch[1] Batch [5100]	Speed: 0.70 samples/sec	Train-RPNAcc=0.909692,	RPNLogLoss=0.245802,	RPNL1Loss=0.077445,	RCNNAcc=0.903208,	RCNNLogLoss=0.271054,	RCNNL1Loss=0.278974,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [5120]	Speed: 0.70 samples/sec	Train-RPNAcc=0.909963,	RPNLogLoss=0.245170,	RPNL1Loss=0.077298,	RCNNAcc=0.903351,	RCNNLogLoss=0.270594,	RCNNL1Loss=0.278668,	
INFO:root:Epoch[1] Batch [5140]	Speed: 0.75 samples/sec	Train-RPNAcc=0.910224,	RPNLogLoss=0.244568,	RPNL1Loss=0.077164,	RCNNAcc=0.903474,	RCNNLogLoss=0.270211,	RCNNL1Loss=0.278516,	
INFO:root:Epoch[1] Batch [5160]	Speed: 0.74 samples/sec	Train-RPNAcc=0.910466,	RPNLogLoss=0.243956,	RPNL1Loss=0.077031,	RCNNAcc=0.903613,	RCNNLogLoss=0.269810,	RCNNL1Loss=0.278249,	
INFO:root:Epoch[1] Batch [5180]	Speed: 0.77 samples/sec	Train-RPNAcc=0.910690,	RPNLogLoss=0.243444,	RPNL1Loss=0.076918,	RCNNAcc=0.903803,	RCNNLogLoss=0.269320,	RCNNL1Loss=0.277901,	
INFO:root:Epoch[1] Batch [5200]	Speed: 0.71 samples/sec	Train-RPNAcc=0.910879,	RPNLogLoss=0.243013,	RPNL1Loss=0.076818,	RCNNAcc=0.903937,	RCNNLogLoss=0.268872,	RCNNL1Loss=0.277825,	
INFO:root:Epoch[1] Batch [5220]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911058,	RPNLogLoss=0.242564,	RPNL1Loss=0.076743,	RCNNAcc=0.904028,	RCNNLogLoss=0.268582,	RCNNL1Loss=0.277632,	
INFO:root:Epoch[1] Batch [5240]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911271,	RPNLogLoss=0.242094,	RPNL1Loss=0.076677,	RCNNAcc=0.904160,	RCNNLogLoss=0.268168,	RCNNL1Loss=0.277501,	
INFO:root:Epoch[1] Batch [5260]	Speed: 0.76 samples/sec	Train-RPNAcc=0.911492,	RPNLogLoss=0.241602,	RPNL1Loss=0.076578,	RCNNAcc=0.904259,	RCNNLogLoss=0.267887,	RCNNL1Loss=0.277402,	
INFO:root:Epoch[1] Batch [5280]	Speed: 0.74 samples/sec	Train-RPNAcc=0.911745,	RPNLogLoss=0.241048,	RPNL1Loss=0.076472,	RCNNAcc=0.904358,	RCNNLogLoss=0.267521,	RCNNL1Loss=0.277258,	
INFO:root:Epoch[1] Batch [5300]	Speed: 0.70 samples/sec	Train-RPNAcc=0.911932,	RPNLogLoss=0.240665,	RPNL1Loss=0.076497,	RCNNAcc=0.904405,	RCNNLogLoss=0.267390,	RCNNL1Loss=0.277314,	
INFO:root:Epoch[1] Batch [5320]	Speed: 0.75 samples/sec	Train-RPNAcc=0.912115,	RPNLogLoss=0.240178,	RPNL1Loss=0.076399,	RCNNAcc=0.904534,	RCNNLogLoss=0.267043,	RCNNL1Loss=0.277159,	
INFO:root:Epoch[1] Batch [5340]	Speed: 0.75 samples/sec	Train-RPNAcc=0.912335,	RPNLogLoss=0.239681,	RPNL1Loss=0.076302,	RCNNAcc=0.904632,	RCNNLogLoss=0.266712,	RCNNL1Loss=0.277067,	
INFO:root:Epoch[1] Batch [5360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.912546,	RPNLogLoss=0.239202,	RPNL1Loss=0.076228,	RCNNAcc=0.904707,	RCNNLogLoss=0.266483,	RCNNL1Loss=0.276950,	
INFO:root:Epoch[1] Batch [5380]	Speed: 0.73 samples/sec	Train-RPNAcc=0.912774,	RPNLogLoss=0.238676,	RPNL1Loss=0.076123,	RCNNAcc=0.904893,	RCNNLogLoss=0.265949,	RCNNL1Loss=0.276662,	
INFO:root:Epoch[1] Batch [5400]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913004,	RPNLogLoss=0.238117,	RPNL1Loss=0.075997,	RCNNAcc=0.904990,	RCNNLogLoss=0.265616,	RCNNL1Loss=0.276434,	
INFO:root:Epoch[1] Batch [5420]	Speed: 0.69 samples/sec	Train-RPNAcc=0.913177,	RPNLogLoss=0.237754,	RPNL1Loss=0.075970,	RCNNAcc=0.905035,	RCNNLogLoss=0.265429,	RCNNL1Loss=0.276429,	
INFO:root:Epoch[1] Batch [5440]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913411,	RPNLogLoss=0.237215,	RPNL1Loss=0.075830,	RCNNAcc=0.905153,	RCNNLogLoss=0.265066,	RCNNL1Loss=0.276254,	
INFO:root:Epoch[1] Batch [5460]	Speed: 0.72 samples/sec	Train-RPNAcc=0.913592,	RPNLogLoss=0.236801,	RPNL1Loss=0.075742,	RCNNAcc=0.905177,	RCNNLogLoss=0.264962,	RCNNL1Loss=0.276302,	
INFO:root:Epoch[1] Batch [5480]	Speed: 0.70 samples/sec	Train-RPNAcc=0.913738,	RPNLogLoss=0.236452,	RPNL1Loss=0.075719,	RCNNAcc=0.905229,	RCNNLogLoss=0.264747,	RCNNL1Loss=0.276287,	
INFO:root:Epoch[1] Batch [5500]	Speed: 0.74 samples/sec	Train-RPNAcc=0.913955,	RPNLogLoss=0.235980,	RPNL1Loss=0.075598,	RCNNAcc=0.905313,	RCNNLogLoss=0.264466,	RCNNL1Loss=0.276218,	
INFO:root:Epoch[1] Batch [5520]	Speed: 0.74 samples/sec	Train-RPNAcc=0.914161,	RPNLogLoss=0.235513,	RPNL1Loss=0.075502,	RCNNAcc=0.905414,	RCNNLogLoss=0.264185,	RCNNL1Loss=0.276074,	
INFO:root:Epoch[1] Batch [5540]	Speed: 0.69 samples/sec	Train-RPNAcc=0.914352,	RPNLogLoss=0.235120,	RPNL1Loss=0.075437,	RCNNAcc=0.905459,	RCNNLogLoss=0.264035,	RCNNL1Loss=0.276114,	
INFO:root:Epoch[1] Batch [5560]	Speed: 0.74 samples/sec	Train-RPNAcc=0.914546,	RPNLogLoss=0.234689,	RPNL1Loss=0.075365,	RCNNAcc=0.905543,	RCNNLogLoss=0.263714,	RCNNL1Loss=0.276001,	
INFO:root:Epoch[1] Batch [5580]	Speed: 0.72 samples/sec	Train-RPNAcc=0.914749,	RPNLogLoss=0.234252,	RPNL1Loss=0.075319,	RCNNAcc=0.905593,	RCNNLogLoss=0.263549,	RCNNL1Loss=0.275978,	
INFO:root:Epoch[1] Batch [5600]	Speed: 0.75 samples/sec	Train-RPNAcc=0.914948,	RPNLogLoss=0.233796,	RPNL1Loss=0.075211,	RCNNAcc=0.905666,	RCNNLogLoss=0.263305,	RCNNL1Loss=0.275851,	
INFO:root:Epoch[1] Batch [5620]	Speed: 0.71 samples/sec	Train-RPNAcc=0.915075,	RPNLogLoss=0.233499,	RPNL1Loss=0.075147,	RCNNAcc=0.905708,	RCNNLogLoss=0.263132,	RCNNL1Loss=0.275739,	
INFO:root:Epoch[1] Batch [5640]	Speed: 0.74 samples/sec	Train-RPNAcc=0.915270,	RPNLogLoss=0.233055,	RPNL1Loss=0.075075,	RCNNAcc=0.905781,	RCNNLogLoss=0.262898,	RCNNL1Loss=0.275707,	
INFO:root:Epoch[1] Batch [5660]	Speed: 0.75 samples/sec	Train-RPNAcc=0.915443,	RPNLogLoss=0.232677,	RPNL1Loss=0.075037,	RCNNAcc=0.905865,	RCNNLogLoss=0.262610,	RCNNL1Loss=0.275551,	
INFO:root:Epoch[1] Batch [5680]	Speed: 0.76 samples/sec	Train-RPNAcc=0.915650,	RPNLogLoss=0.232207,	RPNL1Loss=0.074952,	RCNNAcc=0.905953,	RCNNLogLoss=0.262314,	RCNNL1Loss=0.275368,	
INFO:root:Epoch[1] Batch [5700]	Speed: 0.74 samples/sec	Train-RPNAcc=0.915873,	RPNLogLoss=0.231669,	RPNL1Loss=0.074855,	RCNNAcc=0.906128,	RCNNLogLoss=0.261821,	RCNNL1Loss=0.274966,	
INFO:root:Epoch[1] Batch [5720]	Speed: 0.77 samples/sec	Train-RPNAcc=0.916065,	RPNLogLoss=0.231197,	RPNL1Loss=0.074731,	RCNNAcc=0.906224,	RCNNLogLoss=0.261472,	RCNNL1Loss=0.274897,	
INFO:root:Epoch[1] Batch [5740]	Speed: 0.70 samples/sec	Train-RPNAcc=0.916239,	RPNLogLoss=0.230762,	RPNL1Loss=0.074640,	RCNNAcc=0.906264,	RCNNLogLoss=0.261274,	RCNNL1Loss=0.274790,	
INFO:root:Epoch[1] Batch [5760]	Speed: 0.71 samples/sec	Train-RPNAcc=0.916416,	RPNLogLoss=0.230374,	RPNL1Loss=0.074609,	RCNNAcc=0.906321,	RCNNLogLoss=0.261136,	RCNNL1Loss=0.274685,	
INFO:root:Epoch[1] Batch [5780]	Speed: 0.75 samples/sec	Train-RPNAcc=0.916576,	RPNLogLoss=0.230022,	RPNL1Loss=0.074523,	RCNNAcc=0.906385,	RCNNLogLoss=0.260929,	RCNNL1Loss=0.274483,	
INFO:root:Epoch[1] Batch [5800]	Speed: 0.76 samples/sec	Train-RPNAcc=0.916786,	RPNLogLoss=0.229533,	RPNL1Loss=0.074439,	RCNNAcc=0.906522,	RCNNLogLoss=0.260504,	RCNNL1Loss=0.274300,	
INFO:root:Epoch[1] Batch [5820]	Speed: 0.68 samples/sec	Train-RPNAcc=0.916913,	RPNLogLoss=0.229241,	RPNL1Loss=0.074432,	RCNNAcc=0.906524,	RCNNLogLoss=0.260447,	RCNNL1Loss=0.274352,	
INFO:root:Epoch[1] Batch [5840]	Speed: 0.75 samples/sec	Train-RPNAcc=0.917094,	RPNLogLoss=0.228819,	RPNL1Loss=0.074358,	RCNNAcc=0.906622,	RCNNLogLoss=0.260130,	RCNNL1Loss=0.274158,	
INFO:root:Epoch[1] Batch [5860]	Speed: 0.76 samples/sec	Train-RPNAcc=0.917269,	RPNLogLoss=0.228397,	RPNL1Loss=0.074241,	RCNNAcc=0.906741,	RCNNLogLoss=0.259755,	RCNNL1Loss=0.273905,	
INFO:root:Epoch[1] Batch [5880]	Speed: 0.74 samples/sec	Train-RPNAcc=0.917462,	RPNLogLoss=0.227935,	RPNL1Loss=0.074188,	RCNNAcc=0.906811,	RCNNLogLoss=0.259518,	RCNNL1Loss=0.273790,	
INFO:root:Epoch[1] Batch [5900]	Speed: 0.72 samples/sec	Train-RPNAcc=0.917636,	RPNLogLoss=0.227541,	RPNL1Loss=0.074108,	RCNNAcc=0.906876,	RCNNLogLoss=0.259261,	RCNNL1Loss=0.273655,	
INFO:root:Epoch[1] Batch [5920]	Speed: 0.72 samples/sec	Train-RPNAcc=0.917810,	RPNLogLoss=0.227157,	RPNL1Loss=0.074032,	RCNNAcc=0.906963,	RCNNLogLoss=0.258973,	RCNNL1Loss=0.273480,	
INFO:root:Epoch[1] Batch [5940]	Speed: 0.68 samples/sec	Train-RPNAcc=0.918016,	RPNLogLoss=0.226708,	RPNL1Loss=0.073941,	RCNNAcc=0.907050,	RCNNLogLoss=0.258704,	RCNNL1Loss=0.273414,	
INFO:root:Epoch[1] Batch [5960]	Speed: 0.71 samples/sec	Train-RPNAcc=0.918188,	RPNLogLoss=0.226282,	RPNL1Loss=0.073829,	RCNNAcc=0.907116,	RCNNLogLoss=0.258518,	RCNNL1Loss=0.273364,	
INFO:root:Epoch[1] Batch [5980]	Speed: 0.76 samples/sec	Train-RPNAcc=0.918367,	RPNLogLoss=0.225872,	RPNL1Loss=0.073724,	RCNNAcc=0.907201,	RCNNLogLoss=0.258268,	RCNNL1Loss=0.273211,	
INFO:root:Epoch[1] Batch [6000]	Speed: 0.72 samples/sec	Train-RPNAcc=0.918533,	RPNLogLoss=0.225446,	RPNL1Loss=0.073605,	RCNNAcc=0.907267,	RCNNLogLoss=0.258066,	RCNNL1Loss=0.273150,	
INFO:root:Epoch[1] Batch [6020]	Speed: 0.74 samples/sec	Train-RPNAcc=0.918716,	RPNLogLoss=0.225025,	RPNL1Loss=0.073491,	RCNNAcc=0.907324,	RCNNLogLoss=0.257840,	RCNNL1Loss=0.272991,	
INFO:root:Epoch[1] Batch [6040]	Speed: 0.73 samples/sec	Train-RPNAcc=0.918891,	RPNLogLoss=0.224585,	RPNL1Loss=0.073414,	RCNNAcc=0.907415,	RCNNLogLoss=0.257573,	RCNNL1Loss=0.272863,	
INFO:root:Epoch[1] Batch [6060]	Speed: 0.71 samples/sec	Train-RPNAcc=0.919074,	RPNLogLoss=0.224132,	RPNL1Loss=0.073337,	RCNNAcc=0.907513,	RCNNLogLoss=0.257244,	RCNNL1Loss=0.272696,	
INFO:root:Epoch[1] Batch [6080]	Speed: 0.73 samples/sec	Train-RPNAcc=0.919239,	RPNLogLoss=0.223751,	RPNL1Loss=0.073258,	RCNNAcc=0.907604,	RCNNLogLoss=0.256945,	RCNNL1Loss=0.272629,	
INFO:root:Epoch[1] Batch [6100]	Speed: 0.71 samples/sec	Train-RPNAcc=0.919393,	RPNLogLoss=0.223468,	RPNL1Loss=0.073195,	RCNNAcc=0.907670,	RCNNLogLoss=0.256713,	RCNNL1Loss=0.272679,	
INFO:root:Epoch[1] Batch [6120]	Speed: 0.72 samples/sec	Train-RPNAcc=0.919560,	RPNLogLoss=0.223062,	RPNL1Loss=0.073111,	RCNNAcc=0.907777,	RCNNLogLoss=0.256368,	RCNNL1Loss=0.272506,	
INFO:root:Epoch[1] Batch [6140]	Speed: 0.69 samples/sec	Train-RPNAcc=0.919707,	RPNLogLoss=0.222685,	RPNL1Loss=0.073026,	RCNNAcc=0.907824,	RCNNLogLoss=0.256183,	RCNNL1Loss=0.272461,	
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
INFO:root:Epoch[1] Batch [6160]	Speed: 0.73 samples/sec	Train-RPNAcc=0.919890,	RPNLogLoss=0.222243,	RPNL1Loss=0.072896,	RCNNAcc=0.907886,	RCNNLogLoss=0.255935,	RCNNL1Loss=0.272342,	
INFO:root:Epoch[1] Batch [6180]	Speed: 0.78 samples/sec	Train-RPNAcc=0.920087,	RPNLogLoss=0.221745,	RPNL1Loss=0.072751,	RCNNAcc=0.908035,	RCNNLogLoss=0.255503,	RCNNL1Loss=0.272036,	
INFO:root:Epoch[1] Batch [6200]	Speed: 0.71 samples/sec	Train-RPNAcc=0.920246,	RPNLogLoss=0.221390,	RPNL1Loss=0.072714,	RCNNAcc=0.908067,	RCNNLogLoss=0.255362,	RCNNL1Loss=0.272016,	
INFO:root:Epoch[1] Batch [6220]	Speed: 0.74 samples/sec	Train-RPNAcc=0.920407,	RPNLogLoss=0.221017,	RPNL1Loss=0.072605,	RCNNAcc=0.908151,	RCNNLogLoss=0.255081,	RCNNL1Loss=0.271831,	
INFO:root:Epoch[1] Batch [6240]	Speed: 0.70 samples/sec	Train-RPNAcc=0.920575,	RPNLogLoss=0.220620,	RPNL1Loss=0.072575,	RCNNAcc=0.908213,	RCNNLogLoss=0.254873,	RCNNL1Loss=0.271763,	
INFO:root:Epoch[1] Batch [6260]	Speed: 0.72 samples/sec	Train-RPNAcc=0.920707,	RPNLogLoss=0.220303,	RPNL1Loss=0.072522,	RCNNAcc=0.908234,	RCNNLogLoss=0.254789,	RCNNL1Loss=0.271840,	
INFO:root:Epoch[1] Batch [6280]	Speed: 0.74 samples/sec	Train-RPNAcc=0.920877,	RPNLogLoss=0.219907,	RPNL1Loss=0.072442,	RCNNAcc=0.908335,	RCNNLogLoss=0.254518,	RCNNL1Loss=0.271698,	
INFO:root:Epoch[1] Batch [6300]	Speed: 0.70 samples/sec	Train-RPNAcc=0.921063,	RPNLogLoss=0.219472,	RPNL1Loss=0.072360,	RCNNAcc=0.908428,	RCNNLogLoss=0.254286,	RCNNL1Loss=0.271578,	
INFO:root:Epoch[1] Batch [6320]	Speed: 0.73 samples/sec	Train-RPNAcc=0.921225,	RPNLogLoss=0.219083,	RPNL1Loss=0.072266,	RCNNAcc=0.908538,	RCNNLogLoss=0.253996,	RCNNL1Loss=0.271370,	
INFO:root:Epoch[1] Batch [6340]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921383,	RPNLogLoss=0.218714,	RPNL1Loss=0.072193,	RCNNAcc=0.908613,	RCNNLogLoss=0.253787,	RCNNL1Loss=0.271310,	
INFO:root:Epoch[1] Batch [6360]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921558,	RPNLogLoss=0.218363,	RPNL1Loss=0.072154,	RCNNAcc=0.908671,	RCNNLogLoss=0.253604,	RCNNL1Loss=0.271341,	
INFO:root:Epoch[1] Batch [6380]	Speed: 0.75 samples/sec	Train-RPNAcc=0.921720,	RPNLogLoss=0.217990,	RPNL1Loss=0.072061,	RCNNAcc=0.908757,	RCNNLogLoss=0.253311,	RCNNL1Loss=0.271175,	
INFO:root:Epoch[1] Batch [6400]	Speed: 0.72 samples/sec	Train-RPNAcc=0.921866,	RPNLogLoss=0.217653,	RPNL1Loss=0.071990,	RCNNAcc=0.908778,	RCNNLogLoss=0.253197,	RCNNL1Loss=0.271105,	
INFO:root:Epoch[1] Batch [6420]	Speed: 0.71 samples/sec	Train-RPNAcc=0.921986,	RPNLogLoss=0.217403,	RPNL1Loss=0.071991,	RCNNAcc=0.908775,	RCNNLogLoss=0.253155,	RCNNL1Loss=0.271151,	
INFO:root:Epoch[1] Batch [6440]	Speed: 0.70 samples/sec	Train-RPNAcc=0.922125,	RPNLogLoss=0.217050,	RPNL1Loss=0.071926,	RCNNAcc=0.908817,	RCNNLogLoss=0.252955,	RCNNL1Loss=0.271171,	
INFO:root:Epoch[1] Batch [6460]	Speed: 0.73 samples/sec	Train-RPNAcc=0.922285,	RPNLogLoss=0.216678,	RPNL1Loss=0.071838,	RCNNAcc=0.908850,	RCNNLogLoss=0.252828,	RCNNL1Loss=0.271139,	
INFO:root:Epoch[1] Batch [6480]	Speed: 0.74 samples/sec	Train-RPNAcc=0.922449,	RPNLogLoss=0.216274,	RPNL1Loss=0.071729,	RCNNAcc=0.908936,	RCNNLogLoss=0.252551,	RCNNL1Loss=0.270984,	
INFO:root:Epoch[1] Batch [6500]	Speed: 0.69 samples/sec	Train-RPNAcc=0.922580,	RPNLogLoss=0.215951,	RPNL1Loss=0.071688,	RCNNAcc=0.908967,	RCNNLogLoss=0.252402,	RCNNL1Loss=0.271004,	
INFO:root:Epoch[1] Batch [6520]	Speed: 0.75 samples/sec	Train-RPNAcc=0.922739,	RPNLogLoss=0.215572,	RPNL1Loss=0.071603,	RCNNAcc=0.909047,	RCNNLogLoss=0.252140,	RCNNL1Loss=0.270894,	
INFO:root:Epoch[1] Batch [6540]	Speed: 0.72 samples/sec	Train-RPNAcc=0.922905,	RPNLogLoss=0.215178,	RPNL1Loss=0.071499,	RCNNAcc=0.909120,	RCNNLogLoss=0.251894,	RCNNL1Loss=0.270804,	
INFO:root:Epoch[1] Batch [6560]	Speed: 0.75 samples/sec	Train-RPNAcc=0.923050,	RPNLogLoss=0.214833,	RPNL1Loss=0.071420,	RCNNAcc=0.909174,	RCNNLogLoss=0.251704,	RCNNL1Loss=0.270731,	
INFO:root:Epoch[1] Batch [6580]	Speed: 0.74 samples/sec	Train-RPNAcc=0.923169,	RPNLogLoss=0.214526,	RPNL1Loss=0.071377,	RCNNAcc=0.909232,	RCNNLogLoss=0.251507,	RCNNL1Loss=0.270643,	
INFO:root:Epoch[1] Batch [6600]	Speed: 0.73 samples/sec	Train-RPNAcc=0.923320,	RPNLogLoss=0.214177,	RPNL1Loss=0.071335,	RCNNAcc=0.909318,	RCNNLogLoss=0.251246,	RCNNL1Loss=0.270514,	
INFO:root:Epoch[1] Batch [6620]	Speed: 0.71 samples/sec	Train-RPNAcc=0.923453,	RPNLogLoss=0.213872,	RPNL1Loss=0.071273,	RCNNAcc=0.909360,	RCNNLogLoss=0.251106,	RCNNL1Loss=0.270503,	
INFO:root:Epoch[1] Batch [6640]	Speed: 0.67 samples/sec	Train-RPNAcc=0.923560,	RPNLogLoss=0.213606,	RPNL1Loss=0.071256,	RCNNAcc=0.909413,	RCNNLogLoss=0.250900,	RCNNL1Loss=0.270498,	
INFO:root:Epoch[1] Batch [6660]	Speed: 0.74 samples/sec	Train-RPNAcc=0.923694,	RPNLogLoss=0.213276,	RPNL1Loss=0.071197,	RCNNAcc=0.909516,	RCNNLogLoss=0.250608,	RCNNL1Loss=0.270439,	
INFO:root:Epoch[1] Batch [6680]	Speed: 0.72 samples/sec	Train-RPNAcc=0.923813,	RPNLogLoss=0.212986,	RPNL1Loss=0.071154,	RCNNAcc=0.909600,	RCNNLogLoss=0.250380,	RCNNL1Loss=0.270286,	
INFO:root:Epoch[1] Batch [6700]	Speed: 0.72 samples/sec	Train-RPNAcc=0.923990,	RPNLogLoss=0.212577,	RPNL1Loss=0.071047,	RCNNAcc=0.909714,	RCNNLogLoss=0.250062,	RCNNL1Loss=0.270077,	
INFO:root:Epoch[1] Batch [6720]	Speed: 0.74 samples/sec	Train-RPNAcc=0.924134,	RPNLogLoss=0.212233,	RPNL1Loss=0.071016,	RCNNAcc=0.909795,	RCNNLogLoss=0.249844,	RCNNL1Loss=0.270049,	
INFO:root:Epoch[1] Batch [6740]	Speed: 0.69 samples/sec	Train-RPNAcc=0.924264,	RPNLogLoss=0.211950,	RPNL1Loss=0.070987,	RCNNAcc=0.909844,	RCNNLogLoss=0.249689,	RCNNL1Loss=0.270040,	
INFO:root:Epoch[1] Batch [6760]	Speed: 0.74 samples/sec	Train-RPNAcc=0.924400,	RPNLogLoss=0.211590,	RPNL1Loss=0.070882,	RCNNAcc=0.909927,	RCNNLogLoss=0.249435,	RCNNL1Loss=0.269953,	
INFO:root:Epoch[1] Batch [6780]	Speed: 0.71 samples/sec	Train-RPNAcc=0.924562,	RPNLogLoss=0.211205,	RPNL1Loss=0.070804,	RCNNAcc=0.909996,	RCNNLogLoss=0.249206,	RCNNL1Loss=0.269791,	
INFO:root:Epoch[1] Batch [6800]	Speed: 0.70 samples/sec	Train-RPNAcc=0.924675,	RPNLogLoss=0.210946,	RPNL1Loss=0.070781,	RCNNAcc=0.909991,	RCNNLogLoss=0.249189,	RCNNL1Loss=0.269869,	
INFO:root:Epoch[1] Batch [6820]	Speed: 0.70 samples/sec	Train-RPNAcc=0.924771,	RPNLogLoss=0.210679,	RPNL1Loss=0.070780,	RCNNAcc=0.910039,	RCNNLogLoss=0.249048,	RCNNL1Loss=0.269827,	
INFO:root:Epoch[1] Batch [6840]	Speed: 0.72 samples/sec	Train-RPNAcc=0.924908,	RPNLogLoss=0.210382,	RPNL1Loss=0.070718,	RCNNAcc=0.910064,	RCNNLogLoss=0.248947,	RCNNL1Loss=0.269828,	
INFO:root:Epoch[1] Train-RPNAcc=0.924962
INFO:root:Epoch[1] Train-RPNLogLoss=0.210268
INFO:root:Epoch[1] Train-RPNL1Loss=0.070704
INFO:root:Epoch[1] Train-RCNNAcc=0.910088
INFO:root:Epoch[1] Train-RCNNLogLoss=0.248865
INFO:root:Epoch[1] Train-RCNNL1Loss=0.269769
INFO:root:Epoch[1] Time cost=8478.565
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
752
[12:04:44] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [12:04:44] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f471823771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f4718352ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f4718a263da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f47c1766adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f47c176640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f47c197d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f47c197ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47c2cf4f45]
[bt] (32) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 186, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 139, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 436, in fit
    callback(epoch, self.symbol, arg_params, aux_params)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/callback.py", line 41, in _callback
    arg['bbox_pred_weight_test'] = (arg['bbox_pred_weight'].T * mx.nd.array(stds)).T
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 141, in __mul__
    return multiply(self, other)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 763, in multiply
    None)
  File "/home/hustxly/mxnet/python/mxnet/ndarray.py", line 683, in _ufunc_helper
    return fn_array(lhs, rhs)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/ndarray.py", line 131, in generic_ndarray_function
    c_array(ctypes.c_char_p, [c_str(str(i)) for i in kwargs.values()])))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [12:04:44] src/operator/tensor/./elemwise_binary_broadcast_op.h:44: Check failed: l == 1 || r == 1 operands could not be broadcast together with shapes (4096,84) (16,)

Stack trace returned 33 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f471823771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op20BinaryBroadcastShapeERKN4nnvm9NodeAttrsEPSt6vectorINS1_6TShapeESaIS6_EES9_+0x69b) [0x7f4718352ddb]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXImperativeInvoke+0x14ba) [0x7f4718a263da]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f47c1766adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f47c176640c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f47c197d5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f47c197ef9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (9) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (10) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (11) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python() [0x4a1c9a]
[bt] (15) python() [0x4dfe94]
[bt] (16) python(PyObject_Call+0x36) [0x505f96]
[bt] (17) python() [0x592085]
[bt] (18) python() [0x57c87d]
[bt] (19) python(PyNumber_Multiply+0x96) [0x4a7a16]
[bt] (20) python(PyEval_EvalFrameEx+0x15e8) [0x49a868]
[bt] (21) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (22) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (23) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (24) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (25) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (26) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (27) python() [0x4a1634]
[bt] (28) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (29) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (30) python(Py_Main+0xb5e) [0x44f904]
[bt] (31) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f47c2cf4f45]
[bt] (32) python() [0x578c4e]

{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 3L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[15:31:36] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.32 samples/sec	Train-RPNAcc=0.568266,	RPNLogLoss=0.690575,	RPNL1Loss=0.205601,	RCNNAcc=0.167039,	RCNNLogLoss=2.897209,	RCNNL1Loss=0.392915,	
INFO:root:Epoch[1] Batch [40]	Speed: 0.35 samples/sec	Train-RPNAcc=0.574028,	RPNLogLoss=0.690181,	RPNL1Loss=0.176274,	RCNNAcc=0.455602,	RCNNLogLoss=2.330655,	RCNNL1Loss=0.368696,	
INFO:root:Epoch[1] Batch [60]	Speed: 0.35 samples/sec	Train-RPNAcc=0.590100,	RPNLogLoss=0.688450,	RPNL1Loss=0.173849,	RCNNAcc=0.580943,	RCNNLogLoss=1.935022,	RCNNL1Loss=0.367200,	
INFO:root:Epoch[1] Batch [80]	Speed: 0.39 samples/sec	Train-RPNAcc=0.598139,	RPNLogLoss=0.687671,	RPNL1Loss=0.181154,	RCNNAcc=0.653646,	RCNNLogLoss=1.654464,	RCNNL1Loss=0.346961,	
INFO:root:Epoch[1] Batch [100]	Speed: 0.37 samples/sec	Train-RPNAcc=0.608640,	RPNLogLoss=0.686473,	RPNL1Loss=0.170385,	RCNNAcc=0.696782,	RCNNLogLoss=1.454009,	RCNNL1Loss=0.333254,	
INFO:root:Epoch[1] Batch [120]	Speed: 0.35 samples/sec	Train-RPNAcc=0.615928,	RPNLogLoss=0.685261,	RPNL1Loss=0.160919,	RCNNAcc=0.728435,	RCNNLogLoss=1.300138,	RCNNL1Loss=0.320475,	
INFO:root:Epoch[1] Batch [140]	Speed: 0.31 samples/sec	Train-RPNAcc=0.624197,	RPNLogLoss=0.683894,	RPNL1Loss=0.158642,	RCNNAcc=0.747396,	RCNNLogLoss=1.190032,	RCNNL1Loss=0.320617,	
INFO:root:Epoch[1] Batch [160]	Speed: 0.34 samples/sec	Train-RPNAcc=0.632570,	RPNLogLoss=0.682278,	RPNL1Loss=0.155862,	RCNNAcc=0.760530,	RCNNLogLoss=1.101494,	RCNNL1Loss=0.323855,	
INFO:root:Epoch[1] Batch [180]	Speed: 0.39 samples/sec	Train-RPNAcc=0.638014,	RPNLogLoss=0.680976,	RPNL1Loss=0.157402,	RCNNAcc=0.771193,	RCNNLogLoss=1.028079,	RCNNL1Loss=0.327429,	
INFO:root:Epoch[1] Batch [200]	Speed: 0.36 samples/sec	Train-RPNAcc=0.647699,	RPNLogLoss=0.679157,	RPNL1Loss=0.151758,	RCNNAcc=0.783582,	RCNNLogLoss=0.958333,	RCNNL1Loss=0.322216,	
INFO:root:Epoch[1] Batch [220]	Speed: 0.31 samples/sec	Train-RPNAcc=0.655419,	RPNLogLoss=0.677278,	RPNL1Loss=0.147366,	RCNNAcc=0.791077,	RCNNLogLoss=0.905604,	RCNNL1Loss=0.326945,	
INFO:root:Epoch[1] Batch [240]	Speed: 0.40 samples/sec	Train-RPNAcc=0.663236,	RPNLogLoss=0.675329,	RPNL1Loss=0.144618,	RCNNAcc=0.799630,	RCNNLogLoss=0.857097,	RCNNL1Loss=0.326116,	
INFO:root:Epoch[1] Batch [260]	Speed: 0.39 samples/sec	Train-RPNAcc=0.669630,	RPNLogLoss=0.673505,	RPNL1Loss=0.146396,	RCNNAcc=0.808459,	RCNNLogLoss=0.811099,	RCNNL1Loss=0.318188,	
INFO:root:Epoch[1] Batch [280]	Speed: 0.34 samples/sec	Train-RPNAcc=0.677352,	RPNLogLoss=0.671438,	RPNL1Loss=0.145468,	RCNNAcc=0.812111,	RCNNLogLoss=0.778790,	RCNNL1Loss=0.323562,	
INFO:root:Epoch[1] Batch [300]	Speed: 0.34 samples/sec	Train-RPNAcc=0.683360,	RPNLogLoss=0.669611,	RPNL1Loss=0.145939,	RCNNAcc=0.815070,	RCNNLogLoss=0.749703,	RCNNL1Loss=0.325645,	
INFO:root:Epoch[1] Batch [320]	Speed: 0.37 samples/sec	Train-RPNAcc=0.690664,	RPNLogLoss=0.667664,	RPNL1Loss=0.145182,	RCNNAcc=0.818146,	RCNNLogLoss=0.723253,	RCNNL1Loss=0.328968,	
INFO:root:Epoch[1] Batch [340]	Speed: 0.36 samples/sec	Train-RPNAcc=0.697684,	RPNLogLoss=0.665629,	RPNL1Loss=0.145408,	RCNNAcc=0.821687,	RCNNLogLoss=0.699003,	RCNNL1Loss=0.329717,	
INFO:root:Epoch[1] Batch [360]	Speed: 0.62 samples/sec	Train-RPNAcc=0.705094,	RPNLogLoss=0.663366,	RPNL1Loss=0.144495,	RCNNAcc=0.826091,	RCNNLogLoss=0.674604,	RCNNL1Loss=0.328032,	
INFO:root:Epoch[1] Batch [380]	Speed: 0.54 samples/sec	Train-RPNAcc=0.712475,	RPNLogLoss=0.661046,	RPNL1Loss=0.145015,	RCNNAcc=0.830832,	RCNNLogLoss=0.651164,	RCNNL1Loss=0.324276,	
INFO:root:Epoch[1] Batch [400]	Speed: 0.45 samples/sec	Train-RPNAcc=0.720591,	RPNLogLoss=0.658437,	RPNL1Loss=0.142943,	RCNNAcc=0.833502,	RCNNLogLoss=0.633454,	RCNNL1Loss=0.326085,	
INFO:root:Epoch[1] Batch [420]	Speed: 0.37 samples/sec	Train-RPNAcc=0.726674,	RPNLogLoss=0.656164,	RPNL1Loss=0.142754,	RCNNAcc=0.834806,	RCNNLogLoss=0.619199,	RCNNL1Loss=0.329407,	
INFO:root:Epoch[1] Batch [440]	Speed: 0.39 samples/sec	Train-RPNAcc=0.732276,	RPNLogLoss=0.653843,	RPNL1Loss=0.142357,	RCNNAcc=0.834485,	RCNNLogLoss=0.609091,	RCNNL1Loss=0.338099,	
INFO:root:Epoch[1] Batch [460]	Speed: 0.35 samples/sec	Train-RPNAcc=0.737925,	RPNLogLoss=0.651189,	RPNL1Loss=0.142825,	RCNNAcc=0.837497,	RCNNLogLoss=0.593639,	RCNNL1Loss=0.335519,	
INFO:root:Epoch[1] Batch [480]	Speed: 0.26 samples/sec	Train-RPNAcc=0.742821,	RPNLogLoss=0.648629,	RPNL1Loss=0.142762,	RCNNAcc=0.836977,	RCNNLogLoss=0.585568,	RCNNL1Loss=0.341680,	
INFO:root:Epoch[1] Batch [500]	Speed: 0.38 samples/sec	Train-RPNAcc=0.748503,	RPNLogLoss=0.645714,	RPNL1Loss=0.141457,	RCNNAcc=0.838994,	RCNNLogLoss=0.573152,	RCNNL1Loss=0.341064,	
INFO:root:Epoch[1] Batch [520]	Speed: 0.33 samples/sec	Train-RPNAcc=0.752849,	RPNLogLoss=0.642961,	RPNL1Loss=0.140702,	RCNNAcc=0.840481,	RCNNLogLoss=0.561523,	RCNNL1Loss=0.342540,	
INFO:root:Epoch[1] Batch [540]	Speed: 0.27 samples/sec	Train-RPNAcc=0.757690,	RPNLogLoss=0.639817,	RPNL1Loss=0.139826,	RCNNAcc=0.842291,	RCNNLogLoss=0.551162,	RCNNL1Loss=0.341942,	
INFO:root:Epoch[1] Batch [560]	Speed: 0.34 samples/sec	Train-RPNAcc=0.762248,	RPNLogLoss=0.636640,	RPNL1Loss=0.140053,	RCNNAcc=0.844056,	RCNNLogLoss=0.541311,	RCNNL1Loss=0.341765,	
INFO:root:Epoch[1] Batch [580]	Speed: 0.36 samples/sec	Train-RPNAcc=0.764704,	RPNLogLoss=0.634265,	RPNL1Loss=0.141005,	RCNNAcc=0.844449,	RCNNLogLoss=0.534302,	RCNNL1Loss=0.345216,	
INFO:root:Epoch[1] Batch [600]	Speed: 0.37 samples/sec	Train-RPNAcc=0.768680,	RPNLogLoss=0.630831,	RPNL1Loss=0.140021,	RCNNAcc=0.845700,	RCNNLogLoss=0.525432,	RCNNL1Loss=0.344658,	
INFO:root:Epoch[1] Batch [620]	Speed: 0.40 samples/sec	Train-RPNAcc=0.771412,	RPNLogLoss=0.627968,	RPNL1Loss=0.139923,	RCNNAcc=0.846681,	RCNNLogLoss=0.518945,	RCNNL1Loss=0.345208,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2482L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_boxes': (1L, 9L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[04:47:16] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2482L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 752L, 2482L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
INFO:root:Epoch[1] Batch [20]	Speed: 0.57 samples/sec	Train-RPNAcc=0.584077,	RPNLogLoss=0.690725,	RPNL1Loss=0.163435,	RCNNAcc=0.160714,	RCNNLogLoss=2.895509,	RCNNL1Loss=0.342722,	
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_train_ry_alpha_car_only gt roidb loaded from data/cache/kitti_train_ry_alpha_car_only_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'dim_loss_output': (128L, 192L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'fc8_1_bias': (512L,),
 'fc8_1_weight': (512L, 4096L),
 'fc9_1_bias': (192L,),
 'fc9_1_weight': (192L, 512L),
 'gt_boxes': (1L, 8L, 5L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
[05:02:39] src/operator/./cudnn_convolution-inl.h:55: Running performance tests to find the best convolution algorithm, this can take a while...
WARNING:root:bucketing: data "data" has a shape (1L, 3L, 752L, 2491L), which is larger than already allocated shape (1L, 3L, 1000L, 1000L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "label" has a shape (1L, 65565L), which is larger than already allocated shape (1L, 34596L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_weight" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
WARNING:root:bucketing: data "bbox_target" has a shape (1L, 36L, 47L, 155L), which is larger than already allocated shape (1L, 36L, 62L, 62L). Need to re-allocate. Consider putting default_bucket_key to be the bucket taking the largest input for better memory sharing.
752
Traceback (most recent call last):
  File "example/env/train_3dbox.py", line 197, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_3dbox.py", line 150, in train_net
    arg_params=arg_params, aux_params=aux_params, begin_epoch=begin_epoch, num_epoch=end_epoch)
  File "/home/hustxly/mxnet/python/mxnet/module/base_module.py", line 412, in fit
    self.update_metric(eval_metric, data_batch.label)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/module.py", line 195, in update_metric
    self._curr_module.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/module.py", line 534, in update_metric
    self._exec_group.update_metric(eval_metric, labels)
  File "/home/hustxly/mxnet/python/mxnet/module/executor_group.py", line 438, in update_metric
    eval_metric.update(labels_slice, texec.outputs)
  File "/home/hustxly/mxnet/python/mxnet/metric.py", line 106, in update
    metric.update(labels, preds)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/metric.py", line 87, in update
    cls = pred[np.arange(label.shape[0]), label]
IndexError: index 128 is out of bounds for axis 0 with size 128
  File "example/env/train_end2end.py", line 153
    else
       ^
SyntaxError: invalid syntax
  File "example/env/train_end2end.py", line 153
    else
       ^
SyntaxError: invalid syntax
Error in proposal_target.list_arguments: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 656, in list_arguments_entry
    ret = op_prop.list_arguments()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 88, in list_arguments
    if config.TRAIN.BBOX_3D:
NameError: global name 'config' is not defined

[15:29:38] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:29:38] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe87bb3771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7fe87c4ec13a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7fe87c4ecd49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7fe87c457893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7fe87c44d9ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7fe87d11a558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7fe87c33bfe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe925066adc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe92506640c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe92527d5fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe92527ef9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe9265f4f45]
[bt] (23) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 184, in get_vgg_train
    batch_rois=config.TRAIN.BATCH_ROIS, fg_fraction=config.TRAIN.FG_FRACTION)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/symbol.py", line 181, in creator
    ctypes.byref(sym_handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:29:38] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fe87bb3771c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7fe87c4ec13a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7fe87c4ecd49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7fe87c457893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7fe87c44d9ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7fe87d11a558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7fe87c33bfe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fe925066adc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fe92506640c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fe92527d5fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fe92527ef9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fe9265f4f45]
[bt] (23) python() [0x578c4e]

Error in proposal_target.list_arguments: Traceback (most recent call last):
  File "/home/hustxly/mxnet/python/mxnet/operator.py", line 656, in list_arguments_entry
    ret = op_prop.list_arguments()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/proposal_target.py", line 88, in list_arguments
    if config.TRAIN.BBOX_3D:
NameError: global name 'config' is not defined

[15:29:47] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:29:47] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f008fd7c71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7f009073113a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7f0090731d49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7f009069c893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7f00906929ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7f009135f558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7f0090580fe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f01312abadc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f01312ab40c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f01314c25fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f01314c3f9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0132839f45]
[bt] (23) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 184, in get_vgg_train
    batch_rois=config.TRAIN.BATCH_ROIS, fg_fraction=config.TRAIN.FG_FRACTION)
  File "/home/hustxly/mxnet/python/mxnet/_ctypes/symbol.py", line 181, in creator
    ctypes.byref(sym_handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:29:47] src/operator/./custom-inl.h:139: Check failed: info_->list_arguments(&args, info_->p_list_arguments) 

Stack trace returned 24 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f008fd7c71c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK5mxnet2op12CustomOpProp13ListArgumentsEv+0x16a) [0x7f009073113a]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12CustomOpProp4InitERKSt6vectorISt4pairISsSsESaIS4_EE+0x6e9) [0x7f0090731d49]
[bt] (3) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN5mxnet2op12ParsedOpProp4InitERKN4nnvm9NodeAttrsE+0xd3) [0x7f009069c893]
[bt] (4) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(+0xf7a9ba) [0x7f00906929ba]
[bt] (5) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4nnvm6Symbol13CreateFunctorEPKNS_2OpESt13unordered_mapISsSsSt4hashISsESt8equal_toISsESaISt4pairIKSsSsEEE+0x98) [0x7f009135f558]
[bt] (6) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(MXSymbolCreateAtomicSymbol+0x6a9) [0x7f0090580fe9]
[bt] (7) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f01312abadc]
[bt] (8) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f01312ab40c]
[bt] (9) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f01314c25fe]
[bt] (10) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f01314c3f9e]
[bt] (11) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (12) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (13) python(PyEval_EvalFrameEx+0x18c5) [0x49ab45]
[bt] (14) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (15) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (16) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (17) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (18) python() [0x4a1634]
[bt] (19) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (20) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (21) python(Py_Main+0xb5e) [0x44f904]
[bt] (22) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0132839f45]
[bt] (23) python() [0x578c4e]

[15:31:30] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:31:30] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1800ed271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f18024b4204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f180249361b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f18aa401adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f18aa40140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f18aa6185fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f18aa619f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f18ab98ff45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:31:30] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f1800ed271c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f18024b4204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f180249361b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f18aa401adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f18aa40140c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f18aa6185fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f18aa619f9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f18ab98ff45]
[bt] (22) python() [0x578c4e]

[15:35:46] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:35:46] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0d9374471c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f0d94d26204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f0d94d0561b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0e3cc73adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0e3cc7340c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f0e3ce8a5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f0e3ce8bf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0e3e201f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 221, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 32, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:35:46] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7f0d9374471c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7f0d94d26204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7f0d94d0561b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7f0e3cc73adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7f0e3cc7340c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7f0e3ce8a5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7f0e3ce8bf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7f0e3e201f45]
[bt] (22) python() [0x578c4e]

[15:37:09] /home/hustxly/mxnet/dmlc-core/include/dmlc/./logging.h:300: [15:37:09] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fc2a55e571c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7fc2a6bc7204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7fc2a6ba661b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc34eb14adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fc34eb1440c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fc34ed2b5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fc34ed2cf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fc3500a2f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 190, in get_vgg_train
    dim_label   = group[4]
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 267, in __getitem__
    self.handle, mx_uint(index), ctypes.byref(handle)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: [15:37:09] src/core/symbolic.cc:176: Check failed: index < nreturn (4 vs. 4) Symbol only accept nonnegative index

Stack trace returned 23 entries:
[bt] (0) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZN4dmlc15LogMessageFatalD1Ev+0x3c) [0x7fc2a55e571c]
[bt] (1) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(_ZNK4nnvm6SymbolixEm+0x214) [0x7fc2a6bc7204]
[bt] (2) /home/hustxly/mxnet/python/mxnet/../../lib/libmxnet.so(NNSymbolGetOutput+0x4b) [0x7fc2a6ba661b]
[bt] (3) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call_unix64+0x4c) [0x7fc34eb14adc]
[bt] (4) /usr/lib/x86_64-linux-gnu/libffi.so.6(ffi_call+0x1fc) [0x7fc34eb1440c]
[bt] (5) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(_ctypes_callproc+0x48e) [0x7fc34ed2b5fe]
[bt] (6) /usr/lib/python2.7/lib-dynload/_ctypes.x86_64-linux-gnu.so(+0x15f9e) [0x7fc34ed2cf9e]
[bt] (7) python(PyEval_EvalFrameEx+0x965) [0x499be5]
[bt] (8) python() [0x4a1c9a]
[bt] (9) python() [0x4dfe94]
[bt] (10) python(PyObject_Call+0x36) [0x505f96]
[bt] (11) python() [0x4cac9f]
[bt] (12) python(PyEval_EvalFrameEx+0x16f4) [0x49a974]
[bt] (13) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (14) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (15) python(PyEval_EvalCodeEx+0x2ac) [0x4a090c]
[bt] (16) python(PyEval_EvalFrameEx+0x7d2) [0x499a52]
[bt] (17) python() [0x4a1634]
[bt] (18) python(PyRun_FileExFlags+0x92) [0x44e4a5]
[bt] (19) python(PyRun_SimpleFileExFlags+0x2ee) [0x44ec9f]
[bt] (20) python(Py_Main+0xb5e) [0x44f904]
[bt] (21) /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf5) [0x7fc3500a2f45]
[bt] (22) python() [0x578c4e]

Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 222, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 33, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 266, in get_vgg_train
    dim_loss, angle_loss, conf_loss, mx.symbol.BlockGrad(dims_label), mx.symbol.BlockGrad(angle_label), mx.symbol.BlockGrad(conf_label)])
NameError: global name 'dims_label' is not defined
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 47, in train_net
    imdb = eval(args.dataset)(args.image_set, args.root_path, args.dataset_path)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/dataset/kitti.py", line 29, in __init__
    self.image_set_index = self.load_image_set_index()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/dataset/kitti.py", line 39, in load_image_set_index
    assert os.path.exists(image_set_index_file), 'Path does not exist: {}'.format(image_set_index_file)
AssertionError: Path does not exist: data/kitti/imglists/train_ry_alpha_car_only.lst
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 128, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
{'width': 1242, 'boxes': array([[ 647.61999512,  184.41999817,  695.29998779,  222.78999329],
       [ 711.75      ,  180.25      ,  748.84997559,  208.71000671],
       [ 417.28997803,  183.52999878,  478.65002441,  208.33000183],
       [ 301.90997314,  185.50999451,  370.02001953,  212.36999512]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/004104.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1], dtype=int32), 'height': 375}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 73, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'width': 1242, 'boxes': array([[ 1038.27001953,   202.75      ,  1231.06005859,   316.29000854],
       [  718.04998779,   183.69999695,   774.14001465,   222.69999695],
       [  494.96002197,   165.41999817,   598.23999023,   210.11999512],
       [  917.42004395,   184.63999939,   960.25      ,   214.88999939],
       [  781.7199707 ,   176.52000427,   806.10998535,   198.50999451],
       [  527.70001221,   190.5       ,   679.46002197,   278.92999268]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/001718.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1, 1, 1], dtype=int32), 'height': 375}
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 73, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'width': 1242, 'boxes': array([[ 640.20001221,  172.3999939 ,  661.9699707 ,  193.36000061],
       [ 783.07000732,  178.52999878,  806.04998779,  193.02999878]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1]), 'max_overlaps': array([ 1.,  1.], dtype=float32), 'image': 'data/kitti/images/005653.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1], dtype=int32), 'height': 375}
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 326, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'gt_classes': array([1, 1, 1, 1], dtype=int32), 'gt_angles': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'gt_dims': array([[ 1.52999997,  1.62      ,  3.76999998],
       [ 1.75999999,  1.76999998,  4.40999985],
       [ 1.48000002,  1.64999998,  4.4000001 ],
       [ 1.41999996,  1.65999997,  3.6400001 ]], dtype=float32), 'max_classes': array([1, 1, 1, 1]), 'image': 'data/kitti/images/002586.png', 'height': 375, 'orientation_ry': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'width': 1242, 'boxes': array([[ 1086.52001953,   198.00999451,  1241.        ,   374.        ],
       [  459.17999268,   170.33000183,   548.57000732,   230.77000427],
       [  530.86999512,   176.91000366,   593.33001709,   214.44000244],
       [  619.23999023,   175.27999878,   652.78997803,   198.19999695]], dtype=float32), 'gt_position': array([[  3.00999999,   1.62      ,   1.40999997],
       [ -3.33999991,   1.71000004,  23.29000092],
       [ -1.99000001,   1.65999997,  30.73999977],
       [  1.70000005,   1.59000003,  46.84000015]], dtype=float32), 'gt_confs': array([[1],
       [1],
       [1],
       [1]], dtype=int32), 'max_overlaps': array([ 1.,  1.,  1.,  1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 0.47      ,  1.83000004,  1.80999994,  1.72000003], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32)}
{'gt_classes': array([1, 1, 1, 1], dtype=int32), 'gt_angles': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'gt_dims': array([[ 1.52999997,  1.62      ,  3.76999998],
       [ 1.75999999,  1.76999998,  4.40999985],
       [ 1.48000002,  1.64999998,  4.4000001 ],
       [ 1.41999996,  1.65999997,  3.6400001 ]], dtype=float32), 'max_classes': array([1, 1, 1, 1]), 'image': 'data/kitti/images/002586.png', 'height': 375, 'orientation_ry': array([ 1.52999997,  1.69000006,  1.74000001,  1.75      ], dtype=float32), 'width': 1242, 'boxes': array([[ 1086.52001953,   198.00999451,  1241.        ,   374.        ],
       [  459.17999268,   170.33000183,   548.57000732,   230.77000427],
       [  530.86999512,   176.91000366,   593.33001709,   214.44000244],
       [  619.23999023,   175.27999878,   652.78997803,   198.19999695]], dtype=float32), 'gt_position': array([[  3.00999999,   1.62      ,   1.40999997],
       [ -3.33999991,   1.71000004,  23.29000092],
       [ -1.99000001,   1.65999997,  30.73999977],
       [  1.70000005,   1.59000003,  46.84000015]], dtype=float32), 'gt_confs': array([[1],
       [1],
       [1],
       [1]], dtype=int32), 'max_overlaps': array([ 1.,  1.,  1.,  1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 0.47      ,  1.83000004,  1.80999994,  1.72000003], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32)}
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 4L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 4L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 4L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 4L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'width': 1242, 'boxes': array([[  32.26000977,  180.38000488,  441.7199707 ,  374.        ],
       [ 720.72998047,  183.41000366,  874.77001953,  281.22000122],
       [ 390.79998779,  188.1499939 ,  529.86999512,  283.91000366],
       [ 706.21002197,  179.6000061 ,  796.59997559,  244.71000671],
       [ 469.36999512,  184.30000305,  559.76000977,  249.19000244],
       [ 680.88000488,  179.27999878,  727.59002686,  219.72999573],
       [ 530.44000244,  180.6000061 ,  573.83001709,  213.25      ],
       [ 563.88000488,  176.19000244,  587.91998291,  197.77000427]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1, 1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/003755.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), 'height': 375}
{'width': 1242, 'boxes': array([[  32.26000977,  180.38000488,  441.7199707 ,  374.        ],
       [ 720.72998047,  183.41000366,  874.77001953,  281.22000122],
       [ 390.79998779,  188.1499939 ,  529.86999512,  283.91000366],
       [ 706.21002197,  179.6000061 ,  796.59997559,  244.71000671],
       [ 469.36999512,  184.30000305,  559.76000977,  249.19000244],
       [ 680.88000488,  179.27999878,  727.59002686,  219.72999573],
       [ 530.44000244,  180.6000061 ,  573.83001709,  213.25      ],
       [ 563.88000488,  176.19000244,  587.91998291,  197.77000427]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1, 1, 1, 1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/003755.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1, 1, 1, 1, 1, 1], dtype=int32), 'height': 375}
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 253, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 327, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([-1.57000005], dtype=float32), 'gt_dims': array([[ 1.65999997,  1.73000002,  3.04999995]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/001854.png', 'height': 375, 'orientation_ry': array([-1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 541.0300293 ,  174.86000061,  562.78997803,  193.61999512]], dtype=float32), 'gt_position': array([[ -5.30999994,   1.87      ,  66.15000153]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([-1.49000001], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 1L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 1L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 3L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 3L, 1L)
  data: (1L, 3L, 752L, 2482L)
  gt_angles: (1L, 3L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1, 1, 1], dtype=int32), 'gt_angles': array([-1.59000003,  1.52999997,  1.54999995], dtype=float32), 'gt_dims': array([[ 1.64999998,  1.66999996,  3.6400001 ],
       [ 1.42999995,  1.63      ,  4.30999994],
       [ 1.44000006,  1.62      ,  4.01999998]], dtype=float32), 'max_classes': array([1, 1, 1]), 'image': 'data/kitti/images/000939.png', 'height': 375, 'orientation_ry': array([-1.59000003,  1.52999997,  1.54999995], dtype=float32), 'width': 1242, 'boxes': array([[ 588.47998047,  175.30999756,  615.2199707 ,  201.75      ],
       [ 172.50999451,  194.49000549,  317.16000366,  263.48001099],
       [ 414.16000366,  184.28999329,  460.20999146,  212.97000122]], dtype=float32), 'gt_position': array([[ -0.57999998,   1.83000004,  47.31999969],
       [ -9.06000042,   2.02999997,  18.23999977],
       [ -9.38000011,   2.08999991,  39.31000137]], dtype=float32), 'gt_confs': array([[1],
       [1],
       [1]], dtype=int32), 'max_overlaps': array([ 1.,  1.,  1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([-1.58000004,  1.98000002,  1.77999997], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 3L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 3L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 3L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 3L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'width': 1242, 'boxes': array([[   0.        ,  204.44999695,  215.35998535,  374.        ],
       [ 282.76000977,  179.24000549,  366.66998291,  239.02000427],
       [ 691.84002686,  178.36000061,  877.23999023,  269.36999512]], dtype=float32), 'flipped': True, 'max_classes': array([1, 1, 1]), 'max_overlaps': array([ 1.,  1.,  1.], dtype=float32), 'image': 'data/kitti/images/006881.png', 'gt_overlaps': array([[ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.],
       [ 0.,  1.,  0.,  0.]], dtype=float32), 'gt_classes': array([1, 1, 1], dtype=int32), 'height': 375}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 258, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 337, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([ 1.57000005], dtype=float32), 'gt_dims': array([[ 1.66999996,  1.87      ,  3.69000006]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000001.png', 'height': 375, 'orientation_ry': array([ 1.57000005], dtype=float32), 'width': 1242, 'boxes': array([[ 387.63000488,  181.53999329,  423.80999756,  203.11999512]], dtype=float32), 'gt_position': array([[-16.53000069,   2.3900001 ,  58.49000168]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([ 1.85000002], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
{'gt_classes': array([1], dtype=int32), 'gt_angles': array([-1.52999997], dtype=float32), 'gt_dims': array([[ 1.90999997,  1.64999998,  4.4000001 ]], dtype=float32), 'max_classes': array([1]), 'image': 'data/kitti/images/000153.png', 'height': 370, 'orientation_ry': array([-1.52999997], dtype=float32), 'width': 1224, 'boxes': array([[ 669.59997559,  159.27999878,  704.34002686,  194.50999451]], dtype=float32), 'gt_position': array([[  4.69000006,   0.75      ,  40.86999893]], dtype=float32), 'gt_confs': array([[1]], dtype=int32), 'max_overlaps': array([ 1.], dtype=float32), 'flipped': False, 'orientation_alpha': array([-1.63999999], dtype=float32), 'gt_overlaps': array([[ 0.,  1.,  0.,  0.]], dtype=float32)}
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 1L, 1L)
  data: (1L, 3L, 752L, 2488L)
  gt_angles: (1L, 1L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 35, in train_net
    sym = eval('get_' + args.network + '_train')()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/symbol/symbol_vgg.py", line 261, in get_vgg_train
    angle_loss = mx.symbol.Reshape(data=angle_loss, shape=(config.TRAIN.BATCH_IMAGES, -1, num_bin*2), name='angle_loss_reshape')
UnboundLocalError: local variable 'angle_loss' referenced before assignment
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 5L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 5L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 5L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 5L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator conf: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2482L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 8L),
 'gt_boxes': (1L, 8L, 5L),
 'gt_confs': (1L, 8L, 1L),
 'gt_dims': (1L, 8L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 86, in train_net
    arg_params['fc6_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_dim_weight'])
KeyError: 'fc6_dim_weight'
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
  File "example/env/train_end2end.py", line 107
    arg_params['rpn_conv_3x3_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['rpn_conv_3x3_weight'])
    ^
IndentationError: unexpected indent
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 2L),
 'gt_boxes': (1L, 2L, 5L),
 'gt_confs': (1L, 2L, 1L),
 'gt_dims': (1L, 2L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 204, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 129, in train_net
    conf_metric = metric.RCNNConfLossMetric()
AttributeError: 'module' object has no attribute 'RCNNConfLossMetric'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 2L),
 'gt_boxes': (1L, 2L, 5L),
 'gt_confs': (1L, 2L, 1L),
 'gt_dims': (1L, 2L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 85, in train_net
    if config.TRAIN.BBOX_OK: 
AttributeError: 'EasyDict' object has no attribute 'BBOX_OK'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_bias': (4096L,),
 'fc6_weight': (4096L, 25088L),
 'fc7_bias': (4096L,),
 'fc7_weight': (4096L, 4096L),
 'gt_angles': (1L, 4L),
 'gt_boxes': (1L, 4L, 5L),
 'gt_confs': (1L, 4L, 1L),
 'gt_dims': (1L, 4L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 86, in train_net
    arg_params['fc6_dim_weight'] = mx.random.normal(0, 0.01, shape=arg_shape_dict['fc6_dim_weight'])
KeyError: 'fc6_dim_weight'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
infer_shape error. Arguments:
  bbox_target: (1L, 36L, 47L, 155L)
  im_info: (1L, 3L)
  gt_dims: (1L, 1L, 3L)
  label: (1L, 65565L)
  gt_boxes: (1L, 1L, 5L)
  bbox_weight: (1L, 36L, 47L, 155L)
  gt_confs: (1L, 1L, 1L)
  data: (1L, 3L, 752L, 2491L)
  gt_angles: (1L, 1L)
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 67, in train_net
    arg_shape, out_shape, aux_shape = sym.infer_shape(**data_shape_dict)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 535, in infer_shape
    return self._infer_shape_impl(False, *args, **kwargs)
  File "/home/hustxly/mxnet/python/mxnet/symbol.py", line 602, in _infer_shape_impl
    ctypes.byref(complete)))
  File "/home/hustxly/mxnet/python/mxnet/base.py", line 75, in check_call
    raise MXNetError(py_str(_LIB.MXGetLastError()))
mxnet.base.MXNetError: Error in operator angle: Shape inconsistent, Provided=(128,1), inferred shape=(128,)
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
providing maximum shape [('data', (1, 3, 1000, 1000)), ('gt_boxes', (1, 100, 5))] [('label', (1, 34596)), ('bbox_target', (1, 36, 62, 62)), ('bbox_weight', (1, 36, 62, 62))]
output shape
{'angle_loss_reshape_output': (1L, 128L, 8L),
 'bbox_loss_reshape_output': (1L, 128L, 84L),
 'blockgrad0_output': (1L, 128L),
 'blockgrad1_output': (128L, 3L),
 'blockgrad2_output': (128L, 1L),
 'blockgrad3_output': (128L, 1L),
 'cls_prob_reshape_output': (1L, 128L, 21L),
 'conf_loss_reshape_output': (1L, 128L, 1L),
 'dim_loss_reshape_output': (1L, 128L, 3L),
 'rpn_bbox_loss_output': (1L, 36L, 47L, 155L),
 'rpn_cls_prob_output': (1L, 2L, 423L, 155L)}
arg shape
{'bbox_pred_bias': (84L,),
 'bbox_pred_weight': (84L, 4096L),
 'bbox_target': (1L, 36L, 47L, 155L),
 'bbox_weight': (1L, 36L, 47L, 155L),
 'cls_score_bias': (21L,),
 'cls_score_weight': (21L, 4096L),
 'conv1_1_bias': (64L,),
 'conv1_1_weight': (64L, 3L, 3L, 3L),
 'conv1_2_bias': (64L,),
 'conv1_2_weight': (64L, 64L, 3L, 3L),
 'conv2_1_bias': (128L,),
 'conv2_1_weight': (128L, 64L, 3L, 3L),
 'conv2_2_bias': (128L,),
 'conv2_2_weight': (128L, 128L, 3L, 3L),
 'conv3_1_bias': (256L,),
 'conv3_1_weight': (256L, 128L, 3L, 3L),
 'conv3_2_bias': (256L,),
 'conv3_2_weight': (256L, 256L, 3L, 3L),
 'conv3_3_bias': (256L,),
 'conv3_3_weight': (256L, 256L, 3L, 3L),
 'conv4_1_bias': (512L,),
 'conv4_1_weight': (512L, 256L, 3L, 3L),
 'conv4_2_bias': (512L,),
 'conv4_2_weight': (512L, 512L, 3L, 3L),
 'conv4_3_bias': (512L,),
 'conv4_3_weight': (512L, 512L, 3L, 3L),
 'conv5_1_bias': (512L,),
 'conv5_1_weight': (512L, 512L, 3L, 3L),
 'conv5_2_bias': (512L,),
 'conv5_2_weight': (512L, 512L, 3L, 3L),
 'conv5_3_bias': (512L,),
 'conv5_3_weight': (512L, 512L, 3L, 3L),
 'data': (1L, 3L, 752L, 2491L),
 'fc6_angle_bias': (256L,),
 'fc6_angle_weight': (256L, 4096L),
 'fc6_bias': (4096L,),
 'fc6_conf_bias': (256L,),
 'fc6_conf_weight': (256L, 4096L),
 'fc6_dim_bias': (512L,),
 'fc6_dim_weight': (512L, 4096L),
 'fc6_weight': (4096L, 25088L),
 'fc7_angle_bias': (256L,),
 'fc7_angle_weight': (256L, 256L),
 'fc7_bias': (4096L,),
 'fc7_conf_bias': (128L,),
 'fc7_conf_weight': (128L, 256L),
 'fc7_dim_bias': (512L,),
 'fc7_dim_weight': (512L, 512L),
 'fc7_weight': (4096L, 4096L),
 'fc8_angle_bias': (8L,),
 'fc8_angle_weight': (8L, 256L),
 'fc8_conf_bias': (1L,),
 'fc8_conf_weight': (1L, 128L),
 'fc8_dim_bias': (3L,),
 'fc8_dim_weight': (3L, 512L),
 'gt_angles': (1L, 1L),
 'gt_boxes': (1L, 1L, 5L),
 'gt_confs': (1L, 1L, 1L),
 'gt_dims': (1L, 1L, 3L),
 'im_info': (1L, 3L),
 'label': (1L, 65565L),
 'rpn_bbox_pred_bias': (36L,),
 'rpn_bbox_pred_weight': (36L, 512L, 1L, 1L),
 'rpn_cls_score_bias': (18L,),
 'rpn_cls_score_weight': (18L, 512L, 1L, 1L),
 'rpn_conv_3x3_bias': (512L,),
 'rpn_conv_3x3_weight': (512L, 512L, 3L, 3L)}
aux shape
{}
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 150, in train_net
    if config.TRAIN.BBOX_OK: 
AttributeError: 'EasyDict' object has no attribute 'BBOX_OK'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 226, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
load 0  /  3424
size:  (375, 1242, 3)
load 1  /  3424
size:  (375, 1242, 3)
load 2  /  3424
size:  (375, 1242, 3)
load 3  /  3424
size:  (374, 1238, 3)
load 4  /  3424
size:  (375, 1242, 3)
load 5  /  3424
size:  (374, 1238, 3)
load 6  /  3424
size:  (375, 1242, 3)
load 7  /  3424
size:  (375, 1242, 3)
load 8  /  3424
size:  (375, 1242, 3)
load 9  /  3424
size:  (375, 1242, 3)
load 10  /  3424
size:  (376, 1241, 3)
load 11  /  3424
size:  (375, 1242, 3)
load 12  /  3424
size:  (375, 1242, 3)
load 13  /  3424
size:  (375, 1242, 3)
load 14  /  3424
size:  (375, 1242, 3)
load 15  /  3424
size:  (375, 1242, 3)
load 16  /  3424
size:  (376, 1241, 3)
load 17  /  3424
size:  (375, 1242, 3)
load 18  /  3424
size:  (375, 1242, 3)
load 19  /  3424
size:  (375, 1242, 3)
load 20  /  3424
size:  (376, 1241, 3)
load 21  /  3424
size:  (375, 1242, 3)
load 22  /  3424
size:  (375, 1242, 3)
load 23  /  3424
size:  (375, 1242, 3)
load 24  /  3424
size:  (375, 1242, 3)
load 25  /  3424
size:  (375, 1242, 3)
load 26  /  3424
size:  (375, 1242, 3)
load 27  /  3424
size:  (375, 1242, 3)
load 28  /  3424
size:  (375, 1242, 3)
load 29  /  3424
size:  (375, 1242, 3)
load 30  /  3424
size:  (375, 1242, 3)
load 31  /  3424
size:  (375, 1242, 3)
load 32  /  3424
size:  (375, 1242, 3)
load 33  /  3424
size:  (375, 1242, 3)
load 34  /  3424
size:  (375, 1242, 3)
load 35  /  3424
size:  (375, 1242, 3)
load 36  /  3424
size:  (376, 1241, 3)
load 37  /  3424
size:  (375, 1242, 3)
load 38  /  3424
size:  (375, 1242, 3)
load 39  /  3424
size:  (375, 1242, 3)
load 40  /  3424
size:  (375, 1242, 3)
load 41  /  3424
size:  (375, 1242, 3)
load 42  /  3424
size:  (375, 1242, 3)
load 43  /  3424
size:  (375, 1242, 3)
load 44  /  3424
size:  (375, 1242, 3)
load 45  /  3424
size:  (370, 1224, 3)
load 46  /  3424
size:  (375, 1242, 3)
load 47  /  3424
size:  (375, 1242, 3)
load 48  /  3424
size:  (376, 1241, 3)
load 49  /  3424
size:  (370, 1224, 3)
load 50  /  3424
size:  (375, 1242, 3)
load 51  /  3424
size:  (375, 1242, 3)
load 52  /  3424
size:  (375, 1242, 3)
load 53  /  3424
size:  (375, 1242, 3)
load 54  /  3424
size:  (375, 1242, 3)
load 55  /  3424
size:  (370, 1224, 3)
load 56  /  3424
size:  (375, 1242, 3)
load 57  /  3424
size:  (370, 1224, 3)
load 58  /  3424
size:  (375, 1242, 3)
load 59  /  3424
size:  (375, 1242, 3)
load 60  /  3424
size:  (375, 1242, 3)
load 61  /  3424
size:  (375, 1242, 3)
load 62  /  3424
size:  (376, 1241, 3)
load 63  /  3424
size:  (375, 1242, 3)
load 64  /  3424
size:  (375, 1242, 3)
load 65  /  3424
size:  (375, 1242, 3)
load 66  /  3424
size:  (375, 1242, 3)
load 67  /  3424
size:  (375, 1242, 3)
load 68  /  3424
size:  (375, 1242, 3)
load 69  /  3424
size:  (375, 1242, 3)
load 70  /  3424
size:  (375, 1242, 3)
load 71  /  3424
size:  (374, 1238, 3)
load 72  /  3424
size:  (376, 1241, 3)
load 73  /  3424
size:  (376, 1241, 3)
load 74  /  3424
size:  (375, 1242, 3)
load 75  /  3424
size:  (375, 1242, 3)
load 76  /  3424
size:  (375, 1242, 3)
load 77  /  3424
size:  (375, 1242, 3)
load 78  /  3424
size:  (375, 1242, 3)
load 79  /  3424
size:  (375, 1242, 3)
load 80  /  3424
size:  (375, 1242, 3)
load 81  /  3424
size:  (375, 1242, 3)
load 82  /  3424
size:  (375, 1242, 3)
load 83  /  3424
size:  (375, 1242, 3)
load 84  /  3424
size:  (375, 1242, 3)
load 85  /  3424
size:  (375, 1242, 3)
load 86  /  3424
size:  (375, 1242, 3)
load 87  /  3424
size:  (375, 1242, 3)
load 88  /  3424
size:  (375, 1242, 3)
load 89  /  3424
size:  (375, 1242, 3)
load 90  /  3424
size:  (375, 1242, 3)
load 91  /  3424
size:  (375, 1242, 3)
load 92  /  3424
size:  (375, 1242, 3)
load 93  /  3424
size:  (375, 1242, 3)
load 94  /  3424
size:  (376, 1241, 3)
load 95  /  3424
size:  (375, 1242, 3)
load 96  /  3424
size:  (375, 1242, 3)
load 97  /  3424
size:  (375, 1242, 3)
load 98  /  3424
size:  (376, 1241, 3)
load 99  /  3424
size:  (375, 1242, 3)
load 100  /  3424
size:  (376, 1241, 3)
load 101  /  3424
size:  (376, 1241, 3)
load 102  /  3424
size:  (375, 1242, 3)
load 103  /  3424
size:  (375, 1242, 3)
load 104  /  3424
size:  (375, 1242, 3)
load 105  /  3424
size:  (375, 1242, 3)
load 106  /  3424
size:  (375, 1242, 3)
load 107  /  3424
size:  (375, 1242, 3)
load 108  /  3424
size:  (375, 1242, 3)
load 109  /  3424
size:  (375, 1242, 3)
load 110  /  3424
size:  (375, 1242, 3)
load 111  /  3424
size:  (375, 1242, 3)
load 112  /  3424
size:  (375, 1242, 3)
load 113  /  3424
size:  (375, 1242, 3)
load 114  /  3424
size:  (375, 1242, 3)
load 115  /  3424
size:  (375, 1242, 3)
load 116  /  3424
size:  (375, 1242, 3)
load 117  /  3424
size:  (376, 1241, 3)
load 118  /  3424
size:  (375, 1242, 3)
load 119  /  3424
size:  (375, 1242, 3)
load 120  /  3424
size:  (375, 1242, 3)
load 121  /  3424
size:  (376, 1241, 3)
load 122  /  3424
size:  (374, 1238, 3)
load 123  /  3424
size:  (374, 1238, 3)
load 124  /  3424
size:  (375, 1242, 3)
load 125  /  3424
size:  (370, 1224, 3)
load 126  /  3424
size:  (375, 1242, 3)
load 127  /  3424
size:  (375, 1242, 3)
load 128  /  3424
size:  (375, 1242, 3)
load 129  /  3424
size:  (375, 1242, 3)
load 130  /  3424
size:  (375, 1242, 3)
load 131  /  3424
size:  (375, 1242, 3)
load 132  /  3424
size:  (375, 1242, 3)
load 133  /  3424
size:  (375, 1242, 3)
load 134  /  3424
size:  (375, 1242, 3)
load 135  /  3424
size:  (375, 1242, 3)
load 136  /  3424
size:  (375, 1242, 3)
load 137  /  3424
size:  (374, 1238, 3)
load 138  /  3424
size:  (370, 1224, 3)
load 139  /  3424
size:  (375, 1242, 3)
load 140  /  3424
size:  (374, 1238, 3)
load 141  /  3424
size:  (375, 1242, 3)
load 142  /  3424
size:  (375, 1242, 3)
load 143  /  3424
size:  (376, 1241, 3)
load 144  /  3424
size:  (375, 1242, 3)
load 145  /  3424
size:  (375, 1242, 3)
load 146  /  3424
size:  (375, 1242, 3)
load 147  /  3424
size:  (376, 1241, 3)
load 148  /  3424
size:  (375, 1242, 3)
load 149  /  3424
size:  (375, 1242, 3)
load 150  /  3424
size:  (375, 1242, 3)
load 151  /  3424
size:  (375, 1242, 3)
load 152  /  3424
size:  (376, 1241, 3)
load 153  /  3424
size:  (375, 1242, 3)
load 154  /  3424
size:  (375, 1242, 3)
load 155  /  3424
size:  (375, 1242, 3)
load 156  /  3424
size:  (375, 1242, 3)
load 157  /  3424
size:  (370, 1224, 3)
load 158  /  3424
size:  (376, 1241, 3)
load 159  /  3424
size:  (375, 1242, 3)
load 160  /  3424
size:  (375, 1242, 3)
load 161  /  3424
size:  (375, 1242, 3)
load 162  /  3424
size:  (375, 1242, 3)
load 163  /  3424
size:  (375, 1242, 3)
load 164  /  3424
size:  (375, 1242, 3)
load 165  /  3424
size:  (375, 1242, 3)
load 166  /  3424
size:  (375, 1242, 3)
load 167  /  3424
size:  (370, 1224, 3)
load 168  /  3424
size:  (375, 1242, 3)
load 169  /  3424
size:  (376, 1241, 3)
load 170  /  3424
size:  (375, 1242, 3)
load 171  /  3424
size:  (376, 1241, 3)
load 172  /  3424
size:  (375, 1242, 3)
load 173  /  3424
size:  (375, 1242, 3)
load 174  /  3424
size:  (375, 1242, 3)
load 175  /  3424
size:  (375, 1242, 3)
load 176  /  3424
size:  (375, 1242, 3)
load 177  /  3424
size:  (375, 1242, 3)
load 178  /  3424
size:  (375, 1242, 3)
load 179  /  3424
size:  (375, 1242, 3)
load 180  /  3424
size:  (375, 1242, 3)
load 181  /  3424
size:  (375, 1242, 3)
load 182  /  3424
size:  (376, 1241, 3)
load 183  /  3424
size:  (375, 1242, 3)
load 184  /  3424
size:  (375, 1242, 3)
load 185  /  3424
size:  (375, 1242, 3)
load 186  /  3424
size:  (375, 1242, 3)
load 187  /  3424
size:  (375, 1242, 3)
load 188  /  3424
size:  (376, 1241, 3)
load 189  /  3424
size:  (375, 1242, 3)
load 190  /  3424
size:  (374, 1238, 3)
load 191  /  3424
size:  (376, 1241, 3)
load 192  /  3424
size:  (370, 1224, 3)
load 193  /  3424
size:  (375, 1242, 3)
load 194  /  3424
size:  (375, 1242, 3)
load 195  /  3424
size:  (375, 1242, 3)
load 196  /  3424
size:  (375, 1242, 3)
load 197  /  3424
size:  (375, 1242, 3)
load 198  /  3424
size:  (375, 1242, 3)
load 199  /  3424
size:  (375, 1242, 3)
load 200  /  3424
size:  (370, 1224, 3)
load 201  /  3424
size:  (375, 1242, 3)
load 202  /  3424
size:  (375, 1242, 3)
load 203  /  3424
size:  (375, 1242, 3)
load 204  /  3424
size:  (370, 1224, 3)
load 205  /  3424
size:  (375, 1242, 3)
load 206  /  3424
size:  (375, 1242, 3)
load 207  /  3424
size:  (375, 1242, 3)
load 208  /  3424
size:  (375, 1242, 3)
load 209  /  3424
size:  (375, 1242, 3)
load 210  /  3424
size:  (375, 1242, 3)
load 211  /  3424
size:  (375, 1242, 3)
load 212  /  3424
size:  (375, 1242, 3)
load 213  /  3424
size:  (375, 1242, 3)
load 214  /  3424
size:  (375, 1242, 3)
load 215  /  3424
size:  (374, 1238, 3)
load 216  /  3424
size:  (375, 1242, 3)
load 217  /  3424
size:  (375, 1242, 3)
load 218  /  3424
size:  (375, 1242, 3)
load 219  /  3424
size:  (375, 1242, 3)
load 220  /  3424
size:  (375, 1242, 3)
load 221  /  3424
size:  (375, 1242, 3)
load 222  /  3424
size:  (375, 1242, 3)
load 223  /  3424
size:  (376, 1241, 3)
load 224  /  3424
size:  (375, 1242, 3)
load 225  /  3424
size:  (375, 1242, 3)
load 226  /  3424
size:  (370, 1224, 3)
load 227  /  3424
size:  (375, 1242, 3)
load 228  /  3424
size:  (375, 1242, 3)
load 229  /  3424
size:  (375, 1242, 3)
load 230  /  3424
size:  (375, 1242, 3)
load 231  /  3424
size:  (375, 1242, 3)
load 232  /  3424
size:  (375, 1242, 3)
load 233  /  3424
size:  (376, 1241, 3)
load 234  /  3424
size:  (374, 1238, 3)
load 235  /  3424
size:  (375, 1242, 3)
load 236  /  3424
size:  (375, 1242, 3)
load 237  /  3424
size:  (375, 1242, 3)
load 238  /  3424
size:  (376, 1241, 3)
load 239  /  3424
size:  (375, 1242, 3)
load 240  /  3424
size:  (370, 1224, 3)
load 241  /  3424
size:  (375, 1242, 3)
load 242  /  3424
size:  (375, 1242, 3)
load 243  /  3424
size:  (375, 1242, 3)
load 244  /  3424
size:  (375, 1242, 3)
load 245  /  3424
size:  (375, 1242, 3)
load 246  /  3424
size:  (375, 1242, 3)
load 247  /  3424
size:  (375, 1242, 3)
load 248  /  3424
size:  (375, 1242, 3)
load 249  /  3424
size:  (376, 1241, 3)
load 250  /  3424
size:  (375, 1242, 3)
load 251  /  3424
size:  (375, 1242, 3)
load 252  /  3424
size:  (376, 1241, 3)
load 253  /  3424
size:  (374, 1238, 3)
load 254  /  3424
size:  (375, 1242, 3)
load 255  /  3424
size:  (375, 1242, 3)
load 256  /  3424
size:  (375, 1242, 3)
load 257  /  3424
size:  (375, 1242, 3)
load 258  /  3424
size:  (375, 1242, 3)
load 259  /  3424
size:  (375, 1242, 3)
load 260  /  3424
size:  (375, 1242, 3)
load 261  /  3424
size:  (374, 1238, 3)
load 262  /  3424
size:  (376, 1241, 3)
load 263  /  3424
size:  (375, 1242, 3)
load 264  /  3424
size:  (375, 1242, 3)
load 265  /  3424
size:  (375, 1242, 3)
load 266  /  3424
size:  (375, 1242, 3)
load 267  /  3424
size:  (375, 1242, 3)
load 268  /  3424
size:  (375, 1242, 3)
load 269  /  3424
size:  (374, 1238, 3)
load 270  /  3424
size:  (376, 1241, 3)
load 271  /  3424
size:  (375, 1242, 3)
load 272  /  3424
size:  (375, 1242, 3)
load 273  /  3424
size:  (375, 1242, 3)
load 274  /  3424
size:  (375, 1242, 3)
load 275  /  3424
size:  (375, 1242, 3)
load 276  /  3424
size:  (375, 1242, 3)
load 277  /  3424
size:  (375, 1242, 3)
load 278  /  3424
size:  (375, 1242, 3)
load 279  /  3424
size:  (375, 1242, 3)
load 280  /  3424
size:  (375, 1242, 3)
load 281  /  3424
size:  (375, 1242, 3)
load 282  /  3424
size:  (375, 1242, 3)
load 283  /  3424
size:  (375, 1242, 3)
load 284  /  3424
size:  (375, 1242, 3)
load 285  /  3424
size:  (375, 1242, 3)
load 286  /  3424
size:  (375, 1242, 3)
load 287  /  3424
size:  (375, 1242, 3)
load 288  /  3424
size:  (375, 1242, 3)
load 289  /  3424
size:  (375, 1242, 3)
load 290  /  3424
size:  (375, 1242, 3)
load 291  /  3424
size:  (374, 1238, 3)
load 292  /  3424
size:  (376, 1241, 3)
load 293  /  3424
size:  (375, 1242, 3)
load 294  /  3424
size:  (375, 1242, 3)
load 295  /  3424
size:  (375, 1242, 3)
load 296  /  3424
size:  (375, 1242, 3)
load 297  /  3424
size:  (375, 1242, 3)
load 298  /  3424
size:  (375, 1242, 3)
load 299  /  3424
size:  (375, 1242, 3)
load 300  /  3424
size:  (375, 1242, 3)
load 301  /  3424
size:  (376, 1241, 3)
load 302  /  3424
size:  (375, 1242, 3)
load 303  /  3424
size:  (375, 1242, 3)
load 304  /  3424
size:  (375, 1242, 3)
load 305  /  3424
size:  (374, 1238, 3)
load 306  /  3424
size:  (375, 1242, 3)
load 307  /  3424
size:  (375, 1242, 3)
load 308  /  3424
size:  (375, 1242, 3)
load 309  /  3424
size:  (375, 1242, 3)
load 310  /  3424
size:  (375, 1242, 3)
load 311  /  3424
size:  (375, 1242, 3)
load 312  /  3424
size:  (375, 1242, 3)
load 313  /  3424
size:  (375, 1242, 3)
load 314  /  3424
size:  (375, 1242, 3)
load 315  /  3424
size:  (375, 1242, 3)
load 316  /  3424
size:  (375, 1242, 3)
load 317  /  3424
size:  (375, 1242, 3)
load 318  /  3424
size:  (375, 1242, 3)
load 319  /  3424
size:  (375, 1242, 3)
load 320  /  3424
size:  (375, 1242, 3)
load 321  /  3424
size:  (375, 1242, 3)
load 322  /  3424
size:  (374, 1238, 3)
load 323  /  3424
size:  (376, 1241, 3)
load 324  /  3424
size:  (374, 1238, 3)
load 325  /  3424
size:  (375, 1242, 3)
load 326  /  3424
size:  (375, 1242, 3)
load 327  /  3424
size:  (375, 1242, 3)
load 328  /  3424
size:  (375, 1242, 3)
load 329  /  3424
size:  (375, 1242, 3)
load 330  /  3424
size:  (375, 1242, 3)
load 331  /  3424
size:  (376, 1241, 3)
load 332  /  3424
size:  (376, 1241, 3)
load 333  /  3424
size:  (375, 1242, 3)
load 334  /  3424
size:  (375, 1242, 3)
load 335  /  3424
size:  (375, 1242, 3)
load 336  /  3424
size:  (376, 1241, 3)
load 337  /  3424
size:  (375, 1242, 3)
load 338  /  3424
size:  (376, 1241, 3)
load 339  /  3424
size:  (375, 1242, 3)
load 340  /  3424
size:  (370, 1224, 3)
load 341  /  3424
size:  (375, 1242, 3)
load 342  /  3424
size:  (375, 1242, 3)
load 343  /  3424
size:  (376, 1241, 3)
load 344  /  3424
size:  (370, 1224, 3)
load 345  /  3424
size:  (375, 1242, 3)
load 346  /  3424
size:  (375, 1242, 3)
load 347  /  3424
size:  (375, 1242, 3)
load 348  /  3424
size:  (375, 1242, 3)
load 349  /  3424
size:  (375, 1242, 3)
load 350  /  3424
size:  (375, 1242, 3)
load 351  /  3424
size:  (375, 1242, 3)
load 352  /  3424
size:  (375, 1242, 3)
load 353  /  3424
size:  (375, 1242, 3)
load 354  /  3424
size:  (375, 1242, 3)
load 355  /  3424
size:  (376, 1241, 3)
load 356  /  3424
size:  (375, 1242, 3)
load 357  /  3424
size:  (375, 1242, 3)
load 358  /  3424
size:  (375, 1242, 3)
load 359  /  3424
size:  (375, 1242, 3)
load 360  /  3424
size:  (376, 1241, 3)
load 361  /  3424
size:  (375, 1242, 3)
load 362  /  3424
size:  (375, 1242, 3)
load 363  /  3424
size:  (375, 1242, 3)
load 364  /  3424
size:  (375, 1242, 3)
load 365  /  3424
size:  (374, 1238, 3)
load 366  /  3424
size:  (376, 1241, 3)
load 367  /  3424
size:  (375, 1242, 3)
load 368  /  3424
size:  (375, 1242, 3)
load 369  /  3424
size:  (376, 1241, 3)
load 370  /  3424
size:  (375, 1242, 3)
load 371  /  3424
size:  (375, 1242, 3)
load 372  /  3424
size:  (375, 1242, 3)
load 373  /  3424
size:  (375, 1242, 3)
load 374  /  3424
size:  (375, 1242, 3)
load 375  /  3424
size:  (375, 1242, 3)
load 376  /  3424
size:  (376, 1241, 3)
load 377  /  3424
size:  (375, 1242, 3)
load 378  /  3424
size:  (375, 1242, 3)
load 379  /  3424
size:  (375, 1242, 3)
load 380  /  3424
size:  (375, 1242, 3)
load 381  /  3424
size:  (376, 1241, 3)
load 382  /  3424
size:  (375, 1242, 3)
load 383  /  3424
size:  (375, 1242, 3)
load 384  /  3424
size:  (376, 1241, 3)
load 385  /  3424
size:  (375, 1242, 3)
load 386  /  3424
size:  (375, 1242, 3)
load 387  /  3424
size:  (375, 1242, 3)
load 388  /  3424
size:  (375, 1242, 3)
load 389  /  3424
size:  (375, 1242, 3)
load 390  /  3424
size:  (375, 1242, 3)
load 391  /  3424
size:  (370, 1224, 3)
load 392  /  3424
size:  (375, 1242, 3)
load 393  /  3424
size:  (375, 1242, 3)
load 394  /  3424
size:  (375, 1242, 3)
load 395  /  3424
size:  (375, 1242, 3)
load 396  /  3424
size:  (375, 1242, 3)
load 397  /  3424
size:  (375, 1242, 3)
load 398  /  3424
size:  (375, 1242, 3)
load 399  /  3424
size:  (374, 1238, 3)
load 400  /  3424
size:  (375, 1242, 3)
load 401  /  3424
size:  (375, 1242, 3)
load 402  /  3424
size:  (375, 1242, 3)
load 403  /  3424
size:  (375, 1242, 3)
load 404  /  3424
size:  (375, 1242, 3)
load 405  /  3424
size:  (375, 1242, 3)
load 406  /  3424
size:  (375, 1242, 3)
load 407  /  3424
size:  (375, 1242, 3)
load 408  /  3424
size:  (375, 1242, 3)
load 409  /  3424
size:  (375, 1242, 3)
load 410  /  3424
size:  (375, 1242, 3)
load 411  /  3424
size:  (375, 1242, 3)
load 412  /  3424
size:  (375, 1242, 3)
load 413  /  3424
size:  (375, 1242, 3)
load 414  /  3424
size:  (375, 1242, 3)
load 415  /  3424
size:  (375, 1242, 3)
load 416  /  3424
size:  (375, 1242, 3)
load 417  /  3424
size:  (375, 1242, 3)
load 418  /  3424
size:  (375, 1242, 3)
load 419  /  3424
size:  (376, 1241, 3)
load 420  /  3424
size:  (375, 1242, 3)
load 421  /  3424
size:  (375, 1242, 3)
load 422  /  3424
size:  (374, 1238, 3)
load 423  /  3424
size:  (376, 1241, 3)
load 424  /  3424
size:  (375, 1242, 3)
load 425  /  3424
size:  (375, 1242, 3)
load 426  /  3424
size:  (375, 1242, 3)
load 427  /  3424
size:  (375, 1242, 3)
load 428  /  3424
size:  (375, 1242, 3)
load 429  /  3424
size:  (375, 1242, 3)
load 430  /  3424
size:  (375, 1242, 3)
load 431  /  3424
size:  (375, 1242, 3)
load 432  /  3424
size:  (375, 1242, 3)
load 433  /  3424
size:  (376, 1241, 3)
load 434  /  3424
size:  (375, 1242, 3)
load 435  /  3424
size:  (375, 1242, 3)
load 436  /  3424
size:  (375, 1242, 3)
load 437  /  3424
size:  (374, 1238, 3)
load 438  /  3424
size:  (375, 1242, 3)
load 439  /  3424
size:  (375, 1242, 3)
load 440  /  3424
size:  (375, 1242, 3)
load 441  /  3424
size:  (374, 1238, 3)
load 442  /  3424
size:  (375, 1242, 3)
load 443  /  3424
size:  (375, 1242, 3)
load 444  /  3424
size:  (375, 1242, 3)
load 445  /  3424
size:  (376, 1241, 3)
load 446  /  3424
size:  (375, 1242, 3)
load 447  /  3424
size:  (375, 1242, 3)
load 448  /  3424
size:  (375, 1242, 3)
load 449  /  3424
size:  (375, 1242, 3)
load 450  /  3424
size:  (370, 1224, 3)
load 451  /  3424
size:  (375, 1242, 3)
load 452  /  3424
size:  (375, 1242, 3)
load 453  /  3424
size:  (375, 1242, 3)
load 454  /  3424
size:  (375, 1242, 3)
load 455  /  3424
size:  (375, 1242, 3)
load 456  /  3424
size:  (375, 1242, 3)
load 457  /  3424
size:  (375, 1242, 3)
load 458  /  3424
size:  (374, 1238, 3)
load 459  /  3424
size:  (375, 1242, 3)
load 460  /  3424
size:  (375, 1242, 3)
load 461  /  3424
size:  (375, 1242, 3)
load 462  /  3424
size:  (376, 1241, 3)
load 463  /  3424
size:  (375, 1242, 3)
load 464  /  3424
size:  (375, 1242, 3)
load 465  /  3424
size:  (375, 1242, 3)
load 466  /  3424
size:  (375, 1242, 3)
load 467  /  3424
size:  (375, 1242, 3)
load 468  /  3424
size:  (375, 1242, 3)
load 469  /  3424
size:  (374, 1238, 3)
load 470  /  3424
size:  (370, 1224, 3)
load 471  /  3424
size:  (374, 1238, 3)
load 472  /  3424
size:  (375, 1242, 3)
load 473  /  3424
size:  (375, 1242, 3)
load 474  /  3424
size:  (375, 1242, 3)
load 475  /  3424
size:  (375, 1242, 3)
load 476  /  3424
size:  (375, 1242, 3)
load 477  /  3424
size:  (375, 1242, 3)
load 478  /  3424
size:  (375, 1242, 3)
load 479  /  3424
size:  (375, 1242, 3)
load 480  /  3424
size:  (375, 1242, 3)
load 481  /  3424
size:  (375, 1242, 3)
load 482  /  3424
size:  (375, 1242, 3)
load 483  /  3424
size:  (375, 1242, 3)
load 484  /  3424
size:  (375, 1242, 3)
load 485  /  3424
size:  (375, 1242, 3)
load 486  /  3424
size:  (374, 1238, 3)
load 487  /  3424
size:  (375, 1242, 3)
load 488  /  3424
size:  (376, 1241, 3)
load 489  /  3424
size:  (375, 1242, 3)
load 490  /  3424
size:  (375, 1242, 3)
load 491  /  3424
size:  (375, 1242, 3)
load 492  /  3424
size:  (375, 1242, 3)
load 493  /  3424
size:  (375, 1242, 3)
load 494  /  3424
size:  (375, 1242, 3)
load 495  /  3424
size:  (375, 1242, 3)
load 496  /  3424
size:  (375, 1242, 3)
load 497  /  3424
size:  (375, 1242, 3)
load 498  /  3424
size:  (375, 1242, 3)
load 499  /  3424
size:  (375, 1242, 3)
load 500  /  3424
size:  (374, 1238, 3)
load 501  /  3424
size:  (375, 1242, 3)
load 502  /  3424
size:  (375, 1242, 3)
load 503  /  3424
size:  (375, 1242, 3)
load 504  /  3424
size:  (375, 1242, 3)
load 505  /  3424
size:  (375, 1242, 3)
load 506  /  3424
size:  (376, 1241, 3)
load 507  /  3424
size:  (375, 1242, 3)
load 508  /  3424
size:  (375, 1242, 3)
load 509  /  3424
size:  (375, 1242, 3)
load 510  /  3424
size:  (375, 1242, 3)
load 511  /  3424
size:  (375, 1242, 3)
load 512  /  3424
size:  (375, 1242, 3)
load 513  /  3424
size:  (375, 1242, 3)
load 514  /  3424
size:  (375, 1242, 3)
load 515  /  3424
size:  (375, 1242, 3)
load 516  /  3424
size:  (375, 1242, 3)
load 517  /  3424
size:  (375, 1242, 3)
load 518  /  3424
size:  (375, 1242, 3)
load 519  /  3424
size:  (375, 1242, 3)
load 520  /  3424
size:  (376, 1241, 3)
load 521  /  3424
size:  (375, 1242, 3)
load 522  /  3424
size:  (375, 1242, 3)
load 523  /  3424
size:  (375, 1242, 3)
load 524  /  3424
size:  (375, 1242, 3)
load 525  /  3424
size:  (375, 1242, 3)
load 526  /  3424
size:  (375, 1242, 3)
load 527  /  3424
size:  (375, 1242, 3)
load 528  /  3424
size:  (375, 1242, 3)
load 529  /  3424
size:  (375, 1242, 3)
load 530  /  3424
size:  (375, 1242, 3)
load 531  /  3424
size:  (375, 1242, 3)
load 532  /  3424
size:  (375, 1242, 3)
load 533  /  3424
size:  (375, 1242, 3)
load 534  /  3424
size:  (370, 1224, 3)
load 535  /  3424
size:  (375, 1242, 3)
load 536  /  3424
size:  (374, 1238, 3)
load 537  /  3424
size:  (375, 1242, 3)
load 538  /  3424
size:  (376, 1241, 3)
load 539  /  3424
size:  (375, 1242, 3)
load 540  /  3424
size:  (375, 1242, 3)
load 541  /  3424
size:  (375, 1242, 3)
load 542  /  3424
size:  (375, 1242, 3)
load 543  /  3424
size:  (375, 1242, 3)
load 544  /  3424
size:  (375, 1242, 3)
load 545  /  3424
size:  (375, 1242, 3)
load 546  /  3424
size:  (375, 1242, 3)
load 547  /  3424
size:  (375, 1242, 3)
load 548  /  3424
size:  (375, 1242, 3)
load 549  /  3424
size:  (375, 1242, 3)
load 550  /  3424
size:  (375, 1242, 3)
load 551  /  3424
size:  (375, 1242, 3)
load 552  /  3424
size:  (375, 1242, 3)
load 553  /  3424
size:  (375, 1242, 3)
load 554  /  3424
size:  (375, 1242, 3)
load 555  /  3424
size:  (375, 1242, 3)
load 556  /  3424
size:  (375, 1242, 3)
load 557  /  3424
size:  (375, 1242, 3)
load 558  /  3424
size:  (375, 1242, 3)
load 559  /  3424
size:  (375, 1242, 3)
load 560  /  3424
size:  (375, 1242, 3)
load 561  /  3424
size:  (375, 1242, 3)
load 562  /  3424
size:  (376, 1241, 3)
load 563  /  3424
size:  (375, 1242, 3)
load 564  /  3424
size:  (375, 1242, 3)
load 565  /  3424
size:  (375, 1242, 3)
load 566  /  3424
size:  (374, 1238, 3)
load 567  /  3424
size:  (375, 1242, 3)
load 568  /  3424
size:  (375, 1242, 3)
load 569  /  3424
size:  (375, 1242, 3)
load 570  /  3424
size:  (375, 1242, 3)
load 571  /  3424
size:  (375, 1242, 3)
load 572  /  3424
size:  (375, 1242, 3)
load 573  /  3424
size:  (375, 1242, 3)
load 574  /  3424
size:  (375, 1242, 3)
load 575  /  3424
size:  (370, 1224, 3)
load 576  /  3424
size:  (375, 1242, 3)
load 577  /  3424
size:  (375, 1242, 3)
load 578  /  3424
size:  (375, 1242, 3)
load 579  /  3424
size:  (375, 1242, 3)
load 580  /  3424
size:  (375, 1242, 3)
load 581  /  3424
size:  (375, 1242, 3)
load 582  /  3424
size:  (375, 1242, 3)
load 583  /  3424
size:  (375, 1242, 3)
load 584  /  3424
size:  (375, 1242, 3)
load 585  /  3424
size:  (370, 1224, 3)
load 586  /  3424
size:  (376, 1241, 3)
load 587  /  3424
size:  (370, 1224, 3)
load 588  /  3424
size:  (376, 1241, 3)
load 589  /  3424
size:  (375, 1242, 3)
load 590  /  3424
size:  (375, 1242, 3)
load 591  /  3424
size:  (370, 1224, 3)
load 592  /  3424
size:  (375, 1242, 3)
load 593  /  3424
size:  (375, 1242, 3)
load 594  /  3424
size:  (375, 1242, 3)
load 595  /  3424
size:  (375, 1242, 3)
load 596  /  3424
size:  (376, 1241, 3)
load 597  /  3424
size:  (374, 1238, 3)
load 598  /  3424
size:  (370, 1224, 3)
load 599  /  3424
size:  (375, 1242, 3)
load 600  /  3424
size:  (375, 1242, 3)
load 601  /  3424
size:  (375, 1242, 3)
load 602  /  3424
size:  (375, 1242, 3)
load 603  /  3424
size:  (375, 1242, 3)
load 604  /  3424
size:  (374, 1238, 3)
load 605  /  3424
size:  (375, 1242, 3)
load 606  /  3424
size:  (375, 1242, 3)
load 607  /  3424
size:  (375, 1242, 3)
load 608  /  3424
size:  (375, 1242, 3)
load 609  /  3424
size:  (375, 1242, 3)
load 610  /  3424
size:  (375, 1242, 3)
load 611  /  3424
size:  (375, 1242, 3)
load 612  /  3424
size:  (375, 1242, 3)
load 613  /  3424
size:  (376, 1241, 3)
load 614  /  3424
size:  (375, 1242, 3)
load 615  /  3424
size:  (375, 1242, 3)
load 616  /  3424
size:  (375, 1242, 3)
load 617  /  3424
size:  (374, 1238, 3)
load 618  /  3424
size:  (375, 1242, 3)
load 619  /  3424
size:  (375, 1242, 3)
load 620  /  3424
size:  (375, 1242, 3)
load 621  /  3424
size:  (375, 1242, 3)
load 622  /  3424
size:  (375, 1242, 3)
load 623  /  3424
size:  (375, 1242, 3)
load 624  /  3424
size:  (375, 1242, 3)
load 625  /  3424
size:  (375, 1242, 3)
load 626  /  3424
size:  (375, 1242, 3)
load 627  /  3424
size:  (375, 1242, 3)
load 628  /  3424
size:  (375, 1242, 3)
load 629  /  3424
size:  (375, 1242, 3)
load 630  /  3424
size:  (375, 1242, 3)
load 631  /  3424
size:  (375, 1242, 3)
load 632  /  3424
size:  (375, 1242, 3)
load 633  /  3424
size:  (375, 1242, 3)
load 634  /  3424
size:  (375, 1242, 3)
load 635  /  3424
size:  (375, 1242, 3)
load 636  /  3424
size:  (375, 1242, 3)
load 637  /  3424
size:  (375, 1242, 3)
load 638  /  3424
size:  (375, 1242, 3)
load 639  /  3424
size:  (375, 1242, 3)
load 640  /  3424
size:  (375, 1242, 3)
load 641  /  3424
size:  (375, 1242, 3)
load 642  /  3424
size:  (374, 1238, 3)
load 643  /  3424
size:  (375, 1242, 3)
load 644  /  3424
size:  (375, 1242, 3)
load 645  /  3424
size:  (375, 1242, 3)
load 646  /  3424
size:  (375, 1242, 3)
load 647  /  3424
size:  (375, 1242, 3)
load 648  /  3424
size:  (375, 1242, 3)
load 649  /  3424
size:  (375, 1242, 3)
load 650  /  3424
size:  (375, 1242, 3)
load 651  /  3424
size:  (375, 1242, 3)
load 652  /  3424
size:  (375, 1242, 3)
load 653  /  3424
size:  (376, 1241, 3)
load 654  /  3424
size:  (374, 1238, 3)
load 655  /  3424
size:  (375, 1242, 3)
load 656  /  3424
size:  (375, 1242, 3)
load 657  /  3424
size:  (375, 1242, 3)
load 658  /  3424
size:  (375, 1242, 3)
load 659  /  3424
size:  (375, 1242, 3)
load 660  /  3424
size:  (370, 1224, 3)
load 661  /  3424
size:  (376, 1241, 3)
load 662  /  3424
size:  (375, 1242, 3)
load 663  /  3424
size:  (375, 1242, 3)
load 664  /  3424
size:  (375, 1242, 3)
load 665  /  3424
size:  (376, 1241, 3)
load 666  /  3424
size:  (375, 1242, 3)
load 667  /  3424
size:  (370, 1224, 3)
load 668  /  3424
size:  (375, 1242, 3)
load 669  /  3424
size:  (375, 1242, 3)
load 670  /  3424
size:  (375, 1242, 3)
load 671  /  3424
size:  (375, 1242, 3)
load 672  /  3424
size:  (375, 1242, 3)
load 673  /  3424
size:  (375, 1242, 3)
load 674  /  3424
size:  (375, 1242, 3)
load 675  /  3424
size:  (375, 1242, 3)
load 676  /  3424
size:  (375, 1242, 3)
load 677  /  3424
size:  (376, 1241, 3)
load 678  /  3424
size:  (375, 1242, 3)
load 679  /  3424
size:  (375, 1242, 3)
load 680  /  3424
size:  (375, 1242, 3)
load 681  /  3424
size:  (375, 1242, 3)
load 682  /  3424
size:  (375, 1242, 3)
load 683  /  3424
size:  (375, 1242, 3)
load 684  /  3424
size:  (375, 1242, 3)
load 685  /  3424
size:  (375, 1242, 3)
load 686  /  3424
size:  (376, 1241, 3)
load 687  /  3424
size:  (375, 1242, 3)
load 688  /  3424
size:  (375, 1242, 3)
load 689  /  3424
size:  (375, 1242, 3)
load 690  /  3424
size:  (375, 1242, 3)
load 691  /  3424
size:  (375, 1242, 3)
load 692  /  3424
size:  (375, 1242, 3)
load 693  /  3424
size:  (375, 1242, 3)
load 694  /  3424
size:  (375, 1242, 3)
load 695  /  3424
size:  (375, 1242, 3)
load 696  /  3424
size:  (375, 1242, 3)
load 697  /  3424
size:  (375, 1242, 3)
load 698  /  3424
size:  (375, 1242, 3)
load 699  /  3424
size:  (376, 1241, 3)
load 700  /  3424
size:  (376, 1241, 3)
load 701  /  3424
size:  (375, 1242, 3)
load 702  /  3424
size:  (375, 1242, 3)
load 703  /  3424
size:  (375, 1242, 3)
load 704  /  3424
size:  (376, 1241, 3)
load 705  /  3424
size:  (375, 1242, 3)
load 706  /  3424
size:  (375, 1242, 3)
load 707  /  3424
size:  (375, 1242, 3)
load 708  /  3424
size:  (375, 1242, 3)
load 709  /  3424
size:  (375, 1242, 3)
load 710  /  3424
size:  (375, 1242, 3)
load 711  /  3424
size:  (375, 1242, 3)
load 712  /  3424
size:  (375, 1242, 3)
load 713  /  3424
size:  (370, 1224, 3)
load 714  /  3424
size:  (375, 1242, 3)
load 715  /  3424
size:  (375, 1242, 3)
load 716  /  3424
size:  (375, 1242, 3)
load 717  /  3424
size:  (375, 1242, 3)
load 718  /  3424
size:  (375, 1242, 3)
load 719  /  3424
size:  (374, 1238, 3)
load 720  /  3424
size:  (370, 1224, 3)
load 721  /  3424
size:  (375, 1242, 3)
load 722  /  3424
size:  (376, 1241, 3)
load 723  /  3424
size:  (375, 1242, 3)
load 724  /  3424
size:  (375, 1242, 3)
load 725  /  3424
size:  (375, 1242, 3)
load 726  /  3424
size:  (375, 1242, 3)
load 727  /  3424
size:  (375, 1242, 3)
load 728  /  3424
size:  (376, 1241, 3)
load 729  /  3424
size:  (375, 1242, 3)
load 730  /  3424
size:  (375, 1242, 3)
load 731  /  3424
size:  (375, 1242, 3)
load 732  /  3424
size:  (376, 1241, 3)
load 733  /  3424
size:  (375, 1242, 3)
load 734  /  3424
size:  (375, 1242, 3)
load 735  /  3424
size:  (375, 1242, 3)
load 736  /  3424
size:  (375, 1242, 3)
load 737  /  3424
size:  (375, 1242, 3)
load 738  /  3424
size:  (375, 1242, 3)
load 739  /  3424
size:  (370, 1224, 3)
load 740  /  3424
size:  (375, 1242, 3)
load 741  /  3424
size:  (375, 1242, 3)
load 742  /  3424
size:  (375, 1242, 3)
load 743  /  3424
size:  (375, 1242, 3)
load 744  /  3424
size:  (375, 1242, 3)
load 745  /  3424
size:  (375, 1242, 3)
load 746  /  3424
size:  (375, 1242, 3)
load 747  /  3424
size:  (375, 1242, 3)
load 748  /  3424
size:  (375, 1242, 3)
load 749  /  3424
size:  (375, 1242, 3)
load 750  /  3424
size:  (375, 1242, 3)
load 751  /  3424
size:  (375, 1242, 3)
load 752  /  3424
size:  (375, 1242, 3)
load 753  /  3424
size:  (375, 1242, 3)
load 754  /  3424
size:  (375, 1242, 3)
load 755  /  3424
size:  (375, 1242, 3)
load 756  /  3424
size:  (375, 1242, 3)
load 757  /  3424
size:  (374, 1238, 3)
load 758  /  3424
size:  (375, 1242, 3)
load 759  /  3424
size:  (376, 1241, 3)
load 760  /  3424
size:  (375, 1242, 3)
load 761  /  3424
size:  (375, 1242, 3)
load 762  /  3424
size:  (375, 1242, 3)
load 763  /  3424
size:  (375, 1242, 3)
load 764  /  3424
size:  (376, 1241, 3)
load 765  /  3424
size:  (375, 1242, 3)
load 766  /  3424
size:  (375, 1242, 3)
load 767  /  3424
size:  (375, 1242, 3)
load 768  /  3424
size:  (375, 1242, 3)
load 769  /  3424
size:  (375, 1242, 3)
load 770  /  3424
size:  (375, 1242, 3)
load 771  /  3424
size:  (374, 1238, 3)
load 772  /  3424
size:  (370, 1224, 3)
load 773  /  3424
size:  (375, 1242, 3)
load 774  /  3424
size:  (375, 1242, 3)
load 775  /  3424
size:  (375, 1242, 3)
load 776  /  3424
size:  (375, 1242, 3)
load 777  /  3424
size:  (375, 1242, 3)
load 778  /  3424
size:  (375, 1242, 3)
load 779  /  3424
size:  (375, 1242, 3)
load 780  /  3424
size:  (375, 1242, 3)
load 781  /  3424
size:  (375, 1242, 3)
load 782  /  3424
size:  (375, 1242, 3)
load 783  /  3424
size:  (375, 1242, 3)
load 784  /  3424
size:  (376, 1241, 3)
load 785  /  3424
size:  (376, 1241, 3)
load 786  /  3424
size:  (375, 1242, 3)
load 787  /  3424
size:  (375, 1242, 3)
load 788  /  3424
size:  (375, 1242, 3)
load 789  /  3424
size:  (375, 1242, 3)
load 790  /  3424
size:  (375, 1242, 3)
load 791  /  3424
size:  (375, 1242, 3)
load 792  /  3424
size:  (375, 1242, 3)
load 793  /  3424
size:  (375, 1242, 3)
load 794  /  3424
size:  (376, 1241, 3)
load 795  /  3424
size:  (375, 1242, 3)
load 796  /  3424
size:  (375, 1242, 3)
load 797  /  3424
size:  (375, 1242, 3)
load 798  /  3424
size:  (375, 1242, 3)
load 799  /  3424
size:  (375, 1242, 3)
load 800  /  3424
size:  (374, 1238, 3)
load 801  /  3424
size:  (375, 1242, 3)
load 802  /  3424
size:  (375, 1242, 3)
load 803  /  3424
size:  (375, 1242, 3)
load 804  /  3424
size:  (375, 1242, 3)
load 805  /  3424
size:  (375, 1242, 3)
load 806  /  3424
size:  (375, 1242, 3)
load 807  /  3424
size:  (376, 1241, 3)
load 808  /  3424
size:  (375, 1242, 3)
load 809  /  3424
size:  (375, 1242, 3)
load 810  /  3424
size:  (375, 1242, 3)
load 811  /  3424
size:  (375, 1242, 3)
load 812  /  3424
size:  (375, 1242, 3)
load 813  /  3424
size:  (375, 1242, 3)
load 814  /  3424
size:  (375, 1242, 3)
load 815  /  3424
size:  (370, 1224, 3)
load 816  /  3424
size:  (375, 1242, 3)
load 817  /  3424
size:  (375, 1242, 3)
load 818  /  3424
size:  (375, 1242, 3)
load 819  /  3424
size:  (375, 1242, 3)
load 820  /  3424
size:  (375, 1242, 3)
load 821  /  3424
size:  (376, 1241, 3)
load 822  /  3424
size:  (374, 1238, 3)
load 823  /  3424
size:  (375, 1242, 3)
load 824  /  3424
size:  (375, 1242, 3)
load 825  /  3424
size:  (375, 1242, 3)
load 826  /  3424
size:  (375, 1242, 3)
load 827  /  3424
size:  (375, 1242, 3)
load 828  /  3424
size:  (374, 1238, 3)
load 829  /  3424
size:  (375, 1242, 3)
load 830  /  3424
size:  (376, 1241, 3)
load 831  /  3424
size:  (375, 1242, 3)
load 832  /  3424
size:  (376, 1241, 3)
load 833  /  3424
size:  (375, 1242, 3)
load 834  /  3424
size:  (375, 1242, 3)
load 835  /  3424
size:  (375, 1242, 3)
load 836  /  3424
size:  (375, 1242, 3)
load 837  /  3424
size:  (375, 1242, 3)
load 838  /  3424
size:  (375, 1242, 3)
load 839  /  3424
size:  (375, 1242, 3)
load 840  /  3424
size:  (375, 1242, 3)
load 841  /  3424
size:  (375, 1242, 3)
load 842  /  3424
size:  (370, 1224, 3)
load 843  /  3424
size:  (375, 1242, 3)
load 844  /  3424
size:  (375, 1242, 3)
load 845  /  3424
size:  (375, 1242, 3)
load 846  /  3424
size:  (375, 1242, 3)
load 847  /  3424
size:  (375, 1242, 3)
load 848  /  3424
size:  (375, 1242, 3)
load 849  /  3424
size:  (375, 1242, 3)
load 850  /  3424
size:  (370, 1224, 3)
load 851  /  3424
size:  (375, 1242, 3)
load 852  /  3424
size:  (375, 1242, 3)
load 853  /  3424
size:  (376, 1241, 3)
load 854  /  3424
size:  (375, 1242, 3)
load 855  /  3424
size:  (375, 1242, 3)
load 856  /  3424
size:  (375, 1242, 3)
load 857  /  3424
size:  (375, 1242, 3)
load 858  /  3424
size:  (375, 1242, 3)
load 859  /  3424
size:  (375, 1242, 3)
load 860  /  3424
size:  (375, 1242, 3)
load 861  /  3424
size:  (375, 1242, 3)
load 862  /  3424
size:  (375, 1242, 3)
load 863  /  3424
size:  (376, 1241, 3)
load 864  /  3424
size:  (375, 1242, 3)
load 865  /  3424
size:  (375, 1242, 3)
load 866  /  3424
size:  (376, 1241, 3)
load 867  /  3424
size:  (375, 1242, 3)
load 868  /  3424
size:  (374, 1238, 3)
load 869  /  3424
size:  (375, 1242, 3)
load 870  /  3424
size:  (375, 1242, 3)
load 871  /  3424
size:  (375, 1242, 3)
load 872  /  3424
size:  (375, 1242, 3)
load 873  /  3424
size:  (376, 1241, 3)
load 874  /  3424
size:  (375, 1242, 3)
load 875  /  3424
size:  (375, 1242, 3)
load 876  /  3424
size:  (376, 1241, 3)
load 877  /  3424
size:  (375, 1242, 3)
load 878  /  3424
size:  (375, 1242, 3)
load 879  /  3424
size:  (375, 1242, 3)
load 880  /  3424
size:  (375, 1242, 3)
load 881  /  3424
size:  (375, 1242, 3)
load 882  /  3424
size:  (375, 1242, 3)
load 883  /  3424
size:  (375, 1242, 3)
load 884  /  3424
size:  (375, 1242, 3)
load 885  /  3424
size:  (375, 1242, 3)
load 886  /  3424
size:  (375, 1242, 3)
load 887  /  3424
size:  (375, 1242, 3)
load 888  /  3424
size:  (375, 1242, 3)
load 889  /  3424
size:  (375, 1242, 3)
load 890  /  3424
size:  (375, 1242, 3)
load 891  /  3424
size:  (375, 1242, 3)
load 892  /  3424
size:  (375, 1242, 3)
load 893  /  3424
size:  (376, 1241, 3)
load 894  /  3424
size:  (375, 1242, 3)
load 895  /  3424
size:  (376, 1241, 3)
load 896  /  3424
size:  (375, 1242, 3)
load 897  /  3424
size:  (375, 1242, 3)
load 898  /  3424
size:  (375, 1242, 3)
load 899  /  3424
size:  (375, 1242, 3)
load 900  /  3424
size:  (370, 1224, 3)
load 901  /  3424
size:  (375, 1242, 3)
load 902  /  3424
size:  (375, 1242, 3)
load 903  /  3424
size:  (375, 1242, 3)
load 904  /  3424
size:  (375, 1242, 3)
load 905  /  3424
size:  (375, 1242, 3)
load 906  /  3424
size:  (375, 1242, 3)
load 907  /  3424
size:  (375, 1242, 3)
load 908  /  3424
size:  (375, 1242, 3)
load 909  /  3424
size:  (370, 1224, 3)
load 910  /  3424
size:  (375, 1242, 3)
load 911  /  3424
size:  (375, 1242, 3)
load 912  /  3424
size:  (375, 1242, 3)
load 913  /  3424
size:  (375, 1242, 3)
load 914  /  3424
size:  (375, 1242, 3)
load 915  /  3424
size:  (375, 1242, 3)
load 916  /  3424
size:  (375, 1242, 3)
load 917  /  3424
size:  (375, 1242, 3)
load 918  /  3424
size:  (375, 1242, 3)
load 919  /  3424
size:  (375, 1242, 3)
load 920  /  3424
size:  (375, 1242, 3)
load 921  /  3424
size:  (375, 1242, 3)
load 922  /  3424
size:  (375, 1242, 3)
load 923  /  3424
size:  (375, 1242, 3)
load 924  /  3424
size:  (376, 1241, 3)
load 925  /  3424
size:  (375, 1242, 3)
load 926  /  3424
size:  (375, 1242, 3)
load 927  /  3424
size:  (375, 1242, 3)
load 928  /  3424
size:  (375, 1242, 3)
load 929  /  3424
size:  (376, 1241, 3)
load 930  /  3424
size:  (375, 1242, 3)
load 931  /  3424
size:  (375, 1242, 3)
load 932  /  3424
size:  (375, 1242, 3)
load 933  /  3424
size:  (375, 1242, 3)
load 934  /  3424
size:  (375, 1242, 3)
load 935  /  3424
size:  (375, 1242, 3)
load 936  /  3424
size:  (370, 1224, 3)
load 937  /  3424
size:  (375, 1242, 3)
load 938  /  3424
size:  (375, 1242, 3)
load 939  /  3424
size:  (375, 1242, 3)
load 940  /  3424
size:  (375, 1242, 3)
load 941  /  3424
size:  (375, 1242, 3)
load 942  /  3424
size:  (375, 1242, 3)
load 943  /  3424
size:  (375, 1242, 3)
load 944  /  3424
size:  (375, 1242, 3)
load 945  /  3424
size:  (374, 1238, 3)
load 946  /  3424
size:  (375, 1242, 3)
load 947  /  3424
size:  (375, 1242, 3)
load 948  /  3424
size:  (375, 1242, 3)
load 949  /  3424
size:  (375, 1242, 3)
load 950  /  3424
size:  (375, 1242, 3)
load 951  /  3424
size:  (375, 1242, 3)
load 952  /  3424
size:  (375, 1242, 3)
load 953  /  3424
size:  (375, 1242, 3)
load 954  /  3424
size:  (375, 1242, 3)
load 955  /  3424
size:  (375, 1242, 3)
load 956  /  3424
size:  (375, 1242, 3)
load 957  /  3424
size:  (375, 1242, 3)
load 958  /  3424
size:  (375, 1242, 3)
load 959  /  3424
size:  (375, 1242, 3)
load 960  /  3424
size:  (376, 1241, 3)
load 961  /  3424
size:  (370, 1224, 3)
load 962  /  3424
size:  (375, 1242, 3)
load 963  /  3424
size:  (375, 1242, 3)
load 964  /  3424
size:  (375, 1242, 3)
load 965  /  3424
size:  (375, 1242, 3)
load 966  /  3424
size:  (375, 1242, 3)
load 967  /  3424
size:  (375, 1242, 3)
load 968  /  3424
size:  (375, 1242, 3)
load 969  /  3424
size:  (375, 1242, 3)
load 970  /  3424
size:  (376, 1241, 3)
load 971  /  3424
size:  (376, 1241, 3)
load 972  /  3424
size:  (376, 1241, 3)
load 973  /  3424
size:  (376, 1241, 3)
load 974  /  3424
size:  (375, 1242, 3)
load 975  /  3424
size:  (375, 1242, 3)
load 976  /  3424
size:  (375, 1242, 3)
load 977  /  3424
size:  (375, 1242, 3)
load 978  /  3424
size:  (375, 1242, 3)
load 979  /  3424
size:  (375, 1242, 3)
load 980  /  3424
size:  (375, 1242, 3)
load 981  /  3424
size:  (375, 1242, 3)
load 982  /  3424
size:  (375, 1242, 3)
load 983  /  3424
size:  (375, 1242, 3)
load 984  /  3424
size:  (376, 1241, 3)
load 985  /  3424
size:  (375, 1242, 3)
load 986  /  3424
size:  (375, 1242, 3)
load 987  /  3424
size:  (376, 1241, 3)
load 988  /  3424
size:  (375, 1242, 3)
load 989  /  3424
size:  (375, 1242, 3)
load 990  /  3424
size:  (375, 1242, 3)
load 991  /  3424
size:  (375, 1242, 3)
load 992  /  3424
size:  (375, 1242, 3)
load 993  /  3424
size:  (375, 1242, 3)
load 994  /  3424
size:  (375, 1242, 3)
load 995  /  3424
size:  (376, 1241, 3)
load 996  /  3424
size:  (375, 1242, 3)
load 997  /  3424
size:  (374, 1238, 3)
load 998  /  3424
size:  (375, 1242, 3)
load 999  /  3424
size:  (375, 1242, 3)
load 1000  /  3424
size:  (375, 1242, 3)
load 1001  /  3424
size:  (375, 1242, 3)
load 1002  /  3424
size:  (375, 1242, 3)
load 1003  /  3424
size:  (375, 1242, 3)
load 1004  /  3424
size:  (375, 1242, 3)
load 1005  /  3424
size:  (375, 1242, 3)
load 1006  /  3424
size:  (375, 1242, 3)
load 1007  /  3424
size:  (375, 1242, 3)
load 1008  /  3424
size:  (375, 1242, 3)
load 1009  /  3424
size:  (375, 1242, 3)
load 1010  /  3424
size:  (375, 1242, 3)
load 1011  /  3424
size:  (375, 1242, 3)
load 1012  /  3424
size:  (375, 1242, 3)
load 1013  /  3424
size:  (374, 1238, 3)
load 1014  /  3424
size:  (370, 1224, 3)
load 1015  /  3424
size:  (375, 1242, 3)
load 1016  /  3424
size:  (375, 1242, 3)
load 1017  /  3424
size:  (375, 1242, 3)
load 1018  /  3424
size:  (375, 1242, 3)
load 1019  /  3424
size:  (375, 1242, 3)
load 1020  /  3424
size:  (375, 1242, 3)
load 1021  /  3424
size:  (375, 1242, 3)
load 1022  /  3424
size:  (375, 1242, 3)
load 1023  /  3424
size:  (376, 1241, 3)
load 1024  /  3424
size:  (376, 1241, 3)
load 1025  /  3424
size:  (375, 1242, 3)
load 1026  /  3424
size:  (375, 1242, 3)
load 1027  /  3424
size:  (375, 1242, 3)
load 1028  /  3424
size:  (375, 1242, 3)
load 1029  /  3424
size:  (375, 1242, 3)
load 1030  /  3424
size:  (375, 1242, 3)
load 1031  /  3424
size:  (375, 1242, 3)
load 1032  /  3424
size:  (375, 1242, 3)
load 1033  /  3424
size:  (376, 1241, 3)
load 1034  /  3424
size:  (376, 1241, 3)
load 1035  /  3424
size:  (375, 1242, 3)
load 1036  /  3424
size:  (376, 1241, 3)
load 1037  /  3424
size:  (375, 1242, 3)
load 1038  /  3424
size:  (376, 1241, 3)
load 1039  /  3424
size:  (375, 1242, 3)
load 1040  /  3424
size:  (375, 1242, 3)
load 1041  /  3424
size:  (375, 1242, 3)
load 1042  /  3424
size:  (375, 1242, 3)
load 1043  /  3424
size:  (375, 1242, 3)
load 1044  /  3424
size:  (375, 1242, 3)
load 1045  /  3424
size:  (375, 1242, 3)
load 1046  /  3424
size:  (376, 1241, 3)
load 1047  /  3424
size:  (374, 1238, 3)
load 1048  /  3424
size:  (375, 1242, 3)
load 1049  /  3424
size:  (375, 1242, 3)
load 1050  /  3424
size:  (375, 1242, 3)
load 1051  /  3424
size:  (370, 1224, 3)
load 1052  /  3424
size:  (375, 1242, 3)
load 1053  /  3424
size:  (375, 1242, 3)
load 1054  /  3424
size:  (375, 1242, 3)
load 1055  /  3424
size:  (375, 1242, 3)
load 1056  /  3424
size:  (375, 1242, 3)
load 1057  /  3424
size:  (375, 1242, 3)
load 1058  /  3424
size:  (375, 1242, 3)
load 1059  /  3424
size:  (376, 1241, 3)
load 1060  /  3424
size:  (375, 1242, 3)
load 1061  /  3424
size:  (375, 1242, 3)
load 1062  /  3424
size:  (375, 1242, 3)
load 1063  /  3424
size:  (376, 1241, 3)
load 1064  /  3424
size:  (374, 1238, 3)
load 1065  /  3424
size:  (375, 1242, 3)
load 1066  /  3424
size:  (375, 1242, 3)
load 1067  /  3424
size:  (375, 1242, 3)
load 1068  /  3424
size:  (375, 1242, 3)
load 1069  /  3424
size:  (374, 1238, 3)
load 1070  /  3424
size:  (375, 1242, 3)
load 1071  /  3424
size:  (375, 1242, 3)
load 1072  /  3424
size:  (375, 1242, 3)
load 1073  /  3424
size:  (375, 1242, 3)
load 1074  /  3424
size:  (375, 1242, 3)
load 1075  /  3424
size:  (375, 1242, 3)
load 1076  /  3424
size:  (375, 1242, 3)
load 1077  /  3424
size:  (375, 1242, 3)
load 1078  /  3424
size:  (375, 1242, 3)
load 1079  /  3424
size:  (375, 1242, 3)
load 1080  /  3424
size:  (375, 1242, 3)
load 1081  /  3424
size:  (375, 1242, 3)
load 1082  /  3424
size:  (376, 1241, 3)
load 1083  /  3424
size:  (375, 1242, 3)
load 1084  /  3424
size:  (375, 1242, 3)
load 1085  /  3424
size:  (376, 1241, 3)
load 1086  /  3424
size:  (375, 1242, 3)
load 1087  /  3424
size:  (375, 1242, 3)
load 1088  /  3424
size:  (375, 1242, 3)
load 1089  /  3424
size:  (375, 1242, 3)
load 1090  /  3424
size:  (375, 1242, 3)
load 1091  /  3424
size:  (375, 1242, 3)
load 1092  /  3424
size:  (375, 1242, 3)
load 1093  /  3424
size:  (375, 1242, 3)
load 1094  /  3424
size:  (375, 1242, 3)
load 1095  /  3424
size:  (375, 1242, 3)
load 1096  /  3424
size:  (375, 1242, 3)
load 1097  /  3424
size:  (375, 1242, 3)
load 1098  /  3424
size:  (375, 1242, 3)
load 1099  /  3424
size:  (375, 1242, 3)
load 1100  /  3424
size:  (375, 1242, 3)
load 1101  /  3424
size:  (375, 1242, 3)
load 1102  /  3424
size:  (375, 1242, 3)
load 1103  /  3424
size:  (375, 1242, 3)
load 1104  /  3424
size:  (375, 1242, 3)
load 1105  /  3424
size:  (375, 1242, 3)
load 1106  /  3424
size:  (375, 1242, 3)
load 1107  /  3424
size:  (375, 1242, 3)
load 1108  /  3424
size:  (375, 1242, 3)
load 1109  /  3424
size:  (375, 1242, 3)
load 1110  /  3424
size:  (375, 1242, 3)
load 1111  /  3424
size:  (375, 1242, 3)
load 1112  /  3424
size:  (376, 1241, 3)
load 1113  /  3424
size:  (375, 1242, 3)
load 1114  /  3424
size:  (375, 1242, 3)
load 1115  /  3424
size:  (375, 1242, 3)
load 1116  /  3424
size:  (375, 1242, 3)
load 1117  /  3424
size:  (375, 1242, 3)
load 1118  /  3424
size:  (374, 1238, 3)
load 1119  /  3424
size:  (375, 1242, 3)
load 1120  /  3424
size:  (375, 1242, 3)
load 1121  /  3424
size:  (376, 1241, 3)
load 1122  /  3424
size:  (375, 1242, 3)
load 1123  /  3424
size:  (375, 1242, 3)
load 1124  /  3424
size:  (376, 1241, 3)
load 1125  /  3424
size:  (375, 1242, 3)
load 1126  /  3424
size:  (375, 1242, 3)
load 1127  /  3424
size:  (375, 1242, 3)
load 1128  /  3424
size:  (375, 1242, 3)
load 1129  /  3424
size:  (374, 1238, 3)
load 1130  /  3424
size:  (375, 1242, 3)
load 1131  /  3424
size:  (375, 1242, 3)
load 1132  /  3424
size:  (375, 1242, 3)
load 1133  /  3424
size:  (375, 1242, 3)
load 1134  /  3424
size:  (375, 1242, 3)
load 1135  /  3424
size:  (375, 1242, 3)
load 1136  /  3424
size:  (375, 1242, 3)
load 1137  /  3424
size:  (376, 1241, 3)
load 1138  /  3424
size:  (376, 1241, 3)
load 1139  /  3424
size:  (375, 1242, 3)
load 1140  /  3424
size:  (375, 1242, 3)
load 1141  /  3424
size:  (375, 1242, 3)
load 1142  /  3424
size:  (375, 1242, 3)
load 1143  /  3424
size:  (370, 1224, 3)
load 1144  /  3424
size:  (375, 1242, 3)
load 1145  /  3424
size:  (375, 1242, 3)
load 1146  /  3424
size:  (375, 1242, 3)
load 1147  /  3424
size:  (375, 1242, 3)
load 1148  /  3424
size:  (376, 1241, 3)
load 1149  /  3424
size:  (375, 1242, 3)
load 1150  /  3424
size:  (375, 1242, 3)
load 1151  /  3424
size:  (375, 1242, 3)
load 1152  /  3424
size:  (376, 1241, 3)
load 1153  /  3424
size:  (375, 1242, 3)
load 1154  /  3424
size:  (375, 1242, 3)
load 1155  /  3424
size:  (375, 1242, 3)
load 1156  /  3424
size:  (375, 1242, 3)
load 1157  /  3424
size:  (375, 1242, 3)
load 1158  /  3424
size:  (370, 1224, 3)
load 1159  /  3424
size:  (375, 1242, 3)
load 1160  /  3424
size:  (375, 1242, 3)
load 1161  /  3424
size:  (375, 1242, 3)
load 1162  /  3424
size:  (376, 1241, 3)
load 1163  /  3424
size:  (370, 1224, 3)
load 1164  /  3424
size:  (375, 1242, 3)
load 1165  /  3424
size:  (375, 1242, 3)
load 1166  /  3424
size:  (375, 1242, 3)
load 1167  /  3424
size:  (376, 1241, 3)
load 1168  /  3424
size:  (374, 1238, 3)
load 1169  /  3424
size:  (376, 1241, 3)
load 1170  /  3424
size:  (375, 1242, 3)
load 1171  /  3424
size:  (375, 1242, 3)
load 1172  /  3424
size:  (375, 1242, 3)
load 1173  /  3424
size:  (375, 1242, 3)
load 1174  /  3424
size:  (375, 1242, 3)
load 1175  /  3424
size:  (376, 1241, 3)
load 1176  /  3424
size:  (376, 1241, 3)
load 1177  /  3424
size:  (375, 1242, 3)
load 1178  /  3424
size:  (375, 1242, 3)
load 1179  /  3424
size:  (375, 1242, 3)
load 1180  /  3424
size:  (376, 1241, 3)
load 1181  /  3424
size:  (375, 1242, 3)
load 1182  /  3424
size:  (375, 1242, 3)
load 1183  /  3424
size:  (375, 1242, 3)
load 1184  /  3424
size:  (375, 1242, 3)
load 1185  /  3424
size:  (375, 1242, 3)
load 1186  /  3424
size:  (375, 1242, 3)
load 1187  /  3424
size:  (370, 1224, 3)
load 1188  /  3424
size:  (375, 1242, 3)
load 1189  /  3424
size:  (375, 1242, 3)
load 1190  /  3424
size:  (375, 1242, 3)
load 1191  /  3424
size:  (374, 1238, 3)
load 1192  /  3424
size:  (375, 1242, 3)
load 1193  /  3424
size:  (375, 1242, 3)
load 1194  /  3424
size:  (375, 1242, 3)
load 1195  /  3424
size:  (374, 1238, 3)
load 1196  /  3424
size:  (375, 1242, 3)
load 1197  /  3424
size:  (376, 1241, 3)
load 1198  /  3424
size:  (375, 1242, 3)
load 1199  /  3424
size:  (375, 1242, 3)
load 1200  /  3424
size:  (375, 1242, 3)
load 1201  /  3424
size:  (375, 1242, 3)
load 1202  /  3424
size:  (375, 1242, 3)
load 1203  /  3424
size:  (375, 1242, 3)
load 1204  /  3424
size:  (375, 1242, 3)
load 1205  /  3424
size:  (375, 1242, 3)
load 1206  /  3424
size:  (375, 1242, 3)
load 1207  /  3424
size:  (375, 1242, 3)
load 1208  /  3424
size:  (375, 1242, 3)
load 1209  /  3424
size:  (375, 1242, 3)
load 1210  /  3424
size:  (375, 1242, 3)
load 1211  /  3424
size:  (375, 1242, 3)
load 1212  /  3424
size:  (375, 1242, 3)
load 1213  /  3424
size:  (375, 1242, 3)
load 1214  /  3424
size:  (375, 1242, 3)
load 1215  /  3424
size:  (375, 1242, 3)
load 1216  /  3424
size:  (375, 1242, 3)
load 1217  /  3424
size:  (374, 1238, 3)
load 1218  /  3424
size:  (375, 1242, 3)
load 1219  /  3424
size:  (376, 1241, 3)
load 1220  /  3424
size:  (374, 1238, 3)
load 1221  /  3424
size:  (375, 1242, 3)
load 1222  /  3424
size:  (376, 1241, 3)
load 1223  /  3424
size:  (375, 1242, 3)
load 1224  /  3424
size:  (375, 1242, 3)
load 1225  /  3424
size:  (375, 1242, 3)
load 1226  /  3424
size:  (375, 1242, 3)
load 1227  /  3424
size:  (375, 1242, 3)
load 1228  /  3424
size:  (375, 1242, 3)
load 1229  /  3424
size:  (375, 1242, 3)
load 1230  /  3424
size:  (375, 1242, 3)
load 1231  /  3424
size:  (374, 1238, 3)
load 1232  /  3424
size:  (375, 1242, 3)
load 1233  /  3424
size:  (375, 1242, 3)
load 1234  /  3424
size:  (375, 1242, 3)
load 1235  /  3424
size:  (375, 1242, 3)
load 1236  /  3424
size:  (375, 1242, 3)
load 1237  /  3424
size:  (375, 1242, 3)
load 1238  /  3424
size:  (375, 1242, 3)
load 1239  /  3424
size:  (375, 1242, 3)
load 1240  /  3424
size:  (375, 1242, 3)
load 1241  /  3424
size:  (375, 1242, 3)
load 1242  /  3424
size:  (375, 1242, 3)
load 1243  /  3424
size:  (375, 1242, 3)
load 1244  /  3424
size:  (375, 1242, 3)
load 1245  /  3424
size:  (376, 1241, 3)
load 1246  /  3424
size:  (375, 1242, 3)
load 1247  /  3424
size:  (375, 1242, 3)
load 1248  /  3424
size:  (375, 1242, 3)
load 1249  /  3424
size:  (375, 1242, 3)
load 1250  /  3424
size:  (375, 1242, 3)
load 1251  /  3424
size:  (375, 1242, 3)
load 1252  /  3424
size:  (375, 1242, 3)
load 1253  /  3424
size:  (375, 1242, 3)
load 1254  /  3424
size:  (375, 1242, 3)
load 1255  /  3424
size:  (375, 1242, 3)
load 1256  /  3424
size:  (374, 1238, 3)
load 1257  /  3424
size:  (375, 1242, 3)
load 1258  /  3424
size:  (375, 1242, 3)
load 1259  /  3424
size:  (375, 1242, 3)
load 1260  /  3424
size:  (375, 1242, 3)
load 1261  /  3424
size:  (375, 1242, 3)
load 1262  /  3424
size:  (376, 1241, 3)
load 1263  /  3424
size:  (376, 1241, 3)
load 1264  /  3424
size:  (375, 1242, 3)
load 1265  /  3424
size:  (374, 1238, 3)
load 1266  /  3424
size:  (375, 1242, 3)
load 1267  /  3424
size:  (375, 1242, 3)
load 1268  /  3424
size:  (375, 1242, 3)
load 1269  /  3424
size:  (374, 1238, 3)
load 1270  /  3424
size:  (375, 1242, 3)
load 1271  /  3424
size:  (375, 1242, 3)
load 1272  /  3424
size:  (375, 1242, 3)
load 1273  /  3424
size:  (375, 1242, 3)
load 1274  /  3424
size:  (375, 1242, 3)
load 1275  /  3424
size:  (375, 1242, 3)
load 1276  /  3424
size:  (375, 1242, 3)
load 1277  /  3424
size:  (375, 1242, 3)
load 1278  /  3424
size:  (375, 1242, 3)
load 1279  /  3424
size:  (375, 1242, 3)
load 1280  /  3424
size:  (375, 1242, 3)
load 1281  /  3424
size:  (375, 1242, 3)
load 1282  /  3424
size:  (375, 1242, 3)
load 1283  /  3424
size:  (375, 1242, 3)
load 1284  /  3424
size:  (375, 1242, 3)
load 1285  /  3424
size:  (375, 1242, 3)
load 1286  /  3424
size:  (375, 1242, 3)
load 1287  /  3424
size:  (375, 1242, 3)
load 1288  /  3424
size:  (375, 1242, 3)
load 1289  /  3424
size:  (375, 1242, 3)
load 1290  /  3424
size:  (376, 1241, 3)
load 1291  /  3424
size:  (375, 1242, 3)
load 1292  /  3424
size:  (375, 1242, 3)
load 1293  /  3424
size:  (375, 1242, 3)
load 1294  /  3424
size:  (375, 1242, 3)
load 1295  /  3424
size:  (375, 1242, 3)
load 1296  /  3424
size:  (375, 1242, 3)
load 1297  /  3424
size:  (375, 1242, 3)
load 1298  /  3424
size:  (375, 1242, 3)
load 1299  /  3424
size:  (375, 1242, 3)
load 1300  /  3424
size:  (375, 1242, 3)
load 1301  /  3424
size:  (375, 1242, 3)
load 1302  /  3424
size:  (375, 1242, 3)
load 1303  /  3424
size:  (375, 1242, 3)
load 1304  /  3424
size:  (375, 1242, 3)
load 1305  /  3424
size:  (375, 1242, 3)
load 1306  /  3424
size:  (374, 1238, 3)
load 1307  /  3424
size:  (375, 1242, 3)
load 1308  /  3424
size:  (376, 1241, 3)
load 1309  /  3424
size:  (375, 1242, 3)
load 1310  /  3424
size:  (375, 1242, 3)
load 1311  /  3424
size:  (375, 1242, 3)
load 1312  /  3424
size:  (375, 1242, 3)
load 1313  /  3424
size:  (375, 1242, 3)
load 1314  /  3424
size:  (375, 1242, 3)
load 1315  /  3424
size:  (375, 1242, 3)
load 1316  /  3424
size:  (375, 1242, 3)
load 1317  /  3424
size:  (375, 1242, 3)
load 1318  /  3424
size:  (375, 1242, 3)
load 1319  /  3424
size:  (375, 1242, 3)
load 1320  /  3424
size:  (375, 1242, 3)
load 1321  /  3424
size:  (375, 1242, 3)
load 1322  /  3424
size:  (375, 1242, 3)
load 1323  /  3424
size:  (376, 1241, 3)
load 1324  /  3424
size:  (375, 1242, 3)
load 1325  /  3424
size:  (375, 1242, 3)
load 1326  /  3424
size:  (375, 1242, 3)
load 1327  /  3424
size:  (375, 1242, 3)
load 1328  /  3424
size:  (374, 1238, 3)
load 1329  /  3424
size:  (375, 1242, 3)
load 1330  /  3424
size:  (376, 1241, 3)
load 1331  /  3424
size:  (375, 1242, 3)
load 1332  /  3424
size:  (375, 1242, 3)
load 1333  /  3424
size:  (375, 1242, 3)
load 1334  /  3424
size:  (375, 1242, 3)
load 1335  /  3424
size:  (375, 1242, 3)
load 1336  /  3424
size:  (375, 1242, 3)
load 1337  /  3424
size:  (375, 1242, 3)
load 1338  /  3424
size:  (376, 1241, 3)
load 1339  /  3424
size:  (375, 1242, 3)
load 1340  /  3424
size:  (375, 1242, 3)
load 1341  /  3424
size:  (376, 1241, 3)
load 1342  /  3424
size:  (375, 1242, 3)
load 1343  /  3424
size:  (374, 1238, 3)
load 1344  /  3424
size:  (375, 1242, 3)
load 1345  /  3424
size:  (375, 1242, 3)
load 1346  /  3424
size:  (375, 1242, 3)
load 1347  /  3424
size:  (375, 1242, 3)
load 1348  /  3424
size:  (375, 1242, 3)
load 1349  /  3424
size:  (375, 1242, 3)
load 1350  /  3424
size:  (375, 1242, 3)
load 1351  /  3424
size:  (375, 1242, 3)
load 1352  /  3424
size:  (375, 1242, 3)
load 1353  /  3424
size:  (375, 1242, 3)
load 1354  /  3424
size:  (375, 1242, 3)
load 1355  /  3424
size:  (375, 1242, 3)
load 1356  /  3424
size:  (375, 1242, 3)
load 1357  /  3424
size:  (370, 1224, 3)
load 1358  /  3424
size:  (375, 1242, 3)
load 1359  /  3424
size:  (375, 1242, 3)
load 1360  /  3424
size:  (375, 1242, 3)
load 1361  /  3424
size:  (375, 1242, 3)
load 1362  /  3424
size:  (375, 1242, 3)
load 1363  /  3424
size:  (375, 1242, 3)
load 1364  /  3424
size:  (375, 1242, 3)
load 1365  /  3424
size:  (375, 1242, 3)
load 1366  /  3424
size:  (375, 1242, 3)
load 1367  /  3424
size:  (375, 1242, 3)
load 1368  /  3424
size:  (375, 1242, 3)
load 1369  /  3424
size:  (375, 1242, 3)
load 1370  /  3424
size:  (375, 1242, 3)
load 1371  /  3424
size:  (375, 1242, 3)
load 1372  /  3424
size:  (375, 1242, 3)
load 1373  /  3424
size:  (375, 1242, 3)
load 1374  /  3424
size:  (375, 1242, 3)
load 1375  /  3424
size:  (375, 1242, 3)
load 1376  /  3424
size:  (375, 1242, 3)
load 1377  /  3424
size:  (376, 1241, 3)
load 1378  /  3424
size:  (375, 1242, 3)
load 1379  /  3424
size:  (375, 1242, 3)
load 1380  /  3424
size:  (375, 1242, 3)
load 1381  /  3424
size:  (375, 1242, 3)
load 1382  /  3424
size:  (374, 1238, 3)
load 1383  /  3424
size:  (376, 1241, 3)
load 1384  /  3424
size:  (370, 1224, 3)
load 1385  /  3424
size:  (374, 1238, 3)
load 1386  /  3424
size:  (375, 1242, 3)
load 1387  /  3424
size:  (376, 1241, 3)
load 1388  /  3424
size:  (375, 1242, 3)
load 1389  /  3424
size:  (375, 1242, 3)
load 1390  /  3424
size:  (375, 1242, 3)
load 1391  /  3424
size:  (375, 1242, 3)
load 1392  /  3424
size:  (370, 1224, 3)
load 1393  /  3424
size:  (375, 1242, 3)
load 1394  /  3424
size:  (375, 1242, 3)
load 1395  /  3424
size:  (370, 1224, 3)
load 1396  /  3424
size:  (375, 1242, 3)
load 1397  /  3424
size:  (374, 1238, 3)
load 1398  /  3424
size:  (375, 1242, 3)
load 1399  /  3424
size:  (374, 1238, 3)
load 1400  /  3424
size:  (375, 1242, 3)
load 1401  /  3424
size:  (375, 1242, 3)
load 1402  /  3424
size:  (375, 1242, 3)
load 1403  /  3424
size:  (375, 1242, 3)
load 1404  /  3424
size:  (375, 1242, 3)
load 1405  /  3424
size:  (375, 1242, 3)
load 1406  /  3424
size:  (375, 1242, 3)
load 1407  /  3424
size:  (375, 1242, 3)
load 1408  /  3424
size:  (375, 1242, 3)
load 1409  /  3424
size:  (375, 1242, 3)
load 1410  /  3424
size:  (375, 1242, 3)
load 1411  /  3424
size:  (375, 1242, 3)
load 1412  /  3424
size:  (375, 1242, 3)
load 1413  /  3424
size:  (370, 1224, 3)
load 1414  /  3424
size:  (376, 1241, 3)
load 1415  /  3424
size:  (375, 1242, 3)
load 1416  /  3424
size:  (375, 1242, 3)
load 1417  /  3424
size:  (375, 1242, 3)
load 1418  /  3424
size:  (374, 1238, 3)
load 1419  /  3424
size:  (375, 1242, 3)
load 1420  /  3424
size:  (375, 1242, 3)
load 1421  /  3424
size:  (374, 1238, 3)
load 1422  /  3424
size:  (375, 1242, 3)
load 1423  /  3424
size:  (375, 1242, 3)
load 1424  /  3424
size:  (376, 1241, 3)
load 1425  /  3424
size:  (375, 1242, 3)
load 1426  /  3424
size:  (375, 1242, 3)
load 1427  /  3424
size:  (375, 1242, 3)
load 1428  /  3424
size:  (375, 1242, 3)
load 1429  /  3424
size:  (375, 1242, 3)
load 1430  /  3424
size:  (370, 1224, 3)
load 1431  /  3424
size:  (375, 1242, 3)
load 1432  /  3424
size:  (375, 1242, 3)
load 1433  /  3424
size:  (370, 1224, 3)
load 1434  /  3424
size:  (375, 1242, 3)
load 1435  /  3424
size:  (375, 1242, 3)
load 1436  /  3424
size:  (375, 1242, 3)
load 1437  /  3424
size:  (375, 1242, 3)
load 1438  /  3424
size:  (375, 1242, 3)
load 1439  /  3424
size:  (375, 1242, 3)
load 1440  /  3424
size:  (375, 1242, 3)
load 1441  /  3424
size:  (375, 1242, 3)
load 1442  /  3424
size:  (375, 1242, 3)
load 1443  /  3424
size:  (375, 1242, 3)
load 1444  /  3424
size:  (375, 1242, 3)
load 1445  /  3424
size:  (375, 1242, 3)
load 1446  /  3424
size:  (370, 1224, 3)
load 1447  /  3424
size:  (376, 1241, 3)
load 1448  /  3424
size:  (375, 1242, 3)
load 1449  /  3424
size:  (375, 1242, 3)
load 1450  /  3424
size:  (375, 1242, 3)
load 1451  /  3424
size:  (375, 1242, 3)
load 1452  /  3424
size:  (375, 1242, 3)
load 1453  /  3424
size:  (375, 1242, 3)
load 1454  /  3424
size:  (375, 1242, 3)
load 1455  /  3424
size:  (375, 1242, 3)
load 1456  /  3424
size:  (376, 1241, 3)
load 1457  /  3424
size:  (376, 1241, 3)
load 1458  /  3424
size:  (375, 1242, 3)
load 1459  /  3424
size:  (375, 1242, 3)
load 1460  /  3424
size:  (375, 1242, 3)
load 1461  /  3424
size:  (375, 1242, 3)
load 1462  /  3424
size:  (375, 1242, 3)
load 1463  /  3424
size:  (375, 1242, 3)
load 1464  /  3424
size:  (375, 1242, 3)
load 1465  /  3424
size:  (374, 1238, 3)
load 1466  /  3424
size:  (375, 1242, 3)
load 1467  /  3424
size:  (375, 1242, 3)
load 1468  /  3424
size:  (376, 1241, 3)
load 1469  /  3424
size:  (375, 1242, 3)
load 1470  /  3424
size:  (375, 1242, 3)
load 1471  /  3424
size:  (375, 1242, 3)
load 1472  /  3424
size:  (375, 1242, 3)
load 1473  /  3424
size:  (375, 1242, 3)
load 1474  /  3424
size:  (375, 1242, 3)
load 1475  /  3424
size:  (375, 1242, 3)
load 1476  /  3424
size:  (375, 1242, 3)
load 1477  /  3424
size:  (375, 1242, 3)
load 1478  /  3424
size:  (375, 1242, 3)
load 1479  /  3424
size:  (375, 1242, 3)
load 1480  /  3424
size:  (375, 1242, 3)
load 1481  /  3424
size:  (375, 1242, 3)
load 1482  /  3424
size:  (375, 1242, 3)
load 1483  /  3424
size:  (375, 1242, 3)
load 1484  /  3424
size:  (375, 1242, 3)
load 1485  /  3424
size:  (375, 1242, 3)
load 1486  /  3424
size:  (375, 1242, 3)
load 1487  /  3424
size:  (375, 1242, 3)
load 1488  /  3424
size:  (370, 1224, 3)
load 1489  /  3424
size:  (375, 1242, 3)
load 1490  /  3424
size:  (375, 1242, 3)
load 1491  /  3424
size:  (375, 1242, 3)
load 1492  /  3424
size:  (375, 1242, 3)
load 1493  /  3424
size:  (375, 1242, 3)
load 1494  /  3424
size:  (375, 1242, 3)
load 1495  /  3424
size:  (375, 1242, 3)
load 1496  /  3424
size:  (375, 1242, 3)
load 1497  /  3424
size:  (375, 1242, 3)
load 1498  /  3424
size:  (375, 1242, 3)
load 1499  /  3424
size:  (375, 1242, 3)
load 1500  /  3424
size:  (375, 1242, 3)
load 1501  /  3424
size:  (375, 1242, 3)
load 1502  /  3424
size:  (375, 1242, 3)
load 1503  /  3424
size:  (375, 1242, 3)
load 1504  /  3424
size:  (370, 1224, 3)
load 1505  /  3424
size:  (375, 1242, 3)
load 1506  /  3424
size:  (375, 1242, 3)
load 1507  /  3424
size:  (375, 1242, 3)
load 1508  /  3424
size:  (376, 1241, 3)
load 1509  /  3424
size:  (375, 1242, 3)
load 1510  /  3424
size:  (375, 1242, 3)
load 1511  /  3424
size:  (375, 1242, 3)
load 1512  /  3424
size:  (375, 1242, 3)
load 1513  /  3424
size:  (375, 1242, 3)
load 1514  /  3424
size:  (375, 1242, 3)
load 1515  /  3424
size:  (375, 1242, 3)
load 1516  /  3424
size:  (375, 1242, 3)
load 1517  /  3424
size:  (375, 1242, 3)
load 1518  /  3424
size:  (375, 1242, 3)
load 1519  /  3424
size:  (375, 1242, 3)
load 1520  /  3424
size:  (375, 1242, 3)
load 1521  /  3424
size:  (375, 1242, 3)
load 1522  /  3424
size:  (375, 1242, 3)
load 1523  /  3424
size:  (370, 1224, 3)
load 1524  /  3424
size:  (375, 1242, 3)
load 1525  /  3424
size:  (375, 1242, 3)
load 1526  /  3424
size:  (375, 1242, 3)
load 1527  /  3424
size:  (375, 1242, 3)
load 1528  /  3424
size:  (375, 1242, 3)
load 1529  /  3424
size:  (375, 1242, 3)
load 1530  /  3424
size:  (375, 1242, 3)
load 1531  /  3424
size:  (376, 1241, 3)
load 1532  /  3424
size:  (375, 1242, 3)
load 1533  /  3424
size:  (375, 1242, 3)
load 1534  /  3424
size:  (375, 1242, 3)
load 1535  /  3424
size:  (375, 1242, 3)
load 1536  /  3424
size:  (375, 1242, 3)
load 1537  /  3424
size:  (370, 1224, 3)
load 1538  /  3424
size:  (375, 1242, 3)
load 1539  /  3424
size:  (375, 1242, 3)
load 1540  /  3424
size:  (375, 1242, 3)
load 1541  /  3424
size:  (375, 1242, 3)
load 1542  /  3424
size:  (375, 1242, 3)
load 1543  /  3424
size:  (375, 1242, 3)
load 1544  /  3424
size:  (375, 1242, 3)
load 1545  /  3424
size:  (375, 1242, 3)
load 1546  /  3424
size:  (375, 1242, 3)
load 1547  /  3424
size:  (375, 1242, 3)
load 1548  /  3424
size:  (375, 1242, 3)
load 1549  /  3424
size:  (375, 1242, 3)
load 1550  /  3424
size:  (370, 1224, 3)
load 1551  /  3424
size:  (375, 1242, 3)
load 1552  /  3424
size:  (375, 1242, 3)
load 1553  /  3424
size:  (375, 1242, 3)
load 1554  /  3424
size:  (375, 1242, 3)
load 1555  /  3424
size:  (375, 1242, 3)
load 1556  /  3424
size:  (375, 1242, 3)
load 1557  /  3424
size:  (375, 1242, 3)
load 1558  /  3424
size:  (375, 1242, 3)
load 1559  /  3424
size:  (375, 1242, 3)
load 1560  /  3424
size:  (375, 1242, 3)
load 1561  /  3424
size:  (375, 1242, 3)
load 1562  /  3424
size:  (375, 1242, 3)
load 1563  /  3424
size:  (374, 1238, 3)
load 1564  /  3424
size:  (375, 1242, 3)
load 1565  /  3424
size:  (374, 1238, 3)
load 1566  /  3424
size:  (375, 1242, 3)
load 1567  /  3424
size:  (375, 1242, 3)
load 1568  /  3424
size:  (375, 1242, 3)
load 1569  /  3424
size:  (376, 1241, 3)
load 1570  /  3424
size:  (375, 1242, 3)
load 1571  /  3424
size:  (375, 1242, 3)
load 1572  /  3424
size:  (375, 1242, 3)
load 1573  /  3424
size:  (375, 1242, 3)
load 1574  /  3424
size:  (375, 1242, 3)
load 1575  /  3424
size:  (374, 1238, 3)
load 1576  /  3424
size:  (376, 1241, 3)
load 1577  /  3424
size:  (370, 1224, 3)
load 1578  /  3424
size:  (375, 1242, 3)
load 1579  /  3424
size:  (375, 1242, 3)
load 1580  /  3424
size:  (375, 1242, 3)
load 1581  /  3424
size:  (375, 1242, 3)
load 1582  /  3424
size:  (375, 1242, 3)
load 1583  /  3424
size:  (375, 1242, 3)
load 1584  /  3424
size:  (375, 1242, 3)
load 1585  /  3424
size:  (374, 1238, 3)
load 1586  /  3424
size:  (375, 1242, 3)
load 1587  /  3424
size:  (375, 1242, 3)
load 1588  /  3424
size:  (375, 1242, 3)
load 1589  /  3424
size:  (375, 1242, 3)
load 1590  /  3424
size:  (375, 1242, 3)
load 1591  /  3424
size:  (375, 1242, 3)
load 1592  /  3424
size:  (370, 1224, 3)
load 1593  /  3424
size:  (376, 1241, 3)
load 1594  /  3424
size:  (375, 1242, 3)
load 1595  /  3424
size:  (375, 1242, 3)
load 1596  /  3424
size:  (375, 1242, 3)
load 1597  /  3424
size:  (375, 1242, 3)
load 1598  /  3424
size:  (375, 1242, 3)
load 1599  /  3424
size:  (374, 1238, 3)
load 1600  /  3424
size:  (375, 1242, 3)
load 1601  /  3424
size:  (375, 1242, 3)
load 1602  /  3424
size:  (374, 1238, 3)
load 1603  /  3424
size:  (374, 1238, 3)
load 1604  /  3424
size:  (375, 1242, 3)
load 1605  /  3424
size:  (375, 1242, 3)
load 1606  /  3424
size:  (375, 1242, 3)
load 1607  /  3424
size:  (375, 1242, 3)
load 1608  /  3424
size:  (375, 1242, 3)
load 1609  /  3424
size:  (375, 1242, 3)
load 1610  /  3424
size:  (376, 1241, 3)
load 1611  /  3424
size:  (376, 1241, 3)
load 1612  /  3424
size:  (375, 1242, 3)
load 1613  /  3424
size:  (375, 1242, 3)
load 1614  /  3424
size:  (375, 1242, 3)
load 1615  /  3424
size:  (375, 1242, 3)
load 1616  /  3424
size:  (375, 1242, 3)
load 1617  /  3424
size:  (375, 1242, 3)
load 1618  /  3424
size:  (375, 1242, 3)
load 1619  /  3424
size:  (375, 1242, 3)
load 1620  /  3424
size:  (375, 1242, 3)
load 1621  /  3424
size:  (375, 1242, 3)
load 1622  /  3424
size:  (375, 1242, 3)
load 1623  /  3424
size:  (375, 1242, 3)
load 1624  /  3424
size:  (375, 1242, 3)
load 1625  /  3424
size:  (375, 1242, 3)
load 1626  /  3424
size:  (376, 1241, 3)
load 1627  /  3424
size:  (375, 1242, 3)
load 1628  /  3424
size:  (375, 1242, 3)
load 1629  /  3424
size:  (375, 1242, 3)
load 1630  /  3424
size:  (375, 1242, 3)
load 1631  /  3424
size:  (376, 1241, 3)
load 1632  /  3424
size:  (375, 1242, 3)
load 1633  /  3424
size:  (375, 1242, 3)
load 1634  /  3424
size:  (375, 1242, 3)
load 1635  /  3424
size:  (375, 1242, 3)
load 1636  /  3424
size:  (375, 1242, 3)
load 1637  /  3424
size:  (375, 1242, 3)
load 1638  /  3424
size:  (375, 1242, 3)
load 1639  /  3424
size:  (375, 1242, 3)
load 1640  /  3424
size:  (375, 1242, 3)
load 1641  /  3424
size:  (375, 1242, 3)
load 1642  /  3424
size:  (375, 1242, 3)
load 1643  /  3424
size:  (375, 1242, 3)
load 1644  /  3424
size:  (375, 1242, 3)
load 1645  /  3424
size:  (375, 1242, 3)
load 1646  /  3424
size:  (375, 1242, 3)
load 1647  /  3424
size:  (376, 1241, 3)
load 1648  /  3424
size:  (375, 1242, 3)
load 1649  /  3424
size:  (375, 1242, 3)
load 1650  /  3424
size:  (370, 1224, 3)
load 1651  /  3424
size:  (370, 1224, 3)
load 1652  /  3424
size:  (374, 1238, 3)
load 1653  /  3424
size:  (375, 1242, 3)
load 1654  /  3424
size:  (375, 1242, 3)
load 1655  /  3424
size:  (375, 1242, 3)
load 1656  /  3424
size:  (375, 1242, 3)
load 1657  /  3424
size:  (375, 1242, 3)
load 1658  /  3424
size:  (375, 1242, 3)
load 1659  /  3424
size:  (374, 1238, 3)
load 1660  /  3424
size:  (375, 1242, 3)
load 1661  /  3424
size:  (375, 1242, 3)
load 1662  /  3424
size:  (375, 1242, 3)
load 1663  /  3424
size:  (375, 1242, 3)
load 1664  /  3424
size:  (375, 1242, 3)
load 1665  /  3424
size:  (375, 1242, 3)
load 1666  /  3424
size:  (375, 1242, 3)
load 1667  /  3424
size:  (375, 1242, 3)
load 1668  /  3424
size:  (375, 1242, 3)
load 1669  /  3424
size:  (375, 1242, 3)
load 1670  /  3424
size:  (375, 1242, 3)
load 1671  /  3424
size:  (375, 1242, 3)
load 1672  /  3424
size:  (375, 1242, 3)
load 1673  /  3424
size:  (374, 1238, 3)
load 1674  /  3424
size:  (375, 1242, 3)
load 1675  /  3424
size:  (375, 1242, 3)
load 1676  /  3424
size:  (374, 1238, 3)
load 1677  /  3424
size:  (376, 1241, 3)
load 1678  /  3424
size:  (375, 1242, 3)
load 1679  /  3424
size:  (375, 1242, 3)
load 1680  /  3424
size:  (374, 1238, 3)
load 1681  /  3424
size:  (375, 1242, 3)
load 1682  /  3424
size:  (375, 1242, 3)
load 1683  /  3424
size:  (375, 1242, 3)
load 1684  /  3424
size:  (375, 1242, 3)
load 1685  /  3424
size:  (375, 1242, 3)
load 1686  /  3424
size:  (374, 1238, 3)
load 1687  /  3424
size:  (375, 1242, 3)
load 1688  /  3424
size:  (375, 1242, 3)
load 1689  /  3424
size:  (374, 1238, 3)
load 1690  /  3424
size:  (375, 1242, 3)
load 1691  /  3424
size:  (375, 1242, 3)
load 1692  /  3424
size:  (375, 1242, 3)
load 1693  /  3424
size:  (375, 1242, 3)
load 1694  /  3424
size:  (375, 1242, 3)
load 1695  /  3424
size:  (375, 1242, 3)
load 1696  /  3424
size:  (376, 1241, 3)
load 1697  /  3424
size:  (375, 1242, 3)
load 1698  /  3424
size:  (375, 1242, 3)
load 1699  /  3424
size:  (370, 1224, 3)
load 1700  /  3424
size:  (375, 1242, 3)
load 1701  /  3424
size:  (375, 1242, 3)
load 1702  /  3424
size:  (375, 1242, 3)
load 1703  /  3424
size:  (375, 1242, 3)
load 1704  /  3424
size:  (376, 1241, 3)
load 1705  /  3424
size:  (374, 1238, 3)
load 1706  /  3424
size:  (376, 1241, 3)
load 1707  /  3424
size:  (375, 1242, 3)
load 1708  /  3424
size:  (375, 1242, 3)
load 1709  /  3424
size:  (375, 1242, 3)
load 1710  /  3424
size:  (376, 1241, 3)
load 1711  /  3424
size:  (375, 1242, 3)
load 1712  /  3424
size:  (375, 1242, 3)
load 1713  /  3424
size:  (375, 1242, 3)
load 1714  /  3424
size:  (374, 1238, 3)
load 1715  /  3424
size:  (375, 1242, 3)
load 1716  /  3424
size:  (375, 1242, 3)
load 1717  /  3424
size:  (375, 1242, 3)
load 1718  /  3424
size:  (375, 1242, 3)
load 1719  /  3424
size:  (375, 1242, 3)
load 1720  /  3424
size:  (375, 1242, 3)
load 1721  /  3424
size:  (375, 1242, 3)
load 1722  /  3424
size:  (375, 1242, 3)
load 1723  /  3424
size:  (375, 1242, 3)
load 1724  /  3424
size:  (375, 1242, 3)
load 1725  /  3424
size:  (370, 1224, 3)
load 1726  /  3424
size:  (374, 1238, 3)
load 1727  /  3424
size:  (375, 1242, 3)
load 1728  /  3424
size:  (375, 1242, 3)
load 1729  /  3424
size:  (375, 1242, 3)
load 1730  /  3424
size:  (375, 1242, 3)
load 1731  /  3424
size:  (375, 1242, 3)
load 1732  /  3424
size:  (376, 1241, 3)
load 1733  /  3424
size:  (375, 1242, 3)
load 1734  /  3424
size:  (375, 1242, 3)
load 1735  /  3424
size:  (375, 1242, 3)
load 1736  /  3424
size:  (375, 1242, 3)
load 1737  /  3424
size:  (374, 1238, 3)
load 1738  /  3424
size:  (374, 1238, 3)
load 1739  /  3424
size:  (374, 1238, 3)
load 1740  /  3424
size:  (375, 1242, 3)
load 1741  /  3424
size:  (375, 1242, 3)
load 1742  /  3424
size:  (375, 1242, 3)
load 1743  /  3424
size:  (375, 1242, 3)
load 1744  /  3424
size:  (375, 1242, 3)
load 1745  /  3424
size:  (375, 1242, 3)
load 1746  /  3424
size:  (375, 1242, 3)
load 1747  /  3424
size:  (375, 1242, 3)
load 1748  /  3424
size:  (375, 1242, 3)
load 1749  /  3424
size:  (375, 1242, 3)
load 1750  /  3424
size:  (375, 1242, 3)
load 1751  /  3424
size:  (375, 1242, 3)
load 1752  /  3424
size:  (375, 1242, 3)
load 1753  /  3424
size:  (375, 1242, 3)
load 1754  /  3424
size:  (375, 1242, 3)
load 1755  /  3424
size:  (375, 1242, 3)
load 1756  /  3424
size:  (374, 1238, 3)
load 1757  /  3424
size:  (375, 1242, 3)
load 1758  /  3424
size:  (374, 1238, 3)
load 1759  /  3424
size:  (375, 1242, 3)
load 1760  /  3424
size:  (375, 1242, 3)
load 1761  /  3424
size:  (375, 1242, 3)
load 1762  /  3424
size:  (375, 1242, 3)
load 1763  /  3424
size:  (375, 1242, 3)
load 1764  /  3424
size:  (375, 1242, 3)
load 1765  /  3424
size:  (375, 1242, 3)
load 1766  /  3424
size:  (375, 1242, 3)
load 1767  /  3424
size:  (375, 1242, 3)
load 1768  /  3424
size:  (375, 1242, 3)
load 1769  /  3424
size:  (375, 1242, 3)
load 1770  /  3424
size:  (375, 1242, 3)
load 1771  /  3424
size:  (375, 1242, 3)
load 1772  /  3424
size:  (375, 1242, 3)
load 1773  /  3424
size:  (375, 1242, 3)
load 1774  /  3424
size:  (375, 1242, 3)
load 1775  /  3424
size:  (375, 1242, 3)
load 1776  /  3424
size:  (375, 1242, 3)
load 1777  /  3424
size:  (375, 1242, 3)
load 1778  /  3424
size:  (375, 1242, 3)
load 1779  /  3424
size:  (375, 1242, 3)
load 1780  /  3424
size:  (375, 1242, 3)
load 1781  /  3424
size:  (375, 1242, 3)
load 1782  /  3424
size:  (375, 1242, 3)
load 1783  /  3424
size:  (375, 1242, 3)
load 1784  /  3424
size:  (375, 1242, 3)
load 1785  /  3424
size:  (376, 1241, 3)
load 1786  /  3424
size:  (375, 1242, 3)
load 1787  /  3424
size:  (375, 1242, 3)
load 1788  /  3424
size:  (375, 1242, 3)
load 1789  /  3424
size:  (375, 1242, 3)
load 1790  /  3424
size:  (375, 1242, 3)
load 1791  /  3424
size:  (375, 1242, 3)
load 1792  /  3424
size:  (375, 1242, 3)
load 1793  /  3424
size:  (375, 1242, 3)
load 1794  /  3424
size:  (376, 1241, 3)
load 1795  /  3424
size:  (375, 1242, 3)
load 1796  /  3424
size:  (376, 1241, 3)
load 1797  /  3424
size:  (375, 1242, 3)
load 1798  /  3424
size:  (374, 1238, 3)
load 1799  /  3424
size:  (375, 1242, 3)
load 1800  /  3424
size:  (375, 1242, 3)
load 1801  /  3424
size:  (375, 1242, 3)
load 1802  /  3424
size:  (375, 1242, 3)
load 1803  /  3424
size:  (375, 1242, 3)
load 1804  /  3424
size:  (375, 1242, 3)
load 1805  /  3424
size:  (375, 1242, 3)
load 1806  /  3424
size:  (375, 1242, 3)
load 1807  /  3424
size:  (375, 1242, 3)
load 1808  /  3424
size:  (375, 1242, 3)
load 1809  /  3424
size:  (375, 1242, 3)
load 1810  /  3424
size:  (375, 1242, 3)
load 1811  /  3424
size:  (376, 1241, 3)
load 1812  /  3424
size:  (375, 1242, 3)
load 1813  /  3424
size:  (375, 1242, 3)
load 1814  /  3424
size:  (370, 1224, 3)
load 1815  /  3424
size:  (375, 1242, 3)
load 1816  /  3424
size:  (375, 1242, 3)
load 1817  /  3424
size:  (370, 1224, 3)
load 1818  /  3424
size:  (375, 1242, 3)
load 1819  /  3424
size:  (375, 1242, 3)
load 1820  /  3424
size:  (375, 1242, 3)
load 1821  /  3424
size:  (376, 1241, 3)
load 1822  /  3424
size:  (375, 1242, 3)
load 1823  /  3424
size:  (370, 1224, 3)
load 1824  /  3424
size:  (375, 1242, 3)
load 1825  /  3424
size:  (375, 1242, 3)
load 1826  /  3424
size:  (375, 1242, 3)
load 1827  /  3424
size:  (375, 1242, 3)
load 1828  /  3424
size:  (375, 1242, 3)
load 1829  /  3424
size:  (375, 1242, 3)
load 1830  /  3424
size:  (375, 1242, 3)
load 1831  /  3424
size:  (376, 1241, 3)
load 1832  /  3424
size:  (375, 1242, 3)
load 1833  /  3424
size:  (375, 1242, 3)
load 1834  /  3424
size:  (375, 1242, 3)
load 1835  /  3424
size:  (376, 1241, 3)
load 1836  /  3424
size:  (375, 1242, 3)
load 1837  /  3424
size:  (370, 1224, 3)
load 1838  /  3424
size:  (375, 1242, 3)
load 1839  /  3424
size:  (375, 1242, 3)
load 1840  /  3424
size:  (375, 1242, 3)
load 1841  /  3424
size:  (375, 1242, 3)
load 1842  /  3424
size:  (375, 1242, 3)
load 1843  /  3424
size:  (375, 1242, 3)
load 1844  /  3424
size:  (375, 1242, 3)
load 1845  /  3424
size:  (375, 1242, 3)
load 1846  /  3424
size:  (375, 1242, 3)
load 1847  /  3424
size:  (375, 1242, 3)
load 1848  /  3424
size:  (375, 1242, 3)
load 1849  /  3424
size:  (375, 1242, 3)
load 1850  /  3424
size:  (375, 1242, 3)
load 1851  /  3424
size:  (375, 1242, 3)
load 1852  /  3424
size:  (375, 1242, 3)
load 1853  /  3424
size:  (375, 1242, 3)
load 1854  /  3424
size:  (375, 1242, 3)
load 1855  /  3424
size:  (376, 1241, 3)
load 1856  /  3424
size:  (375, 1242, 3)
load 1857  /  3424
size:  (375, 1242, 3)
load 1858  /  3424
size:  (375, 1242, 3)
load 1859  /  3424
size:  (376, 1241, 3)
load 1860  /  3424
size:  (375, 1242, 3)
load 1861  /  3424
size:  (375, 1242, 3)
load 1862  /  3424
size:  (375, 1242, 3)
load 1863  /  3424
size:  (375, 1242, 3)
load 1864  /  3424
size:  (375, 1242, 3)
load 1865  /  3424
size:  (375, 1242, 3)
load 1866  /  3424
size:  (375, 1242, 3)
load 1867  /  3424
size:  (375, 1242, 3)
load 1868  /  3424
size:  (375, 1242, 3)
load 1869  /  3424
size:  (375, 1242, 3)
load 1870  /  3424
size:  (375, 1242, 3)
load 1871  /  3424
size:  (375, 1242, 3)
load 1872  /  3424
size:  (375, 1242, 3)
load 1873  /  3424
size:  (375, 1242, 3)
load 1874  /  3424
size:  (375, 1242, 3)
load 1875  /  3424
size:  (375, 1242, 3)
load 1876  /  3424
size:  (375, 1242, 3)
load 1877  /  3424
size:  (375, 1242, 3)
load 1878  /  3424
size:  (370, 1224, 3)
load 1879  /  3424
size:  (375, 1242, 3)
load 1880  /  3424
size:  (375, 1242, 3)
load 1881  /  3424
size:  (375, 1242, 3)
load 1882  /  3424
size:  (376, 1241, 3)
load 1883  /  3424
size:  (375, 1242, 3)
load 1884  /  3424
size:  (376, 1241, 3)
load 1885  /  3424
size:  (375, 1242, 3)
load 1886  /  3424
size:  (375, 1242, 3)
load 1887  /  3424
size:  (375, 1242, 3)
load 1888  /  3424
size:  (375, 1242, 3)
load 1889  /  3424
size:  (375, 1242, 3)
load 1890  /  3424
size:  (376, 1241, 3)
load 1891  /  3424
size:  (375, 1242, 3)
load 1892  /  3424
size:  (375, 1242, 3)
load 1893  /  3424
size:  (376, 1241, 3)
load 1894  /  3424
size:  (375, 1242, 3)
load 1895  /  3424
size:  (375, 1242, 3)
load 1896  /  3424
size:  (375, 1242, 3)
load 1897  /  3424
size:  (375, 1242, 3)
load 1898  /  3424
size:  (374, 1238, 3)
load 1899  /  3424
size:  (375, 1242, 3)
load 1900  /  3424
size:  (375, 1242, 3)
load 1901  /  3424
size:  (375, 1242, 3)
load 1902  /  3424
size:  (375, 1242, 3)
load 1903  /  3424
size:  (375, 1242, 3)
load 1904  /  3424
size:  (375, 1242, 3)
load 1905  /  3424
size:  (375, 1242, 3)
load 1906  /  3424
size:  (376, 1241, 3)
load 1907  /  3424
size:  (375, 1242, 3)
load 1908  /  3424
size:  (376, 1241, 3)
load 1909  /  3424
size:  (375, 1242, 3)
load 1910  /  3424
size:  (370, 1224, 3)
load 1911  /  3424
size:  (375, 1242, 3)
load 1912  /  3424
size:  (376, 1241, 3)
load 1913  /  3424
size:  (375, 1242, 3)
load 1914  /  3424
size:  (375, 1242, 3)
load 1915  /  3424
size:  (375, 1242, 3)
load 1916  /  3424
size:  (375, 1242, 3)
load 1917  /  3424
size:  (375, 1242, 3)
load 1918  /  3424
size:  (376, 1241, 3)
load 1919  /  3424
size:  (374, 1238, 3)
load 1920  /  3424
size:  (376, 1241, 3)
load 1921  /  3424
size:  (376, 1241, 3)
load 1922  /  3424
size:  (375, 1242, 3)
load 1923  /  3424
size:  (375, 1242, 3)
load 1924  /  3424
size:  (375, 1242, 3)
load 1925  /  3424
size:  (375, 1242, 3)
load 1926  /  3424
size:  (375, 1242, 3)
load 1927  /  3424
size:  (375, 1242, 3)
load 1928  /  3424
size:  (376, 1241, 3)
load 1929  /  3424
size:  (375, 1242, 3)
load 1930  /  3424
size:  (375, 1242, 3)
load 1931  /  3424
size:  (370, 1224, 3)
load 1932  /  3424
size:  (375, 1242, 3)
load 1933  /  3424
size:  (375, 1242, 3)
load 1934  /  3424
size:  (376, 1241, 3)
load 1935  /  3424
size:  (374, 1238, 3)
load 1936  /  3424
size:  (375, 1242, 3)
load 1937  /  3424
size:  (375, 1242, 3)
load 1938  /  3424
size:  (375, 1242, 3)
load 1939  /  3424
size:  (375, 1242, 3)
load 1940  /  3424
size:  (375, 1242, 3)
load 1941  /  3424
size:  (375, 1242, 3)
load 1942  /  3424
size:  (375, 1242, 3)
load 1943  /  3424
size:  (375, 1242, 3)
load 1944  /  3424
size:  (375, 1242, 3)
load 1945  /  3424
size:  (375, 1242, 3)
load 1946  /  3424
size:  (376, 1241, 3)
load 1947  /  3424
size:  (375, 1242, 3)
load 1948  /  3424
size:  (374, 1238, 3)
load 1949  /  3424
size:  (375, 1242, 3)
load 1950  /  3424
size:  (375, 1242, 3)
load 1951  /  3424
size:  (374, 1238, 3)
load 1952  /  3424
size:  (375, 1242, 3)
load 1953  /  3424
size:  (370, 1224, 3)
load 1954  /  3424
size:  (375, 1242, 3)
load 1955  /  3424
size:  (375, 1242, 3)
load 1956  /  3424
size:  (375, 1242, 3)
load 1957  /  3424
size:  (370, 1224, 3)
load 1958  /  3424
size:  (375, 1242, 3)
load 1959  /  3424
size:  (376, 1241, 3)
load 1960  /  3424
size:  (375, 1242, 3)
load 1961  /  3424
size:  (375, 1242, 3)
load 1962  /  3424
size:  (374, 1238, 3)
load 1963  /  3424
size:  (375, 1242, 3)
load 1964  /  3424
size:  (375, 1242, 3)
load 1965  /  3424
size:  (375, 1242, 3)
load 1966  /  3424
size:  (375, 1242, 3)
load 1967  /  3424
size:  (370, 1224, 3)
load 1968  /  3424
size:  (375, 1242, 3)
load 1969  /  3424
size:  (375, 1242, 3)
load 1970  /  3424
size:  (370, 1224, 3)
load 1971  /  3424
size:  (375, 1242, 3)
load 1972  /  3424
size:  (375, 1242, 3)
load 1973  /  3424
size:  (375, 1242, 3)
load 1974  /  3424
size:  (375, 1242, 3)
load 1975  /  3424
size:  (375, 1242, 3)
load 1976  /  3424
size:  (375, 1242, 3)
load 1977  /  3424
size:  (375, 1242, 3)
load 1978  /  3424
size:  (370, 1224, 3)
load 1979  /  3424
size:  (374, 1238, 3)
load 1980  /  3424
size:  (375, 1242, 3)
load 1981  /  3424
size:  (375, 1242, 3)
load 1982  /  3424
size:  (375, 1242, 3)
load 1983  /  3424
size:  (375, 1242, 3)
load 1984  /  3424
size:  (375, 1242, 3)
load 1985  /  3424
size:  (375, 1242, 3)
load 1986  /  3424
size:  (375, 1242, 3)
load 1987  /  3424
size:  (375, 1242, 3)
load 1988  /  3424
size:  (375, 1242, 3)
load 1989  /  3424
size:  (375, 1242, 3)
load 1990  /  3424
size:  (370, 1224, 3)
load 1991  /  3424
size:  (375, 1242, 3)
load 1992  /  3424
size:  (375, 1242, 3)
load 1993  /  3424
size:  (370, 1224, 3)
load 1994  /  3424
size:  (375, 1242, 3)
load 1995  /  3424
size:  (375, 1242, 3)
load 1996  /  3424
size:  (375, 1242, 3)
load 1997  /  3424
size:  (375, 1242, 3)
load 1998  /  3424
size:  (375, 1242, 3)
load 1999  /  3424
size:  (370, 1224, 3)
load 2000  /  3424
size:  (374, 1238, 3)
load 2001  /  3424
size:  (375, 1242, 3)
load 2002  /  3424
size:  (374, 1238, 3)
load 2003  /  3424
size:  (375, 1242, 3)
load 2004  /  3424
size:  (375, 1242, 3)
load 2005  /  3424
size:  (375, 1242, 3)
load 2006  /  3424
size:  (375, 1242, 3)
load 2007  /  3424
size:  (375, 1242, 3)
load 2008  /  3424
size:  (375, 1242, 3)
load 2009  /  3424
size:  (375, 1242, 3)
load 2010  /  3424
size:  (375, 1242, 3)
load 2011  /  3424
size:  (375, 1242, 3)
load 2012  /  3424
size:  (375, 1242, 3)
load 2013  /  3424
size:  (374, 1238, 3)
load 2014  /  3424
size:  (375, 1242, 3)
load 2015  /  3424
size:  (376, 1241, 3)
load 2016  /  3424
size:  (375, 1242, 3)
load 2017  /  3424
size:  (375, 1242, 3)
load 2018  /  3424
size:  (376, 1241, 3)
load 2019  /  3424
size:  (375, 1242, 3)
load 2020  /  3424
size:  (375, 1242, 3)
load 2021  /  3424
size:  (375, 1242, 3)
load 2022  /  3424
size:  (375, 1242, 3)
load 2023  /  3424
size:  (375, 1242, 3)
load 2024  /  3424
size:  (375, 1242, 3)
load 2025  /  3424
size:  (374, 1238, 3)
load 2026  /  3424
size:  (376, 1241, 3)
load 2027  /  3424
size:  (375, 1242, 3)
load 2028  /  3424
size:  (376, 1241, 3)
load 2029  /  3424
size:  (375, 1242, 3)
load 2030  /  3424
size:  (375, 1242, 3)
load 2031  /  3424
size:  (375, 1242, 3)
load 2032  /  3424
size:  (375, 1242, 3)
load 2033  /  3424
size:  (375, 1242, 3)
load 2034  /  3424
size:  (375, 1242, 3)
load 2035  /  3424
size:  (375, 1242, 3)
load 2036  /  3424
size:  (374, 1238, 3)
load 2037  /  3424
size:  (375, 1242, 3)
load 2038  /  3424
size:  (375, 1242, 3)
load 2039  /  3424
size:  (375, 1242, 3)
load 2040  /  3424
size:  (376, 1241, 3)
load 2041  /  3424
size:  (375, 1242, 3)
load 2042  /  3424
size:  (375, 1242, 3)
load 2043  /  3424
size:  (376, 1241, 3)
load 2044  /  3424
size:  (376, 1241, 3)
load 2045  /  3424
size:  (375, 1242, 3)
load 2046  /  3424
size:  (375, 1242, 3)
load 2047  /  3424
size:  (375, 1242, 3)
load 2048  /  3424
size:  (375, 1242, 3)
load 2049  /  3424
size:  (375, 1242, 3)
load 2050  /  3424
size:  (375, 1242, 3)
load 2051  /  3424
size:  (375, 1242, 3)
load 2052  /  3424
size:  (375, 1242, 3)
load 2053  /  3424
size:  (375, 1242, 3)
load 2054  /  3424
size:  (375, 1242, 3)
load 2055  /  3424
size:  (375, 1242, 3)
load 2056  /  3424
size:  (375, 1242, 3)
load 2057  /  3424
size:  (375, 1242, 3)
load 2058  /  3424
size:  (375, 1242, 3)
load 2059  /  3424
size:  (375, 1242, 3)
load 2060  /  3424
size:  (375, 1242, 3)
load 2061  /  3424
size:  (375, 1242, 3)
load 2062  /  3424
size:  (375, 1242, 3)
load 2063  /  3424
size:  (370, 1224, 3)
load 2064  /  3424
size:  (375, 1242, 3)
load 2065  /  3424
size:  (370, 1224, 3)
load 2066  /  3424
size:  (375, 1242, 3)
load 2067  /  3424
size:  (375, 1242, 3)
load 2068  /  3424
size:  (375, 1242, 3)
load 2069  /  3424
size:  (375, 1242, 3)
load 2070  /  3424
size:  (375, 1242, 3)
load 2071  /  3424
size:  (375, 1242, 3)
load 2072  /  3424
size:  (375, 1242, 3)
load 2073  /  3424
size:  (375, 1242, 3)
load 2074  /  3424
size:  (375, 1242, 3)
load 2075  /  3424
size:  (375, 1242, 3)
load 2076  /  3424
size:  (375, 1242, 3)
load 2077  /  3424
size:  (375, 1242, 3)
load 2078  /  3424
size:  (375, 1242, 3)
load 2079  /  3424
size:  (375, 1242, 3)
load 2080  /  3424
size:  (375, 1242, 3)
load 2081  /  3424
size:  (375, 1242, 3)
load 2082  /  3424
size:  (375, 1242, 3)
load 2083  /  3424
size:  (375, 1242, 3)
load 2084  /  3424
size:  (375, 1242, 3)
load 2085  /  3424
size:  (375, 1242, 3)
load 2086  /  3424
size:  (375, 1242, 3)
load 2087  /  3424
size:  (375, 1242, 3)
load 2088  /  3424
size:  (375, 1242, 3)
load 2089  /  3424
size:  (375, 1242, 3)
load 2090  /  3424
size:  (375, 1242, 3)
load 2091  /  3424
size:  (375, 1242, 3)
load 2092  /  3424
size:  (375, 1242, 3)
load 2093  /  3424
size:  (375, 1242, 3)
load 2094  /  3424
size:  (375, 1242, 3)
load 2095  /  3424
size:  (375, 1242, 3)
load 2096  /  3424
size:  (375, 1242, 3)
load 2097  /  3424
size:  (375, 1242, 3)
load 2098  /  3424
size:  (375, 1242, 3)
load 2099  /  3424
size:  (375, 1242, 3)
load 2100  /  3424
size:  (376, 1241, 3)
load 2101  /  3424
size:  (375, 1242, 3)
load 2102  /  3424
size:  (375, 1242, 3)
load 2103  /  3424
size:  (375, 1242, 3)
load 2104  /  3424
size:  (375, 1242, 3)
load 2105  /  3424
size:  (375, 1242, 3)
load 2106  /  3424
size:  (374, 1238, 3)
load 2107  /  3424
size:  (375, 1242, 3)
load 2108  /  3424
size:  (375, 1242, 3)
load 2109  /  3424
size:  (374, 1238, 3)
load 2110  /  3424
size:  (375, 1242, 3)
load 2111  /  3424
size:  (375, 1242, 3)
load 2112  /  3424
size:  (375, 1242, 3)
load 2113  /  3424
size:  (375, 1242, 3)
load 2114  /  3424
size:  (375, 1242, 3)
load 2115  /  3424
size:  (375, 1242, 3)
load 2116  /  3424
size:  (375, 1242, 3)
load 2117  /  3424
size:  (376, 1241, 3)
load 2118  /  3424
size:  (375, 1242, 3)
load 2119  /  3424
size:  (375, 1242, 3)
load 2120  /  3424
size:  (376, 1241, 3)
load 2121  /  3424
size:  (375, 1242, 3)
load 2122  /  3424
size:  (375, 1242, 3)
load 2123  /  3424
size:  (375, 1242, 3)
load 2124  /  3424
size:  (375, 1242, 3)
load 2125  /  3424
size:  (370, 1224, 3)
load 2126  /  3424
size:  (375, 1242, 3)
load 2127  /  3424
size:  (376, 1241, 3)
load 2128  /  3424
size:  (375, 1242, 3)
load 2129  /  3424
size:  (375, 1242, 3)
load 2130  /  3424
size:  (375, 1242, 3)
load 2131  /  3424
size:  (375, 1242, 3)
load 2132  /  3424
size:  (375, 1242, 3)
load 2133  /  3424
size:  (375, 1242, 3)
load 2134  /  3424
size:  (375, 1242, 3)
load 2135  /  3424
size:  (375, 1242, 3)
load 2136  /  3424
size:  (375, 1242, 3)
load 2137  /  3424
size:  (375, 1242, 3)
load 2138  /  3424
size:  (375, 1242, 3)
load 2139  /  3424
size:  (375, 1242, 3)
load 2140  /  3424
size:  (375, 1242, 3)
load 2141  /  3424
size:  (376, 1241, 3)
load 2142  /  3424
size:  (375, 1242, 3)
load 2143  /  3424
size:  (375, 1242, 3)
load 2144  /  3424
size:  (375, 1242, 3)
load 2145  /  3424
size:  (370, 1224, 3)
load 2146  /  3424
size:  (375, 1242, 3)
load 2147  /  3424
size:  (375, 1242, 3)
load 2148  /  3424
size:  (375, 1242, 3)
load 2149  /  3424
size:  (375, 1242, 3)
load 2150  /  3424
size:  (375, 1242, 3)
load 2151  /  3424
size:  (375, 1242, 3)
load 2152  /  3424
size:  (375, 1242, 3)
load 2153  /  3424
size:  (375, 1242, 3)
load 2154  /  3424
size:  (375, 1242, 3)
load 2155  /  3424
size:  (375, 1242, 3)
load 2156  /  3424
size:  (374, 1238, 3)
load 2157  /  3424
size:  (376, 1241, 3)
load 2158  /  3424
size:  (376, 1241, 3)
load 2159  /  3424
size:  (375, 1242, 3)
load 2160  /  3424
size:  (374, 1238, 3)
load 2161  /  3424
size:  (375, 1242, 3)
load 2162  /  3424
size:  (375, 1242, 3)
load 2163  /  3424
size:  (375, 1242, 3)
load 2164  /  3424
size:  (375, 1242, 3)
load 2165  /  3424
size:  (376, 1241, 3)
load 2166  /  3424
size:  (375, 1242, 3)
load 2167  /  3424
size:  (375, 1242, 3)
load 2168  /  3424
size:  (375, 1242, 3)
load 2169  /  3424
size:  (375, 1242, 3)
load 2170  /  3424
size:  (375, 1242, 3)
load 2171  /  3424
size:  (376, 1241, 3)
load 2172  /  3424
size:  (375, 1242, 3)
load 2173  /  3424
size:  (375, 1242, 3)
load 2174  /  3424
size:  (374, 1238, 3)
load 2175  /  3424
size:  (375, 1242, 3)
load 2176  /  3424
size:  (375, 1242, 3)
load 2177  /  3424
size:  (375, 1242, 3)
load 2178  /  3424
size:  (370, 1224, 3)
load 2179  /  3424
size:  (375, 1242, 3)
load 2180  /  3424
size:  (375, 1242, 3)
load 2181  /  3424
size:  (375, 1242, 3)
load 2182  /  3424
size:  (375, 1242, 3)
load 2183  /  3424
size:  (375, 1242, 3)
load 2184  /  3424
size:  (370, 1224, 3)
load 2185  /  3424
size:  (375, 1242, 3)
load 2186  /  3424
size:  (375, 1242, 3)
load 2187  /  3424
size:  (375, 1242, 3)
load 2188  /  3424
size:  (375, 1242, 3)
load 2189  /  3424
size:  (375, 1242, 3)
load 2190  /  3424
size:  (375, 1242, 3)
load 2191  /  3424
size:  (375, 1242, 3)
load 2192  /  3424
size:  (374, 1238, 3)
load 2193  /  3424
size:  (375, 1242, 3)
load 2194  /  3424
size:  (375, 1242, 3)
load 2195  /  3424
size:  (375, 1242, 3)
load 2196  /  3424
size:  (375, 1242, 3)
load 2197  /  3424
size:  (375, 1242, 3)
load 2198  /  3424
size:  (375, 1242, 3)
load 2199  /  3424
size:  (376, 1241, 3)
load 2200  /  3424
size:  (375, 1242, 3)
load 2201  /  3424
size:  (375, 1242, 3)
load 2202  /  3424
size:  (376, 1241, 3)
load 2203  /  3424
size:  (375, 1242, 3)
load 2204  /  3424
size:  (375, 1242, 3)
load 2205  /  3424
size:  (375, 1242, 3)
load 2206  /  3424
size:  (375, 1242, 3)
load 2207  /  3424
size:  (375, 1242, 3)
load 2208  /  3424
size:  (375, 1242, 3)
load 2209  /  3424
size:  (375, 1242, 3)
load 2210  /  3424
size:  (375, 1242, 3)
load 2211  /  3424
size:  (375, 1242, 3)
load 2212  /  3424
size:  (375, 1242, 3)
load 2213  /  3424
size:  (375, 1242, 3)
load 2214  /  3424
size:  (375, 1242, 3)
load 2215  /  3424
size:  (375, 1242, 3)
load 2216  /  3424
size:  (375, 1242, 3)
load 2217  /  3424
size:  (375, 1242, 3)
load 2218  /  3424
size:  (375, 1242, 3)
load 2219  /  3424
size:  (375, 1242, 3)
load 2220  /  3424
size:  (375, 1242, 3)
load 2221  /  3424
size:  (375, 1242, 3)
load 2222  /  3424
size:  (375, 1242, 3)
load 2223  /  3424
size:  (376, 1241, 3)
load 2224  /  3424
size:  (375, 1242, 3)
load 2225  /  3424
size:  (375, 1242, 3)
load 2226  /  3424
size:  (375, 1242, 3)
load 2227  /  3424
size:  (375, 1242, 3)
load 2228  /  3424
size:  (375, 1242, 3)
load 2229  /  3424
size:  (375, 1242, 3)
load 2230  /  3424
size:  (375, 1242, 3)
load 2231  /  3424
size:  (375, 1242, 3)
load 2232  /  3424
size:  (375, 1242, 3)
load 2233  /  3424
size:  (375, 1242, 3)
load 2234  /  3424
size:  (375, 1242, 3)
load 2235  /  3424
size:  (375, 1242, 3)
load 2236  /  3424
size:  (375, 1242, 3)
load 2237  /  3424
size:  (375, 1242, 3)
load 2238  /  3424
size:  (375, 1242, 3)
load 2239  /  3424
size:  (375, 1242, 3)
load 2240  /  3424
size:  (375, 1242, 3)
load 2241  /  3424
size:  (375, 1242, 3)
load 2242  /  3424
size:  (375, 1242, 3)
load 2243  /  3424
size:  (375, 1242, 3)
load 2244  /  3424
size:  (376, 1241, 3)
load 2245  /  3424
size:  (375, 1242, 3)
load 2246  /  3424
size:  (375, 1242, 3)
load 2247  /  3424
size:  (375, 1242, 3)
load 2248  /  3424
size:  (375, 1242, 3)
load 2249  /  3424
size:  (375, 1242, 3)
load 2250  /  3424
size:  (375, 1242, 3)
load 2251  /  3424
size:  (375, 1242, 3)
load 2252  /  3424
size:  (370, 1224, 3)
load 2253  /  3424
size:  (375, 1242, 3)
load 2254  /  3424
size:  (375, 1242, 3)
load 2255  /  3424
size:  (375, 1242, 3)
load 2256  /  3424
size:  (375, 1242, 3)
load 2257  /  3424
size:  (374, 1238, 3)
load 2258  /  3424
size:  (375, 1242, 3)
load 2259  /  3424
size:  (374, 1238, 3)
load 2260  /  3424
size:  (375, 1242, 3)
load 2261  /  3424
size:  (370, 1224, 3)
load 2262  /  3424
size:  (375, 1242, 3)
load 2263  /  3424
size:  (374, 1238, 3)
load 2264  /  3424
size:  (375, 1242, 3)
load 2265  /  3424
size:  (375, 1242, 3)
load 2266  /  3424
size:  (375, 1242, 3)
load 2267  /  3424
size:  (376, 1241, 3)
load 2268  /  3424
size:  (374, 1238, 3)
load 2269  /  3424
size:  (375, 1242, 3)
load 2270  /  3424
size:  (375, 1242, 3)
load 2271  /  3424
size:  (375, 1242, 3)
load 2272  /  3424
size:  (376, 1241, 3)
load 2273  /  3424
size:  (375, 1242, 3)
load 2274  /  3424
size:  (375, 1242, 3)
load 2275  /  3424
size:  (375, 1242, 3)
load 2276  /  3424
size:  (375, 1242, 3)
load 2277  /  3424
size:  (375, 1242, 3)
load 2278  /  3424
size:  (375, 1242, 3)
load 2279  /  3424
size:  (376, 1241, 3)
load 2280  /  3424
size:  (375, 1242, 3)
load 2281  /  3424
size:  (375, 1242, 3)
load 2282  /  3424
size:  (375, 1242, 3)
load 2283  /  3424
size:  (375, 1242, 3)
load 2284  /  3424
size:  (376, 1241, 3)
load 2285  /  3424
size:  (375, 1242, 3)
load 2286  /  3424
size:  (375, 1242, 3)
load 2287  /  3424
size:  (375, 1242, 3)
load 2288  /  3424
size:  (375, 1242, 3)
load 2289  /  3424
size:  (375, 1242, 3)
load 2290  /  3424
size:  (375, 1242, 3)
load 2291  /  3424
size:  (375, 1242, 3)
load 2292  /  3424
size:  (370, 1224, 3)
load 2293  /  3424
size:  (375, 1242, 3)
load 2294  /  3424
size:  (375, 1242, 3)
load 2295  /  3424
size:  (375, 1242, 3)
load 2296  /  3424
size:  (375, 1242, 3)
load 2297  /  3424
size:  (375, 1242, 3)
load 2298  /  3424
size:  (375, 1242, 3)
load 2299  /  3424
size:  (376, 1241, 3)
load 2300  /  3424
size:  (375, 1242, 3)
load 2301  /  3424
size:  (375, 1242, 3)
load 2302  /  3424
size:  (375, 1242, 3)
load 2303  /  3424
size:  (375, 1242, 3)
load 2304  /  3424
size:  (376, 1241, 3)
load 2305  /  3424
size:  (375, 1242, 3)
load 2306  /  3424
size:  (375, 1242, 3)
load 2307  /  3424
size:  (370, 1224, 3)
load 2308  /  3424
size:  (374, 1238, 3)
load 2309  /  3424
size:  (376, 1241, 3)
load 2310  /  3424
size:  (375, 1242, 3)
load 2311  /  3424
size:  (370, 1224, 3)
load 2312  /  3424
size:  (375, 1242, 3)
load 2313  /  3424
size:  (376, 1241, 3)
load 2314  /  3424
size:  (375, 1242, 3)
load 2315  /  3424
size:  (370, 1224, 3)
load 2316  /  3424
size:  (375, 1242, 3)
load 2317  /  3424
size:  (370, 1224, 3)
load 2318  /  3424
size:  (375, 1242, 3)
load 2319  /  3424
size:  (375, 1242, 3)
load 2320  /  3424
size:  (375, 1242, 3)
load 2321  /  3424
size:  (374, 1238, 3)
load 2322  /  3424
size:  (374, 1238, 3)
load 2323  /  3424
size:  (375, 1242, 3)
load 2324  /  3424
size:  (375, 1242, 3)
load 2325  /  3424
size:  (376, 1241, 3)
load 2326  /  3424
size:  (375, 1242, 3)
load 2327  /  3424
size:  (375, 1242, 3)
load 2328  /  3424
size:  (375, 1242, 3)
load 2329  /  3424
size:  (375, 1242, 3)
load 2330  /  3424
size:  (376, 1241, 3)
load 2331  /  3424
size:  (375, 1242, 3)
load 2332  /  3424
size:  (370, 1224, 3)
load 2333  /  3424
size:  (370, 1224, 3)
load 2334  /  3424
size:  (375, 1242, 3)
load 2335  /  3424
size:  (375, 1242, 3)
load 2336  /  3424
size:  (375, 1242, 3)
load 2337  /  3424
size:  (375, 1242, 3)
load 2338  /  3424
size:  (375, 1242, 3)
load 2339  /  3424
size:  (375, 1242, 3)
load 2340  /  3424
size:  (375, 1242, 3)
load 2341  /  3424
size:  (375, 1242, 3)
load 2342  /  3424
size:  (375, 1242, 3)
load 2343  /  3424
size:  (375, 1242, 3)
load 2344  /  3424
size:  (376, 1241, 3)
load 2345  /  3424
size:  (375, 1242, 3)
load 2346  /  3424
size:  (375, 1242, 3)
load 2347  /  3424
size:  (375, 1242, 3)
load 2348  /  3424
size:  (375, 1242, 3)
load 2349  /  3424
size:  (375, 1242, 3)
load 2350  /  3424
size:  (375, 1242, 3)
load 2351  /  3424
size:  (375, 1242, 3)
load 2352  /  3424
size:  (375, 1242, 3)
load 2353  /  3424
size:  (375, 1242, 3)
load 2354  /  3424
size:  (375, 1242, 3)
load 2355  /  3424
size:  (375, 1242, 3)
load 2356  /  3424
size:  (375, 1242, 3)
load 2357  /  3424
size:  (375, 1242, 3)
load 2358  /  3424
size:  (375, 1242, 3)
load 2359  /  3424
size:  (375, 1242, 3)
load 2360  /  3424
size:  (376, 1241, 3)
load 2361  /  3424
size:  (375, 1242, 3)
load 2362  /  3424
size:  (375, 1242, 3)
load 2363  /  3424
size:  (370, 1224, 3)
load 2364  /  3424
size:  (374, 1238, 3)
load 2365  /  3424
size:  (375, 1242, 3)
load 2366  /  3424
size:  (375, 1242, 3)
load 2367  /  3424
size:  (374, 1238, 3)
load 2368  /  3424
size:  (375, 1242, 3)
load 2369  /  3424
size:  (375, 1242, 3)
load 2370  /  3424
size:  (375, 1242, 3)
load 2371  /  3424
size:  (375, 1242, 3)
load 2372  /  3424
size:  (375, 1242, 3)
load 2373  /  3424
size:  (375, 1242, 3)
load 2374  /  3424
size:  (375, 1242, 3)
load 2375  /  3424
size:  (375, 1242, 3)
load 2376  /  3424
size:  (375, 1242, 3)
load 2377  /  3424
size:  (375, 1242, 3)
load 2378  /  3424
size:  (376, 1241, 3)
load 2379  /  3424
size:  (375, 1242, 3)
load 2380  /  3424
size:  (375, 1242, 3)
load 2381  /  3424
size:  (375, 1242, 3)
load 2382  /  3424
size:  (375, 1242, 3)
load 2383  /  3424
size:  (375, 1242, 3)
load 2384  /  3424
size:  (375, 1242, 3)
load 2385  /  3424
size:  (375, 1242, 3)
load 2386  /  3424
size:  (376, 1241, 3)
load 2387  /  3424
size:  (375, 1242, 3)
load 2388  /  3424
size:  (375, 1242, 3)
load 2389  /  3424
size:  (375, 1242, 3)
load 2390  /  3424
size:  (375, 1242, 3)
load 2391  /  3424
size:  (375, 1242, 3)
load 2392  /  3424
size:  (376, 1241, 3)
load 2393  /  3424
size:  (375, 1242, 3)
load 2394  /  3424
size:  (375, 1242, 3)
load 2395  /  3424
size:  (375, 1242, 3)
load 2396  /  3424
size:  (375, 1242, 3)
load 2397  /  3424
size:  (370, 1224, 3)
load 2398  /  3424
size:  (375, 1242, 3)
load 2399  /  3424
size:  (375, 1242, 3)
load 2400  /  3424
size:  (375, 1242, 3)
load 2401  /  3424
size:  (375, 1242, 3)
load 2402  /  3424
size:  (375, 1242, 3)
load 2403  /  3424
size:  (375, 1242, 3)
load 2404  /  3424
size:  (375, 1242, 3)
load 2405  /  3424
size:  (375, 1242, 3)
load 2406  /  3424
size:  (376, 1241, 3)
load 2407  /  3424
size:  (375, 1242, 3)
load 2408  /  3424
size:  (375, 1242, 3)
load 2409  /  3424
size:  (375, 1242, 3)
load 2410  /  3424
size:  (375, 1242, 3)
load 2411  /  3424
size:  (370, 1224, 3)
load 2412  /  3424
size:  (375, 1242, 3)
load 2413  /  3424
size:  (375, 1242, 3)
load 2414  /  3424
size:  (375, 1242, 3)
load 2415  /  3424
size:  (375, 1242, 3)
load 2416  /  3424
size:  (375, 1242, 3)
load 2417  /  3424
size:  (375, 1242, 3)
load 2418  /  3424
size:  (375, 1242, 3)
load 2419  /  3424
size:  (375, 1242, 3)
load 2420  /  3424
size:  (375, 1242, 3)
load 2421  /  3424
size:  (375, 1242, 3)
load 2422  /  3424
size:  (375, 1242, 3)
load 2423  /  3424
size:  (375, 1242, 3)
load 2424  /  3424
size:  (375, 1242, 3)
load 2425  /  3424
size:  (375, 1242, 3)
load 2426  /  3424
size:  (375, 1242, 3)
load 2427  /  3424
size:  (375, 1242, 3)
load 2428  /  3424
size:  (375, 1242, 3)
load 2429  /  3424
size:  (375, 1242, 3)
load 2430  /  3424
size:  (375, 1242, 3)
load 2431  /  3424
size:  (375, 1242, 3)
load 2432  /  3424
size:  (375, 1242, 3)
load 2433  /  3424
size:  (375, 1242, 3)
load 2434  /  3424
size:  (375, 1242, 3)
load 2435  /  3424
size:  (376, 1241, 3)
load 2436  /  3424
size:  (375, 1242, 3)
load 2437  /  3424
size:  (376, 1241, 3)
load 2438  /  3424
size:  (375, 1242, 3)
load 2439  /  3424
size:  (375, 1242, 3)
load 2440  /  3424
size:  (375, 1242, 3)
load 2441  /  3424
size:  (375, 1242, 3)
load 2442  /  3424
size:  (375, 1242, 3)
load 2443  /  3424
size:  (375, 1242, 3)
load 2444  /  3424
size:  (375, 1242, 3)
load 2445  /  3424
size:  (375, 1242, 3)
load 2446  /  3424
size:  (374, 1238, 3)
load 2447  /  3424
size:  (375, 1242, 3)
load 2448  /  3424
size:  (375, 1242, 3)
load 2449  /  3424
size:  (375, 1242, 3)
load 2450  /  3424
size:  (375, 1242, 3)
load 2451  /  3424
size:  (375, 1242, 3)
load 2452  /  3424
size:  (375, 1242, 3)
load 2453  /  3424
size:  (375, 1242, 3)
load 2454  /  3424
size:  (375, 1242, 3)
load 2455  /  3424
size:  (375, 1242, 3)
load 2456  /  3424
size:  (375, 1242, 3)
load 2457  /  3424
size:  (375, 1242, 3)
load 2458  /  3424
size:  (376, 1241, 3)
load 2459  /  3424
size:  (375, 1242, 3)
load 2460  /  3424
size:  (374, 1238, 3)
load 2461  /  3424
size:  (375, 1242, 3)
load 2462  /  3424
size:  (375, 1242, 3)
load 2463  /  3424
size:  (375, 1242, 3)
load 2464  /  3424
size:  (375, 1242, 3)
load 2465  /  3424
size:  (375, 1242, 3)
load 2466  /  3424
size:  (375, 1242, 3)
load 2467  /  3424
size:  (375, 1242, 3)
load 2468  /  3424
size:  (375, 1242, 3)
load 2469  /  3424
size:  (375, 1242, 3)
load 2470  /  3424
size:  (375, 1242, 3)
load 2471  /  3424
size:  (375, 1242, 3)
load 2472  /  3424
size:  (370, 1224, 3)
load 2473  /  3424
size:  (375, 1242, 3)
load 2474  /  3424
size:  (375, 1242, 3)
load 2475  /  3424
size:  (375, 1242, 3)
load 2476  /  3424
size:  (375, 1242, 3)
load 2477  /  3424
size:  (375, 1242, 3)
load 2478  /  3424
size:  (375, 1242, 3)
load 2479  /  3424
size:  (375, 1242, 3)
load 2480  /  3424
size:  (375, 1242, 3)
load 2481  /  3424
size:  (376, 1241, 3)
load 2482  /  3424
size:  (375, 1242, 3)
load 2483  /  3424
size:  (375, 1242, 3)
load 2484  /  3424
size:  (375, 1242, 3)
load 2485  /  3424
size:  (376, 1241, 3)
load 2486  /  3424
size:  (375, 1242, 3)
load 2487  /  3424
size:  (375, 1242, 3)
load 2488  /  3424
size:  (375, 1242, 3)
load 2489  /  3424
size:  (375, 1242, 3)
load 2490  /  3424
size:  (375, 1242, 3)
load 2491  /  3424
size:  (375, 1242, 3)
load 2492  /  3424
size:  (375, 1242, 3)
load 2493  /  3424
size:  (375, 1242, 3)
load 2494  /  3424
size:  (374, 1238, 3)
load 2495  /  3424
size:  (375, 1242, 3)
load 2496  /  3424
size:  (375, 1242, 3)
load 2497  /  3424
size:  (375, 1242, 3)
load 2498  /  3424
size:  (375, 1242, 3)
load 2499  /  3424
size:  (374, 1238, 3)
load 2500  /  3424
size:  (375, 1242, 3)
load 2501  /  3424
size:  (374, 1238, 3)
load 2502  /  3424
size:  (375, 1242, 3)
load 2503  /  3424
size:  (375, 1242, 3)
load 2504  /  3424
size:  (375, 1242, 3)
load 2505  /  3424
size:  (375, 1242, 3)
load 2506  /  3424
size:  (375, 1242, 3)
load 2507  /  3424
size:  (375, 1242, 3)
load 2508  /  3424
size:  (370, 1224, 3)
load 2509  /  3424
size:  (375, 1242, 3)
load 2510  /  3424
size:  (375, 1242, 3)
load 2511  /  3424
size:  (375, 1242, 3)
load 2512  /  3424
size:  (375, 1242, 3)
load 2513  /  3424
size:  (375, 1242, 3)
load 2514  /  3424
size:  (370, 1224, 3)
load 2515  /  3424
size:  (376, 1241, 3)
load 2516  /  3424
size:  (375, 1242, 3)
load 2517  /  3424
size:  (374, 1238, 3)
load 2518  /  3424
size:  (370, 1224, 3)
load 2519  /  3424
size:  (375, 1242, 3)
load 2520  /  3424
size:  (375, 1242, 3)
load 2521  /  3424
size:  (375, 1242, 3)
load 2522  /  3424
size:  (375, 1242, 3)
load 2523  /  3424
size:  (375, 1242, 3)
load 2524  /  3424
size:  (375, 1242, 3)
load 2525  /  3424
size:  (375, 1242, 3)
load 2526  /  3424
size:  (375, 1242, 3)
load 2527  /  3424
size:  (376, 1241, 3)
load 2528  /  3424
size:  (375, 1242, 3)
load 2529  /  3424
size:  (374, 1238, 3)
load 2530  /  3424
size:  (375, 1242, 3)
load 2531  /  3424
size:  (375, 1242, 3)
load 2532  /  3424
size:  (375, 1242, 3)
load 2533  /  3424
size:  (375, 1242, 3)
load 2534  /  3424
size:  (375, 1242, 3)
load 2535  /  3424
size:  (376, 1241, 3)
load 2536  /  3424
size:  (376, 1241, 3)
load 2537  /  3424
size:  (375, 1242, 3)
load 2538  /  3424
size:  (375, 1242, 3)
load 2539  /  3424
size:  (375, 1242, 3)
load 2540  /  3424
size:  (375, 1242, 3)
load 2541  /  3424
size:  (375, 1242, 3)
load 2542  /  3424
size:  (375, 1242, 3)
load 2543  /  3424
size:  (376, 1241, 3)
load 2544  /  3424
size:  (375, 1242, 3)
load 2545  /  3424
size:  (375, 1242, 3)
load 2546  /  3424
size:  (375, 1242, 3)
load 2547  /  3424
size:  (375, 1242, 3)
load 2548  /  3424
size:  (375, 1242, 3)
load 2549  /  3424
size:  (375, 1242, 3)
load 2550  /  3424
size:  (375, 1242, 3)
load 2551  /  3424
size:  (375, 1242, 3)
load 2552  /  3424
size:  (375, 1242, 3)
load 2553  /  3424
size:  (375, 1242, 3)
load 2554  /  3424
size:  (375, 1242, 3)
load 2555  /  3424
size:  (374, 1238, 3)
load 2556  /  3424
size:  (375, 1242, 3)
load 2557  /  3424
size:  (375, 1242, 3)
load 2558  /  3424
size:  (375, 1242, 3)
load 2559  /  3424
size:  (375, 1242, 3)
load 2560  /  3424
size:  (375, 1242, 3)
load 2561  /  3424
size:  (375, 1242, 3)
load 2562  /  3424
size:  (374, 1238, 3)
load 2563  /  3424
size:  (375, 1242, 3)
load 2564  /  3424
size:  (375, 1242, 3)
load 2565  /  3424
size:  (375, 1242, 3)
load 2566  /  3424
size:  (375, 1242, 3)
load 2567  /  3424
size:  (375, 1242, 3)
load 2568  /  3424
size:  (375, 1242, 3)
load 2569  /  3424
size:  (370, 1224, 3)
load 2570  /  3424
size:  (375, 1242, 3)
load 2571  /  3424
size:  (376, 1241, 3)
load 2572  /  3424
size:  (375, 1242, 3)
load 2573  /  3424
size:  (375, 1242, 3)
load 2574  /  3424
size:  (375, 1242, 3)
load 2575  /  3424
size:  (375, 1242, 3)
load 2576  /  3424
size:  (375, 1242, 3)
load 2577  /  3424
size:  (375, 1242, 3)
load 2578  /  3424
size:  (375, 1242, 3)
load 2579  /  3424
size:  (376, 1241, 3)
load 2580  /  3424
size:  (375, 1242, 3)
load 2581  /  3424
size:  (375, 1242, 3)
load 2582  /  3424
size:  (375, 1242, 3)
load 2583  /  3424
size:  (375, 1242, 3)
load 2584  /  3424
size:  (375, 1242, 3)
load 2585  /  3424
size:  (375, 1242, 3)
load 2586  /  3424
size:  (375, 1242, 3)
load 2587  /  3424
size:  (375, 1242, 3)
load 2588  /  3424
size:  (375, 1242, 3)
load 2589  /  3424
size:  (375, 1242, 3)
load 2590  /  3424
size:  (375, 1242, 3)
load 2591  /  3424
size:  (375, 1242, 3)
load 2592  /  3424
size:  (375, 1242, 3)
load 2593  /  3424
size:  (376, 1241, 3)
load 2594  /  3424
size:  (376, 1241, 3)
load 2595  /  3424
size:  (375, 1242, 3)
load 2596  /  3424
size:  (375, 1242, 3)
load 2597  /  3424
size:  (375, 1242, 3)
load 2598  /  3424
size:  (375, 1242, 3)
load 2599  /  3424
size:  (376, 1241, 3)
load 2600  /  3424
size:  (375, 1242, 3)
load 2601  /  3424
size:  (375, 1242, 3)
load 2602  /  3424
size:  (376, 1241, 3)
load 2603  /  3424
size:  (375, 1242, 3)
load 2604  /  3424
size:  (375, 1242, 3)
load 2605  /  3424
size:  (375, 1242, 3)
load 2606  /  3424
size:  (375, 1242, 3)
load 2607  /  3424
size:  (375, 1242, 3)
load 2608  /  3424
size:  (374, 1238, 3)
load 2609  /  3424
size:  (375, 1242, 3)
load 2610  /  3424
size:  (375, 1242, 3)
load 2611  /  3424
size:  (375, 1242, 3)
load 2612  /  3424
size:  (376, 1241, 3)
load 2613  /  3424
size:  (375, 1242, 3)
load 2614  /  3424
size:  (375, 1242, 3)
load 2615  /  3424
size:  (375, 1242, 3)
load 2616  /  3424
size:  (375, 1242, 3)
load 2617  /  3424
size:  (375, 1242, 3)
load 2618  /  3424
size:  (375, 1242, 3)
load 2619  /  3424
size:  (375, 1242, 3)
load 2620  /  3424
size:  (375, 1242, 3)
load 2621  /  3424
size:  (375, 1242, 3)
load 2622  /  3424
size:  (376, 1241, 3)
load 2623  /  3424
size:  (375, 1242, 3)
load 2624  /  3424
size:  (375, 1242, 3)
load 2625  /  3424
size:  (370, 1224, 3)
load 2626  /  3424
size:  (374, 1238, 3)
load 2627  /  3424
size:  (375, 1242, 3)
load 2628  /  3424
size:  (375, 1242, 3)
load 2629  /  3424
size:  (375, 1242, 3)
load 2630  /  3424
size:  (375, 1242, 3)
load 2631  /  3424
size:  (375, 1242, 3)
load 2632  /  3424
size:  (375, 1242, 3)
load 2633  /  3424
size:  (375, 1242, 3)
load 2634  /  3424
size:  (370, 1224, 3)
load 2635  /  3424
size:  (375, 1242, 3)
load 2636  /  3424
size:  (375, 1242, 3)
load 2637  /  3424
size:  (370, 1224, 3)
load 2638  /  3424
size:  (375, 1242, 3)
load 2639  /  3424
size:  (375, 1242, 3)
load 2640  /  3424
size:  (375, 1242, 3)
load 2641  /  3424
size:  (375, 1242, 3)
load 2642  /  3424
size:  (376, 1241, 3)
load 2643  /  3424
size:  (375, 1242, 3)
load 2644  /  3424
size:  (375, 1242, 3)
load 2645  /  3424
size:  (375, 1242, 3)
load 2646  /  3424
size:  (375, 1242, 3)
load 2647  /  3424
size:  (375, 1242, 3)
load 2648  /  3424
size:  (375, 1242, 3)
load 2649  /  3424
size:  (375, 1242, 3)
load 2650  /  3424
size:  (376, 1241, 3)
load 2651  /  3424
size:  (376, 1241, 3)
load 2652  /  3424
size:  (370, 1224, 3)
load 2653  /  3424
size:  (375, 1242, 3)
load 2654  /  3424
size:  (375, 1242, 3)
load 2655  /  3424
size:  (375, 1242, 3)
load 2656  /  3424
size:  (375, 1242, 3)
load 2657  /  3424
size:  (376, 1241, 3)
load 2658  /  3424
size:  (375, 1242, 3)
load 2659  /  3424
size:  (375, 1242, 3)
load 2660  /  3424
size:  (375, 1242, 3)
load 2661  /  3424
size:  (375, 1242, 3)
load 2662  /  3424
size:  (375, 1242, 3)
load 2663  /  3424
size:  (375, 1242, 3)
load 2664  /  3424
size:  (375, 1242, 3)
load 2665  /  3424
size:  (375, 1242, 3)
load 2666  /  3424
size:  (375, 1242, 3)
load 2667  /  3424
size:  (375, 1242, 3)
load 2668  /  3424
size:  (375, 1242, 3)
load 2669  /  3424
size:  (375, 1242, 3)
load 2670  /  3424
size:  (375, 1242, 3)
load 2671  /  3424
size:  (375, 1242, 3)
load 2672  /  3424
size:  (375, 1242, 3)
load 2673  /  3424
size:  (376, 1241, 3)
load 2674  /  3424
size:  (375, 1242, 3)
load 2675  /  3424
size:  (375, 1242, 3)
load 2676  /  3424
size:  (375, 1242, 3)
load 2677  /  3424
size:  (375, 1242, 3)
load 2678  /  3424
size:  (375, 1242, 3)
load 2679  /  3424
size:  (375, 1242, 3)
load 2680  /  3424
size:  (375, 1242, 3)
load 2681  /  3424
size:  (375, 1242, 3)
load 2682  /  3424
size:  (375, 1242, 3)
load 2683  /  3424
size:  (376, 1241, 3)
load 2684  /  3424
size:  (375, 1242, 3)
load 2685  /  3424
size:  (375, 1242, 3)
load 2686  /  3424
size:  (375, 1242, 3)
load 2687  /  3424
size:  (375, 1242, 3)
load 2688  /  3424
size:  (375, 1242, 3)
load 2689  /  3424
size:  (375, 1242, 3)
load 2690  /  3424
size:  (375, 1242, 3)
load 2691  /  3424
size:  (375, 1242, 3)
load 2692  /  3424
size:  (375, 1242, 3)
load 2693  /  3424
size:  (375, 1242, 3)
load 2694  /  3424
size:  (375, 1242, 3)
load 2695  /  3424
size:  (375, 1242, 3)
load 2696  /  3424
size:  (376, 1241, 3)
load 2697  /  3424
size:  (375, 1242, 3)
load 2698  /  3424
size:  (375, 1242, 3)
load 2699  /  3424
size:  (375, 1242, 3)
load 2700  /  3424
size:  (375, 1242, 3)
load 2701  /  3424
size:  (375, 1242, 3)
load 2702  /  3424
size:  (375, 1242, 3)
load 2703  /  3424
size:  (376, 1241, 3)
load 2704  /  3424
size:  (375, 1242, 3)
load 2705  /  3424
size:  (375, 1242, 3)
load 2706  /  3424
size:  (375, 1242, 3)
load 2707  /  3424
size:  (375, 1242, 3)
load 2708  /  3424
size:  (370, 1224, 3)
load 2709  /  3424
size:  (375, 1242, 3)
load 2710  /  3424
size:  (375, 1242, 3)
load 2711  /  3424
size:  (374, 1238, 3)
load 2712  /  3424
size:  (375, 1242, 3)
load 2713  /  3424
size:  (375, 1242, 3)
load 2714  /  3424
size:  (376, 1241, 3)
load 2715  /  3424
size:  (375, 1242, 3)
load 2716  /  3424
size:  (375, 1242, 3)
load 2717  /  3424
size:  (376, 1241, 3)
load 2718  /  3424
size:  (370, 1224, 3)
load 2719  /  3424
size:  (375, 1242, 3)
load 2720  /  3424
size:  (375, 1242, 3)
load 2721  /  3424
size:  (375, 1242, 3)
load 2722  /  3424
size:  (375, 1242, 3)
load 2723  /  3424
size:  (375, 1242, 3)
load 2724  /  3424
size:  (375, 1242, 3)
load 2725  /  3424
size:  (375, 1242, 3)
load 2726  /  3424
size:  (376, 1241, 3)
load 2727  /  3424
size:  (375, 1242, 3)
load 2728  /  3424
size:  (375, 1242, 3)
load 2729  /  3424
size:  (375, 1242, 3)
load 2730  /  3424
size:  (375, 1242, 3)
load 2731  /  3424
size:  (375, 1242, 3)
load 2732  /  3424
size:  (375, 1242, 3)
load 2733  /  3424
size:  (375, 1242, 3)
load 2734  /  3424
size:  (370, 1224, 3)
load 2735  /  3424
size:  (375, 1242, 3)
load 2736  /  3424
size:  (375, 1242, 3)
load 2737  /  3424
size:  (375, 1242, 3)
load 2738  /  3424
size:  (375, 1242, 3)
load 2739  /  3424
size:  (375, 1242, 3)
load 2740  /  3424
size:  (375, 1242, 3)
load 2741  /  3424
size:  (375, 1242, 3)
load 2742  /  3424
size:  (375, 1242, 3)
load 2743  /  3424
size:  (375, 1242, 3)
load 2744  /  3424
size:  (375, 1242, 3)
load 2745  /  3424
size:  (376, 1241, 3)
load 2746  /  3424
size:  (375, 1242, 3)
load 2747  /  3424
size:  (375, 1242, 3)
load 2748  /  3424
size:  (375, 1242, 3)
load 2749  /  3424
size:  (376, 1241, 3)
load 2750  /  3424
size:  (375, 1242, 3)
load 2751  /  3424
size:  (375, 1242, 3)
load 2752  /  3424
size:  (376, 1241, 3)
load 2753  /  3424
size:  (375, 1242, 3)
load 2754  /  3424
size:  (375, 1242, 3)
load 2755  /  3424
size:  (375, 1242, 3)
load 2756  /  3424
size:  (375, 1242, 3)
load 2757  /  3424
size:  (375, 1242, 3)
load 2758  /  3424
size:  (375, 1242, 3)
load 2759  /  3424
size:  (375, 1242, 3)
load 2760  /  3424
size:  (375, 1242, 3)
load 2761  /  3424
size:  (376, 1241, 3)
load 2762  /  3424
size:  (375, 1242, 3)
load 2763  /  3424
size:  (375, 1242, 3)
load 2764  /  3424
size:  (375, 1242, 3)
load 2765  /  3424
size:  (374, 1238, 3)
load 2766  /  3424
size:  (375, 1242, 3)
load 2767  /  3424
size:  (370, 1224, 3)
load 2768  /  3424
size:  (375, 1242, 3)
load 2769  /  3424
size:  (375, 1242, 3)
load 2770  /  3424
size:  (375, 1242, 3)
load 2771  /  3424
size:  (375, 1242, 3)
load 2772  /  3424
size:  (370, 1224, 3)
load 2773  /  3424
size:  (374, 1238, 3)
load 2774  /  3424
size:  (375, 1242, 3)
load 2775  /  3424
size:  (375, 1242, 3)
load 2776  /  3424
size:  (375, 1242, 3)
load 2777  /  3424
size:  (375, 1242, 3)
load 2778  /  3424
size:  (375, 1242, 3)
load 2779  /  3424
size:  (375, 1242, 3)
load 2780  /  3424
size:  (375, 1242, 3)
load 2781  /  3424
size:  (375, 1242, 3)
load 2782  /  3424
size:  (375, 1242, 3)
load 2783  /  3424
size:  (375, 1242, 3)
load 2784  /  3424
size:  (375, 1242, 3)
load 2785  /  3424
size:  (375, 1242, 3)
load 2786  /  3424
size:  (375, 1242, 3)
load 2787  /  3424
size:  (375, 1242, 3)
load 2788  /  3424
size:  (375, 1242, 3)
load 2789  /  3424
size:  (370, 1224, 3)
load 2790  /  3424
size:  (375, 1242, 3)
load 2791  /  3424
size:  (375, 1242, 3)
load 2792  /  3424
size:  (375, 1242, 3)
load 2793  /  3424
size:  (376, 1241, 3)
load 2794  /  3424
size:  (375, 1242, 3)
load 2795  /  3424
size:  (375, 1242, 3)
load 2796  /  3424
size:  (376, 1241, 3)
load 2797  /  3424
size:  (375, 1242, 3)
load 2798  /  3424
size:  (370, 1224, 3)
load 2799  /  3424
size:  (376, 1241, 3)
load 2800  /  3424
size:  (375, 1242, 3)
load 2801  /  3424
size:  (375, 1242, 3)
load 2802  /  3424
size:  (375, 1242, 3)
load 2803  /  3424
size:  (375, 1242, 3)
load 2804  /  3424
size:  (375, 1242, 3)
load 2805  /  3424
size:  (375, 1242, 3)
load 2806  /  3424
size:  (375, 1242, 3)
load 2807  /  3424
size:  (375, 1242, 3)
load 2808  /  3424
size:  (374, 1238, 3)
load 2809  /  3424
size:  (375, 1242, 3)
load 2810  /  3424
size:  (374, 1238, 3)
load 2811  /  3424
size:  (375, 1242, 3)
load 2812  /  3424
size:  (375, 1242, 3)
load 2813  /  3424
size:  (375, 1242, 3)
load 2814  /  3424
size:  (375, 1242, 3)
load 2815  /  3424
size:  (370, 1224, 3)
load 2816  /  3424
size:  (375, 1242, 3)
load 2817  /  3424
size:  (376, 1241, 3)
load 2818  /  3424
size:  (375, 1242, 3)
load 2819  /  3424
size:  (375, 1242, 3)
load 2820  /  3424
size:  (374, 1238, 3)
load 2821  /  3424
size:  (375, 1242, 3)
load 2822  /  3424
size:  (375, 1242, 3)
load 2823  /  3424
size:  (375, 1242, 3)
load 2824  /  3424
size:  (375, 1242, 3)
load 2825  /  3424
size:  (375, 1242, 3)
load 2826  /  3424
size:  (376, 1241, 3)
load 2827  /  3424
size:  (375, 1242, 3)
load 2828  /  3424
size:  (375, 1242, 3)
load 2829  /  3424
size:  (375, 1242, 3)
load 2830  /  3424
size:  (375, 1242, 3)
load 2831  /  3424
size:  (375, 1242, 3)
load 2832  /  3424
size:  (375, 1242, 3)
load 2833  /  3424
size:  (375, 1242, 3)
load 2834  /  3424
size:  (375, 1242, 3)
load 2835  /  3424
size:  (375, 1242, 3)
load 2836  /  3424
size:  (375, 1242, 3)
load 2837  /  3424
size:  (375, 1242, 3)
load 2838  /  3424
size:  (375, 1242, 3)
load 2839  /  3424
size:  (375, 1242, 3)
load 2840  /  3424
size:  (375, 1242, 3)
load 2841  /  3424
size:  (375, 1242, 3)
load 2842  /  3424
size:  (370, 1224, 3)
load 2843  /  3424
size:  (375, 1242, 3)
load 2844  /  3424
size:  (375, 1242, 3)
load 2845  /  3424
size:  (375, 1242, 3)
load 2846  /  3424
size:  (375, 1242, 3)
load 2847  /  3424
size:  (375, 1242, 3)
load 2848  /  3424
size:  (375, 1242, 3)
load 2849  /  3424
size:  (375, 1242, 3)
load 2850  /  3424
size:  (375, 1242, 3)
load 2851  /  3424
size:  (375, 1242, 3)
load 2852  /  3424
size:  (375, 1242, 3)
load 2853  /  3424
size:  (375, 1242, 3)
load 2854  /  3424
size:  (375, 1242, 3)
load 2855  /  3424
size:  (376, 1241, 3)
load 2856  /  3424
size:  (375, 1242, 3)
load 2857  /  3424
size:  (375, 1242, 3)
load 2858  /  3424
size:  (375, 1242, 3)
load 2859  /  3424
size:  (375, 1242, 3)
load 2860  /  3424
size:  (375, 1242, 3)
load 2861  /  3424
size:  (375, 1242, 3)
load 2862  /  3424
size:  (375, 1242, 3)
load 2863  /  3424
size:  (375, 1242, 3)
load 2864  /  3424
size:  (375, 1242, 3)
load 2865  /  3424
size:  (375, 1242, 3)
load 2866  /  3424
size:  (375, 1242, 3)
load 2867  /  3424
size:  (375, 1242, 3)
load 2868  /  3424
size:  (375, 1242, 3)
load 2869  /  3424
size:  (375, 1242, 3)
load 2870  /  3424
size:  (375, 1242, 3)
load 2871  /  3424
size:  (375, 1242, 3)
load 2872  /  3424
size:  (376, 1241, 3)
load 2873  /  3424
size:  (376, 1241, 3)
load 2874  /  3424
size:  (375, 1242, 3)
load 2875  /  3424
size:  (375, 1242, 3)
load 2876  /  3424
size:  (375, 1242, 3)
load 2877  /  3424
size:  (375, 1242, 3)
load 2878  /  3424
size:  (375, 1242, 3)
load 2879  /  3424
size:  (375, 1242, 3)
load 2880  /  3424
size:  (375, 1242, 3)
load 2881  /  3424
size:  (375, 1242, 3)
load 2882  /  3424
size:  (375, 1242, 3)
load 2883  /  3424
size:  (375, 1242, 3)
load 2884  /  3424
size:  (375, 1242, 3)
load 2885  /  3424
size:  (375, 1242, 3)
load 2886  /  3424
size:  (375, 1242, 3)
load 2887  /  3424
size:  (375, 1242, 3)
load 2888  /  3424
size:  (375, 1242, 3)
load 2889  /  3424
size:  (375, 1242, 3)
load 2890  /  3424
size:  (375, 1242, 3)
load 2891  /  3424
size:  (375, 1242, 3)
load 2892  /  3424
size:  (375, 1242, 3)
load 2893  /  3424
size:  (375, 1242, 3)
load 2894  /  3424
size:  (375, 1242, 3)
load 2895  /  3424
size:  (375, 1242, 3)
load 2896  /  3424
size:  (375, 1242, 3)
load 2897  /  3424
size:  (375, 1242, 3)
load 2898  /  3424
size:  (376, 1241, 3)
load 2899  /  3424
size:  (370, 1224, 3)
load 2900  /  3424
size:  (375, 1242, 3)
load 2901  /  3424
size:  (375, 1242, 3)
load 2902  /  3424
size:  (375, 1242, 3)
load 2903  /  3424
size:  (370, 1224, 3)
load 2904  /  3424
size:  (375, 1242, 3)
load 2905  /  3424
size:  (375, 1242, 3)
load 2906  /  3424
size:  (375, 1242, 3)
load 2907  /  3424
size:  (375, 1242, 3)
load 2908  /  3424
size:  (375, 1242, 3)
load 2909  /  3424
size:  (376, 1241, 3)
load 2910  /  3424
size:  (376, 1241, 3)
load 2911  /  3424
size:  (374, 1238, 3)
load 2912  /  3424
size:  (375, 1242, 3)
load 2913  /  3424
size:  (375, 1242, 3)
load 2914  /  3424
size:  (374, 1238, 3)
load 2915  /  3424
size:  (370, 1224, 3)
load 2916  /  3424
size:  (375, 1242, 3)
load 2917  /  3424
size:  (375, 1242, 3)
load 2918  /  3424
size:  (375, 1242, 3)
load 2919  /  3424
size:  (375, 1242, 3)
load 2920  /  3424
size:  (375, 1242, 3)
load 2921  /  3424
size:  (374, 1238, 3)
load 2922  /  3424
size:  (375, 1242, 3)
load 2923  /  3424
size:  (374, 1238, 3)
load 2924  /  3424
size:  (375, 1242, 3)
load 2925  /  3424
size:  (375, 1242, 3)
load 2926  /  3424
size:  (375, 1242, 3)
load 2927  /  3424
size:  (375, 1242, 3)
load 2928  /  3424
size:  (375, 1242, 3)
load 2929  /  3424
size:  (375, 1242, 3)
load 2930  /  3424
size:  (375, 1242, 3)
load 2931  /  3424
size:  (376, 1241, 3)
load 2932  /  3424
size:  (375, 1242, 3)
load 2933  /  3424
size:  (375, 1242, 3)
load 2934  /  3424
size:  (375, 1242, 3)
load 2935  /  3424
size:  (374, 1238, 3)
load 2936  /  3424
size:  (375, 1242, 3)
load 2937  /  3424
size:  (374, 1238, 3)
load 2938  /  3424
size:  (375, 1242, 3)
load 2939  /  3424
size:  (375, 1242, 3)
load 2940  /  3424
size:  (375, 1242, 3)
load 2941  /  3424
size:  (375, 1242, 3)
load 2942  /  3424
size:  (374, 1238, 3)
load 2943  /  3424
size:  (375, 1242, 3)
load 2944  /  3424
size:  (375, 1242, 3)
load 2945  /  3424
size:  (370, 1224, 3)
load 2946  /  3424
size:  (376, 1241, 3)
load 2947  /  3424
size:  (375, 1242, 3)
load 2948  /  3424
size:  (370, 1224, 3)
load 2949  /  3424
size:  (375, 1242, 3)
load 2950  /  3424
size:  (374, 1238, 3)
load 2951  /  3424
size:  (375, 1242, 3)
load 2952  /  3424
size:  (375, 1242, 3)
load 2953  /  3424
size:  (375, 1242, 3)
load 2954  /  3424
size:  (375, 1242, 3)
load 2955  /  3424
size:  (375, 1242, 3)
load 2956  /  3424
size:  (375, 1242, 3)
load 2957  /  3424
size:  (375, 1242, 3)
load 2958  /  3424
size:  (375, 1242, 3)
load 2959  /  3424
size:  (375, 1242, 3)
load 2960  /  3424
size:  (375, 1242, 3)
load 2961  /  3424
size:  (375, 1242, 3)
load 2962  /  3424
size:  (375, 1242, 3)
load 2963  /  3424
size:  (375, 1242, 3)
load 2964  /  3424
size:  (375, 1242, 3)
load 2965  /  3424
size:  (375, 1242, 3)
load 2966  /  3424
size:  (375, 1242, 3)
load 2967  /  3424
size:  (375, 1242, 3)
load 2968  /  3424
size:  (375, 1242, 3)
load 2969  /  3424
size:  (375, 1242, 3)
load 2970  /  3424
size:  (375, 1242, 3)
load 2971  /  3424
size:  (375, 1242, 3)
load 2972  /  3424
size:  (375, 1242, 3)
load 2973  /  3424
size:  (375, 1242, 3)
load 2974  /  3424
size:  (375, 1242, 3)
load 2975  /  3424
size:  (375, 1242, 3)
load 2976  /  3424
size:  (375, 1242, 3)
load 2977  /  3424
size:  (375, 1242, 3)
load 2978  /  3424
size:  (375, 1242, 3)
load 2979  /  3424
size:  (375, 1242, 3)
load 2980  /  3424
size:  (375, 1242, 3)
load 2981  /  3424
size:  (375, 1242, 3)
load 2982  /  3424
size:  (375, 1242, 3)
load 2983  /  3424
size:  (375, 1242, 3)
load 2984  /  3424
size:  (375, 1242, 3)
load 2985  /  3424
size:  (375, 1242, 3)
load 2986  /  3424
size:  (375, 1242, 3)
load 2987  /  3424
size:  (375, 1242, 3)
load 2988  /  3424
size:  (375, 1242, 3)
load 2989  /  3424
size:  (375, 1242, 3)
load 2990  /  3424
size:  (375, 1242, 3)
load 2991  /  3424
size:  (375, 1242, 3)
load 2992  /  3424
size:  (375, 1242, 3)
load 2993  /  3424
size:  (375, 1242, 3)
load 2994  /  3424
size:  (375, 1242, 3)
load 2995  /  3424
size:  (375, 1242, 3)
load 2996  /  3424
size:  (375, 1242, 3)
load 2997  /  3424
size:  (375, 1242, 3)
load 2998  /  3424
size:  (375, 1242, 3)
load 2999  /  3424
size:  (375, 1242, 3)
load 3000  /  3424
size:  (375, 1242, 3)
load 3001  /  3424
size:  (375, 1242, 3)
load 3002  /  3424
size:  (375, 1242, 3)
load 3003  /  3424
size:  (375, 1242, 3)
load 3004  /  3424
size:  (375, 1242, 3)
load 3005  /  3424
size:  (375, 1242, 3)
load 3006  /  3424
size:  (375, 1242, 3)
load 3007  /  3424
size:  (376, 1241, 3)
load 3008  /  3424
size:  (375, 1242, 3)
load 3009  /  3424
size:  (375, 1242, 3)
load 3010  /  3424
size:  (375, 1242, 3)
load 3011  /  3424
size:  (375, 1242, 3)
load 3012  /  3424
size:  (375, 1242, 3)
load 3013  /  3424
size:  (375, 1242, 3)
load 3014  /  3424
size:  (375, 1242, 3)
load 3015  /  3424
size:  (375, 1242, 3)
load 3016  /  3424
size:  (376, 1241, 3)
load 3017  /  3424
size:  (375, 1242, 3)
load 3018  /  3424
size:  (375, 1242, 3)
load 3019  /  3424
size:  (375, 1242, 3)
load 3020  /  3424
size:  (375, 1242, 3)
load 3021  /  3424
size:  (375, 1242, 3)
load 3022  /  3424
size:  (375, 1242, 3)
load 3023  /  3424
size:  (375, 1242, 3)
load 3024  /  3424
size:  (376, 1241, 3)
load 3025  /  3424
size:  (375, 1242, 3)
load 3026  /  3424
size:  (375, 1242, 3)
load 3027  /  3424
size:  (374, 1238, 3)
load 3028  /  3424
size:  (375, 1242, 3)
load 3029  /  3424
size:  (375, 1242, 3)
load 3030  /  3424
size:  (376, 1241, 3)
load 3031  /  3424
size:  (375, 1242, 3)
load 3032  /  3424
size:  (375, 1242, 3)
load 3033  /  3424
size:  (375, 1242, 3)
load 3034  /  3424
size:  (375, 1242, 3)
load 3035  /  3424
size:  (370, 1224, 3)
load 3036  /  3424
size:  (375, 1242, 3)
load 3037  /  3424
size:  (375, 1242, 3)
load 3038  /  3424
size:  (375, 1242, 3)
load 3039  /  3424
size:  (375, 1242, 3)
load 3040  /  3424
size:  (375, 1242, 3)
load 3041  /  3424
size:  (375, 1242, 3)
load 3042  /  3424
size:  (375, 1242, 3)
load 3043  /  3424
size:  (375, 1242, 3)
load 3044  /  3424
size:  (375, 1242, 3)
load 3045  /  3424
size:  (375, 1242, 3)
load 3046  /  3424
size:  (375, 1242, 3)
load 3047  /  3424
size:  (375, 1242, 3)
load 3048  /  3424
size:  (375, 1242, 3)
load 3049  /  3424
size:  (375, 1242, 3)
load 3050  /  3424
size:  (375, 1242, 3)
load 3051  /  3424
size:  (375, 1242, 3)
load 3052  /  3424
size:  (375, 1242, 3)
load 3053  /  3424
size:  (375, 1242, 3)
load 3054  /  3424
size:  (375, 1242, 3)
load 3055  /  3424
size:  (376, 1241, 3)
load 3056  /  3424
size:  (375, 1242, 3)
load 3057  /  3424
size:  (375, 1242, 3)
load 3058  /  3424
size:  (375, 1242, 3)
load 3059  /  3424
size:  (375, 1242, 3)
load 3060  /  3424
size:  (375, 1242, 3)
load 3061  /  3424
size:  (375, 1242, 3)
load 3062  /  3424
size:  (375, 1242, 3)
load 3063  /  3424
size:  (375, 1242, 3)
load 3064  /  3424
size:  (370, 1224, 3)
load 3065  /  3424
size:  (374, 1238, 3)
load 3066  /  3424
size:  (375, 1242, 3)
load 3067  /  3424
size:  (375, 1242, 3)
load 3068  /  3424
size:  (375, 1242, 3)
load 3069  /  3424
size:  (375, 1242, 3)
load 3070  /  3424
size:  (375, 1242, 3)
load 3071  /  3424
size:  (375, 1242, 3)
load 3072  /  3424
size:  (375, 1242, 3)
load 3073  /  3424
size:  (375, 1242, 3)
load 3074  /  3424
size:  (375, 1242, 3)
load 3075  /  3424
size:  (375, 1242, 3)
load 3076  /  3424
size:  (375, 1242, 3)
load 3077  /  3424
size:  (375, 1242, 3)
load 3078  /  3424
size:  (375, 1242, 3)
load 3079  /  3424
size:  (375, 1242, 3)
load 3080  /  3424
size:  (375, 1242, 3)
load 3081  /  3424
size:  (374, 1238, 3)
load 3082  /  3424
size:  (375, 1242, 3)
load 3083  /  3424
size:  (375, 1242, 3)
load 3084  /  3424
size:  (375, 1242, 3)
load 3085  /  3424
size:  (376, 1241, 3)
load 3086  /  3424
size:  (375, 1242, 3)
load 3087  /  3424
size:  (375, 1242, 3)
load 3088  /  3424
size:  (376, 1241, 3)
load 3089  /  3424
size:  (376, 1241, 3)
load 3090  /  3424
size:  (375, 1242, 3)
load 3091  /  3424
size:  (375, 1242, 3)
load 3092  /  3424
size:  (375, 1242, 3)
load 3093  /  3424
size:  (375, 1242, 3)
load 3094  /  3424
size:  (376, 1241, 3)
load 3095  /  3424
size:  (375, 1242, 3)
load 3096  /  3424
size:  (375, 1242, 3)
load 3097  /  3424
size:  (375, 1242, 3)
load 3098  /  3424
size:  (375, 1242, 3)
load 3099  /  3424
size:  (375, 1242, 3)
load 3100  /  3424
size:  (375, 1242, 3)
load 3101  /  3424
size:  (374, 1238, 3)
load 3102  /  3424
size:  (375, 1242, 3)
load 3103  /  3424
size:  (375, 1242, 3)
load 3104  /  3424
size:  (375, 1242, 3)
load 3105  /  3424
size:  (375, 1242, 3)
load 3106  /  3424
size:  (375, 1242, 3)
load 3107  /  3424
size:  (370, 1224, 3)
load 3108  /  3424
size:  (375, 1242, 3)
load 3109  /  3424
size:  (375, 1242, 3)
load 3110  /  3424
size:  (374, 1238, 3)
load 3111  /  3424
size:  (375, 1242, 3)
load 3112  /  3424
size:  (375, 1242, 3)
load 3113  /  3424
size:  (375, 1242, 3)
load 3114  /  3424
size:  (375, 1242, 3)
load 3115  /  3424
size:  (375, 1242, 3)
load 3116  /  3424
size:  (375, 1242, 3)
load 3117  /  3424
size:  (375, 1242, 3)
load 3118  /  3424
size:  (375, 1242, 3)
load 3119  /  3424
size:  (375, 1242, 3)
load 3120  /  3424
size:  (375, 1242, 3)
load 3121  /  3424
size:  (375, 1242, 3)
load 3122  /  3424
size:  (376, 1241, 3)
load 3123  /  3424
size:  (376, 1241, 3)
load 3124  /  3424
size:  (375, 1242, 3)
load 3125  /  3424
size:  (375, 1242, 3)
load 3126  /  3424
size:  (376, 1241, 3)
load 3127  /  3424
size:  (375, 1242, 3)
load 3128  /  3424
size:  (375, 1242, 3)
load 3129  /  3424
size:  (376, 1241, 3)
load 3130  /  3424
size:  (375, 1242, 3)
load 3131  /  3424
size:  (375, 1242, 3)
load 3132  /  3424
size:  (375, 1242, 3)
load 3133  /  3424
size:  (375, 1242, 3)
load 3134  /  3424
size:  (375, 1242, 3)
load 3135  /  3424
size:  (375, 1242, 3)
load 3136  /  3424
size:  (375, 1242, 3)
load 3137  /  3424
size:  (375, 1242, 3)
load 3138  /  3424
size:  (375, 1242, 3)
load 3139  /  3424
size:  (375, 1242, 3)
load 3140  /  3424
size:  (375, 1242, 3)
load 3141  /  3424
size:  (375, 1242, 3)
load 3142  /  3424
size:  (376, 1241, 3)
load 3143  /  3424
size:  (375, 1242, 3)
load 3144  /  3424
size:  (375, 1242, 3)
load 3145  /  3424
size:  (375, 1242, 3)
load 3146  /  3424
size:  (375, 1242, 3)
load 3147  /  3424
size:  (375, 1242, 3)
load 3148  /  3424
size:  (375, 1242, 3)
load 3149  /  3424
size:  (375, 1242, 3)
load 3150  /  3424
size:  (375, 1242, 3)
load 3151  /  3424
size:  (376, 1241, 3)
load 3152  /  3424
size:  (374, 1238, 3)
load 3153  /  3424
size:  (375, 1242, 3)
load 3154  /  3424
size:  (375, 1242, 3)
load 3155  /  3424
size:  (375, 1242, 3)
load 3156  /  3424
size:  (375, 1242, 3)
load 3157  /  3424
size:  (375, 1242, 3)
load 3158  /  3424
size:  (376, 1241, 3)
load 3159  /  3424
size:  (375, 1242, 3)
load 3160  /  3424
size:  (375, 1242, 3)
load 3161  /  3424
size:  (374, 1238, 3)
load 3162  /  3424
size:  (375, 1242, 3)
load 3163  /  3424
size:  (375, 1242, 3)
load 3164  /  3424
size:  (376, 1241, 3)
load 3165  /  3424
size:  (375, 1242, 3)
load 3166  /  3424
size:  (375, 1242, 3)
load 3167  /  3424
size:  (375, 1242, 3)
load 3168  /  3424
size:  (375, 1242, 3)
load 3169  /  3424
size:  (376, 1241, 3)
load 3170  /  3424
size:  (375, 1242, 3)
load 3171  /  3424
size:  (375, 1242, 3)
load 3172  /  3424
size:  (375, 1242, 3)
load 3173  /  3424
size:  (375, 1242, 3)
load 3174  /  3424
size:  (375, 1242, 3)
load 3175  /  3424
size:  (375, 1242, 3)
load 3176  /  3424
size:  (375, 1242, 3)
load 3177  /  3424
size:  (375, 1242, 3)
load 3178  /  3424
size:  (375, 1242, 3)
load 3179  /  3424
size:  (376, 1241, 3)
load 3180  /  3424
size:  (375, 1242, 3)
load 3181  /  3424
size:  (375, 1242, 3)
load 3182  /  3424
size:  (375, 1242, 3)
load 3183  /  3424
size:  (375, 1242, 3)
load 3184  /  3424
size:  (375, 1242, 3)
load 3185  /  3424
size:  (375, 1242, 3)
load 3186  /  3424
size:  (370, 1224, 3)
load 3187  /  3424
size:  (375, 1242, 3)
load 3188  /  3424
size:  (375, 1242, 3)
load 3189  /  3424
size:  (375, 1242, 3)
load 3190  /  3424
size:  (375, 1242, 3)
load 3191  /  3424
size:  (375, 1242, 3)
load 3192  /  3424
size:  (375, 1242, 3)
load 3193  /  3424
size:  (376, 1241, 3)
load 3194  /  3424
size:  (375, 1242, 3)
load 3195  /  3424
size:  (375, 1242, 3)
load 3196  /  3424
size:  (375, 1242, 3)
load 3197  /  3424
size:  (375, 1242, 3)
load 3198  /  3424
size:  (376, 1241, 3)
load 3199  /  3424
size:  (375, 1242, 3)
load 3200  /  3424
size:  (375, 1242, 3)
load 3201  /  3424
size:  (375, 1242, 3)
load 3202  /  3424
size:  (375, 1242, 3)
load 3203  /  3424
size:  (375, 1242, 3)
load 3204  /  3424
size:  (375, 1242, 3)
load 3205  /  3424
size:  (375, 1242, 3)
load 3206  /  3424
size:  (375, 1242, 3)
load 3207  /  3424
size:  (375, 1242, 3)
load 3208  /  3424
size:  (375, 1242, 3)
load 3209  /  3424
size:  (375, 1242, 3)
load 3210  /  3424
size:  (375, 1242, 3)
load 3211  /  3424
size:  (375, 1242, 3)
load 3212  /  3424
size:  (375, 1242, 3)
load 3213  /  3424
size:  (375, 1242, 3)
load 3214  /  3424
size:  (375, 1242, 3)
load 3215  /  3424
size:  (375, 1242, 3)
load 3216  /  3424
size:  (375, 1242, 3)
load 3217  /  3424
size:  (375, 1242, 3)
load 3218  /  3424
size:  (375, 1242, 3)
load 3219  /  3424
size:  (375, 1242, 3)
load 3220  /  3424
size:  (375, 1242, 3)
load 3221  /  3424
size:  (375, 1242, 3)
load 3222  /  3424
size:  (375, 1242, 3)
load 3223  /  3424
size:  (375, 1242, 3)
load 3224  /  3424
size:  (375, 1242, 3)
load 3225  /  3424
size:  (375, 1242, 3)
load 3226  /  3424
size:  (375, 1242, 3)
load 3227  /  3424
size:  (375, 1242, 3)
load 3228  /  3424
size:  (375, 1242, 3)
load 3229  /  3424
size:  (375, 1242, 3)
load 3230  /  3424
size:  (375, 1242, 3)
load 3231  /  3424
size:  (375, 1242, 3)
load 3232  /  3424
size:  (375, 1242, 3)
load 3233  /  3424
size:  (375, 1242, 3)
load 3234  /  3424
size:  (375, 1242, 3)
load 3235  /  3424
size:  (375, 1242, 3)
load 3236  /  3424
size:  (375, 1242, 3)
load 3237  /  3424
size:  (375, 1242, 3)
load 3238  /  3424
size:  (375, 1242, 3)
load 3239  /  3424
size:  (375, 1242, 3)
load 3240  /  3424
size:  (375, 1242, 3)
load 3241  /  3424
size:  (375, 1242, 3)
load 3242  /  3424
size:  (375, 1242, 3)
load 3243  /  3424
size:  (375, 1242, 3)
load 3244  /  3424
size:  (375, 1242, 3)
load 3245  /  3424
size:  (375, 1242, 3)
load 3246  /  3424
size:  (374, 1238, 3)
load 3247  /  3424
size:  (375, 1242, 3)
load 3248  /  3424
size:  (375, 1242, 3)
load 3249  /  3424
size:  (375, 1242, 3)
load 3250  /  3424
size:  (375, 1242, 3)
load 3251  /  3424
size:  (375, 1242, 3)
load 3252  /  3424
size:  (375, 1242, 3)
load 3253  /  3424
size:  (375, 1242, 3)
load 3254  /  3424
size:  (375, 1242, 3)
load 3255  /  3424
size:  (375, 1242, 3)
load 3256  /  3424
size:  (375, 1242, 3)
load 3257  /  3424
size:  (375, 1242, 3)
load 3258  /  3424
size:  (375, 1242, 3)
load 3259  /  3424
size:  (375, 1242, 3)
load 3260  /  3424
size:  (375, 1242, 3)
load 3261  /  3424
size:  (375, 1242, 3)
load 3262  /  3424
size:  (375, 1242, 3)
load 3263  /  3424
size:  (375, 1242, 3)
load 3264  /  3424
size:  (375, 1242, 3)
load 3265  /  3424
size:  (375, 1242, 3)
load 3266  /  3424
size:  (374, 1238, 3)
load 3267  /  3424
size:  (376, 1241, 3)
load 3268  /  3424
size:  (375, 1242, 3)
load 3269  /  3424
size:  (375, 1242, 3)
load 3270  /  3424
size:  (375, 1242, 3)
load 3271  /  3424
size:  (375, 1242, 3)
load 3272  /  3424
size:  (375, 1242, 3)
load 3273  /  3424
size:  (375, 1242, 3)
load 3274  /  3424
size:  (374, 1238, 3)
load 3275  /  3424
size:  (375, 1242, 3)
load 3276  /  3424
size:  (375, 1242, 3)
load 3277  /  3424
size:  (375, 1242, 3)
load 3278  /  3424
size:  (375, 1242, 3)
load 3279  /  3424
size:  (375, 1242, 3)
load 3280  /  3424
size:  (375, 1242, 3)
load 3281  /  3424
size:  (375, 1242, 3)
load 3282  /  3424
size:  (375, 1242, 3)
load 3283  /  3424
size:  (375, 1242, 3)
load 3284  /  3424
size:  (375, 1242, 3)
load 3285  /  3424
size:  (375, 1242, 3)
load 3286  /  3424
size:  (375, 1242, 3)
load 3287  /  3424
size:  (375, 1242, 3)
load 3288  /  3424
size:  (375, 1242, 3)
load 3289  /  3424
size:  (375, 1242, 3)
load 3290  /  3424
size:  (375, 1242, 3)
load 3291  /  3424
size:  (375, 1242, 3)
load 3292  /  3424
size:  (375, 1242, 3)
load 3293  /  3424
size:  (375, 1242, 3)
load 3294  /  3424
size:  (375, 1242, 3)
load 3295  /  3424
size:  (374, 1238, 3)
load 3296  /  3424
size:  (375, 1242, 3)
load 3297  /  3424
size:  (375, 1242, 3)
load 3298  /  3424
size:  (375, 1242, 3)
load 3299  /  3424
size:  (375, 1242, 3)
load 3300  /  3424
size:  (375, 1242, 3)
load 3301  /  3424
size:  (375, 1242, 3)
load 3302  /  3424
size:  (375, 1242, 3)
load 3303  /  3424
size:  (375, 1242, 3)
load 3304  /  3424
size:  (375, 1242, 3)
load 3305  /  3424
size:  (375, 1242, 3)
load 3306  /  3424
size:  (375, 1242, 3)
load 3307  /  3424
size:  (374, 1238, 3)
load 3308  /  3424
size:  (375, 1242, 3)
load 3309  /  3424
size:  (375, 1242, 3)
load 3310  /  3424
size:  (375, 1242, 3)
load 3311  /  3424
size:  (370, 1224, 3)
load 3312  /  3424
size:  (375, 1242, 3)
load 3313  /  3424
size:  (375, 1242, 3)
load 3314  /  3424
size:  (375, 1242, 3)
load 3315  /  3424
size:  (375, 1242, 3)
load 3316  /  3424
size:  (375, 1242, 3)
load 3317  /  3424
size:  (375, 1242, 3)
load 3318  /  3424
size:  (375, 1242, 3)
load 3319  /  3424
size:  (375, 1242, 3)
load 3320  /  3424
size:  (376, 1241, 3)
load 3321  /  3424
size:  (376, 1241, 3)
load 3322  /  3424
size:  (375, 1242, 3)
load 3323  /  3424
size:  (375, 1242, 3)
load 3324  /  3424
size:  (375, 1242, 3)
load 3325  /  3424
size:  (375, 1242, 3)
load 3326  /  3424
size:  (375, 1242, 3)
load 3327  /  3424
size:  (375, 1242, 3)
load 3328  /  3424
size:  (375, 1242, 3)
load 3329  /  3424
size:  (375, 1242, 3)
load 3330  /  3424
size:  (370, 1224, 3)
load 3331  /  3424
size:  (375, 1242, 3)
load 3332  /  3424
size:  (375, 1242, 3)
load 3333  /  3424
size:  (375, 1242, 3)
load 3334  /  3424
size:  (375, 1242, 3)
load 3335  /  3424
size:  (375, 1242, 3)
load 3336  /  3424
size:  (375, 1242, 3)
load 3337  /  3424
size:  (375, 1242, 3)
load 3338  /  3424
size:  (375, 1242, 3)
load 3339  /  3424
size:  (375, 1242, 3)
load 3340  /  3424
size:  (375, 1242, 3)
load 3341  /  3424
size:  (374, 1238, 3)
load 3342  /  3424
size:  (375, 1242, 3)
load 3343  /  3424
size:  (375, 1242, 3)
load 3344  /  3424
size:  (375, 1242, 3)
load 3345  /  3424
size:  (370, 1224, 3)
load 3346  /  3424
size:  (376, 1241, 3)
load 3347  /  3424
size:  (375, 1242, 3)
load 3348  /  3424
size:  (375, 1242, 3)
load 3349  /  3424
size:  (375, 1242, 3)
load 3350  /  3424
size:  (375, 1242, 3)
load 3351  /  3424
size:  (376, 1241, 3)
load 3352  /  3424
size:  (375, 1242, 3)
load 3353  /  3424
size:  (375, 1242, 3)
load 3354  /  3424
size:  (375, 1242, 3)
load 3355  /  3424
size:  (370, 1224, 3)
load 3356  /  3424
size:  (375, 1242, 3)
load 3357  /  3424
size:  (375, 1242, 3)
load 3358  /  3424
size:  (376, 1241, 3)
load 3359  /  3424
size:  (375, 1242, 3)
load 3360  /  3424
size:  (370, 1224, 3)
load 3361  /  3424
size:  (376, 1241, 3)
load 3362  /  3424
size:  (376, 1241, 3)
load 3363  /  3424
size:  (375, 1242, 3)
load 3364  /  3424
size:  (375, 1242, 3)
load 3365  /  3424
size:  (375, 1242, 3)
load 3366  /  3424
size:  (375, 1242, 3)
load 3367  /  3424
size:  (375, 1242, 3)
load 3368  /  3424
size:  (375, 1242, 3)
load 3369  /  3424
size:  (374, 1238, 3)
load 3370  /  3424
size:  (375, 1242, 3)
load 3371  /  3424
size:  (375, 1242, 3)
load 3372  /  3424
size:  (375, 1242, 3)
load 3373  /  3424
size:  (376, 1241, 3)
load 3374  /  3424
size:  (375, 1242, 3)
load 3375  /  3424
size:  (375, 1242, 3)
load 3376  /  3424
size:  (376, 1241, 3)
load 3377  /  3424
size:  (375, 1242, 3)
load 3378  /  3424
size:  (375, 1242, 3)
load 3379  /  3424
size:  (375, 1242, 3)
load 3380  /  3424
size:  (375, 1242, 3)
load 3381  /  3424
size:  (375, 1242, 3)
load 3382  /  3424
size:  (374, 1238, 3)
load 3383  /  3424
size:  (375, 1242, 3)
load 3384  /  3424
size:  (375, 1242, 3)
load 3385  /  3424
size:  (374, 1238, 3)
load 3386  /  3424
size:  (375, 1242, 3)
load 3387  /  3424
size:  (375, 1242, 3)
load 3388  /  3424
size:  (375, 1242, 3)
load 3389  /  3424
size:  (375, 1242, 3)
load 3390  /  3424
size:  (375, 1242, 3)
load 3391  /  3424
size:  (374, 1238, 3)
load 3392  /  3424
size:  (375, 1242, 3)
load 3393  /  3424
size:  (375, 1242, 3)
load 3394  /  3424
size:  (375, 1242, 3)
load 3395  /  3424
size:  (375, 1242, 3)
load 3396  /  3424
size:  (374, 1238, 3)
load 3397  /  3424
size:  (375, 1242, 3)
load 3398  /  3424
size:  (374, 1238, 3)
load 3399  /  3424
size:  (375, 1242, 3)
load 3400  /  3424
size:  (375, 1242, 3)
load 3401  /  3424
size:  (375, 1242, 3)
load 3402  /  3424
size:  (375, 1242, 3)
load 3403  /  3424
size:  (375, 1242, 3)
load 3404  /  3424
size:  (375, 1242, 3)
load 3405  /  3424
size:  (375, 1242, 3)
load 3406  /  3424
size:  (375, 1242, 3)
load 3407  /  3424
size:  (376, 1241, 3)
load 3408  /  3424
size:  (375, 1242, 3)
load 3409  /  3424
size:  (375, 1242, 3)
load 3410  /  3424
size:  (375, 1242, 3)
load 3411  /  3424
size:  (375, 1242, 3)
load 3412  /  3424
size:  (375, 1242, 3)
load 3413  /  3424
size:  (375, 1242, 3)
load 3414  /  3424
size:  (374, 1238, 3)
load 3415  /  3424
size:  (374, 1238, 3)
load 3416  /  3424
size:  (375, 1242, 3)
load 3417  /  3424
size:  (376, 1241, 3)
load 3418  /  3424
size:  (374, 1238, 3)
load 3419  /  3424
size:  (375, 1242, 3)
load 3420  /  3424
size:  (370, 1224, 3)
load 3421  /  3424
size:  (376, 1241, 3)
load 3422  /  3424
size:  (375, 1242, 3)
load 3423  /  3424
size:  (375, 1242, 3)
append flipped images to roidb
752
enter main
set config
load symbol
set gppu
{'ANCHOR_RATIOS': [0.5, 1, 2],
 'ANCHOR_SCALES': [8, 16, 32, 48],
 'EPS': 1e-14,
 'FIXED_PARAMS': ['conv1', 'conv2', 'gamma', 'beta'],
 'FIXED_PARAMS_FINETUNE': ['conv1', 'conv2', 'gamma', 'beta'],
 'IMAGE_STRIDE': 0,
 'INVALID_ORI': -10000,
 'NUM_ANCHORS': 12,
 'NUM_CLASSES': 4,
 'PI': 3.141592653,
 'PIXEL_MEANS': array([[[ 123.68 ,  116.779,  103.939]]]),
 'RCNN_FEAT_SRTIDE': 16,
 'RPN_FEAT_STRIDE': 16,
 'RY_CLASSES': 72,
 'SCALES': [(752, 2500)],
 'TEST': {'BATCH_IMAGES': 1,
          'CXX_PROPOSAL': False,
          'HAS_RPN': False,
          'NMS': 0.3,
          'RPN_MIN_SIZE': 16,
          'RPN_NMS_THRESH': 0.7,
          'RPN_POST_NMS_TOP_N': 300,
          'RPN_PRE_NMS_TOP_N': 6000},
 'TRAIN': {'BATCH_IMAGES': 1,
           'BATCH_ROIS': 128,
           'BATCH_SIZE': 1,
           'BBOX_3D': True,
           'BBOX_INSIDE_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BBOX_MEANS': [0.0, 0.0, 0.0, 0.0],
           'BBOX_NORMALIZATION_PRECOMPUTED': True,
           'BBOX_REGRESSION_THRESH': 0.5,
           'BBOX_STDS': [0.1, 0.1, 0.2, 0.2],
           'BBOX_WEIGHTS': array([ 1.,  1.,  1.,  1.]),
           'BG_THRESH_HI': 0.5,
           'BG_THRESH_LO': 0.0,
           'CXX_PROPOSAL': False,
           'END2END': True,
           'FG_FRACTION': 0.25,
           'FG_THRESH': 0.5,
           'HAS_RPN': False,
           'ORIENTATION': True,
           'ORIENTATION_INSIDE_WEIGHTS': 4,
           'ORIENTATION_WEIGHTS': 4,
           'RPN_BATCH_SIZE': 256,
           'RPN_BBOX_INSIDE_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_BBOX_WEIGHTS': [1.0, 1.0, 1.0, 1.0],
           'RPN_CLOBBER_POSITIVES': False,
           'RPN_FG_FRACTION': 0.5,
           'RPN_MIN_SIZE': 16,
           'RPN_NEGATIVE_OVERLAP': 0.3,
           'RPN_NMS_THRESH': 0.7,
           'RPN_POSITIVE_OVERLAP': 0.7,
           'RPN_POSITIVE_WEIGHT': -1.0,
           'RPN_POST_NMS_TOP_N': 2000,
           'RPN_PRE_NMS_TOP_N': 12000}}
num_images 3424
kitti_val gt roidb loaded from data/cache/kitti_val_gt_roidb.pkl
append flipped images to roidb
752
Traceback (most recent call last):
  File "example/env/train_end2end.py", line 227, in <module>
    lr=args.lr, lr_step=args.lr_step)
  File "example/env/train_end2end.py", line 54, in train_net
    ctx=ctx, work_load_list=args.work_load_list)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 250, in __init__
    self.get_batch()
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/loader.py", line 323, in get_batch
    data, label = minibatch.get_rpn_batch(iroidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 129, in get_rpn_batch
    imgs, roidb = get_image(roidb)
  File "/home/hustxly/Car/Car_Orientation/pre3D/rcnn/core/minibatch.py", line 72, in get_image
    new_rec['gt_dims']   = roi_rec['gt_dims']
KeyError: 'gt_dims'
